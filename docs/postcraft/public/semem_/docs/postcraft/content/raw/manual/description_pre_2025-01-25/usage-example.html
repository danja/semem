<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <meta http-equiv="X-UA-Compatible" content="ie=edge">
        <link rel="stylesheet" href="/css/fonts.css" type="text/css"/>
        <link rel="stylesheet" href="/css/grid-columns.css" type="text/css"/>
        <link rel="stylesheet" href="/css/style.css" type="text/css"/>
        <title>usage-example.js</title>
    </head>
    <!-- POST PAGE TEMPLATE -->
    <body>
        <header id="entry-header">
            <h1 class="post-title h-cinzel">
                
            </h1>
        </header>
        <p> // Import core components
import MemoryManager from &#39;./src/MemoryManager.js&#39;;
import JSONStore from &#39;./src/stores/JSONStore.js&#39;;
import OllamaConnector from &#39;./src/connectors/OllamaConnector.js&#39;;
import Config from &#39;./src/Config.js&#39;;</p>
<p>async function main() {
    // Initialize configuration
    const config = new Config({
        storage: {
            type: &#39;json&#39;,
            options: { path: &#39;memory.json&#39; }
        },
        models: {
            chat: {
                provider: &#39;ollama&#39;,
                model: &#39;llama2&#39;  // Or any other Ollama model
            },
            embedding: {
                provider: &#39;ollama&#39;,
                model: &#39;nomic-embed-text&#39;
            }
        }
    });</p>
<pre><code>// Set up storage and LLM connector
const storage = new JSONStore(config.get(&#39;storage.options.path&#39;));
const llmProvider = new OllamaConnector();

// Initialize the memory manager
const memoryManager = new MemoryManager({
    llmProvider,
    chatModel: config.get(&#39;models.chat.model&#39;),
    embeddingModel: config.get(&#39;models.embedding.model&#39;),
    storage
});

try {
    // Example interaction
    const prompt = &quot;What&#39;s the weather like today?&quot;;
    
    // Retrieve relevant past interactions
    const relevantMemories = await memoryManager.retrieveRelevantInteractions(prompt);
    
    // Generate response using context
    const response = await memoryManager.generateResponse(
        prompt, 
        [], // recent interactions
        relevantMemories
    );

    // Store the interaction
    const embedding = await memoryManager.generateEmbedding(`${prompt} ${response}`);
    const concepts = await memoryManager.extractConcepts(`${prompt} ${response}`);
    await memoryManager.addInteraction(prompt, response, embedding, concepts);

    console.log(&#39;Response:&#39;, response);
} catch (error) {
    console.error(&#39;Error:&#39;, error);
} finally {
    // Clean up
    await memoryManager.dispose();
}
</code></pre>
<p>}</p>
<p>main().catch(console.error);
 </p>

        <div class="entry-footer">
            <h2>About</h2>
            
        </div>
    </body>
</html>