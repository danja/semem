# OLD-DESCRIPTION

================================================================
File Summary
================================================================

Purpose:
--------
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

File Format:
------------
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Multiple file entries, each consisting of:
  a. A separator line (================)
  b. The file path (File: path/to/file)
  c. Another separator line
  d. The full contents of the file
  e. A blank line

Usage Guidelines:
-----------------
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.

Notes:
------
- Some files may have been excluded based on .gitignore rules and Repomix's
  configuration.
- Binary files are not included in this packed representation. Please refer to
  the Repository Structure section for a complete list of file paths, including
  binary files.

Additional Info:
----------------

For more information about Repomix, visit: https://github.com/yamadashy/repomix

================================================================
Directory Structure
================================================================
architecture.md
capabilities.md
concept-system.md
config-guide.md
custom-storage.js
handover-api.ttl
handover-api1.md
memory-dynamics.md
memory-flow.mermaid
retrieval-algorithm.md
semem-repomix-docs-pre_2025-01-13.md
sparql-details.md
system-overview.mermaid
troubleshooting.md
usage-example.js

================================================================
Files
================================================================

================
File: architecture.md
================
# Semem Architecture

## Core Components

### Memory Manager
The central component that orchestrates all memory operations. It handles:
- Interaction storage and retrieval
- Embedding generation and caching
- Concept extraction
- Memory classification

### Storage Layer
Implements a pluggable storage architecture with multiple backends:
- BaseStore: Abstract interface for storage implementations
- InMemoryStore: RAM-based storage for testing
- JSONStore: File-based persistent storage
- SPARQLStore: Semantic triple store integration
- CachedSPARQLStore: Performance-optimized SPARQL storage

### Context Management
Manages conversation context through:
- Window size calculation
- Content overlap handling
- Token counting
- Context pruning

### LLM Integration
Provides abstracted access to language models:
- OllamaConnector: Integration with local Ollama models
- Configurable model selection
- Prompt template management
- Embedding generation

### Memory Processing
Sophisticated memory handling through:
- Vector similarity search
- Semantic clustering
- Concept graph maintenance
- Decay and reinforcement mechanisms

## Data Flow
1. New interactions are processed for embedding generation
2. Concepts are extracted using LLM
3. Memory is stored with metadata
4. Retrieval combines embedding similarity and concept matching
5. Context is managed for optimal interaction

================
File: capabilities.md
================
# Semem Capabilities Overview

Semem is a semantic memory system designed for AI applications that provides persistent, queryable storage of conversations and interactions. It combines embedding-based similarity search with semantic understanding.

## Core Features

### Memory Management
- Short-term and long-term memory storage
- Automatic memory classification and decay
- Concept extraction from interactions
- Semantic clustering of related memories
- Context window management for large conversations

### AI Integration
- Supports multiple LLM providers (Ollama, OpenAI)
- Embedding generation for semantic search
- Configurable models for chat and embeddings
- Prompt template management for different models

### Storage Options
- In-memory storage for testing/development
- JSON file-based persistent storage
- SPARQL-based semantic triple store
- Cached SPARQL store with automatic cleanup

### Advanced Features
- Transaction support with rollback capability
- Backup and recovery mechanisms
- Federation across multiple SPARQL endpoints
- Memory clustering and concept relationships
- Automatic decay and reinforcement of memories

## Configuration
The system is highly configurable, supporting:
- Custom storage backends
- Multiple LLM providers
- Adjustable memory parameters
- SPARQL endpoint configuration
- Context window sizes

================
File: concept-system.md
================
# Concept System Architecture

The concept system in Semem builds a semantic network of related ideas extracted from interactions. This network enhances memory retrieval by understanding conceptual relationships.

## Concept Extraction
The system uses the LLM to extract key concepts through carefully crafted prompts that:
1. Identify main topics and themes
2. Extract entities and relationships
3. Recognize abstract concepts
4. Maintain consistency across extractions

For example, from a weather-related interaction, it might extract:
- weather conditions
- temperature
- location
- time period
- weather patterns

## Graph Building
The system maintains a weighted graph where:
- Nodes represent concepts
- Edges represent co-occurrence relationships
- Edge weights indicate relationship strength
- Node centrality reflects concept importance

Each time concepts are extracted:
1. New concepts become nodes
2. Co-occurring concepts get connected
3. Existing relationships are strengthened
4. Graph metrics are updated

## Spreading Activation
During memory retrieval, the system uses spreading activation to:
1. Start from query concepts
2. Activate connected concepts
3. Decay activation with distance
4. Combine with embedding similarity

This creates a rich semantic network that improves memory retrieval accuracy.

================
File: config-guide.md
================
# Semem Configuration Guide

## Basic Configuration
The configuration system uses a hierarchical structure with sensible defaults that can be overridden.

### Storage Configuration
```javascript
{
    storage: {
        type: 'json',  // 'json', 'memory', or 'sparql'
        options: {
            path: 'memory.json',  // For JSON storage
            // OR for SPARQL:
            graphName: 'http://example.org/memory',
            endpoint: 'http://localhost:4030'
        }
    }
}
```

### Model Configuration
```javascript
{
    models: {
        chat: {
            provider: 'ollama',  // 'ollama' or 'openai'
            model: 'llama2',
            options: {
                temperature: 0.7
            }
        },
        embedding: {
            provider: 'ollama',
            model: 'nomic-embed-text',
            options: {
                dimension: 1536
            }
        }
    }
}
```

### Memory Parameters
```javascript
{
    memory: {
        dimension: 1536,
        similarityThreshold: 40,
        contextWindow: 3,
        decayRate: 0.0001
    }
}
```

### SPARQL Endpoint Configuration
```javascript
{
    sparqlEndpoints: [{
        label: "main",
        user: "admin",
        password: "admin123",
        urlBase: "http://localhost:4030",
        query: "/query",
        update: "/update"
    }]
}
```

## Advanced Options
- Cache configuration for SPARQL store
- Transaction handling settings
- Context window parameters
- Backup and recovery settings

================
File: custom-storage.js
================
// Import the base storage class
import BaseStore from './BaseStore.js';
import { logger } from '../Utils.js';

export default class CustomStore extends BaseStore {
    constructor(options = {}) {
        super();
        // Initialize your custom storage
        this.options = options;
        this.connected = false;
        this.inTransaction = false;
    }

    // Required: Load both short-term and long-term memories
    async loadHistory() {
        try {
            // Implement your loading logic
            const shortTerm = await this.loadShortTermMemories();
            const longTerm = await this.loadLongTermMemories();

            // Return as tuple: [shortTerm, longTerm]
            return [shortTerm, longTerm];
        } catch (error) {
            logger.error('Error loading history:', error);
            throw error;
        }
    }

    // Required: Save the complete memory store
    async saveMemoryToHistory(memoryStore) {
        try {
            // Start transaction if supported
            await this.beginTransaction();

            // Save short-term memories
            await this.saveMemories(
                memoryStore.shortTermMemory,
                'short-term'
            );

            // Save long-term memories
            await this.saveMemories(
                memoryStore.longTermMemory,
                'long-term'
            );

            // Commit changes
            await this.commitTransaction();
        } catch (error) {
            // Rollback on error
            await this.rollbackTransaction();
            throw error;
        }
    }

    // Optional: Transaction support
    async beginTransaction() {
        if (this.inTransaction) {
            throw new Error('Transaction already in progress');
        }
        this.inTransaction = true;
        // Implement transaction start logic
    }

    async commitTransaction() {
        if (!this.inTransaction) {
            throw new Error('No transaction in progress');
        }
        // Implement commit logic
        this.inTransaction = false;
    }

    async rollbackTransaction() {
        if (!this.inTransaction) {
            throw new Error('No transaction in progress');
        }
        // Implement rollback logic
        this.inTransaction = false;
    }

    // Optional: Storage health check
    async verify() {
        try {
            // Implement verification logic
            return true;
        } catch {
            return false;
        }
    }

    // Required: Cleanup resources
    async close() {
        if (this.inTransaction) {
            await this.rollbackTransaction();
        }
        // Implement cleanup logic
    }
}

================
File: handover-api.ttl
================
@prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .
@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .
@prefix owl: <http://www.w3.org/2002/07/owl#> .
@prefix xsd: <http://www.w3.org/2001/XMLSchema#> .
@prefix doap: <http://usefulinc.com/ns/doap#> .
@prefix dc: <http://purl.org/dc/terms/> .
@prefix foaf: <http://xmlns.com/foaf/0.1/> .
@prefix prj: <http://example.org/project/> .

# Project Description
prj:SememAPI a doap:Project ;
    dc:title "Semem API Implementation"@en ;
    dc:description "API layer for Semantic Memory System with multiple access modes"@en ;
    dc:created "2025-01-13"^^xsd:date ;
    doap:programming-language "JavaScript" ;
    doap:repository [
        a doap:GitRepository ;
        doap:location <https://github.com/organization/semem>
    ] .

# Core Components
prj:CoreComponents a prj:ComponentSet ;
    rdfs:label "Core API Components"@en ;
    prj:includes
        prj:BaseAPI,
        prj:APIRegistry,
        prj:RDFParser,
        prj:RDFValidator .

prj:BaseAPI a prj:Component ;
    rdfs:label "Base API"@en ;
    dc:description "Abstract base interface for all API implementations"@en ;
    prj:sourceFile "src/api/common/BaseAPI.js" ;
    prj:features (
        "Lifecycle management"
        "Event emission"
        "Error handling"
        "Metric collection"
    ) .

prj:APIRegistry a prj:Component ;
    rdfs:label "API Registry"@en ;
    dc:description "Central registry for API service discovery"@en ;
    prj:sourceFile "src/api/common/APIRegistry.js" ;
    prj:features (
        "Service registration"
        "Instance management"
        "Configuration"
        "Metrics aggregation"
    ) .

# Access Modes
prj:AccessModes a prj:ComponentSet ;
    rdfs:label "Access Modes"@en ;
    prj:includes
        prj:CLIHandler,
        prj:REPLHandler,
        prj:HTTPServer,
        prj:WebForms,
        prj:RDFParser .

prj:CLIHandler a prj:Component ;
    rdfs:label "CLI Handler"@en ;
    dc:description "Command line interface implementation"@en ;
    prj:sourceFile "src/api/cli/CLIHandler.js" ;
    prj:dependencies (
        "yargs"
        "chalk"
    ) ;
    prj:features (
        "Command parsing"
        "Colorized output"
        "History management"
    ) .

# Feature Sets
prj:FeatureSets a prj:ComponentSet ;
    rdfs:label "Feature Sets"@en ;
    prj:includes
        prj:SelfieHandler,
        prj:PassiveHandler,
        prj:ActiveHandler .

prj:SelfieHandler a prj:Component ;
    rdfs:label "Selfie Handler"@en ;
    dc:description "System monitoring and metrics"@en ;
    prj:sourceFile "src/api/features/SelfieHandler.js" ;
    prj:features (
        "Metric collection"
        "Performance monitoring"
        "Error tracking"
        "OpenTelemetry integration"
    ) .

# Data Validation
prj:Validation a prj:ComponentSet ;
    rdfs:label "Data Validation"@en ;
    prj:includes
        prj:RDFValidator,
        prj:CustomValidators .

prj:RDFValidator a prj:Component ;
    rdfs:label "RDF Validator"@en ;
    dc:description "RDF schema and SHACL validation"@en ;
    prj:sourceFile "src/api/common/RDFValidator.js" ;
    prj:features (
        "Schema validation"
        "SHACL support"
        "Error reporting"
        "Shape management"
    ) .

# Development Notes
prj:DevelopmentNotes a prj:Documentation ;
    rdfs:label "Development Notes"@en ;
    prj:shortTerm (
        "Complete WebSocket implementation"
        "Add visualization components"
        "Enhance RDF validation"
        "Improve error handling"
        "Add test coverage"
    ) ;
    prj:mediumTerm (
        "Add federation support"
        "Implement caching improvements"
        "Enhance monitoring"
        "Add backup systems"
    ) ;
    prj:longTerm (
        "Add graph visualization"
        "Implement distributed storage"
        "Add machine learning features"
    ) .

# Critical Notes
prj:CriticalNotes a prj:Documentation ;
    rdfs:label "Critical Implementation Notes"@en ;
    prj:notes (
        "Always use transactions for storage"
        "Monitor API rate limits"
        "Keep secret management secure"
        "Regular metric collection"
        "Proper error handling"
    ) .

# Dependencies
prj:Dependencies a prj:Requirements ;
    rdfs:label "Project Dependencies"@en ;
    prj:runtime (
        "Node.js 18+"
        "Express"
        "yargs"
        "chalk"
        "dotenv"
        "loglevel"
    ) ;
    prj:development (
        "Jasmine"
        "nodemon"
        "eslint"
    ) .

================
File: handover-api1.md
================
# Semem API Implementation Handover

## Overview
Implementation of an API layer for Semem (Semantic Memory) system with multiple access modes and comprehensive monitoring. Follows modular architecture with clear separation of concerns.

## Core Components

### Base API Layer
- `BaseAPI`: Abstract interface for API implementations
- `APIRegistry`: Central service discovery and management
- Event emission for monitoring
- Lifecycle management (initialize/shutdown)

### Access Modes
1. **Command Line Interface (CLI)**
   - Entry point: `src/api/cli/run.js`
   - Uses yargs for command parsing
   - Colorized output with chalk
   - Command history support

2. **REPL Environment**
   - Interactive shell with chat/RDF modes
   - Command completion
   - Help system
   - History management

3. **HTTP REST API**
   - Express-based server
   - OpenAPI documentation
   - Rate limiting
   - Compression and security middleware
   - CORS support

4. **Web Forms**
   - Static HTML/CSS/JS interface
   - No framework dependencies
   - Real-time API integration
   - Responsive design

5. **RDF DSL**
   - Custom semantic query language
   - SPARQL generation
   - Prefix management
   - Transaction support

## Feature Sets

### Selfie (Monitoring)
- Metric collection and aggregation
- OpenTelemetry integration
- Error tracking and reporting
- Storage metrics
- API performance monitoring

### Passive (Storage)
- SPARQL endpoint integration
- Caching layer
- Transaction support
- Batch operations
- Query federation

### Active (End-User)
- Chat interface
- Semantic search
- Memory retrieval
- Concept mapping
- Context management

## Data Validation
- RDF schema validation
- SHACL constraint support
- Custom validation functions
- Shape management
- Error reporting

## Configuration
- Environment-based config
- Secure secret management
- Override support
- Runtime reconfiguration

## Dependencies
- Node.js 18+
- Express for HTTP
- yargs for CLI
- chalk for terminal output
- dotenv for secrets
- loglevel for logging

## Testing
- Unit tests with Jasmine
- Integration tests for endpoints
- SPARQL testing utilities
- Mock data generators
- Performance testing

## Security
- API key authentication
- Rate limiting
- Input validation
- CORS configuration
- Error sanitization

## Future Development

### Short Term
1. Complete WebSocket implementation
2. Add visualization components
3. Enhance RDF validation
4. Improve error handling
5. Add more test coverage

### Medium Term
1. Add federation support
2. Implement caching improvements
3. Enhance monitoring
4. Add backup systems
5. Improve documentation

### Long Term
1. Add graph visualization
2. Implement distributed storage
3. Add machine learning features
4. Create management interface
5. Add workflow automation

## Critical Notes
1. Always use transactions for storage operations
2. Monitor API rate limits
3. Keep secret management secure
4. Regular metric collection
5. Proper error handling

## Support
- Source: src/api/
- Tests: spec/
- Documentation: docs/
- Issues: GitHub repository

================
File: memory-dynamics.md
================
# Memory Dynamics in Semem

The memory system in Semem mimics human memory by implementing both decay and reinforcement mechanisms. This creates a dynamic system where frequently accessed, relevant memories remain readily available while less useful ones gradually fade.

## Decay Mechanism
Memories in Semem decay over time following an exponential decay function:

decayFactor = baseDecay * Math.exp(-decayRate * timeDiff)

Where:
- baseDecay starts at 1.0 for new memories
- decayRate is configurable (default 0.0001)
- timeDiff is the time since last access in seconds

This creates a natural forgetting curve where older memories become progressively less influential in retrieval unless reinforced.

## Reinforcement System
Every time a memory is accessed during retrieval:
1. Its accessCount increments
2. The timestamp updates to current time
3. The decayFactor increases by 10% (multiplied by 1.1)
4. A reinforcement boost is calculated as log(accessCount + 1)

This creates a rich-get-richer dynamic where useful memories become more likely to be retrieved again.

## Memory Classification
Memories that exceed an access threshold (default 10 accesses) get promoted to long-term memory. This creates two tiers:
- Short-term: Recent or infrequently accessed memories
- Long-term: Frequently accessed, well-established memories

The system maintains balance through regular cleanup cycles that assess and adjust memory status based on these dynamics.

================
File: memory-flow.mermaid
================
sequenceDiagram
    participant U as User
    participant MM as MemoryManager
    participant LLM as LLM Provider
    participant S as Storage

    U->>MM: New Interaction
    MM->>LLM: Generate Embedding
    MM->>LLM: Extract Concepts

    MM->>MM: Process Memory
    Note over MM: Classify Memory<br/>Update Concepts Graph<br/>Calculate Decay

    MM->>S: Store Memory

    U->>MM: Query Memory
    MM->>S: Retrieve Similar
    MM->>MM: Apply Context
    MM->>U: Return Response

================
File: retrieval-algorithm.md
================
# Memory Retrieval Algorithm

The retrieval system uses a sophisticated multi-stage approach:

1. **Vector Similarity**
   - Generates embedding for query
   - Performs cosine similarity comparison
   - Applies decay factor based on time
   - Considers access count reinforcement

2. **Concept Matching**
   - Extracts concepts from query
   - Activates related concepts in graph
   - Uses spreading activation for concept relationships
   - Combines with vector similarity scores

3. **Semantic Clustering**
   - Groups related memories
   - Maintains cluster centroids
   - Updates clusters dynamically
   - Provides fallback recommendations

4. **Context Building**
   - Selects most relevant memories
   - Manages context window size
   - Handles content overlap
   - Builds coherent context for LLM

The final relevance score is calculated as:
```
relevance = (similarity * decay * reinforcement) + conceptScore
```

Where:
- similarity: cosine similarity between embeddings
- decay: exponential decay based on time
- reinforcement: logarithmic function of access count
- conceptScore: spreading activation score from concept graph

================
File: semem-repomix-docs-pre_2025-01-13.md
================
This file contains an earlier summary of semem. Many descriptions should still be valid, but a lot has been added since. The code in project knowledge should be used as the primary reference.

This material has been taken from the following docs:

architecture.md
capabilities.md
concept-system.md
config-guide.md
custom-storage.js
handover-api.ttl
handover-api1.md
memory-dynamics.md
memory-flow.mermaid
retrieval-algorithm.md
sparql-details.md
system-overview.mermaid
troubleshooting.md
usage-example.js

================================================================
Files
================================================================

================
File: architecture.md
================
# Semem Architecture

## Core Components

### Memory Manager
The central component that orchestrates all memory operations. It handles:
- Interaction storage and retrieval
- Embedding generation and caching
- Concept extraction
- Memory classification

### Storage Layer
Implements a pluggable storage architecture with multiple backends:
- BaseStore: Abstract interface for storage implementations
- InMemoryStore: RAM-based storage for testing
- JSONStore: File-based persistent storage
- SPARQLStore: Semantic triple store integration
- CachedSPARQLStore: Performance-optimized SPARQL storage

### Context Management
Manages conversation context through:
- Window size calculation
- Content overlap handling
- Token counting
- Context pruning

### LLM Integration
Provides abstracted access to language models:
- OllamaConnector: Integration with local Ollama models
- Configurable model selection
- Prompt template management
- Embedding generation

### Memory Processing
Sophisticated memory handling through:
- Vector similarity search
- Semantic clustering
- Concept graph maintenance
- Decay and reinforcement mechanisms

## Data Flow
1. New interactions are processed for embedding generation
2. Concepts are extracted using LLM
3. Memory is stored with metadata
4. Retrieval combines embedding similarity and concept matching
5. Context is managed for optimal interaction

================
File: capabilities.md
================
# Semem Capabilities Overview

Semem is a semantic memory system designed for AI applications that provides persistent, queryable storage of conversations and interactions. It combines embedding-based similarity search with semantic understanding.

## Core Features

### Memory Management
- Short-term and long-term memory storage
- Automatic memory classification and decay
- Concept extraction from interactions
- Semantic clustering of related memories
- Context window management for large conversations

### AI Integration
- Supports multiple LLM providers (Ollama, OpenAI)
- Embedding generation for semantic search
- Configurable models for chat and embeddings
- Prompt template management for different models

### Storage Options
- In-memory storage for testing/development
- JSON file-based persistent storage
- SPARQL-based semantic triple store
- Cached SPARQL store with automatic cleanup

### Advanced Features
- Transaction support with rollback capability
- Backup and recovery mechanisms
- Federation across multiple SPARQL endpoints
- Memory clustering and concept relationships
- Automatic decay and reinforcement of memories

## Configuration
The system is highly configurable, supporting:
- Custom storage backends
- Multiple LLM providers
- Adjustable memory parameters
- SPARQL endpoint configuration
- Context window sizes

================
File: concept-system.md
================
# Concept System Architecture

The concept system in Semem builds a semantic network of related ideas extracted from interactions. This network enhances memory retrieval by understanding conceptual relationships.

## Concept Extraction
The system uses the LLM to extract key concepts through carefully crafted prompts that:
1. Identify main topics and themes
2. Extract entities and relationships
3. Recognize abstract concepts
4. Maintain consistency across extractions

For example, from a weather-related interaction, it might extract:
- weather conditions
- temperature
- location
- time period
- weather patterns

## Graph Building
The system maintains a weighted graph where:
- Nodes represent concepts
- Edges represent co-occurrence relationships
- Edge weights indicate relationship strength
- Node centrality reflects concept importance

Each time concepts are extracted:
1. New concepts become nodes
2. Co-occurring concepts get connected
3. Existing relationships are strengthened
4. Graph metrics are updated

## Spreading Activation
During memory retrieval, the system uses spreading activation to:
1. Start from query concepts
2. Activate connected concepts
3. Decay activation with distance
4. Combine with embedding similarity

This creates a rich semantic network that improves memory retrieval accuracy.

================
File: config-guide.md
================
# Semem Configuration Guide

## Basic Configuration
The configuration system uses a hierarchical structure with sensible defaults that can be overridden.

### Storage Configuration
```javascript
{
    storage: {
        type: 'json',  // 'json', 'memory', or 'sparql'
        options: {
            path: 'memory.json',  // For JSON storage
            // OR for SPARQL:
            graphName: 'http://example.org/memory',
            endpoint: 'http://localhost:4030'
        }
    }
}
```

### Model Configuration
```javascript
{
    models: {
        chat: {
            provider: 'ollama',  // 'ollama' or 'openai'
            model: 'llama2',
            options: {
                temperature: 0.7
            }
        },
        embedding: {
            provider: 'ollama',
            model: 'nomic-embed-text',
            options: {
                dimension: 1536
            }
        }
    }
}
```

### Memory Parameters
```javascript
{
    memory: {
        dimension: 1536,
        similarityThreshold: 40,
        contextWindow: 3,
        decayRate: 0.0001
    }
}
```

### SPARQL Endpoint Configuration
```javascript
{
    sparqlEndpoints: [{
        label: "main",
        user: "admin",
        password: "admin123",
        urlBase: "http://localhost:4030",
        query: "/query",
        update: "/update"
    }]
}
```

## Advanced Options
- Cache configuration for SPARQL store
- Transaction handling settings
- Context window parameters
- Backup and recovery settings

================
File: custom-storage.js
================
// Import the base storage class
import BaseStore from './BaseStore.js';
import { logger } from '../Utils.js';

export default class CustomStore extends BaseStore {
    constructor(options = {}) {
        super();
        // Initialize your custom storage
        this.options = options;
        this.connected = false;
        this.inTransaction = false;
    }

    // Required: Load both short-term and long-term memories
    async loadHistory() {
        try {
            // Implement your loading logic
            const shortTerm = await this.loadShortTermMemories();
            const longTerm = await this.loadLongTermMemories();

            // Return as tuple: [shortTerm, longTerm]
            return [shortTerm, longTerm];
        } catch (error) {
            logger.error('Error loading history:', error);
            throw error;
        }
    }

    // Required: Save the complete memory store
    async saveMemoryToHistory(memoryStore) {
        try {
            // Start transaction if supported
            await this.beginTransaction();

            // Save short-term memories
            await this.saveMemories(
                memoryStore.shortTermMemory,
                'short-term'
            );

            // Save long-term memories
            await this.saveMemories(
                memoryStore.longTermMemory,
                'long-term'
            );

            // Commit changes
            await this.commitTransaction();
        } catch (error) {
            // Rollback on error
            await this.rollbackTransaction();
            throw error;
        }
    }

    // Optional: Transaction support
    async beginTransaction() {
        if (this.inTransaction) {
            throw new Error('Transaction already in progress');
        }
        this.inTransaction = true;
        // Implement transaction start logic
    }

    async commitTransaction() {
        if (!this.inTransaction) {
            throw new Error('No transaction in progress');
        }
        // Implement commit logic
        this.inTransaction = false;
    }

    async rollbackTransaction() {
        if (!this.inTransaction) {
            throw new Error('No transaction in progress');
        }
        // Implement rollback logic
        this.inTransaction = false;
    }

    // Optional: Storage health check
    async verify() {
        try {
            // Implement verification logic
            return true;
        } catch {
            return false;
        }
    }

    // Required: Cleanup resources
    async close() {
        if (this.inTransaction) {
            await this.rollbackTransaction();
        }
        // Implement cleanup logic
    }
}

================
File: handover-api.ttl
================
@prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .
@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .
@prefix owl: <http://www.w3.org/2002/07/owl#> .
@prefix xsd: <http://www.w3.org/2001/XMLSchema#> .
@prefix doap: <http://usefulinc.com/ns/doap#> .
@prefix dc: <http://purl.org/dc/terms/> .
@prefix foaf: <http://xmlns.com/foaf/0.1/> .
@prefix prj: <http://example.org/project/> .

# Project Description
prj:SememAPI a doap:Project ;
    dc:title "Semem API Implementation"@en ;
    dc:description "API layer for Semantic Memory System with multiple access modes"@en ;
    dc:created "2025-01-13"^^xsd:date ;
    doap:programming-language "JavaScript" ;
    doap:repository [
        a doap:GitRepository ;
        doap:location <https://github.com/organization/semem>
    ] .

# Core Components
prj:CoreComponents a prj:ComponentSet ;
    rdfs:label "Core API Components"@en ;
    prj:includes
        prj:BaseAPI,
        prj:APIRegistry,
        prj:RDFParser,
        prj:RDFValidator .

prj:BaseAPI a prj:Component ;
    rdfs:label "Base API"@en ;
    dc:description "Abstract base interface for all API implementations"@en ;
    prj:sourceFile "src/api/common/BaseAPI.js" ;
    prj:features (
        "Lifecycle management"
        "Event emission"
        "Error handling"
        "Metric collection"
    ) .

prj:APIRegistry a prj:Component ;
    rdfs:label "API Registry"@en ;
    dc:description "Central registry for API service discovery"@en ;
    prj:sourceFile "src/api/common/APIRegistry.js" ;
    prj:features (
        "Service registration"
        "Instance management"
        "Configuration"
        "Metrics aggregation"
    ) .

# Access Modes
prj:AccessModes a prj:ComponentSet ;
    rdfs:label "Access Modes"@en ;
    prj:includes
        prj:CLIHandler,
        prj:REPLHandler,
        prj:HTTPServer,
        prj:WebForms,
        prj:RDFParser .

prj:CLIHandler a prj:Component ;
    rdfs:label "CLI Handler"@en ;
    dc:description "Command line interface implementation"@en ;
    prj:sourceFile "src/api/cli/CLIHandler.js" ;
    prj:dependencies (
        "yargs"
        "chalk"
    ) ;
    prj:features (
        "Command parsing"
        "Colorized output"
        "History management"
    ) .

# Feature Sets
prj:FeatureSets a prj:ComponentSet ;
    rdfs:label "Feature Sets"@en ;
    prj:includes
        prj:SelfieHandler,
        prj:PassiveHandler,
        prj:ActiveHandler .

prj:SelfieHandler a prj:Component ;
    rdfs:label "Selfie Handler"@en ;
    dc:description "System monitoring and metrics"@en ;
    prj:sourceFile "src/api/features/SelfieHandler.js" ;
    prj:features (
        "Metric collection"
        "Performance monitoring"
        "Error tracking"
        "OpenTelemetry integration"
    ) .

# Data Validation
prj:Validation a prj:ComponentSet ;
    rdfs:label "Data Validation"@en ;
    prj:includes
        prj:RDFValidator,
        prj:CustomValidators .

prj:RDFValidator a prj:Component ;
    rdfs:label "RDF Validator"@en ;
    dc:description "RDF schema and SHACL validation"@en ;
    prj:sourceFile "src/api/common/RDFValidator.js" ;
    prj:features (
        "Schema validation"
        "SHACL support"
        "Error reporting"
        "Shape management"
    ) .

# Development Notes
prj:DevelopmentNotes a prj:Documentation ;
    rdfs:label "Development Notes"@en ;
    prj:shortTerm (
        "Complete WebSocket implementation"
        "Add visualization components"
        "Enhance RDF validation"
        "Improve error handling"
        "Add test coverage"
    ) ;
    prj:mediumTerm (
        "Add federation support"
        "Implement caching improvements"
        "Enhance monitoring"
        "Add backup systems"
    ) ;
    prj:longTerm (
        "Add graph visualization"
        "Implement distributed storage"
        "Add machine learning features"
    ) .

# Critical Notes
prj:CriticalNotes a prj:Documentation ;
    rdfs:label "Critical Implementation Notes"@en ;
    prj:notes (
        "Always use transactions for storage"
        "Monitor API rate limits"
        "Keep secret management secure"
        "Regular metric collection"
        "Proper error handling"
    ) .

# Dependencies
prj:Dependencies a prj:Requirements ;
    rdfs:label "Project Dependencies"@en ;
    prj:runtime (
        "Node.js 18+"
        "Express"
        "yargs"
        "chalk"
        "dotenv"
        "loglevel"
    ) ;
    prj:development (
        "Jasmine"
        "nodemon"
        "eslint"
    ) .

================
File: handover-api1.md
================
# Semem API Implementation Handover

## Overview
Implementation of an API layer for Semem (Semantic Memory) system with multiple access modes and comprehensive monitoring. Follows modular architecture with clear separation of concerns.

## Core Components

### Base API Layer
- `BaseAPI`: Abstract interface for API implementations
- `APIRegistry`: Central service discovery and management
- Event emission for monitoring
- Lifecycle management (initialize/shutdown)

### Access Modes
1. **Command Line Interface (CLI)**
   - Entry point: `src/api/cli/run.js`
   - Uses yargs for command parsing
   - Colorized output with chalk
   - Command history support

2. **REPL Environment**
   - Interactive shell with chat/RDF modes
   - Command completion
   - Help system
   - History management

3. **HTTP REST API**
   - Express-based server
   - OpenAPI documentation
   - Rate limiting
   - Compression and security middleware
   - CORS support

4. **Web Forms**
   - Static HTML/CSS/JS interface
   - No framework dependencies
   - Real-time API integration
   - Responsive design

5. **RDF DSL**
   - Custom semantic query language
   - SPARQL generation
   - Prefix management
   - Transaction support

## Feature Sets

### Selfie (Monitoring)
- Metric collection and aggregation
- OpenTelemetry integration
- Error tracking and reporting
- Storage metrics
- API performance monitoring

### Passive (Storage)
- SPARQL endpoint integration
- Caching layer
- Transaction support
- Batch operations
- Query federation

### Active (End-User)
- Chat interface
- Semantic search
- Memory retrieval
- Concept mapping
- Context management

## Data Validation
- RDF schema validation
- SHACL constraint support
- Custom validation functions
- Shape management
- Error reporting

## Configuration
- Environment-based config
- Secure secret management
- Override support
- Runtime reconfiguration

## Dependencies
- Node.js 18+
- Express for HTTP
- yargs for CLI
- chalk for terminal output
- dotenv for secrets
- loglevel for logging

## Testing
- Unit tests with Jasmine
- Integration tests for endpoints
- SPARQL testing utilities
- Mock data generators
- Performance testing

## Security
- API key authentication
- Rate limiting
- Input validation
- CORS configuration
- Error sanitization

## Future Development

### Short Term
1. Complete WebSocket implementation
2. Add visualization components
3. Enhance RDF validation
4. Improve error handling
5. Add more test coverage

### Medium Term
1. Add federation support
2. Implement caching improvements
3. Enhance monitoring
4. Add backup systems
5. Improve documentation

### Long Term
1. Add graph visualization
2. Implement distributed storage
3. Add machine learning features
4. Create management interface
5. Add workflow automation

## Critical Notes
1. Always use transactions for storage operations
2. Monitor API rate limits
3. Keep secret management secure
4. Regular metric collection
5. Proper error handling

## Support
- Source: src/api/
- Tests: spec/
- Documentation: docs/
- Issues: GitHub repository

================
File: memory-dynamics.md
================
# Memory Dynamics in Semem

The memory system in Semem mimics human memory by implementing both decay and reinforcement mechanisms. This creates a dynamic system where frequently accessed, relevant memories remain readily available while less useful ones gradually fade.

## Decay Mechanism
Memories in Semem decay over time following an exponential decay function:

decayFactor = baseDecay * Math.exp(-decayRate * timeDiff)

Where:
- baseDecay starts at 1.0 for new memories
- decayRate is configurable (default 0.0001)
- timeDiff is the time since last access in seconds

This creates a natural forgetting curve where older memories become progressively less influential in retrieval unless reinforced.

## Reinforcement System
Every time a memory is accessed during retrieval:
1. Its accessCount increments
2. The timestamp updates to current time
3. The decayFactor increases by 10% (multiplied by 1.1)
4. A reinforcement boost is calculated as log(accessCount + 1)

This creates a rich-get-richer dynamic where useful memories become more likely to be retrieved again.

## Memory Classification
Memories that exceed an access threshold (default 10 accesses) get promoted to long-term memory. This creates two tiers:
- Short-term: Recent or infrequently accessed memories
- Long-term: Frequently accessed, well-established memories

The system maintains balance through regular cleanup cycles that assess and adjust memory status based on these dynamics.

================
File: memory-flow.mermaid
================
sequenceDiagram
    participant U as User
    participant MM as MemoryManager
    participant LLM as LLM Provider
    participant S as Storage

    U->>MM: New Interaction
    MM->>LLM: Generate Embedding
    MM->>LLM: Extract Concepts

    MM->>MM: Process Memory
    Note over MM: Classify Memory<br/>Update Concepts Graph<br/>Calculate Decay

    MM->>S: Store Memory

    U->>MM: Query Memory
    MM->>S: Retrieve Similar
    MM->>MM: Apply Context
    MM->>U: Return Response

================
File: retrieval-algorithm.md
================
# Memory Retrieval Algorithm

The retrieval system uses a sophisticated multi-stage approach:

1. **Vector Similarity**
   - Generates embedding for query
   - Performs cosine similarity comparison
   - Applies decay factor based on time
   - Considers access count reinforcement

2. **Concept Matching**
   - Extracts concepts from query
   - Activates related concepts in graph
   - Uses spreading activation for concept relationships
   - Combines with vector similarity scores

3. **Semantic Clustering**
   - Groups related memories
   - Maintains cluster centroids
   - Updates clusters dynamically
   - Provides fallback recommendations

4. **Context Building**
   - Selects most relevant memories
   - Manages context window size
   - Handles content overlap
   - Builds coherent context for LLM

The final relevance score is calculated as:
```
relevance = (similarity * decay * reinforcement) + conceptScore
```

Where:
- similarity: cosine similarity between embeddings
- decay: exponential decay based on time
- reinforcement: logarithmic function of access count
- conceptScore: spreading activation score from concept graph

================
File: sparql-details.md
================
# SPARQL Integration in Semem

The SPARQL integration in Semem provides a sophisticated semantic storage layer that enables rich querying and knowledge graph capabilities. The system uses a carefully designed RDF schema to represent memories and their relationships.

## Core Schema
Memories are stored using a custom vocabulary:
```turtle
@prefix mcp: <http://purl.org/stuff/mcp/>

mcp:Interaction
    a rdfs:Class ;
    rdfs:label "Memory Interaction" .

mcp:embedding
    a rdf:Property ;
    rdfs:domain mcp:Interaction ;
    rdfs:range xsd:string .
```

## Transaction Management
The SPARQLStore implements ACID transactions through:
1. Automatic backup creation before transactions
2. Graph-level locking for concurrent access
3. Rollback capability using backup graphs
4. Transaction isolation through separate graph contexts

## Caching Layer
The CachedSPARQLStore extends functionality with:
1. In-memory query result caching
2. Automatic cache invalidation on updates
3. Time-based cache expiration
4. Size-limited LRU caching strategy

## Federation Support
The system supports federated queries across multiple endpoints, enabling:
1. Distributed memory storage
2. Cross-graph concept relationships
3. Metadata management in separate graphs
4. Scalable memory organization

================
File: system-overview.mermaid
================
graph TB
    User[User/Application] --> MM[Memory Manager]

    subgraph Core["Core Components"]
        MM --> CM[Context Manager]
        MM --> Vector[Vector Store]
        MM --> Concepts[Concept Extractor]
    end

    subgraph Storage["Storage Layer"]
        MM --> InMem[In-Memory Store]
        MM --> JSON[JSON Store]
        MM --> SPARQL[SPARQL Store]
    end

    subgraph AI["AI Integration"]
        MM --> Ollama[Ollama]
        MM --> OpenAI[OpenAI]
        Ollama --> Embed[Embedding Models]
        Ollama --> Chat[Chat Models]
        OpenAI --> Embed
        OpenAI --> Chat
    end

================
File: troubleshooting.md
================
# Troubleshooting Guide

## Common Issues and Solutions

### Embedding Generation
- Error: "Embedding dimension mismatch"
  - Verify model configuration
  - Check embedding model availability
  - Ensure consistent dimensions across storage

### Storage Issues
- SPARQL Connection Failures
  - Verify endpoint configuration
  - Check authentication credentials
  - Confirm graph exists and permissions

### Memory Management
- High Memory Usage
  - Adjust cache size settings
  - Enable automatic cleanup
  - Use appropriate storage backend

### Performance
- Slow Retrieval
  - Enable caching for SPARQL
  - Optimize similarity threshold
  - Adjust context window size

### Integration
- LLM Provider Issues
  - Verify Ollama/OpenAI setup
  - Check API credentials
  - Confirm model availability

## Debugging Steps
1. Enable debug logging
2. Check configuration
3. Verify storage health
4. Test LLM connectivity
5. Validate embeddings
6. Monitor memory usage

================
File: usage-example.js
================
// Import core components
import MemoryManager from './src/MemoryManager.js';
import JSONStore from './src/stores/JSONStore.js';
import OllamaConnector from './src/connectors/OllamaConnector.js';
import Config from './src/Config.js';

async function main() {
    // Initialize configuration
    const config = new Config({
        storage: {
            type: 'json',
            options: { path: 'memory.json' }
        },
        models: {
            chat: {
                provider: 'ollama',
                model: 'llama2'  // Or any other Ollama model
            },
            embedding: {
                provider: 'ollama',
                model: 'nomic-embed-text'
            }
        }
    });

    // Set up storage and LLM connector
    const storage = new JSONStore(config.get('storage.options.path'));
    const llmProvider = new OllamaConnector();

    // Initialize the memory manager
    const memoryManager = new MemoryManager({
        llmProvider,
        chatModel: config.get('models.chat.model'),
        embeddingModel: config.get('models.embedding.model'),
        storage
    });

    try {
        // Example interaction
        const prompt = "What's the weather like today?";

        // Retrieve relevant past interactions
        const relevantMemories = await memoryManager.retrieveRelevantInteractions(prompt);

        // Generate response using context
        const response = await memoryManager.generateResponse(
            prompt,
            [], // recent interactions
            relevantMemories
        );

        // Store the interaction
        const embedding = await memoryManager.generateEmbedding(`${prompt} ${response}`);
        const concepts = await memoryManager.extractConcepts(`${prompt} ${response}`);
        await memoryManager.addInteraction(prompt, response, embedding, concepts);

        console.log('Response:', response);
    } catch (error) {
        console.error('Error:', error);
    } finally {
        // Clean up
        await memoryManager.dispose();
    }
}

main().catch(console.error);

================
File: sparql-details.md
================
# SPARQL Integration in Semem

The SPARQL integration in Semem provides a sophisticated semantic storage layer that enables rich querying and knowledge graph capabilities. The system uses a carefully designed RDF schema to represent memories and their relationships.

## Core Schema
Memories are stored using a custom vocabulary:
```turtle
@prefix mcp: <http://purl.org/stuff/mcp/>

mcp:Interaction
    a rdfs:Class ;
    rdfs:label "Memory Interaction" .

mcp:embedding
    a rdf:Property ;
    rdfs:domain mcp:Interaction ;
    rdfs:range xsd:string .
```

## Transaction Management
The SPARQLStore implements ACID transactions through:
1. Automatic backup creation before transactions
2. Graph-level locking for concurrent access
3. Rollback capability using backup graphs
4. Transaction isolation through separate graph contexts

## Caching Layer
The CachedSPARQLStore extends functionality with:
1. In-memory query result caching
2. Automatic cache invalidation on updates
3. Time-based cache expiration
4. Size-limited LRU caching strategy

## Federation Support
The system supports federated queries across multiple endpoints, enabling:
1. Distributed memory storage
2. Cross-graph concept relationships
3. Metadata management in separate graphs
4. Scalable memory organization

================
File: system-overview.mermaid
================
graph TB
    User[User/Application] --> MM[Memory Manager]

    subgraph Core["Core Components"]
        MM --> CM[Context Manager]
        MM --> Vector[Vector Store]
        MM --> Concepts[Concept Extractor]
    end

    subgraph Storage["Storage Layer"]
        MM --> InMem[In-Memory Store]
        MM --> JSON[JSON Store]
        MM --> SPARQL[SPARQL Store]
    end

    subgraph AI["AI Integration"]
        MM --> Ollama[Ollama]
        MM --> OpenAI[OpenAI]
        Ollama --> Embed[Embedding Models]
        Ollama --> Chat[Chat Models]
        OpenAI --> Embed
        OpenAI --> Chat
    end

================
File: troubleshooting.md
================
# Troubleshooting Guide

## Common Issues and Solutions

### Embedding Generation
- Error: "Embedding dimension mismatch"
  - Verify model configuration
  - Check embedding model availability
  - Ensure consistent dimensions across storage

### Storage Issues
- SPARQL Connection Failures
  - Verify endpoint configuration
  - Check authentication credentials
  - Confirm graph exists and permissions

### Memory Management
- High Memory Usage
  - Adjust cache size settings
  - Enable automatic cleanup
  - Use appropriate storage backend

### Performance
- Slow Retrieval
  - Enable caching for SPARQL
  - Optimize similarity threshold
  - Adjust context window size

### Integration
- LLM Provider Issues
  - Verify Ollama/OpenAI setup
  - Check API credentials
  - Confirm model availability

## Debugging Steps
1. Enable debug logging
2. Check configuration
3. Verify storage health
4. Test LLM connectivity
5. Validate embeddings
6. Monitor memory usage

================
File: usage-example.js
================
// Import core components
import MemoryManager from './src/MemoryManager.js';
import JSONStore from './src/stores/JSONStore.js';
import OllamaConnector from './src/connectors/OllamaConnector.js';
import Config from './src/Config.js';

async function main() {
    // Initialize configuration
    const config = new Config({
        storage: {
            type: 'json',
            options: { path: 'memory.json' }
        },
        models: {
            chat: {
                provider: 'ollama',
                model: 'llama2'  // Or any other Ollama model
            },
            embedding: {
                provider: 'ollama',
                model: 'nomic-embed-text'
            }
        }
    });

    // Set up storage and LLM connector
    const storage = new JSONStore(config.get('storage.options.path'));
    const llmProvider = new OllamaConnector();

    // Initialize the memory manager
    const memoryManager = new MemoryManager({
        llmProvider,
        chatModel: config.get('models.chat.model'),
        embeddingModel: config.get('models.embedding.model'),
        storage
    });

    try {
        // Example interaction
        const prompt = "What's the weather like today?";

        // Retrieve relevant past interactions
        const relevantMemories = await memoryManager.retrieveRelevantInteractions(prompt);

        // Generate response using context
        const response = await memoryManager.generateResponse(
            prompt,
            [], // recent interactions
            relevantMemories
        );

        // Store the interaction
        const embedding = await memoryManager.generateEmbedding(`${prompt} ${response}`);
        const concepts = await memoryManager.extractConcepts(`${prompt} ${response}`);
        await memoryManager.addInteraction(prompt, response, embedding, concepts);

        console.log('Response:', response);
    } catch (error) {
        console.error('Error:', error);
    } finally {
        // Clean up
        await memoryManager.dispose();
    }
}

main().catch(console.error);
