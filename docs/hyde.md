The HyDE (Hypothetical Document Embeddings) algorithm enhances retrieval for large language models (LLMs) by first using an LLM to generate a hypothetical answer or document in response to a user query. This synthetic document is then embedded into a vector space, and the resulting embedding is used to search for semantically similar real-world documents in a vector database, improving the chances of retrieving relevant information—especially when queries are vague or poorly phrased—compared to traditional query-to-document retrieval methods. This approach shifts retrieval from query-to-answer similarity to answer-to-answer similarity, often boosting accuracy and recall in retrieval-augmented generation (RAG) pipelines without requiring extensive labeled training data.