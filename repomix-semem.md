This file is a merged representation of the entire codebase, combining all repository files into a single document.
Generated by Repomix on: 2025-01-26T21:23:43.842Z

================================================================
File Summary
================================================================

Purpose:
--------
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

File Format:
------------
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Multiple file entries, each consisting of:
  a. A separator line (================)
  b. The file path (File: path/to/file)
  c. Another separator line
  d. The full contents of the file
  e. A blank line

Usage Guidelines:
-----------------
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
- Pay special attention to the Repository Description. These contain important context and guidelines specific to this project.

Notes:
------
- Some files may have been excluded based on .gitignore rules and Repomix's
  configuration.
- Binary files are not included in this packed representation. Please refer to
  the Repository Structure section for a complete list of file paths, including
  binary files.

Additional Info:
----------------
User Provided Header:
-----------------------
Semem repo

================================================================
Directory Structure
================================================================
_old-src/
  example.js
  memory-manager.js
  remote-storage.js
examples/
  about.md
  ClaudeExample.js
  OllamaClaudeExample.js
  OllamaExample.js
  SPARQLExample.js
misc/
  scripts/
    ollama-embedding-test.sh
    sparql-auth-test.sh
    sparql-upload-test.sh
scripts/
  run-tests.js
src/
  _old/
    config.js
  api/
    cli/
      about.md
      CLIHandler.js
    common/
      APIRegistry.js
      BaseAPI.js
      CustomValidators.js
      RDFParser.js
      RDFValidator.js
      types.d.ts.ts
    features/
      ActiveHandler.js
      PassiveHandler.js
      SelfieHandler.js
    http/
      client/
        SememClient.js
      middleware/
        auth.js
        error.js
        logging.js
      server/
        HTTPServer.js
        MessageQueue.js
        openapi-schema.js
        WebSocketServer.js
    repl/
      REPLHandler.js
    about.md
    APILogger.js
    MetricsCollector.js
  connectors/
    OllamaConnector.js
  handlers/
    CacheManager.js
    EmbeddingHandler.js
    LLMHandler.js
  stores/
    BaseStore.js
    CachedSPARQLStore.js
    InMemoryStore.js
    JSONStore.js
    MemoryStore.js
    SPARQLStore.js
  types/
    MemoryTypes.js
    MemoryTypes.ts
  utils/
    EmbeddingValidator.js
    FusekiDiscovery.js
    SPARQLHelpers.js
  Config.js
  ContextManager.js
  ContextWindowManager.js
  index.js
  MemoryManager.js
  PromptTemplates.js
  Utils.js
tests/
  bash/
    check_fuseki.sh
    test-endpoints.sh
  helpers/
    jasmine_examples/
      SpecHelper.js
    reporter.js
    setupGlobals.js
    setupSPARQL.js
  integration/
    examples/
      OllamaExample.spec.js
    http/
      HTTPServer.integration.spec.js
      websocket-integration.spec.js
    llms/
      LLMHandler.integration.spec.js
      Ollama.spec.js
    sparql/
      sparql-advanced-backup-spec.js
      sparql-basic-backup-spec.js
      sparql-endpoint-spec.js
      sparql-federation-spec.js
      sparql-store-integration-spec.js
    ContextManager.integration.spec.js
  mocks/
    Ollama.js
  support/
    jasmine.json
  unit/
    api/
      APILogger.spec.js
      APIRegistry.spec.js
      BaseAPI.spec.js
      MetricsCollector.spec.js
    handlers/
      ActiveHandler.spec.js
      CLIHandler.spec.js
      EmbeddingHandler.spec.js
      LLMHandler.spec.js
      PassiveHandler.spec.js
      REPLHandler.spec.js
      SelfieHandler.spec.js
    http/
      message-queue.spec.js
      WebSocketServer.spec.js
    utils/
      EmbeddingValidator.spec.js
      SPARQLHelpers.spec.js 
    cached-sparql-store-spec.js
    Config.spec.js
    ContextWindowManager.spec.js
    MemoryManager.spec.js
    sparql-endpoint-spec.js
    sparql-store-spec.js
  about.md
  test-list-structure_2025-01-26.md
.git
.gitignore
about.md
jasmine.json
jsconfig.json
jsdoc.json
LICENSE
package copy.json
package-ref.json
package.json
package.json.bak
repomix-docs.config.json
repomix.config.json

================================================================
Files
================================================================

================
File: _old-src/example.js
================
import MemoryManager from './memoryManager.js';
import JSONStorage from './jsonStorage.js';
import RemoteStorage from './remoteStorage.js';
import Config from './config.js';

async function main() {
    // Initialize with custom configuration
    const config = new Config({
        storage: {
            type: 'remote',
            options: {
                endpoint: 'https://api.example.com/memory',
                apiKey: process.env.STORAGE_API_KEY
            }
        },
        models: {
            chat: {
                provider: 'openai',
                model: 'gpt-4-turbo-preview'
            },
            embedding: {
                provider: 'openai',
                model: 'text-embedding-3-small'
            }
        }
    });

    // Initialize storage based on configuration
    let storage;
    switch (config.get('storage.type')) {
        case 'json':
            storage = new JSONStorage(config.get('storage.options.path'));
            break;
        case 'remote':
            storage = new RemoteStorage(config.get('storage.options'));
            break;
        default:
            storage = new InMemoryStorage();
    }

    // Initialize memory manager
    const memoryManager = new MemoryManager({
        apiKey: process.env.OPENAI_API_KEY,
        chatModel: config.get('models.chat.provider'),
        chatModelName: config.get('models.chat.model'),
        embeddingModel: config.get('models.embedding.provider'),
        embeddingModelName: config.get('models.embedding.model'),
        storage
    });

    // Example interaction
    const prompt = "What's the current state of AI technology?";
    
    // Get relevant past interactions
    const relevantInteractions = await memoryManager.retrieveRelevantInteractions(prompt);
    
    // Generate response
    const response = await memoryManager.generateResponse(prompt, [], relevantInteractions);
    console.log('Response:', response);

    // Store the interaction
    const embedding = await memoryManager.getEmbedding(`${prompt} ${response}`);
    const concepts = await memoryManager.extractConcepts(`${prompt} ${response}`);
    await memoryManager.addInteraction(prompt, response, embedding, concepts);
}

main().catch(console.error);

================
File: _old-src/memory-manager.js
================
import { ChatOpenAI } from '@langchain/openai';
import { ChatOllama } from '@langchain/community/chat_models/ollama';
import { OpenAIEmbeddings } from '@langchain/openai';
import ollama from 'ollama';
import { v4 as uuidv4 } from 'uuid';
import MemoryStore from './memoryStore.js';
import InMemoryStorage from './inMemoryStorage.js';
import { logger } from './utils.js';

export default class MemoryManager {
    constructor({
        apiKey,
        chatModel = 'ollama',
        chatModelName = 'llama2',
        embeddingModel = 'ollama',
        embeddingModelName = 'nomic-embed-text',
        storage = null
    }) {
        this.apiKey = apiKey;
        this.chatModelName = chatModelName;
        this.embeddingModelName = embeddingModelName;
        this.dimension = 1536;  // Default dimension

        this.initializeChatModel(chatModel, chatModelName);
        this.initializeEmbeddingModel(embeddingModel, embeddingModelName);

        this.memoryStore = new MemoryStore(this.dimension);
        this.storage = storage || new InMemoryStorage();
        
        this.initialize();
    }

    initializeChatModel(chatModel, modelName) {
        if (chatModel.toLowerCase() === 'openai') {
            this.llm = new ChatOpenAI({
                modelName: modelName,
                apiKey: this.apiKey
            });
        } else if (chatModel.toLowerCase() === 'ollama') {
            this.llm = new ChatOllama({
                model: modelName,
                temperature: 0
            });
        } else {
            throw new Error(`Unsupported chat model: ${chatModel}`);
        }
    }

    async initializeEmbeddingModel(embeddingModel, modelName) {
        if (embeddingModel.toLowerCase() === 'openai') {
            this.embeddings = new OpenAIEmbeddings({
                modelName,
                apiKey: this.apiKey
            });
            this.dimension = modelName === 'text-embedding-3-small' ? 1536 : 1024;
        } else if (embeddingModel.toLowerCase() === 'ollama') {
            this.embeddings = async (text) => {
                const response = await ollama.embeddings({
                    model: modelName,
                    prompt: text
                });
                return response.embedding;
            };
            this.dimension = 1024;  // Default for Ollama
        } else {
            throw new Error(`Unsupported embedding model: ${embeddingModel}`);
        }
    }

    async initialize() {
        const [shortTerm, longTerm] = await this.storage.loadHistory();
        
        for (const interaction of shortTerm) {
            const embedding = this.standardizeEmbedding(interaction.embedding);
            interaction.embedding = embedding;
            this.memoryStore.addInteraction(interaction);
        }

        this.memoryStore.longTermMemory.push(...longTerm);
        this.memoryStore.clusterInteractions();
        
        logger.info(`Memory initialized with ${shortTerm.length} short-term and ${longTerm.length} long-term memories`);
    }

    standardizeEmbedding(embedding) {
        const current = embedding.length;
        if (current === this.dimension) return embedding;
        
        if (current < this.dimension) {
            return [...embedding, ...new Array(this.dimension - current).fill(0)];
        }
        return embedding.slice(0, this.dimension);
    }

    async getEmbedding(text) {
        logger.info('Generating embedding...');
        let embedding;
        
        try {
            if (typeof this.embeddings === 'function') {
                embedding = await this.embeddings(text);
            } else {
                embedding = await this.embeddings.embedQuery(text);
            }
            
            return this.standardizeEmbedding(embedding);
        } catch (error) {
            logger.error('Error generating embedding:', error);
            throw error;
        }
    }

    async extractConcepts(text) {
        logger.info('Extracting concepts...');
        
        const messages = [{
            role: 'system',
            content: 'Extract key concepts from the text. Return only an array of strings.'
        }, {
            role: 'user',
            content: text
        }];

        try {
            const response = await this.llm.call(messages);
            const concepts = JSON.parse(response.content);
            logger.info('Extracted concepts:', concepts);
            return concepts;
        } catch (error) {
            logger.error('Error extracting concepts:', error);
            return [];
        }
    }

    async addInteraction(prompt, output, embedding, concepts) {
        const interaction = {
            id: uuidv4(),
            prompt,
            output,
            embedding,
            timestamp: Date.now(),
            accessCount: 1,
            concepts,
            decayFactor: 1.0
        };

        this.memoryStore.addInteraction(interaction);
        await this.storage.saveMemoryToHistory(this.memoryStore);
    }

    async retrieveRelevantInteractions(query, similarityThreshold = 40, excludeLastN = 0) {
        const queryEmbedding = await this.getEmbedding(query);
        const queryConcepts = await this.extractConcepts(query);
        return this.memoryStore.retrieve(queryEmbedding, queryConcepts, similarityThreshold, excludeLastN);
    }

    async generateResponse(prompt, lastInteractions = [], retrievals = [], contextWindow = 3) {
        const context = this.buildContext(lastInteractions, retrievals, contextWindow);
        
        const messages = [{
            role: 'system',
            content: "You're a helpful assistant with memory of past interactions."
        }, {
            role: 'user',
            content: `${context}\nCurrent prompt: ${prompt}`
        }];

        try {
            const response = await this.llm.call(messages);
            return response.content.trim();
        } catch (error) {
            logger.error('Error generating response:', error);
            throw error;
        }
    }

    buildContext(lastInteractions, retrievals, contextWindow) {

================
File: _old-src/remote-storage.js
================
import BaseStorage from './storage.js';
import { logger } from './utils.js';

export default class RemoteStorage extends BaseStorage {
    constructor(options = {}) {
        super();
        this.endpoint = options.endpoint || 'http://localhost:8080';
        this.apiKey = options.apiKey;
        this.timeout = options.timeout || 5000;
    }

    async loadHistory() {
        try {
            const response = await fetch(`${this.endpoint}/memory`, {
                method: 'GET',
                headers: {
                    'Authorization': `Bearer ${this.apiKey}`,
                    'Content-Type': 'application/json'
                },
                timeout: this.timeout
            });

            if (!response.ok) {
                throw new Error(`HTTP error! status: ${response.status}`);
            }

            const data = await response.json();
            return [
                data.shortTermMemory || [],
                data.longTermMemory || []
            ];
        } catch (error) {
            logger.error('Error loading remote history:', error);
            throw error;
        }
    }

    async saveMemoryToHistory(memoryStore) {
        try {
            const history = {
                shortTermMemory: memoryStore.shortTermMemory.map((item, idx) => ({
                    id: item.id,
                    prompt: item.prompt,
                    output: item.output,
                    embedding: Array.from(memoryStore.embeddings[idx].flat()),
                    timestamp: memoryStore.timestamps[idx],
                    accessCount: memoryStore.accessCounts[idx],
                    concepts: Array.from(memoryStore.conceptsList[idx]),
                    decayFactor: item.decayFactor || 1.0
                })),
                longTermMemory: memoryStore.longTermMemory
            };

            const response = await fetch(`${this.endpoint}/memory`, {
                method: 'POST',
                headers: {
                    'Authorization': `Bearer ${this.apiKey}`,
                    'Content-Type': 'application/json'
                },
                body: JSON.stringify(history),
                timeout: this.timeout
            });

            if (!response.ok) {
                throw new Error(`HTTP error! status: ${response.status}`);
            }

            logger.info(`Saved memory to remote storage. Short-term: ${history.shortTermMemory.length}, Long-term: ${history.longTermMemory.length}`);
        } catch (error) {
            logger.error('Error saving to remote storage:', error);
            throw error;
        }
    }
}

================
File: examples/about.md
================
# About examples

```sh
ollama pull nomic-embed-text
ollama pull qwen2:1.5b
```

================
File: examples/ClaudeExample.js
================
import logger from 'loglevel'
import MemoryManager from '../src/MemoryManager.js'
import JSONStore from '../src/stores/JSONStore.js'
import Config from '../src/Config.js'

class ClaudeConnector {
    constructor(apiKey, baseUrl = 'https://api.anthropic.com/v1') {
        this.apiKey = apiKey
        this.baseUrl = baseUrl
        this.defaultModel = 'voyage-3' // voyage-3 claude-3-5-sonnet-20241022
    }

    async generateEmbedding(model, input) {
        logger.setLevel('debug')
        logger.log(`ClaudeExample.generateEmbedding, this.apiKey = ${this.apiKey}`)
        // process.exit(0)
        model = await Promise.resolve(model) // TODO unhackify
        logger.log(`ClaudeExample.generateEmbedding,
            model = ${model}
            input = ${input}`)
        const response = await fetch(`${this.baseUrl}/messages`, {
            method: 'POST',
            headers: {
                'Content-Type': 'application/json',
                'x-api-key': this.apiKey,
                'anthropic-version': '2023-06-01'
            },
            body: JSON.stringify({
                //  model: this.defaultModel,
                model: model,
                messages: [{ role: 'user', content: input }],
                system: "Generate an embedding vector for the input text."
            })
        })

        if (!response.ok) {
            throw new Error(`Claude API error: ${response.status} ${response.text}`)
        }

        const data = await response.json()
        return data.embedding
    }

    async generateChat(model, messages, options = {}) {
        const response = await fetch(`${this.baseUrl}/messages`, {
            method: 'POST',
            headers: {
                'Content-Type': 'application/json',
                'x-api-key': this.apiKey,
                'anthropic-version': '2023-06-01'
            },
            body: JSON.stringify({
                model: this.defaultModel,
                messages: messages.map(msg => ({
                    role: msg.role,
                    content: msg.content
                })),
                ...options
            })
        })

        if (!response.ok) {
            throw new Error(`Claude API error: ${response.status}`)
        }

        const data = await response.json()
        return data.content[0].text
    }

    async generateCompletion(model, prompt, options = {}) {
        return this.generateChat(model, [{
            role: 'user',
            content: prompt
        }], options)
    }
}

// Handle graceful shutdown
let memoryManager = null

async function shutdown(signal) {
    console.log(`\nReceived ${signal}, starting graceful shutdown...`)
    if (memoryManager) {
        try {
            await memoryManager.dispose()
            console.log('Cleanup complete')
            process.exit(0)
        } catch (error) {
            console.error('Error during cleanup:', error)
            process.exit(1)
        }
    } else {
        process.exit(0)
    }
}

// Handle different termination signals
process.on('SIGTERM', () => shutdown('SIGTERM'))
process.on('SIGINT', () => shutdown('SIGINT'))
process.on('uncaughtException', async (error) => {
    console.error('Uncaught Exception:', error)
    await shutdown('uncaughtException')
})
process.on('unhandledRejection', async (reason, promise) => {
    console.error('Unhandled Rejection at:', promise, 'reason:', reason)
    await shutdown('unhandledRejection')
})

async function main() {
    // Load environment variables
    const CLAUDE_API_KEY = process.env.CLAUDE_API_KEY
    if (!CLAUDE_API_KEY) {
        throw new Error('CLAUDE_API_KEY environment variable is required')
    }

    const config = new Config({
        storage: {
            type: 'json',
            options: {
                path: 'data/memory.json'
            }
        },
        models: {
            chat: {
                provider: 'claude',
                model: 'claude-3-opus-20240229'
            },
            embedding: {
                provider: 'claude',
                model: 'claude-3-opus-20240229'
            }
        }
    })

    const storage = new JSONStore(config.get('storage.options.path'))
    const claude = new ClaudeConnector(CLAUDE_API_KEY)

    memoryManager = new MemoryManager({
        llmProvider: claude,
        chatModel: config.get('models.chat.model'),
        embeddingModel: config.get('models.embedding.model'),
        storage
    })

    const prompt = "What's the current state of AI technology?"

    try {
        const relevantInteractions = await memoryManager.retrieveRelevantInteractions(prompt)
        const response = await memoryManager.generateResponse(prompt, [], relevantInteractions)
        console.log('Response:', response)

        const embedding = await memoryManager.generateEmbedding(`${prompt} ${response}`)
        const concepts = await memoryManager.extractConcepts(`${prompt} ${response}`)
        await memoryManager.addInteraction(prompt, response, embedding, concepts)
    } catch (error) {
        console.error('Error during execution:', error)
        await shutdown('error')
    }
}

// Start the application
main().catch(async (error) => {
    console.error('Fatal error:', error)
    await shutdown('fatal error')
})

export default ClaudeConnector

================
File: examples/OllamaClaudeExample.js
================
import logger from 'loglevel'
import MemoryManager from '../src/MemoryManager.js'
import JSONStore from '../src/stores/JSONStore.js'
import Config from '../src/Config.js'
import Anthropic from '@anthropic-ai/sdk'

class HybridConnector {
    constructor(claudeApiKey, ollamaBaseUrl = 'http://localhost:11434') {
        this.anthropic = new Anthropic({ apiKey: claudeApiKey })
        this.ollamaBaseUrl = ollamaBaseUrl
    }

    async generateEmbedding(model, input) {
        const response = await fetch(`${this.ollamaBaseUrl}/api/embeddings`, {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({
                model: 'nomic-embed-text',
                prompt: input,
                options: { num_ctx: 8192 }
            })
        })

        if (!response.ok) {
            throw new Error(`Ollama embedding error: ${response.status}`)
        }

        const data = await response.json()
        return data.embedding
    }

    async generateChat(model, messages, options = {}) {
        // Extract system message if present
        const systemMessage = messages.find(msg => msg.role === 'system')?.content || ''

        // Convert to Claude's format
        const claudeMessages = messages
            .filter(msg => msg.role !== 'system')
            .map(msg => ({
                role: msg.role === 'assistant' ? 'assistant' : 'user',
                content: msg.content
            }))

        const response = await this.anthropic.messages.create({
            model: "claude-3-opus-20240229",
            max_tokens: options.max_tokens || 1024,
            messages: claudeMessages,
            system: systemMessage,
            temperature: options.temperature || 0.7
        })

        return response.content[0].text
    }

    async generateCompletion(model, prompt, options = {}) {
        return this.generateChat(model, [{
            role: 'user',
            content: prompt
        }], options)
    }
}

let memoryManager = null

async function shutdown(signal) {
    console.log(`\nReceived ${signal}, starting graceful shutdown...`)
    if (memoryManager) {
        try {
            await memoryManager.dispose()
            console.log('Cleanup complete')
            process.exit(0)
        } catch (error) {
            console.error('Error during cleanup:', error)
            process.exit(1)
        }
    } else {
        process.exit(0)
    }
}

process.on('SIGTERM', () => shutdown('SIGTERM'))
process.on('SIGINT', () => shutdown('SIGINT'))
process.on('uncaughtException', async (error) => {
    console.error('Uncaught Exception:', error)
    await shutdown('uncaughtException')
})
process.on('unhandledRejection', async (reason, promise) => {
    console.error('Unhandled Rejection at:', promise, 'reason:', reason)
    await shutdown('unhandledRejection')
})

async function main() {
    const CLAUDE_API_KEY = process.env.CLAUDE_API_KEY
    if (!CLAUDE_API_KEY) {
        throw new Error('CLAUDE_API_KEY environment variable is required')
    }

    const config = new Config({
        storage: {
            type: 'json',
            options: {
                path: 'data/memory.json'
            }
        },
        models: {
            chat: {
                provider: 'claude',
                model: 'claude-3-opus-20240229'
            },
            embedding: {
                provider: 'ollama',
                model: 'nomic-embed-text'
            }
        }
    })

    const storage = new JSONStore(config.get('storage.options.path'))
    const hybridProvider = new HybridConnector(CLAUDE_API_KEY)

    memoryManager = new MemoryManager({
        llmProvider: hybridProvider,
        chatModel: config.get('models.chat.model'),
        embeddingModel: config.get('models.embedding.model'),
        storage
    })

    const prompt = "How many agents does it take to change a lightbulb?"

    try {
        const relevantInteractions = await memoryManager.retrieveRelevantInteractions(prompt)
        const response = await memoryManager.generateResponse(prompt, [], relevantInteractions)
        console.log('Response:', response)

        const embedding = await memoryManager.generateEmbedding(`${prompt} ${response}`)
        const concepts = await memoryManager.extractConcepts(`${prompt} ${response}`)
        await memoryManager.addInteraction(prompt, response, embedding, concepts)
    } catch (error) {
        console.error('Error during execution:', error)
        await shutdown('error')
    }
}

main().catch(async (error) => {
    console.error('Fatal error:', error)
    await shutdown('fatal error')
})

================
File: examples/OllamaExample.js
================
import logger from 'loglevel'
import MemoryManager from '../src/MemoryManager.js'
import JSONStore from '../src/stores/JSONStore.js'
import Config from '../src/Config.js'
import OllamaConnector from '../src/connectors/OllamaConnector.js'

let memoryManager = null

async function shutdown(signal) {
    logger.info(`\nReceived ${signal}, starting graceful shutdown...`)
    if (memoryManager) {
        try {
            await memoryManager.dispose()
            logger.info('Cleanup complete')
            process.exit(0)
        } catch (error) {
            logger.error('Error during cleanup:', error)
            process.exit(1)
        }
    } else {
        process.exit(0)
    }
}

process.on('SIGTERM', () => shutdown('SIGTERM'))
process.on('SIGINT', () => shutdown('SIGINT'))
process.on('uncaughtException', async (error) => {
    logger.error('Uncaught Exception:', error)
    await shutdown('uncaughtException')
})
process.on('unhandledRejection', async (reason, promise) => {
    logger.error('Unhandled Rejection at:', promise, 'reason:', reason)
    await shutdown('unhandledRejection')
})

async function main() {
    const config = Config.create({
        storage: {
            type: 'json',
            options: {
                path: 'data/memory.json'
            }
        },
        models: {
            chat: {
                provider: 'ollama',
                model: 'qwen2:1.5b'
            },
            embedding: {
                provider: 'ollama',
                model: 'nomic-embed-text'
            }
        }
    })

    const storage = new JSONStore(config.get('storage.options.path'))
    const ollama = new OllamaConnector()

    memoryManager = new MemoryManager({
        llmProvider: ollama,
        chatModel: config.get('models.chat.model'),
        embeddingModel: config.get('models.embedding.model'),
        storage
    })

    const prompt = "How many LLMs does it take to change a lightbulb?"

    try {
        const relevantInteractions = await memoryManager.retrieveRelevantInteractions(prompt)
        const response = await memoryManager.generateResponse(prompt, [], relevantInteractions)
        logger.info('Response:', response)

        const embedding = await memoryManager.generateEmbedding(`${prompt} ${response}`)
        const concepts = await memoryManager.extractConcepts(`${prompt} ${response}`)
        await memoryManager.addInteraction(prompt, response, embedding, concepts)
    } catch (error) {
        logger.error('Error during execution:', error)
        await shutdown('error')
    }
}

main().catch(async (error) => {
    logger.error('Fatal error:', error)
    await shutdown('fatal error')
})

================
File: examples/SPARQLExample.js
================
import logger from 'loglevel'
import Config from '../src/Config.js'
import SPARQLStore from '../src/stores/SPARQLStore.js'
import MemoryManager from '../src/MemoryManager.js'
import OllamaConnector from '../src/connectors/OllamaConnector.js'

async function main() {
    // Initialize configuration
    /*
        const config = new Config({
            storage: {
                type: 'sparql',
                options: {
                    graphName: 'http://example.org/mcp/memory'
                }
            }
        })
    */
    const config = new Config()
    config.init()
    logger.setLevel('debug')
    logger.log('config:', config.config)
    // Get SPARQL endpoint configuration
    //  const sparqlConfig = config.get('sparqlEndpoints')[0]
    const sparqlConfig = config.config.sparqlEndpoints[0] // TODO unhackify

    // Initialize SPARQL store
    const store = new SPARQLStore({
        query: `${sparqlConfig.urlBase}${sparqlConfig.query}`,
        update: `${sparqlConfig.urlBase}${sparqlConfig.update}`
    }, {
        user: sparqlConfig.user,
        password: sparqlConfig.password,
        graphName: config.get('storage.options.graphName')
    })

    // Initialize other components
    const ollama = new OllamaConnector()
    const memoryManager = new MemoryManager({
        llmProvider: ollama,
        chatModel: config.get('models.chat.model'),
        embeddingModel: config.get('models.embedding.model'),
        storage: store
    })

    // Example usage
    const prompt = "How can Semantic Web technologies be used with AI?"
    try {
        const relevantInteractions = await memoryManager.retrieveRelevantInteractions(prompt)
        const response = await memoryManager.generateResponse(prompt, [], relevantInteractions)
        console.log('Response:', response)

        const embedding = await memoryManager.generateEmbedding(`${prompt} ${response}`)
        const concepts = await memoryManager.extractConcepts(`${prompt} ${response}`)
        await memoryManager.addInteraction(prompt, response, embedding, concepts)
    } catch (error) {
        console.error('Error:', error)
    } finally {
        await store.close()
    }
}

main().catch(console.error)

================
File: misc/scripts/ollama-embedding-test.sh
================
#!/bin/sh

# ollama pull nomic-embed-text

curl http://localhost:11434/api/embeddings -d '{
  "model": "nomic-embed-text",
  "prompt": "The sky is blue because of Rayleigh scattering"
}'

================
File: misc/scripts/sparql-auth-test.sh
================
#!/bin/sh

curl -X POST \
  -H "Authorization: Basic $(echo -n 'invalid:credentials' | base64)" \
  -H "Content-Type: application/sparql-query" \
  -H "Accept: application/json" \
  --data 'SELECT * WHERE { ?s ?p ?o } LIMIT 1' \
  'http://localhost:4030/test/query'

================
File: misc/scripts/sparql-upload-test.sh
================
#!/bin/sh

curl -X POST \
  -H "Authorization: Basic $(echo -n 'admin:admin123' | base64)" \
  -H "Content-Type: text/turtle" \
  --data-binary '@-' \
  'http://localhost:4030/test/data?graph=http://example.org/test-graph' << 'EOF'
@prefix ex: <http://example.org/> .
ex:subject ex:predicate "test value" .
EOF

================
File: scripts/run-tests.js
================
import Jasmine from 'jasmine'
import { fileURLToPath } from 'url'
import { dirname, join } from 'path'
import Config from '../src/Config.js'
import { initTestGraphs } from '../tests/helpers/setupSPARQL.js'

const __dirname = dirname(fileURLToPath(import.meta.url))

async function runTests() {
    try {
        console.log('Initializing configuration...')
        const config = new Config()
        await config.init()

        console.log('Initializing test environment...')
        await initTestGraphs(config)

        console.log('Running tests...')
        const jasmine = new Jasmine({
            projectBaseDir: join(__dirname, '..')
        })

        const configPath = join(__dirname, '..', 'jasmine.json')
        console.log('Loading config from:', configPath)

        jasmine.loadConfigFile(configPath)
        jasmine.exitOnCompletion = false

        // Execute specs with proper error handling
        try {
            const failures = await jasmine.execute()
            process.exit(failures ? 1 : 0)
        } catch (error) {
            console.error('Test execution failed:', error)
            process.exit(1)
        }
    } catch (error) {
        console.error('Test setup failed:', error)
        process.exit(1)
    }
}

runTests().catch(error => {
    console.error('Fatal error:', error)
    process.exit(1)
})

================
File: src/_old/config.js
================
// config.js
class Config {
  constructor() {
    this.environment = process.env.NODE_ENV || 'development';
    this.paths = {
      base: process.cwd(),
      config: './config'
    };
  }

  async load() {
    // Add configuration loading logic here
    return this;
  }
}

export const config = new Config();

================
File: src/api/cli/about.md
================
# Command line Interfaces

================
File: src/api/cli/CLIHandler.js
================
import yargs from 'yargs'
import { hideBin } from 'yargs/helpers'
import chalk from 'chalk'
import log from 'loglevel'
import APIRegistry from '../common/APIRegistry.js'
import BaseAPI from '../common/BaseAPI.js'

export default class CLIHandler extends BaseAPI {
    constructor(config = {}) {
        super(config)
        this.registry = new APIRegistry()
        this.setupCommands()
    }

    setupCommands() {
        this.yargs = yargs(hideBin(process.argv))
            .command('chat', 'Chat with the system', {
                prompt: {
                    alias: 'p',
                    type: 'string',
                    demandOption: true,
                    describe: 'Input prompt'
                },
                model: {
                    alias: 'm',
                    type: 'string',
                    default: 'qwen2:1.5b',
                    describe: 'Model to use'
                }
            })
            .command('store', 'Store data', {
                data: {
                    alias: 'd',
                    type: 'string',
                    demandOption: true,
                    describe: 'Data to store'
                },
                format: {
                    alias: 'f',
                    choices: ['text', 'turtle'],
                    default: 'text'
                }
            })
            .command('query', 'Query stored data', {
                query: {
                    alias: 'q',
                    type: 'string',
                    demandOption: true,
                    describe: 'Search query'
                },
                limit: {
                    alias: 'l',
                    type: 'number',
                    default: 10
                }
            })
            .command('metrics', 'Show system metrics', {
                format: {
                    choices: ['text', 'json'],
                    default: 'text'
                }
            })
            .option('color', {
                type: 'boolean',
                default: true,
                describe: 'Colorize output'
            })
            .option('verbose', {
                alias: 'v',
                type: 'boolean',
                describe: 'Run with verbose logging'
            })
            .help()
            .alias('h', 'help')
    }

    async initialize() {
        await super.initialize()

        // Set up logging based on verbosity
        if (this.yargs.argv.verbose) {
            log.setLevel('debug')
        }

        process.on('SIGINT', async () => {
            await this.shutdown()
            process.exit(0)
        })
    }

    async executeOperation(command, args) {
        try {
            switch (command) {
                case 'chat':
                    return this.handleChat(args)
                case 'store':
                    return this.handleStore(args)
                case 'query':
                    return this.handleQuery(args)
                case 'metrics':
                    return this.handleMetrics(args)
                default:
                    throw new Error(`Unknown command: ${command}`)
            }
        } catch (error) {
            this.logger.error('Operation failed:', error)
            this.formatOutput({
                success: false,
                error: error.message
            }, args)
        }
    }

    async handleChat({ prompt, model }) {
        const api = this.registry.get('chat')
        const response = await api.executeOperation('chat', {
            prompt,
            model
        })

        return this.formatOutput({
            success: true,
            data: response
        })
    }

    async handleStore({ data, format }) {
        const api = this.registry.get('storage')
        const stored = await api.storeInteraction({
            content: data,
            format,
            timestamp: Date.now()
        })

        return this.formatOutput({
            success: true,
            data: stored
        })
    }

    async handleQuery({ query, limit }) {
        const api = this.registry.get('storage')
        const results = await api.retrieveInteractions({
            text: query,
            limit
        })

        return this.formatOutput({
            success: true,
            data: results
        })
    }

    async handleMetrics({ format }) {
        const metrics = await this.getMetrics()
        return this.formatOutput({
            success: true,
            data: metrics
        }, { format })
    }

    formatOutput(result, { format = 'text', color = true } = {}) {
        const c = color ? chalk : (text => text)

        if (format === 'json') {
            return console.log(JSON.stringify(result, null, 2))
        }

        if (!result.success) {
            return console.error(c.red(`Error: ${result.error}`))
        }

        if (Array.isArray(result.data)) {
            result.data.forEach(item => {
                console.log(c.cyan('---'))
                Object.entries(item).forEach(([key, value]) => {
                    console.log(c.yellow(`${key}:`), value)
                })
            })
            return
        }

        if (typeof result.data === 'object') {
            Object.entries(result.data).forEach(([key, value]) => {
                console.log(c.yellow(`${key}:`), value)
            })
            return
        }

        console.log(result.data)
    }

    async run() {
        await this.initialize()
        const argv = await this.yargs.argv
        const command = argv._[0]

        if (!command) {
            this.yargs.showHelp()
            process.exit(1)
        }

        await this.executeOperation(command, argv)
    }
}

================
File: src/api/common/APIRegistry.js
================
import logger from 'loglevel'
import BaseAPI from './BaseAPI.js'

/**
 * Registry for managing API instances
 * @singleton
 */
export default class APIRegistry {
    constructor() {
        if (APIRegistry.instance) {
            return APIRegistry.instance
        }
        APIRegistry.instance = this

        this.apis = new Map()
        this.logger = logger.getLogger('APIRegistry')
        this.metrics = new Map()
    }

    /**
     * Register a new API implementation
     * @param {string} name - Unique identifier for the API
     * @param {typeof BaseAPI} apiClass - API implementation class
     * @param {Object} config - Configuration for the API
     */
    async register(name, apiClass, config = {}) {
        logger.log(`APIRegistry.register,
        name = ${name}
        apiClass = ${apiClass}
        config = ${config}`)

        if (this.apis.has(name)) {
            throw new Error(`API ${name} already registered`)
        }

        if (!(apiClass.prototype instanceof BaseAPI)) {
            throw new Error('API must extend BaseAPI')
        }

        try {
            const api = new apiClass(config)
            await api.initialize()

            // Set up metric collection
            api.on('metric', (metric) => {
                this.metrics.set(`${name}.${metric.name}`, {
                    value: metric.value,
                    timestamp: metric.timestamp
                })
            })

            this.apis.set(name, api)
            this.logger.info(`Registered API: ${name}`)

            return api
        } catch (error) {
            this.logger.error(`Failed to register API ${name}:`, error)
            throw error
        }
    }

    /**
     * Get an API instance by name
     * @param {string} name - API identifier
     * @returns {BaseAPI} API instance
     */
    get(name) {
        const api = this.apis.get(name)
        if (!api) {
            throw new Error(`API ${name} not found`)
        }
        return api
    }

    /**
     * Remove an API instance
     * @param {string} name - API identifier
     */
    async unregister(name) {
        const api = this.apis.get(name)
        if (api) {
            await api.shutdown()
            this.apis.delete(name)
            this.logger.info(`Unregistered API: ${name}`)
        }
    }

    /**
     * Get all registered API instances
     * @returns {Map<string, BaseAPI>}
     */
    getAll() {
        return new Map(this.apis)
    }

    /**
     * Get collected metrics
     * @returns {Object} Metrics data
     */
    getMetrics() {
        return {
            timestamp: Date.now(),
            apiCount: this.apis.size,
            apis: Object.fromEntries(
                Array.from(this.apis.entries()).map(([name, api]) => [
                    name,
                    {
                        status: api.initialized ? 'active' : 'inactive',
                        metrics: Object.fromEntries(
                            Array.from(this.metrics.entries())
                                .filter(([key]) => key.startsWith(name))
                                .map(([key, value]) => [
                                    key.split('.')[1],
                                    value
                                ])
                        )
                    }
                ])
            )
        }
    }

    /**
     * Shutdown all registered APIs
     */
    async shutdownAll() {
        const shutdowns = Array.from(this.apis.entries()).map(
            async ([name, api]) => {
                try {
                    await this.unregister(name)
                } catch (error) {
                    this.logger.error(`Error shutting down ${name}:`, error)
                }
            }
        )
        await Promise.all(shutdowns)
    }
}

================
File: src/api/common/BaseAPI.js
================
import log from 'loglevel';
import { EventEmitter } from 'events';

/**
 * Abstract base class for all Semem API implementations
 * @abstract
 */
export default class BaseAPI extends EventEmitter {
    constructor(config = {}) {
        super();
        this.config = config;
        this.logger = log.getLogger(this.constructor.name);
        this.initialized = false;
    }

    /**
     * Initialize the API instance
     * @abstract
     */
    async initialize() {
        if (this.initialized) {
            throw new Error('API already initialized');
        }
        this.initialized = true;
    }

    /**
     * Shutdown the API instance
     * @abstract
     */
    async shutdown() {
        if (!this.initialized) {
            throw new Error('API not initialized');
        }
        this.initialized = false;
    }

    /**
     * Execute a memory operation
     * @abstract
     * @param {string} operation - Operation name
     * @param {Object} params - Operation parameters
     */
    async executeOperation(operation, params) {
        throw new Error('executeOperation must be implemented');
    }

    /**
     * Store an interaction
     * @abstract
     * @param {Object} interaction - Interaction data
     */
    async storeInteraction(interaction) {
        throw new Error('storeInteraction must be implemented');
    }

    /**
     * Retrieve interactions
     * @abstract
     * @param {Object} query - Query parameters
     */
    async retrieveInteractions(query) {
        throw new Error('retrieveInteractions must be implemented');
    }

    /**
     * Get system metrics
     * @returns {Object} System metrics
     */
    async getMetrics() {
        return {
            timestamp: Date.now(),
            status: this.initialized ? 'active' : 'inactive',
            memoryUsage: process.memoryUsage(),
            uptime: process.uptime()
        };
    }

    /**
     * Validate operation parameters
     * @protected
     */
    _validateParams(params, schema) {
        // Basic validation - extend as needed
        if (!params || typeof params !== 'object') {
            throw new Error('Invalid parameters');
        }
    }
    
    /**
     * Emit a metric event
     * @protected
     */
    _emitMetric(name, value) {
        this.emit('metric', { name, value, timestamp: Date.now() });
    }
}

================
File: src/api/common/CustomValidators.js
================
/**
 * Manages custom validation functions for RDF data validation
 */
export default class CustomValidators {
    constructor() {
        this.validators = new Map();
        this.registerBuiltins();
    }

    registerBuiltins() {
        // Basic type validators
        this.register('uri', {
            validate: (value) => {
                try {
                    new URL(value);
                    return { valid: true };
                } catch {
                    return { 
                        valid: false, 
                        message: 'Invalid URI format' 
                    };
                }
            }
        });

        this.register('language', {
            validate: (value) => {
                const langPattern = /^[a-zA-Z]{2,3}(-[a-zA-Z]{2,4})?$/;
                return {
                    valid: langPattern.test(value),
                    message: langPattern.test(value) ? null : 'Invalid language tag'
                };
            }
        });

        // Semantic validators
        this.register('concept', {
            validate: (value, options = {}) => {
                if (!value.startsWith(options.namespace || 'http://')) {
                    return {
                        valid: false,
                        message: 'Concept URI must use correct namespace'
                    };
                }
                return { valid: true };
            }
        });

        // Temporal validators
        this.register('timerange', {
            validate: (value, options = {}) => {
                const { start, end } = value;
                const startDate = new Date(start);
                const endDate = new Date(end);

                if (isNaN(startDate.getTime()) || isNaN(endDate.getTime())) {
                    return {
                        valid: false,
                        message: 'Invalid date format'
                    };
                }

                if (startDate > endDate) {
                    return {
                        valid: false,
                        message: 'Start date must be before end date'
                    };
                }

                return { valid: true };
            }
        });
    }

    /**
     * Register a new validator
     * @param {string} name - Validator name
     * @param {Object} validator - Validator definition
     */
    register(name, validator) {
        if (typeof validator.validate !== 'function') {
            throw new Error('Validator must have a validate function');
        }

        this.validators.set(name, {
            ...validator,
            async: validator.validate.constructor.name === 'AsyncFunction'
        });
    }

    /**
     * Register multiple validators
     * @param {Object} validators - Map of validator names to definitions
     */
    registerBatch(validators) {
        for (const [name, validator] of Object.entries(validators)) {
            this.register(name, validator);
        }
    }

    /**
     * Get a registered validator
     * @param {string} name - Validator name
     */
    get(name) {
        const validator = this.validators.get(name);
        if (!validator) {
            throw new Error(`Validator not found: ${name}`);
        }
        return validator;
    }

    /**
     * Execute a validator
     * @param {string} name - Validator name
     * @param {*} value - Value to validate
     * @param {Object} options - Validator options
     */
    async execute(name, value, options = {}) {
        const validator = this.get(name);
        try {
            const result = await validator.validate(value, options);
            return {
                valid: result.valid,
                message: result.message,
                validator: name,
                value
            };
        } catch (error) {
            return {
                valid: false,
                message: error.message,
                validator: name,
                value,
                error
            };
        }
    }

    /**
     * Create a composite validator from multiple validators
     * @param {Array} validators - Array of validator names or definitions
     */
    compose(validators) {
        return {
            validate: async (value, options = {}) => {
                const results = [];
                for (const validator of validators) {
                    const name = typeof validator === 'string' ? 
                        validator : validator.name;
                    const validatorOptions = typeof validator === 'string' ? 
                        options : { ...options, ...validator.options };

                    const result = await this.execute(name, value, validatorOptions);
                    results.push(result);

                    if (!result.valid) break;
                }

                const valid = results.every(r => r.valid);
                return {
                    valid,
                    results,
                    message: valid ? null : results.find(r => !r.valid)?.message
                };
            }
        };
    }

    /**
     * Create a conditional validator
     * @param {Function} condition - Condition function
     * @param {string|Object} validator - Validator to apply if condition is true
     */
    conditional(condition, validator) {
        return {
            validate: async (value, options = {}) => {
                if (!await condition(value, options)) {
                    return { valid: true };
                }

                const name = typeof validator === 'string' ? 
                    validator : validator.name;
                const validatorOptions = typeof validator === 'string' ? 
                    options : { ...options, ...validator.options };

                return this.execute(name, value, validatorOptions);
            }
        };
    }

    /**
     * Create a recursive validator for nested structures
     * @param {string|Object} validator - Base validator
     * @param {Object} options - Recursion options
     */
    recursive(validator, options = {}) {
        return {
            validate: async (value, validatorOptions = {}) => {
                const results = [];
                const maxDepth = options.maxDepth || 10;

                const validateNode = async (node, depth = 0) => {
                    if (depth > maxDepth) {
                        throw new Error('Maximum recursion depth exceeded');
                    }

                    // Validate current node
                    const result = await this.execute(
                        typeof validator === 'string' ? validator : validator.name,
                        node,
                        typeof validator === 'string' ? 
                            validatorOptions : 
                            { ...validatorOptions, ...validator.options }
                    );
                    results.push(result);

                    // Recurse into children if any
                    if (node && typeof node === 'object') {
                        for (const child of Object.values(node)) {
                            if (child && typeof child === 'object') {
                                await validateNode(child, depth + 1);
                            }
                        }
                    }
                };

                await validateNode(value);

                const valid = results.every(r => r.valid);
                return {
                    valid,
                    results,
                    message: valid ? null : results.find(r => !r.valid)?.message
                };
            }
        };
    }
}

================
File: src/api/common/RDFParser.js
================
import APIRegistry from './APIRegistry.js'
import { SPARQLHelpers } from '../../utils/SPARQLHelpers.js'

export default class RDFParser {
    constructor(config = {}) {
        this.registry = new APIRegistry()
        this.prefixes = {
            mcp: 'http://purl.org/stuff/mcp/',
            rdf: 'http://www.w3.org/1999/02/22-rdf-syntax-ns#',
            rdfs: 'http://www.w3.org/2000/01/rdf-schema#',
            xsd: 'http://www.w3.org/2001/XMLSchema#',
            qb: 'http://purl.org/linked-data/cube#',
            skos: 'http://www.w3.org/2004/02/skos/core#',
            ...config.prefixes
        }
    }

    parse(input) {
        const lines = input.trim().split('\n')
        const commands = []
        let currentCommand = ''

        for (const line of lines) {
            const trimmed = line.trim()
            if (!trimmed || trimmed.startsWith('#')) continue

            if (trimmed.endsWith(';')) {
                currentCommand += ' ' + trimmed.slice(0, -1)
                commands.push(currentCommand.trim())
                currentCommand = ''
            } else {
                currentCommand += ' ' + trimmed
            }
        }

        if (currentCommand) {
            commands.push(currentCommand.trim())
        }

        return commands.map(cmd => this.parseCommand(cmd))
    }

    parseCommand(command) {
        const tokens = command.split(' ')
        const action = tokens[0].toLowerCase()

        switch (action) {
            case 'store':
                return this.parseStoreCommand(tokens.slice(1))
            case 'query':
                return this.parseQueryCommand(tokens.slice(1))
            case 'update':
                return this.parseUpdateCommand(tokens.slice(1))
            case 'define':
                return this.parseDefineCommand(tokens.slice(1))
            default:
                throw new Error(`Unknown command: ${action}`)
        }
    }

    parseStoreCommand(tokens) {
        const options = this.parseOptions(tokens)
        const data = options.data || tokens.join(' ')

        return {
            type: 'store',
            data: this.expandPrefixes(data),
            format: options.format || 'turtle',
            graph: options.graph
        }
    }

    parseQueryCommand(tokens) {
        const options = this.parseOptions(tokens)
        let query = options.query || tokens.join(' ')

        // Handle simplified query syntax
        if (!query.toLowerCase().startsWith('select') &&
            !query.toLowerCase().startsWith('ask') &&
            !query.toLowerCase().startsWith('construct')) {
            query = this.buildSimpleQuery(query, options)
        }

        return {
            type: 'query',
            query: this.expandPrefixes(query),
            format: options.format || 'json'
        }
    }

    parseUpdateCommand(tokens) {
        const options = this.parseOptions(tokens)
        let update = options.update || tokens.join(' ')

        // Handle simplified update syntax
        if (!update.toLowerCase().startsWith('insert') &&
            !update.toLowerCase().startsWith('delete')) {
            update = this.buildSimpleUpdate(update, options)
        }

        return {
            type: 'update',
            update: this.expandPrefixes(update),
            graph: options.graph
        }
    }

    parseDefineCommand(tokens) {
        const name = tokens[0]
        const value = tokens.slice(1).join(' ')

        if (name && value) {
            this.prefixes[name] = value.replace(/[<>]/g, '')
        }

        return {
            type: 'define',
            prefix: name,
            uri: value
        }
    }

    parseOptions(tokens) {
        const options = {}
        let i = 0

        while (i < tokens.length) {
            if (tokens[i].startsWith('--')) {
                const key = tokens[i].slice(2)
                i++
                if (i < tokens.length && !tokens[i].startsWith('--')) {
                    options[key] = tokens[i]
                    i++
                } else {
                    options[key] = true
                }
            } else {
                i++
            }
        }

        return options
    }

    buildSimpleQuery(text, options) {
        const vars = options.vars?.split(',') || ['s', 'p', 'o']
        const limit = options.limit || 10
        const offset = options.offset || 0

        return `
            SELECT ${vars.map(v => `?${v}`).join(' ')}
            ${options.graph ? `FROM <${options.graph}>` : ''}
            WHERE {
                ${text.includes(' ') ? text : `?s ?p ?o . FILTER(regex(str(?o), "${text}", "i"))`}
            }
            LIMIT ${limit}
            OFFSET ${offset}
        `
    }

    buildSimpleUpdate(text, options) {
        const [subject, predicate, object] = text.split(' ')
        const graph = options.graph ? `GRAPH <${options.graph}>` : ''

        return `
            INSERT DATA {
                ${graph} {
                    ${this.expandPrefixes(`${subject} ${predicate} ${object}`)}
                }
            }
        `
    }

    expandPrefixes(text) {
        let expanded = text
        for (const [prefix, uri] of Object.entries(this.prefixes)) {
            const regex = new RegExp(`${prefix}:([\\w-]+)`, 'g')
            expanded = expanded.replace(regex, `<${uri}$1>`)
        }
        return expanded
    }

    async execute(commands) {
        const results = []
        const api = this.registry.get('storage')

        for (const command of commands) {
            try {
                switch (command.type) {
                    case 'store':
                        results.push(await api.storeInteraction({
                            content: command.data,
                            format: command.format,
                            graph: command.graph
                        }))
                        break

                    case 'query':
                        results.push(await api.executeOperation('query', {
                            sparql: command.query,
                            format: command.format
                        }))
                        break

                    case 'update':
                        results.push(await api.executeOperation('update', {
                            sparql: command.update,
                            graph: command.graph
                        }))
                        break

                    case 'define':
                        results.push({
                            success: true,
                            prefix: command.prefix,
                            uri: command.uri
                        })
                        break
                }
            } catch (error) {
                results.push({
                    success: false,
                    error: error.message,
                    command
                })
            }
        }

        return results
    }
}

================
File: src/api/common/RDFValidator.js
================
import { SPARQLHelpers } from '../../utils/SPARQLHelpers.js';

export default class RDFValidator {
    constructor(config = {}) {
        this.shapes = new Map();
        this.constraints = new Map();
        this.loadShapes(config.shapes || {});
    }

    loadShapes(shapes) {
        for (const [name, shape] of Object.entries(shapes)) {
            this.registerShape(name, shape);
        }
    }

    registerShape(name, shape) {
        this.shapes.set(name, {
            ...shape,
            constraints: shape.constraints?.map(c => this.parseConstraint(c)) || []
        });
    }

    parseConstraint(constraint) {
        const parsed = {
            path: constraint.path,
            type: constraint.type,
            message: constraint.message
        };

        switch (constraint.type) {
            case 'datatype':
                parsed.datatype = constraint.datatype;
                break;
            case 'pattern':
                parsed.pattern = new RegExp(constraint.pattern);
                break;
            case 'range':
                parsed.min = constraint.min;
                parsed.max = constraint.max;
                break;
            case 'cardinality':
                parsed.min = constraint.min;
                parsed.max = constraint.max;
                break;
            case 'class':
                parsed.class = constraint.class;
                break;
            case 'in':
                parsed.values = new Set(constraint.values);
                break;
        }

        return parsed;
    }

    generateSHACL(shape) {
        const prefixes = {
            sh: 'http://www.w3.org/ns/shacl#',
            xsd: 'http://www.w3.org/2001/XMLSchema#'
        };

        let shacl = '';
        for (const prefix in prefixes) {
            shacl += `@prefix ${prefix}: <${prefixes[prefix]}> .\n`;
        }

        shacl += `\n${shape.targetClass} a sh:NodeShape ;\n`;

        for (const constraint of shape.constraints) {
            shacl += this.constraintToSHACL(constraint);
        }

        return shacl;
    }

    constraintToSHACL(constraint) {
        let shacl = `  sh:property [\n`;
        shacl += `    sh:path ${constraint.path} ;\n`;

        switch (constraint.type) {
            case 'datatype':
                shacl += `    sh:datatype ${constraint.datatype} ;\n`;
                break;
            case 'pattern':
                shacl += `    sh:pattern "${constraint.pattern.source}" ;\n`;
                break;
            case 'range':
                if (constraint.min !== undefined) {
                    shacl += `    sh:minInclusive ${constraint.min} ;\n`;
                }
                if (constraint.max !== undefined) {
                    shacl += `    sh:maxInclusive ${constraint.max} ;\n`;
                }
                break;
            case 'cardinality':
                if (constraint.min !== undefined) {
                    shacl += `    sh:minCount ${constraint.min} ;\n`;
                }
                if (constraint.max !== undefined) {
                    shacl += `    sh:maxCount ${constraint.max} ;\n`;
                }
                break;
            case 'class':
                shacl += `    sh:class ${constraint.class} ;\n`;
                break;
            case 'in':
                shacl += `    sh:in (${Array.from(constraint.values).join(' ')}) ;\n`;
                break;
        }

        if (constraint.message) {
            shacl += `    sh:message "${constraint.message}" ;\n`;
        }

        shacl += `  ] ;\n`;
        return shacl;
    }

    async validate(data, shapeName) {
        const shape = this.shapes.get(shapeName);
        if (!shape) {
            throw new Error(`Shape not found: ${shapeName}`);
        }

        const validationResults = {
            valid: true,
            errors: []
        };

        for (const constraint of shape.constraints) {
            try {
                const result = await this.validateConstraint(data, constraint);
                if (!result.valid) {
                    validationResults.valid = false;
                    validationResults.errors.push(result);
                }
            } catch (error) {
                validationResults.valid = false;
                validationResults.errors.push({
                    path: constraint.path,
                    message: error.message
                });
            }
        }

        return validationResults;
    }

    async validateConstraint(data, constraint) {
        const value = this.getValue(data, constraint.path);

        switch (constraint.type) {
            case 'datatype':
                return this.validateDatatype(value, constraint);
            case 'pattern':
                return this.validatePattern(value, constraint);
            case 'range':
                return this.validateRange(value, constraint);
            case 'cardinality':
                return this.validateCardinality(value, constraint);
            case 'class':
                return this.validateClass(value, constraint);
            case 'in':
                return this.validateIn(value, constraint);
            default:
                throw new Error(`Unknown constraint type: ${constraint.type}`);
        }
    }

    getValue(data, path) {
        const parts = path.split('.');
        let value = data;
        for (const part of parts) {
            value = value?.[part];
            if (value === undefined) break;
        }
        return value;
    }

    validateDatatype(value, constraint) {
        if (value === undefined) return { valid: true };

        const valid = this.checkDatatype(value, constraint.datatype);
        return {
            valid,
            path: constraint.path,
            message: valid ? null : 
                constraint.message || `Invalid datatype: expected ${constraint.datatype}`
        };
    }

    validatePattern(value, constraint) {
        if (value === undefined) return { valid: true };

        const valid = constraint.pattern.test(String(value));
        return {
            valid,
            path: constraint.path,
            message: valid ? null :
                constraint.message || `Value does not match pattern: ${constraint.pattern}`
        };
    }

    validateRange(value, constraint) {
        if (value === undefined) return { valid: true };

        const num = Number(value);
        const valid = !isNaN(num) &&
            (constraint.min === undefined || num >= constraint.min) &&
            (constraint.max === undefined || num <= constraint.max);

        return {
            valid,
            path: constraint.path,
            message: valid ? null :
                constraint.message || `Value out of range: ${constraint.min} - ${constraint.max}`
        };
    }

    validateCardinality(value, constraint) {
        const count = Array.isArray(value) ? value.length : (value === undefined ? 0 : 1);
        const valid = (constraint.min === undefined || count >= constraint.min) &&
                     (constraint.max === undefined || count <= constraint.max);

        return {
            valid,
            path: constraint.path,
            message: valid ? null :
                constraint.message || `Cardinality violation: expected ${constraint.min}-${constraint.max}`
        };
    }

    validateClass(value, constraint) {
        if (value === undefined) return { valid: true };
        
        const valid = value.type === constraint.class;
        return {
            valid,
            path: constraint.path,
            message: valid ? null :
                constraint.message || `Invalid class: expected ${constraint.class}`
        };
    }

    validateIn(value, constraint) {
        if (value === undefined) return { valid: true };

        const valid = constraint.values.has(value);
        return {
            valid,
            path: constraint.path,
            message: valid ? null :
                constraint.message || `Value not in allowed set: ${Array.from(constraint.values).join(', ')}`
        };
    }

    checkDatatype(value, type) {
        switch (type) {
            case 'xsd:string':
                return typeof value === 'string';
            case 'xsd:integer':
                return Number.isInteger(Number(value));
            case 'xsd:decimal':
            case 'xsd:float':
            case 'xsd:double':
                return !isNaN(Number(value));
            case 'xsd:boolean':
                return typeof value === 'boolean';
            case 'xsd:date':
            case 'xsd:dateTime':
                return !isNaN(Date.parse(value));
            default:
                return true;
        }
    }
}

================
File: src/api/common/types.d.ts.ts
================
import { EventEmitter } from 'events';

export interface APIConfig {
    storage?: StorageConfig;
    models?: ModelConfig;
    metrics?: MetricsConfig;
}

export interface StorageConfig {
    type: 'memory' | 'json' | 'sparql';
    options: {
        path?: string;
        endpoint?: string;
        graphName?: string;
    };
}

export interface ModelConfig {
    chat: {
        provider: 'ollama' | 'openai';
        model: string;
        options?: Record<string, any>;
    };
    embedding: {
        provider: 'ollama' | 'openai';
        model: string;
        options?: Record<string, any>;
    };
}

export interface MetricsConfig {
    enabled: boolean;
    interval?: number;
    storageEndpoint?: string;
}

export interface Interaction {
    id: string;
    prompt: string;
    output: string;
    embedding: number[];
    timestamp: number;
    accessCount: number;
    concepts: string[];
    decayFactor: number;
}

export interface Query {
    text?: string;
    concepts?: string[];
    similarity?: number;
    limit?: number;
    offset?: number;
}

export interface MetricEvent {
    name: string;
    value: number | string | boolean;
    timestamp: number;
    labels?: Record<string, string>;
}

export interface APIMetrics {
    timestamp: number;
    status: 'active' | 'inactive';
    memoryUsage: NodeJS.MemoryUsage;
    uptime: number;
}

export declare class BaseAPI extends EventEmitter {
    protected config: APIConfig;
    protected logger: any;
    protected initialized: boolean;

    constructor(config?: APIConfig);
    
    initialize(): Promise<void>;
    shutdown(): Promise<void>;
    
    executeOperation(operation: string, params: Record<string, any>): Promise<any>;
    storeInteraction(interaction: Interaction): Promise<void>;
    retrieveInteractions(query: Query): Promise<Interaction[]>;
    getMetrics(): Promise<APIMetrics>;

    protected _validateParams(params: unknown, schema: unknown): void;
    protected _emitMetric(name: string, value: MetricEvent['value']): void;
}

export declare class APIRegistry {
    private static instance: APIRegistry;
    private apis: Map<string, BaseAPI>;
    private metrics: Map<string, MetricEvent>;
    
    register(name: string, apiClass: typeof BaseAPI, config?: APIConfig): Promise<BaseAPI>;
    get(name: string): BaseAPI;
    unregister(name: string): Promise<void>;
    getAll(): Map<string, BaseAPI>;
    getMetrics(): Record<string, any>;
    shutdownAll(): Promise<void>;
}

// CLI Types
export interface CommandOptions {
    operation: string;
    params: Record<string, any>;
    format?: 'text' | 'json';
    color?: boolean;
}

// HTTP Types
export interface APIResponse<T = any> {
    success: boolean;
    data?: T;
    error?: string;
    metadata?: {
        timestamp: number;
        version: string;
    };
}

// REPL Types
export interface REPLContext {
    api: BaseAPI;
    history: string[];
    mode: 'chat' | 'rdf';
}

// Feature Set Types
export interface SelfieMetrics {
    storage: {
        size: number;
        operations: number;
        latency: number;
    };
    performance: {
        memory: NodeJS.MemoryUsage;
        cpu: number;
        uptime: number;
    };
    errors: Array<{
        type: string;
        count: number;
        lastOccurred: number;
    }>;
}

================
File: src/api/features/ActiveHandler.js
================
import BaseAPI from '../common/BaseAPI.js'
import APIRegistry from '../common/APIRegistry.js'
import { logger } from '../../Utils.js'

export default class ActiveHandler extends BaseAPI {
    constructor(config = {}) {
        super(config)
        this.registry = new APIRegistry()
        this.contextWindow = config.contextWindow || 3
        this.similarityThreshold = config.similarityThreshold || 40
    }

    async executeOperation(operation, params) {
        switch (operation) {
            case 'interact':
                return this.handleInteraction(params)
            case 'search':
                return this.handleSearch(params)
            case 'analyze':
                return this.handleAnalysis(params)
            default:
                throw new Error(`Unknown operation: ${operation}`)
        }
    }

    async handleInteraction({ prompt, context = [], options = {} }) {
        try {
            const memoryManager = this.registry.get('memory')
            const passive = this.registry.get('passive')

            // Get relevant past interactions
            const retrievals = await memoryManager.retrieveRelevantInteractions(
                prompt,
                this.similarityThreshold
            )

            // Generate response using chat
            const response = await passive.executeOperation('chat', {
                prompt,
                context: this._buildContext(context, retrievals),
                ...options
            })

            // Store interaction
            const embedding = await memoryManager.generateEmbedding(
                `${prompt} ${response}`
            )
            const concepts = await memoryManager.extractConcepts(
                `${prompt} ${response}`
            )

            await memoryManager.addInteraction(prompt, response, embedding, concepts)

            this._emitMetric('interaction.count', 1)
            return { response, concepts, retrievals }
        } catch (error) {
            this._emitMetric('interaction.errors', 1)
            throw error
        }
    }

    async handleSearch({ query, type = 'semantic', limit = 10 }) {
        try {
            const memoryManager = this.registry.get('memory')
            const passive = this.registry.get('passive')

            let results
            if (type === 'semantic') {
                const embedding = await memoryManager.generateEmbedding(query)
                results = await memoryManager.retrieveRelevantInteractions(
                    query,
                    this.similarityThreshold,
                    0,
                    limit
                )
            } else {
                results = await passive.executeOperation('query', {
                    sparql: this._buildSearchQuery(query, limit)
                })
            }

            this._emitMetric('search.count', 1)
            return results
        } catch (error) {
            this._emitMetric('search.errors', 1)
            throw error
        }
    }

    async handleAnalysis({ content, type = 'concept' }) {
        try {
            const memoryManager = this.registry.get('memory')

            let results
            switch (type) {
                case 'concept':
                    results = await memoryManager.extractConcepts(content)
                    break
                case 'embedding':
                    results = await memoryManager.generateEmbedding(content)
                    break
                default:
                    throw new Error(`Unknown analysis type: ${type}`)
            }

            this._emitMetric('analysis.count', 1)
            return results
        } catch (error) {
            this._emitMetric('analysis.errors', 1)
            throw error
        }
    }

    _buildContext(context, retrievals) {
        return {
            previous: context.slice(-this.contextWindow),
            relevant: retrievals
                .slice(0, this.contextWindow)
                .map(r => ({
                    prompt: r.interaction.prompt,
                    response: r.interaction.output
                }))
        }
    }

    _buildSearchQuery(query, limit) {
        return `
            PREFIX mcp: <http://purl.org/stuff/mcp/>
            SELECT ?interaction ?prompt ?output ?timestamp
            WHERE {
                ?interaction a mcp:Interaction ;
                    mcp:prompt ?prompt ;
                    mcp:output ?output ;
                    mcp:timestamp ?timestamp .
                FILTER(CONTAINS(LCASE(?prompt), LCASE("${query}")) ||
                       CONTAINS(LCASE(?output), LCASE("${query}")))
            }
            ORDER BY DESC(?timestamp)
            LIMIT ${limit}
        `
    }

    async getMetrics() {
        const baseMetrics = await super.getMetrics()
        return {
            ...baseMetrics,
            operations: {
                interaction: await this._getOperationMetrics('interaction'),
                search: await this._getOperationMetrics('search'),
                analysis: await this._getOperationMetrics('analysis')
            }
        }
    }

    async _getOperationMetrics(operation) {
        return {
            count: await this._getMetricValue(`${operation}.count`),
            errors: await this._getMetricValue(`${operation}.errors`),
            latency: await this._getMetricValue(`${operation}.latency`)
        }
    }
}

================
File: src/api/features/PassiveHandler.js
================
import BaseAPI from '../common/BaseAPI.js'
import APIRegistry from '../common/APIRegistry.js'
import { logger } from '../../Utils.js'

export default class PassiveHandler extends BaseAPI {
    constructor(config = {}) {
        super(config)
        this.registry = new APIRegistry()
        this.llmProvider = config.llmProvider
        this.sparqlEndpoint = config.sparqlEndpoint
    }

    async executeOperation(operation, params) {
        switch (operation) {
            case 'chat':
                return this.handleChat(params)
            case 'query':
                return this.handleQuery(params)
            case 'store':
                return this.handleStore(params)
            default:
                throw new Error(`Unknown operation: ${operation}`)
        }
    }

    async handleChat({ prompt, model = 'qwen2:1.5b', options = {} }) {
        try {
            const response = await this.llmProvider.generateChat(model, [{
                role: 'user',
                content: prompt
            }], options)

            this._emitMetric('chat.requests', 1)
            return response
        } catch (error) {
            this._emitMetric('chat.errors', 1)
            throw error
        }
    }

    async handleQuery({ sparql, format = 'json' }) {
        try {
            const storage = this.registry.get('storage')
            const results = await storage.executeOperation('query', {
                sparql,
                format
            })

            this._emitMetric('query.requests', 1)
            return results
        } catch (error) {
            this._emitMetric('query.errors', 1)
            throw error
        }
    }

    async handleStore({ content, format = 'text' }) {
        try {
            const storage = this.registry.get('storage')
            await storage.storeInteraction({
                content,
                format,
                timestamp: Date.now()
            })

            this._emitMetric('store.requests', 1)
            return { success: true }
        } catch (error) {
            this._emitMetric('store.errors', 1)
            throw error
        }
    }

    async getMetrics() {
        const baseMetrics = await super.getMetrics()
        return {
            ...baseMetrics,
            operations: {
                chat: await this._getOperationMetrics('chat'),
                query: await this._getOperationMetrics('query'),
                store: await this._getOperationMetrics('store')
            }
        }
    }

    async _getOperationMetrics(operation) {
        return {
            requests: await this._getMetricValue(`${operation}.requests`),
            errors: await this._getMetricValue(`${operation}.errors`),
            latency: await this._getMetricValue(`${operation}.latency`)
        }
    }
}

================
File: src/api/features/SelfieHandler.js
================
import { EventEmitter } from 'events'
import log from 'loglevel'
import APIRegistry from '../common/APIRegistry.js'
import BaseAPI from '../common/BaseAPI.js'

export default class SelfieHandler extends BaseAPI {
    constructor(config = {}) {
        super(config)
        this.registry = new APIRegistry()
        this.metrics = new Map()
        this.errors = new Map()
        this.interval = config.interval || 60000
        this.eventBus = new EventEmitter()
        this.setupMetricCollectors()
    }

    setupMetricCollectors() {
        this.collectors = {
            storage: {
                collect: async () => {
                    const api = this.registry.get('storage')
                    const metrics = await api.getMetrics()
                    return {
                        size: metrics.size || 0,
                        operations: metrics.operations || 0,
                        latency: metrics.latency || 0
                    }
                },
                labels: ['size', 'operations', 'latency']
            },
            performance: {
                collect: () => ({
                    memory: process.memoryUsage(),
                    cpu: process.cpuUsage(),
                    uptime: process.uptime()
                }),
                labels: ['memory', 'cpu', 'uptime']
            },
            api: {
                collect: async () => {
                    const apis = this.registry.getAll()
                    const metrics = {}
                    for (const [name, api] of apis) {
                        metrics[name] = await api.getMetrics()
                    }
                    return metrics
                },
                labels: ['status', 'requests', 'errors']
            }
        }
    }

    async initialize() {
        await super.initialize()

        // Start metric collection
        this.collectionTimer = setInterval(
            () => this.collectMetrics(),
            this.interval
        )

        // Error event listeners
        process.on('uncaughtException', (error) => {
            this.trackError('uncaughtException', error)
        })

        process.on('unhandledRejection', (error) => {
            this.trackError('unhandledRejection', error)
        })

        // Set up OpenTelemetry if configured
        if (this.config.openTelemetry) {
            await this.setupOpenTelemetry()
        }

        this.logger.info('SelfieHandler initialized')
    }

    async setupOpenTelemetry() {
        // Basic OpenTelemetry setup - extend as needed
        const { trace, metrics } = await import('@opentelemetry/api')
        const { Resource } = await import('@opentelemetry/resources')
        const { SemanticResourceAttributes } = await import('@opentelemetry/semantic-conventions')

        const resource = new Resource({
            [SemanticResourceAttributes.SERVICE_NAME]: 'semem'
        })

        // Set up metrics export if configured
        if (this.config.openTelemetry.metrics) {
            const meter = metrics.getMeter('semem-metrics')
            this.setupMetricInstruments(meter)
        }
    }

    setupMetricInstruments(meter) {
        this.instruments = {
            memoryUsage: meter.createHistogram('memory_usage', {
                description: 'Memory usage statistics'
            }),
            apiLatency: meter.createHistogram('api_latency', {
                description: 'API request latency'
            }),
            storageOperations: meter.createCounter('storage_operations', {
                description: 'Storage operation count'
            })
        }
    }

    async collectMetrics() {
        try {
            for (const [name, collector] of Object.entries(this.collectors)) {
                const metrics = await collector.collect()
                this.metrics.set(name, {
                    timestamp: Date.now(),
                    values: metrics
                })

                // Emit metric events
                this.eventBus.emit('metrics', {
                    name,
                    metrics,
                    timestamp: Date.now()
                })

                // Update OpenTelemetry if configured
                if (this.instruments) {
                    this.updateOpenTelemetryMetrics(name, metrics)
                }
            }

            // Store metrics if configured
            if (this.config.storageEndpoint) {
                await this.storeMetrics()
            }
        } catch (error) {
            this.logger.error('Error collecting metrics:', error)
            this.trackError('metricCollection', error)
        }
    }

    updateOpenTelemetryMetrics(name, metrics) {
        switch (name) {
            case 'performance':
                this.instruments.memoryUsage.record(
                    metrics.memory.heapUsed,
                    { type: 'heap_used' }
                )
                break
            case 'api':
                Object.entries(metrics).forEach(([api, apiMetrics]) => {
                    this.instruments.apiLatency.record(
                        apiMetrics.latency || 0,
                        { api }
                    )
                })
                break
            case 'storage':
                this.instruments.storageOperations.add(
                    metrics.operations,
                    { type: 'total' }
                )
                break
        }
    }

    async storeMetrics() {
        try {
            const metricsData = this.formatMetricsForStorage()
            const response = await fetch(this.config.storageEndpoint, {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json'
                },
                body: JSON.stringify(metricsData)
            })

            if (!response.ok) {
                throw new Error(`Failed to store metrics: ${response.status}`)
            }
        } catch (error) {
            this.logger.error('Error storing metrics:', error)
            this.trackError('metricStorage', error)
        }
    }

    formatMetricsForStorage() {
        return {
            timestamp: Date.now(),
            metrics: Object.fromEntries(this.metrics),
            errors: Array.from(this.errors.values())
        }
    }

    trackError(type, error) {
        const errorKey = `${type}:${error.message}`
        const existing = this.errors.get(errorKey) || {
            type,
            message: error.message,
            count: 0,
            firstOccurred: Date.now(),
            lastOccurred: Date.now()
        }

        existing.count++
        existing.lastOccurred = Date.now()
        this.errors.set(errorKey, existing)

        this.eventBus.emit('error', {
            type,
            error,
            count: existing.count
        })
    }

    getMetrics() {
        return {
            timestamp: Date.now(),
            collectors: Object.fromEntries(this.metrics),
            errors: Array.from(this.errors.values())
        }
    }

    onMetrics(callback) {
        this.eventBus.on('metrics', callback)
    }

    onError(callback) {
        this.eventBus.on('error', callback)
    }

    async shutdown() {
        if (this.collectionTimer) {
            clearInterval(this.collectionTimer)
        }

        // Store final metrics if configured
        if (this.config.storageEndpoint) {
            await this.storeMetrics()
        }

        this.eventBus.removeAllListeners()
        await super.shutdown()
    }
}

================
File: src/api/http/client/SememClient.js
================
/**
 * Client wrapper for Semem API
 */
export default class SememClient {
    constructor(config = {}) {
        this.baseUrl = config.baseUrl || 'http://localhost:3000/api';
        this.apiKey = config.apiKey;
        this.timeout = config.timeout || 30000;
        this.retries = config.retries || 3;
        this.retryDelay = config.retryDelay || 1000;
    }

    async request(endpoint, options = {}) {
        const controller = new AbortController();
        const timeoutId = setTimeout(() => controller.abort(), this.timeout);

        try {
            const response = await this.retryRequest(endpoint, {
                ...options,
                signal: controller.signal,
                headers: {
                    'Content-Type': 'application/json',
                    'X-API-Key': this.apiKey,
                    ...options.headers
                }
            });

            const data = await response.json();
            if (!data.success) {
                throw new Error(data.error || 'API request failed');
            }

            return data.data;
        } finally {
            clearTimeout(timeoutId);
        }
    }

    async retryRequest(endpoint, options) {
        let lastError;
        for (let attempt = 0; attempt < this.retries; attempt++) {
            try {
                const response = await fetch(`${this.baseUrl}${endpoint}`, options);
                if (response.ok) return response;
                
                lastError = new Error(`HTTP ${response.status}: ${response.statusText}`);
                if (!this.isRetryable(response.status)) throw lastError;
            } catch (error) {
                lastError = error;
                if (!this.isRetryable(error)) throw error;
            }

            await new Promise(resolve => 
                setTimeout(resolve, this.retryDelay * Math.pow(2, attempt))
            );
        }
        throw lastError;
    }

    isRetryable(statusOrError) {
        if (typeof statusOrError === 'number') {
            return [408, 429, 500, 502, 503, 504].includes(statusOrError);
        }
        return statusOrError.name === 'AbortError' || 
               statusOrError.name === 'NetworkError';
    }

    // Chat operations
    async chat(prompt, options = {}) {
        return this.request('/chat', {
            method: 'POST',
            body: JSON.stringify({
                prompt,
                model: options.model || 'qwen2:1.5b',
                ...options
            })
        });
    }

    // Storage operations
    async store(data, format = 'text') {
        return this.request('/store', {
            method: 'POST',
            body: JSON.stringify({ content: data, format })
        });
    }

    async storeInteraction(interaction) {
        return this.request('/store', {
            method: 'POST',
            body: JSON.stringify(interaction)
        });
    }

    // Query operations
    async query(options = {}) {
        const params = new URLSearchParams();
        if (options.text) params.set('text', options.text);
        if (options.concepts) params.set('concepts', JSON.stringify(options.concepts));
        if (options.similarity) params.set('similarity', options.similarity);
        if (options.limit) params.set('limit', options.limit);
        if (options.offset) params.set('offset', options.offset);

        return this.request(`/query?${params}`);
    }

    async sparqlQuery(query) {
        return this.request('/query', {
            method: 'POST',
            body: JSON.stringify({ sparql: query })
        });
    }

    // Metric operations
    async getMetrics() {
        return this.request('/metrics');
    }

    // Streaming operations
    async *streamChat(prompt, options = {}) {
        const response = await fetch(`${this.baseUrl}/chat/stream`, {
            method: 'POST',
            headers: {
                'Content-Type': 'application/json',
                'X-API-Key': this.apiKey
            },
            body: JSON.stringify({
                prompt,
                model: options.model || 'qwen2:1.5b',
                ...options
            })
        });

        if (!response.ok) {
            throw new Error(`HTTP ${response.status}: ${response.statusText}`);
        }

        const reader = response.body.getReader();
        const decoder = new TextDecoder();

        try {
            while (true) {
                const { value, done } = await reader.read();
                if (done) break;
                
                const chunk = decoder.decode(value, { stream: true });
                yield JSON.parse(chunk);
            }
        } finally {
            reader.releaseLock();
        }
    }

    // Batch operations
    async batchStore(interactions) {
        return this.request('/store/batch', {
            method: 'POST',
            body: JSON.stringify(interactions)
        });
    }

    async batchQuery(queries) {
        return this.request('/query/batch', {
            method: 'POST',
            body: JSON.stringify(queries)
        });
    }

    // Helper methods
    formatInteraction(prompt, response, options = {}) {
        return {
            prompt,
            output: response,
            timestamp: Date.now(),
            ...options
        };
    }

    buildQuery(text, options = {}) {
        return {
            text,
            similarity: 0.7,
            limit: 10,
            ...options
        };
    }
}

================
File: src/api/http/middleware/auth.js
================
// Basic authentication middleware
export const authenticateRequest = (req, res, next) => {
    const authHeader = req.headers.authorization

    if (!authHeader) {
        return res.status(401).json({
            success: false,
            error: 'Missing authorization header'
        })
    }

    try {
        const [type, credentials] = authHeader.split(' ')

        if (type !== 'Basic') {
            return res.status(401).json({
                success: false,
                error: 'Invalid authorization type'
            })
        }

        const decoded = Buffer.from(credentials, 'base64').toString('utf-8')
        const [username, password] = decoded.split(':')

        // Simple credential check - should be environment variables in production
        if (username === 'admin' && password === 'admin123') {
            req.user = { username }
            next()
        } else {
            res.status(401).json({
                success: false,
                error: 'Invalid credentials'
            })
        }
    } catch (error) {
        res.status(401).json({
            success: false,
            error: 'Invalid authorization header'
        })
    }
}

================
File: src/api/http/middleware/error.js
================
// Global error handling middleware
export const errorHandler = (logger) => (err, req, res, next) => {
    logger.error('API Error:', err);

    // Handle known error types
    if (err.name === 'ValidationError') {
        return res.status(400).json({
            success: false,
            error: err.message,
            details: err.details
        });
    }

    if (err.name === 'AuthenticationError') {
        return res.status(401).json({
            success: false,
            error: 'Authentication failed'
        });
    }

    // Default error response
    res.status(500).json({
        success: false,
        error: 'Internal server error'
    });
};

================
File: src/api/http/middleware/logging.js
================
// Request logging middleware
export const requestLogger = (logger) => (req, res, next) => {
    const start = Date.now();
    
    // Log request
    logger.info(`${req.method} ${req.url}`, {
        headers: req.headers,
        query: req.query,
        body: req.body
    });

    // Log response
    res.on('finish', () => {
        const duration = Date.now() - start;
        logger.info(`${req.method} ${req.url} ${res.statusCode} ${duration}ms`);
    });

    next();
};

================
File: src/api/http/server/HTTPServer.js
================
// src/api/http/server/HTTPServer.js
import express from 'express'
import cors from 'cors'
import helmet from 'helmet'
import rateLimit from 'express-rate-limit'
import compression from 'compression'
import swaggerUi from 'swagger-ui-express'
import APIRegistry from '../../common/APIRegistry.js'
import BaseAPI from '../../common/BaseAPI.js'
import { authenticateRequest } from '../middleware/auth.js'
import { errorHandler } from '../middleware/error.js'
import { requestLogger } from '../middleware/logging.js'
import apiSpec from './openapi-schema.js'

export default class HTTPServer extends BaseAPI {
    constructor(config = {}) {
        super(config)
        this.app = express()
        this.registry = new APIRegistry()
        this.port = config.port || 3000
        this.setupMiddleware()
        this.setupRoutes()
        this.setupErrorHandling()
    }

    setupMiddleware() {
        // Security
        this.app.use(helmet())
        this.app.use(cors(this.config.cors))

        // Performance
        this.app.use(compression())
        this.app.use(express.json({ limit: '1mb' }))

        // Rate limiting
        const limiter = rateLimit({
            windowMs: 15 * 60 * 1000,
            max: 100,
            standardHeaders: true,
            legacyHeaders: false,
            message: 'Too many requests, please try again later.'
        })
        this.app.use('/api/', limiter)

        // Logging and metrics
        this.app.use(requestLogger(this.logger))
        this.app.use((req, res, next) => {
            const start = Date.now()
            res.on('finish', () => {
                this._emitMetric('http.request.duration', Date.now() - start)
                this._emitMetric('http.response.status', res.statusCode)
            })
            next()
        })
    }

    setupRoutes() {
        // API Documentation
        this.app.use('/docs', swaggerUi.serve, swaggerUi.setup(apiSpec))

        // API Routes
        const apiRouter = express.Router()

        // Memory operations
        apiRouter.post('/memory', authenticateRequest, async (req, res, next) => {
            try {
                const memoryAPI = this.registry.get('memory')
                const result = await memoryAPI.storeInteraction(req.body)
                res.json({ success: true, data: result })
            } catch (error) {
                next(error)
            }
        })

        apiRouter.get('/memory/search', authenticateRequest, async (req, res, next) => {
            try {
                const memoryAPI = this.registry.get('memory')
                const results = await memoryAPI.retrieveInteractions(req.query)
                res.json({ success: true, data: results })
            } catch (error) {
                next(error)
            }
        })

        // Chat operations
        apiRouter.post('/chat', authenticateRequest, async (req, res, next) => {
            try {
                const chatAPI = this.registry.get('chat')
                const response = await chatAPI.executeOperation('chat', req.body)
                res.json({ success: true, data: response })
            } catch (error) {
                next(error)
            }
        })

        // Streaming chat
        apiRouter.post('/chat/stream', authenticateRequest, async (req, res, next) => {
            try {
                const chatAPI = this.registry.get('chat')
                res.setHeader('Content-Type', 'text/event-stream')
                res.setHeader('Cache-Control', 'no-cache')
                res.setHeader('Connection', 'keep-alive')

                const stream = await chatAPI.executeOperation('stream', req.body)
                stream.on('data', chunk => {
                    res.write(`data: ${JSON.stringify(chunk)}\n\n`)
                })
                stream.on('end', () => res.end())
                stream.on('error', error => next(error))
            } catch (error) {
                next(error)
            }
        })

        // Metrics and monitoring
        apiRouter.get('/metrics', authenticateRequest, async (req, res, next) => {
            try {
                const metrics = await this.getMetrics()
                res.json({ success: true, data: metrics })
            } catch (error) {
                next(error)
            }
        })

        // Health check
        apiRouter.get('/health', (req, res) => {
            res.json({
                status: 'healthy',
                timestamp: Date.now(),
                uptime: process.uptime()
            })
        })

        this.app.use('/api', apiRouter)
    }

    setupErrorHandling() {
        this.app.use(errorHandler(this.logger))
    }

    async initialize() {
        await super.initialize()
        return new Promise((resolve) => {
            this.server = this.app.listen(this.port, () => {
                this.wsServer = new MemoryWebSocketServer(this.server)

                // Notify clients of memory updates
                this.registry.on('memoryUpdate', (interaction) => {
                    this.wsServer.notifyUpdate(interaction)
                })

                this.logger.info(`HTTP server listening on port ${this.port}`)
                resolve()
            })
        })
    }

    async shutdown() {
        if (this.server) {
            await new Promise((resolve) => {
                this.server.close(resolve)
            })
            this.logger.info('HTTP server shut down')
        }
        await super.shutdown()
    }
}

================
File: src/api/http/server/MessageQueue.js
================
import { EventEmitter } from 'events';

export default class MessageQueue extends EventEmitter {
    constructor(options = {}) {
        super();
        this.maxQueueSize = options.maxQueueSize || 1000;
        this.maxAge = options.maxAge || 24 * 60 * 60 * 1000; // 24 hours
        this.queues = new Map();
        this.setupCleanup();
    }

    setupCleanup() {
        setInterval(() => this.pruneExpiredMessages(), this.maxAge / 4);
    }

    pruneExpiredMessages() {
        const now = Date.now();
        for (const [clientId, queue] of this.queues) {
            queue.messages = queue.messages.filter(msg => 
                now - msg.timestamp < this.maxAge
            );
            if (queue.messages.length === 0) {
                this.queues.delete(clientId);
            }
        }
    }

    addMessage(clientId, topic, message) {
        if (!this.queues.has(clientId)) {
            this.queues.set(clientId, { 
                messages: [],
                topics: new Set([topic])
            });
        }

        const queue = this.queues.get(clientId);
        queue.topics.add(topic);

        queue.messages.push({
            topic,
            message,
            timestamp: Date.now(),
            id: crypto.randomUUID()
        });

        // Enforce queue size limit
        if (queue.messages.length > this.maxQueueSize) {
            queue.messages.shift();
        }

        this.emit('messageQueued', { clientId, topic, message });
    }

    getMessages(clientId, topic = null, since = 0) {
        const queue = this.queues.get(clientId);
        if (!queue) return [];

        return queue.messages
            .filter(msg => 
                msg.timestamp > since && 
                (!topic || msg.topic === topic)
            )
            .sort((a, b) => a.timestamp - b.timestamp);
    }

    subscribeTopic(clientId, topic) {
        if (!this.queues.has(clientId)) {
            this.queues.set(clientId, { 
                messages: [],
                topics: new Set([topic])
            });
        } else {
            this.queues.get(clientId).topics.add(topic);
        }
    }

    unsubscribeTopic(clientId, topic) {
        const queue = this.queues.get(clientId);
        if (queue) {
            queue.topics.delete(topic);
            if (queue.topics.size === 0 && queue.messages.length === 0) {
                this.queues.delete(clientId);
            }
        }
    }

    getClientTopics(clientId) {
        return Array.from(this.queues.get(clientId)?.topics || []);
    }

    acknowledgeMessages(clientId, messageIds) {
        const queue = this.queues.get(clientId);
        if (!queue) return;

        queue.messages = queue.messages.filter(msg => 
            !messageIds.includes(msg.id)
        );

        if (queue.messages.length === 0 && queue.topics.size === 0) {
            this.queues.delete(clientId);
        }
    }

    dispose() {
        this.queues.clear();
        this.removeAllListeners();
    }
}

================
File: src/api/http/server/openapi-schema.js
================
export default {
    openapi: '3.0.0',
    info: {
        title: 'Semem API',
        version: '1.0.0',
        description: 'Semantic Memory Management System API'
    },
    servers: [
        {
            url: 'http://localhost:3000',
            description: 'Development server'
        }
    ],
    components: {
        schemas: {
            Interaction: {
                type: 'object',
                required: ['prompt', 'output', 'embedding'],
                properties: {
                    id: { type: 'string', format: 'uuid' },
                    prompt: { type: 'string' },
                    output: { type: 'string' },
                    embedding: {
                        type: 'array',
                        items: { type: 'number' }
                    },
                    timestamp: { type: 'integer' },
                    accessCount: { type: 'integer' },
                    concepts: {
                        type: 'array',
                        items: { type: 'string' }
                    },
                    decayFactor: { type: 'number' }
                }
            },
            Query: {
                type: 'object',
                properties: {
                    text: { type: 'string' },
                    concepts: {
                        type: 'array',
                        items: { type: 'string' }
                    },
                    similarity: { type: 'number', minimum: 0, maximum: 100 },
                    limit: { type: 'integer', minimum: 1 },
                    offset: { type: 'integer', minimum: 0 }
                }
            },
            APIResponse: {
                type: 'object',
                required: ['success'],
                properties: {
                    success: { type: 'boolean' },
                    data: { type: 'object' },
                    error: { type: 'string' },
                    metadata: {
                        type: 'object',
                        properties: {
                            timestamp: { type: 'integer' },
                            version: { type: 'string' }
                        }
                    }
                }
            },
            Metrics: {
                type: 'object',
                properties: {
                    timestamp: { type: 'integer' },
                    status: {
                        type: 'string',
                        enum: ['active', 'inactive']
                    },
                    memoryUsage: {
                        type: 'object',
                        properties: {
                            heapTotal: { type: 'number' },
                            heapUsed: { type: 'number' },
                            external: { type: 'number' }
                        }
                    },
                    uptime: { type: 'number' }
                }
            }
        },
        securitySchemes: {
            apiKey: {
                type: 'apiKey',
                in: 'header',
                name: 'X-API-Key'
            }
        }
    },
    paths: {
        '/api/chat': {
            post: {
                summary: 'Chat with the system',
                tags: ['Chat'],
                security: [{ apiKey: [] }],
                requestBody: {
                    required: true,
                    content: {
                        'application/json': {
                            schema: {
                                type: 'object',
                                required: ['prompt'],
                                properties: {
                                    prompt: { type: 'string' },
                                    model: { type: 'string' },
                                    options: { type: 'object' }
                                }
                            }
                        }
                    }
                },
                responses: {
                    '200': {
                        description: 'Successful response',
                        content: {
                            'application/json': {
                                schema: { $ref: '#/components/schemas/APIResponse' }
                            }
                        }
                    }
                }
            }
        },
        '/api/store': {
            post: {
                summary: 'Store an interaction',
                tags: ['Storage'],
                security: [{ apiKey: [] }],
                requestBody: {
                    required: true,
                    content: {
                        'application/json': {
                            schema: { $ref: '#/components/schemas/Interaction' }
                        }
                    }
                },
                responses: {
                    '200': {
                        description: 'Successfully stored',
                        content: {
                            'application/json': {
                                schema: { $ref: '#/components/schemas/APIResponse' }
                            }
                        }
                    }
                }
            }
        },
        '/api/query': {
            get: {
                summary: 'Query stored interactions',
                tags: ['Storage'],
                security: [{ apiKey: [] }],
                parameters: [
                    {
                        name: 'text',
                        in: 'query',
                        schema: { type: 'string' }
                    },
                    {
                        name: 'concepts',
                        in: 'query',
                        schema: {
                            type: 'array',
                            items: { type: 'string' }
                        }
                    },
                    {
                        name: 'similarity',
                        in: 'query',
                        schema: { type: 'number' }
                    },
                    {
                        name: 'limit',
                        in: 'query',
                        schema: { type: 'integer' }
                    },
                    {
                        name: 'offset',
                        in: 'query',
                        schema: { type: 'integer' }
                    }
                ],
                responses: {
                    '200': {
                        description: 'Query results',
                        content: {
                            'application/json': {
                                schema: { $ref: '#/components/schemas/APIResponse' }
                            }
                        }
                    }
                }
            }
        },
        '/api/metrics': {
            get: {
                summary: 'Get system metrics',
                tags: ['Monitoring'],
                security: [{ apiKey: [] }],
                responses: {
                    '200': {
                        description: 'System metrics',
                        content: {
                            'application/json': {
                                schema: { $ref: '#/components/schemas/Metrics' }
                            }
                        }
                    }
                }
            }
        },
        '/health': {
            get: {
                summary: 'Health check',
                tags: ['Monitoring'],
                responses: {
                    '200': {
                        description: 'System health status',
                        content: {
                            'application/json': {
                                schema: {
                                    type: 'object',
                                    properties: {
                                        status: { type: 'string' },
                                        timestamp: { type: 'integer' },
                                        uptime: { type: 'number' }
                                    }
                                }
                            }
                        }
                    }
                }
            }
        }
    }
};

================
File: src/api/http/server/WebSocketServer.js
================
import { WebSocketServer } from 'ws';
import { EventEmitter } from 'events';
import MessageQueue from './MessageQueue.js';

export default class MemoryWebSocketServer extends EventEmitter {
    constructor(server, options = {}) {
        super();
        this.wss = new WebSocketServer({ 
            server,
            path: options.path || '/ws'
        });
        
        this.messageQueue = new MessageQueue(options.queue);
        this.clients = new Map(); // clientId -> {ws, lastSeen, topics}
        this.setupHandlers();
    }

    setupHandlers() {
        this.wss.on('connection', (ws, req) => {
            if (!this.authenticateConnection(ws, req)) return;

            const clientId = crypto.randomUUID();
            this.clients.set(clientId, {
                ws,
                lastSeen: Date.now(),
                topics: new Set(['system', 'memory'])
            });

            // Send queued messages
            this.sendQueuedMessages(clientId);

            ws.on('message', async (message) => {
                try {
                    const data = JSON.parse(message);
                    this.handleClientMessage(clientId, data);
                } catch (error) {
                    ws.send(JSON.stringify({
                        type: 'error',
                        error: 'Invalid message format'
                    }));
                }
            });

            ws.on('close', () => this.handleDisconnect(clientId));

            // Send connection confirmation
            ws.send(JSON.stringify({
                type: 'connected',
                clientId,
                timestamp: Date.now()
            }));
        });
    }

    authenticateConnection(ws, req) {
        const authHeader = req.headers['authorization'];
        if (authHeader) {
            try {
                const [type, credentials] = authHeader.split(' ');
                if (type === 'Basic') {
                    const decoded = Buffer.from(credentials, 'base64').toString('utf-8');
                    const [username, password] = decoded.split(':');
                    if (username !== 'admin' || password !== 'admin123') {
                        ws.close(1008, 'Invalid credentials');
                        return false;
                    }
                }
            } catch (error) {
                ws.close(1008, 'Invalid authorization');
                return false;
            }
        }
        return true;
    }

    handleClientMessage(clientId, data) {
        const client = this.clients.get(clientId);
        if (!client) return;

        client.lastSeen = Date.now();

        switch (data.type) {
            case 'subscribe':
                this.messageQueue.subscribeTopic(clientId, data.topic);
                client.topics.add(data.topic);
                break;

            case 'unsubscribe':
                this.messageQueue.unsubscribeTopic(clientId, data.topic);
                client.topics.delete(data.topic);
                break;

            case 'ack':
                if (Array.isArray(data.messageIds)) {
                    this.messageQueue.acknowledgeMessages(clientId, data.messageIds);
                }
                break;

            default:
                this.emit('message', data, client.ws);
        }
    }

    handleDisconnect(clientId) {
        const client = this.clients.get(clientId);
        if (!client) return;

        // Keep subscriptions in message queue for reconnect
        this.clients.delete(clientId);
        this.emit('clientDisconnected', clientId);
    }

    async sendQueuedMessages(clientId) {
        const client = this.clients.get(clientId);
        if (!client) return;

        const messages = this.messageQueue.getMessages(
            clientId, 
            null,
            Date.now() - (24 * 60 * 60 * 1000) // Last 24 hours
        );

        for (const msg of messages) {
            if (client.topics.has(msg.topic)) {
                client.ws.send(JSON.stringify({
                    type: 'queued_message',
                    ...msg
                }));
            }
        }
    }

    broadcast(topic, data) {
        const message = JSON.stringify({ 
            type: 'broadcast',
            topic,
            data,
            timestamp: Date.now()
        });

        // Queue for offline clients and send to connected ones
        for (const [clientId, client] of this.clients) {
            if (client.topics.has(topic)) {
                if (client.ws.readyState === 1) { // OPEN
                    client.ws.send(message);
                } else {
                    this.messageQueue.addMessage(clientId, topic, data);
                }
            }
        }
    }

    notifyUpdate(interaction) {
        this.broadcast('memory', {
            type: 'interaction_added',
            data: interaction
        });
    }

    close() {
        for (const [clientId, client] of this.clients) {
            client.ws.close(1000, 'Server shutting down');
        }
        this.clients.clear();
        this.messageQueue.dispose();
        this.wss.close();
    }
}

================
File: src/api/repl/REPLHandler.js
================
import { createInterface } from 'readline'
import chalk from 'chalk'
import BaseAPI from '../common/BaseAPI.js'
import APIRegistry from '../common/APIRegistry.js'

export default class REPLHandler extends BaseAPI {
    constructor(config = {}) {
        super(config)
        this.registry = new APIRegistry()
        this.history = []
        this.mode = 'chat'
        this.commands = this.setupCommands()
    }

    setupCommands() {
        return {
            help: {
                desc: 'Show help menu',
                handler: () => this.showHelp()
            },
            mode: {
                desc: 'Switch mode (chat/rdf)',
                handler: (args) => this.switchMode(args[0])
            },
            clear: {
                desc: 'Clear screen',
                handler: () => console.clear()
            },
            history: {
                desc: 'Show command history',
                handler: () => this.showHistory()
            },
            exit: {
                desc: 'Exit REPL',
                handler: () => this.shutdown()
            }
        }
    }

    async initialize() {
        await super.initialize()

        this.rl = createInterface({
            input: process.stdin,
            output: process.stdout,
            prompt: this.getPrompt(),
            historySize: 100,
            removeHistoryDuplicates: true
        })

        this.rl.on('line', async (line) => {
            if (line.trim()) {
                this.history.push(line)
                await this.processInput(line)
            }
            this.rl.prompt()
        })

        this.rl.on('close', () => {
            this.shutdown()
        })

        console.clear()
        this.showWelcome()
        this.rl.prompt()
    }

    getPrompt() {
        return chalk.cyan(`semem(${this.mode})> `)
    }

    showWelcome() {
        console.log(chalk.green('Welcome to Semem Interactive Shell'))
        console.log(chalk.gray('Type "help" for available commands'))
        console.log()
    }

    showHelp() {
        console.log(chalk.yellow('\nAvailable Commands:'))
        Object.entries(this.commands).forEach(([cmd, info]) => {
            console.log(chalk.cyan(`  ${cmd.padEnd(10)} - ${info.desc}`))
        })
        console.log(chalk.yellow('\nModes:'))
        console.log(chalk.cyan('  chat      - Natural language interactions'))
        console.log(chalk.cyan('  rdf       - RDF/SPARQL queries'))
        console.log()
    }

    showHistory() {
        if (this.history.length === 0) {
            console.log(chalk.gray('No history available'))
            return
        }

        console.log(chalk.yellow('\nCommand History:'))
        this.history.slice(-10).forEach((cmd, i) => {
            console.log(chalk.gray(`  ${i + 1}. ${cmd}`))
        })
        console.log()
    }

    switchMode(newMode) {
        const validModes = ['chat', 'rdf']
        if (!validModes.includes(newMode)) {
            console.log(chalk.red(`Invalid mode. Valid modes: ${validModes.join(', ')}`))
            return
        }

        this.mode = newMode
        this.rl.setPrompt(this.getPrompt())
        console.log(chalk.green(`Switched to ${newMode} mode`))
    }

    async processInput(input) {
        const trimmed = input.trim()
        if (!trimmed) return

        const [command, ...args] = trimmed.split(' ')

        // Check for built-in commands
        if (this.commands[command]) {
            await this.commands[command].handler(args)
            return
        }

        try {
            // Handle mode-specific operations
            switch (this.mode) {
                case 'chat':
                    await this.handleChat(trimmed)
                    break
                case 'rdf':
                    await this.handleRDF(trimmed)
                    break
            }
        } catch (error) {
            console.error(chalk.red('Error:'), error.message)
        }
    }

    async handleChat(input) {
        try {
            const api = this.registry.get('chat')
            const response = await api.executeOperation('chat', {
                prompt: input,
                mode: 'chat'
            })

            // Format and display response
            console.log(chalk.green('\nAssistant:'), response)
            console.log()

            // Store interaction
            const storageApi = this.registry.get('storage')
            await storageApi.storeInteraction({
                prompt: input,
                output: response,
                timestamp: Date.now()
            })
        } catch (error) {
            console.error(chalk.red('Chat error:'), error.message)
        }
    }

    async handleRDF(input) {
        try {
            const api = this.registry.get('storage')
            let response

            if (input.toLowerCase().startsWith('select') ||
                input.toLowerCase().startsWith('ask') ||
                input.toLowerCase().startsWith('construct')) {
                // Query operation
                response = await api.executeOperation('query', {
                    sparql: input
                })
            } else {
                // Update operation
                response = await api.executeOperation('update', {
                    sparql: input
                })
            }

            // Format and display response
            if (Array.isArray(response)) {
                console.log(chalk.yellow('\nResults:'))
                response.forEach(result => {
                    console.log(chalk.gray('-'), result)
                })
            } else {
                console.log(chalk.green('\nOperation completed successfully'))
            }
            console.log()
        } catch (error) {
            console.error(chalk.red('RDF error:'), error.message)
        }
    }

    async shutdown() {
        console.log(chalk.yellow('\nShutting down...'))
        if (this.rl) {
            this.rl.close()
        }
        await super.shutdown()
        process.exit(0)
    }
}

================
File: src/api/about.md
================
src/api/
├── common/
│ ├── BaseAPI.js # Abstract base interface
│ ├── APIRegistry.js # API registration/discovery
│ └── types.d.ts # TypeScript definitions
├── cli/
│ └── CLIHandler.js # Command line interface
├── repl/
│ └── REPLHandler.js # Interactive shell
├── http/
│ ├── server/
│ │ ├── HTTPServer.js # Express server
│ │ └── routes/ # API endpoints
│ └── client/
│ └── forms/ # Web interface
├── features/
│ ├── SelfieHandler.js # Metrics & monitoring
│ ├── PassiveHandler.js # Individual operations
│ └── ActiveHandler.js # Combined operations
└── utils/
├── MetricsCollector.js # Performance tracking
└── APILogger.js # Logging wrapper

================
File: src/api/APILogger.js
================
import log from 'loglevel';
import { EventEmitter } from 'events';

export default class APILogger extends EventEmitter {
    constructor(options = {}) {
        super();
        this.name = options.name || 'API';
        this.level = options.level || 'info';
        this.maxEntries = options.maxEntries || 1000;
        this.logEntries = [];
        
        this.logger = log.getLogger(this.name);
        this.logger.setLevel(this.level);
        
        this.setupMethods();
    }

    setupMethods() {
        const levels = ['trace', 'debug', 'info', 'warn', 'error'];
        
        levels.forEach(level => {
            this[level] = (...args) => {
                const entry = this.createLogEntry(level, ...args);
                this.logEntries.push(entry);
                
                if (this.logEntries.length > this.maxEntries) {
                    this.logEntries.shift();
                }
                
                this.emit('log', entry);
                this.logger[level](...args);
                
                return entry;
            };
        });
    }

    createLogEntry(level, ...args) {
        const entry = {
            timestamp: new Date().toISOString(),
            level,
            message: args.map(arg => 
                typeof arg === 'object' ? JSON.stringify(arg) : String(arg)
            ).join(' '),
            metadata: {
                pid: process.pid,
                hostname: require('os').hostname()
            }
        };

        // Extract error details if present
        const error = args.find(arg => arg instanceof Error);
        if (error) {
            entry.error = {
                name: error.name,
                message: error.message,
                stack: error.stack
            };
        }

        return entry;
    }

    getEntries(options = {}) {
        let entries = [...this.logEntries];
        
        if (options.level) {
            entries = entries.filter(entry => entry.level === options.level);
        }
        
        if (options.since) {
            entries = entries.filter(entry => 
                new Date(entry.timestamp) >= new Date(options.since)
            );
        }
        
        if (options.until) {
            entries = entries.filter(entry => 
                new Date(entry.timestamp) <= new Date(options.until)
            );
        }
        
        if (options.limit) {
            entries = entries.slice(-options.limit);
        }
        
        return entries;
    }

    clearEntries() {
        this.logEntries = [];
    }

    setLevel(level) {
        this.level = level;
        this.logger.setLevel(level);
    }

    getLevel() {
        return this.level;
    }

    createChild(name, options = {}) {
        return new APILogger({
            ...options,
            name: `${this.name}:${name}`,
            level: options.level || this.level
        });
    }

    dispose() {
        this.removeAllListeners();
        this.clearEntries();
    }
}

================
File: src/api/MetricsCollector.js
================
import { EventEmitter } from 'events';
import { logger } from '../Utils.js';

export default class MetricsCollector extends EventEmitter {
    constructor(options = {}) {
        super();
        this.metrics = new Map();
        this.interval = options.interval || 60000;
        this.maxHistory = options.maxHistory || 1000;
        this.startTime = Date.now();
        this.setupCleanup();
    }

    setupCleanup() {
        this.cleanupInterval = setInterval(() => {
            this.pruneMetrics();
        }, this.interval);
    }

    collect(name, value, labels = {}) {
        const timestamp = Date.now();
        const key = this.generateKey(name, labels);
        
        if (!this.metrics.has(key)) {
            this.metrics.set(key, []);
        }
        
        const series = this.metrics.get(key);
        series.push({ timestamp, value });
        
        this.emit('metric', { name, value, timestamp, labels });
        
        if (series.length > this.maxHistory) {
            series.shift();
        }
    }

    generateKey(name, labels) {
        const labelStr = Object.entries(labels)
            .sort(([a], [b]) => a.localeCompare(b))
            .map(([k, v]) => `${k}=${v}`)
            .join(',');
        return labelStr ? `${name}{${labelStr}}` : name;
    }

    getMetric(name, labels = {}) {
        const key = this.generateKey(name, labels);
        return this.metrics.get(key) || [];
    }

    getSummary(name, labels = {}) {
        const series = this.getMetric(name, labels);
        if (series.length === 0) return null;

        const values = series.map(point => point.value);
        return {
            count: values.length,
            min: Math.min(...values),
            max: Math.max(...values),
            avg: values.reduce((a, b) => a + b, 0) / values.length,
            last: values[values.length - 1]
        };
    }

    pruneMetrics() {
        const cutoff = Date.now() - this.interval;
        
        for (const [key, series] of this.metrics.entries()) {
            const filtered = series.filter(point => point.timestamp >= cutoff);
            if (filtered.length === 0) {
                this.metrics.delete(key);
            } else {
                this.metrics.set(key, filtered);
            }
        }
    }

    getSnapshot() {
        const snapshot = {
            timestamp: Date.now(),
            uptime: Date.now() - this.startTime,
            metrics: {}
        };

        for (const [key, series] of this.metrics.entries()) {
            snapshot.metrics[key] = this.getSummary(key);
        }

        return snapshot;
    }

    reset() {
        this.metrics.clear();
        this.startTime = Date.now();
    }

    dispose() {
        if (this.cleanupInterval) {
            clearInterval(this.cleanupInterval);
        }
        this.removeAllListeners();
        this.metrics.clear();
    }
}

================
File: src/connectors/OllamaConnector.js
================
import logger from 'loglevel'

/**
 * Connector for Ollama API operations
 */
export default class OllamaConnector {
    constructor(baseUrl = 'http://localhost:11434') {
        this.baseUrl = baseUrl
        logger.setLevel('debug')
    }

    /**
     * Generate embeddings using Ollama
     */
    async generateEmbedding(model, input) {
        logger.debug(`Generating embedding with model ${model}`)
        logger.debug('Input:', input)

        try {
            const response = await fetch(`${this.baseUrl}/api/embeddings`, {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify({
                    model,
                    prompt: input,
                    options: { num_ctx: 8192 }
                })
            })

            if (!response.ok) {
                throw new Error(`Ollama API error: ${response.status}`)
            }

            const data = await response.json()
            logger.debug('Embedding generated successfully')
            return data.embedding
        } catch (error) {
            logger.error('Embedding generation failed:', error)
            throw error
        }
    }

    /**
     * Generate chat completion using Ollama
     */
    async generateChat(model, messages, options = {}) {
        logger.debug(`Generating chat with model ${model}`)
        logger.debug('Messages:', messages)

        try {
            const response = await fetch(`${this.baseUrl}/api/chat`, {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify({
                    model,
                    messages,
                    stream: false,
                    options: {
                        temperature: options.temperature || 0.7,
                        ...options
                    }
                })
            })

            if (!response.ok) {
                throw new Error(`Ollama API error: ${response.status}`)
            }

            const data = await response.json()
            logger.debug('Chat response:', data.message?.content)
            return data.message?.content || ''
        } catch (error) {
            logger.error('Chat generation failed:', error)
            throw error
        }
    }

    /**
     * Generate completion using Ollama
     */
    async generateCompletion(model, prompt, options = {}) {
        logger.debug(`Generating completion with model ${model}`)
        logger.debug('Prompt:', prompt)

        try {
            const response = await fetch(`${this.baseUrl}/api/generate`, {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify({
                    model,
                    prompt,
                    stream: false,
                    options: {
                        temperature: options.temperature || 0.7,
                        ...options
                    }
                })
            })

            if (!response.ok) {
                throw new Error(`Ollama API error: ${response.status}`)
            }

            const data = await response.json()
            logger.debug('Completion response:', data.response)
            return data.response || ''
        } catch (error) {
            logger.error('Completion generation failed:', error)
            throw error
        }
    }
}

================
File: src/handlers/CacheManager.js
================
import logger from 'loglevel'

export default class CacheManager {
    constructor({ maxSize = 1000, ttl = 3600000 }) {
        this.maxSize = maxSize
        this.ttl = ttl
        this.cache = new Map()
        this.timestamps = new Map()

        this.cleanupInterval = setInterval(
            () => this.cleanup(),
            ttl / 2
        )
    }

    get(key) {
        const value = this.cache.get(key)
        if (value) {
            this.timestamps.set(key, Date.now())
            return value
        }
        return null
    }

    set(key, value) {
        this.cache.set(key, value)
        this.timestamps.set(key, Date.now())

        if (this.cache.size > this.maxSize) {
            this.cleanup()
        }
    }

    cleanup() {
        const now = Date.now()
        let removed = 0

        // Remove expired entries
        for (const [key, timestamp] of this.timestamps.entries()) {
            if (now - timestamp > this.ttl) {
                this.cache.delete(key)
                this.timestamps.delete(key)
                removed++
            }
        }

        // Remove oldest entries if still over size
        while (this.cache.size > this.maxSize) {
            const oldestKey = this.getOldestKey()
            if (oldestKey) {
                this.cache.delete(oldestKey)
                this.timestamps.delete(oldestKey)
                removed++
            }
        }

        if (removed > 0) {
            logger.debug(`Cache cleanup: removed ${removed} entries`)
        }
    }

    getOldestKey() {
        let oldestKey = null
        let oldestTime = Infinity

        for (const [key, timestamp] of this.timestamps.entries()) {
            if (timestamp < oldestTime) {
                oldestTime = timestamp
                oldestKey = key
            }
        }

        return oldestKey
    }

    clear() {
        this.cache.clear()
        this.timestamps.clear()
    }

    dispose() {
        if (this.cleanupInterval) {
            clearInterval(this.cleanupInterval)
        }
        this.clear()
    }
}

================
File: src/handlers/EmbeddingHandler.js
================
import logger from 'loglevel'

export default class EmbeddingHandler {
    /**
     * @param {Object} llmProvider
     * @param {string} model Model identifier
     * @param {number} dimension Embedding dimension
     * @param {Object} cacheManager
     */
    constructor(llmProvider, model, dimension, cacheManager) {
        if (typeof model !== 'string') {
            throw new TypeError('Model must be a string')
        }

        this.llmProvider = llmProvider
        this.model = model
        this.dimension = dimension
        this.cacheManager = cacheManager
    }

    /**
     * @param {string} text
     * @returns {Promise<number[]>}
     */
    async generateEmbedding(text) {
        const cacheKey = `${this.model}:${text.slice(0, 100)}`

        const cached = this.cacheManager.get(cacheKey)
        if (cached) return cached

        try {
            const embedding = await this.llmProvider.generateEmbedding(
                this.model,
                text
            )

            const standardized = this.standardizeEmbedding(embedding)
            this.cacheManager.set(cacheKey, standardized)
            return standardized
        } catch (error) {
            logger.error('Error generating embedding:', error)
            throw error
        }
    }

    /**
     * @param {number[]} embedding
     * @private
     */
    validateEmbedding(embedding) {
        if (!Array.isArray(embedding)) {
            throw new TypeError('Embedding must be an array')
        }
        if (!embedding.every(x => typeof x === 'number' && !isNaN(x))) {
            throw new TypeError('Embedding must contain only valid numbers')
        }
    }

    /**
     * @param {number[]} embedding
     * @returns {number[]}
     */
    standardizeEmbedding(embedding) {
        this.validateEmbedding(embedding)
        const current = embedding.length

        if (current === this.dimension) return embedding
        if (current < this.dimension) {
            return [...embedding, ...new Array(this.dimension - current).fill(0)]
        }
        return embedding.slice(0, this.dimension)
    }
}

================
File: src/handlers/LLMHandler.js
================
import logger from 'loglevel'
import PromptTemplates from '../PromptTemplates.js'

/**
 * @typedef {import('../types/MemoryTypes').LLMProvider} LLMProvider
 * @typedef {import('../types/MemoryTypes').ChatMessage} ChatMessage
 */

export default class LLMHandler {
    /**
     * @param {LLMProvider} llmProvider
     * @param {string} chatModel
     * @param {number} [temperature=0.7]
     */
    constructor(llmProvider, chatModel, temperature = 0.7) {
        this.llmProvider = llmProvider
        this.chatModel = chatModel
        this.temperature = temperature
    }

    /**
     * @param {string} prompt
     * @param {string} context
     * @param {string} [systemPrompt]
     * @returns {Promise<string>}
     */
    async generateResponse(prompt, context, systemPrompt = "You're a helpful assistant with memory of past interactions.") {
        try {
            const messages = PromptTemplates.formatChatPrompt(
                this.chatModel,
                systemPrompt,
                context,
                prompt
            )

            return await this.llmProvider.generateChat(
                this.chatModel,
                messages,
                { temperature: this.temperature }
            )
        } catch (error) {
            logger.error('Error generating chat response:', error)
            throw error
        }
    }

    /**
     * @param {string} text
     * @returns {Promise<string[]>}
     */
    async extractConcepts(text) {
        try {
            const prompt = PromptTemplates.formatConceptPrompt(this.chatModel, text)
            const response = await this.llmProvider.generateCompletion(
                this.chatModel,
                prompt,
                { temperature: 0.2 }
            )

            const match = response.match(/\[.*\]/)
            if (!match) {
                logger.warn('No concept array found in LLM response')
                return []
            }

            try {
                return JSON.parse(match[0])
            } catch (parseError) {
                logger.error('Failed to parse concepts array:', parseError)
                return []
            }
        } catch (error) {
            logger.error('Error extracting concepts:', error)
            return []
        }
    }

    /**
     * @param {string} text
     * @param {string} model
     * @param {number} [retries=3]
     * @returns {Promise<number[]>}
     */
    async generateEmbedding(text, model, retries = 3) {
        let lastError = null

        for (let attempt = 0; attempt < retries; attempt++) {
            try {
                return await this.llmProvider.generateEmbedding(model, text)
            } catch (error) {
                lastError = error
                logger.warn(`Embedding generation attempt ${attempt + 1} failed:`, error)
                await new Promise(resolve => setTimeout(resolve, 1000 * (attempt + 1)))
            }
        }

        throw new Error(`Failed to generate embedding after ${retries} attempts: ${lastError?.message}`)
    }

    /**
     * @param {number} temperature
     * @throws {Error} If temperature is invalid
     */
    setTemperature(temperature) {
        if (temperature < 0 || temperature > 1) {
            throw new Error('Temperature must be between 0 and 1')
        }
        this.temperature = temperature
    }

    /**
     * @param {string} model
     * @returns {boolean}
     */
    validateModel(model) {
        return typeof model === 'string' && model.length > 0
    }
}

================
File: src/stores/BaseStore.js
================
export default class BaseStore {
    async loadHistory() {
        throw new Error('Method loadHistory() must be implemented');
    }

    async saveMemoryToHistory(memoryStore) {
        throw new Error('Method saveMemoryToHistory() must be implemented');
    }

    async beginTransaction() {
        throw new Error('Method beginTransaction() must be implemented');
    }

    async commitTransaction() {
        throw new Error('Method commitTransaction() must be implemented');
    }

    async rollbackTransaction() {
        throw new Error('Method rollbackTransaction() must be implemented');
    }

    async verify() {
        throw new Error('Method verify() must be implemented');
    }

    async close() {
        throw new Error('Method close() must be implemented');
    }
}

================
File: src/stores/CachedSPARQLStore.js
================
import SPARQLStore from './SPARQLStore.js';
import { logger } from '../Utils.js';

export default class CachedSPARQLStore extends SPARQLStore {
    constructor(endpoint, options = {}) {
        super(endpoint, options);
        
        // Cache configuration
        this.cacheEnabled = options.cacheEnabled ?? true;
        this.cacheTTL = options.cacheTTL || 300000; // 5 minutes default
        this.maxCacheSize = options.maxCacheSize || 100;
        
        // Initialize cache
        this.queryCache = new Map();
        this.cacheTimestamps = new Map();
        
        // Start cache cleanup interval
        this.cleanupInterval = setInterval(() => {
            this.cleanupCache();
        }, this.cacheTTL / 2);
    }

    async _executeSparqlQuery(query, endpoint) {
        if (!this.cacheEnabled) {
            return super._executeSparqlQuery(query, endpoint);
        }

        const cacheKey = this._generateCacheKey(query);

        // Check cache
        const cachedResult = this.queryCache.get(cacheKey);
        if (cachedResult) {
            const timestamp = this.cacheTimestamps.get(cacheKey);
            if (Date.now() - timestamp < this.cacheTTL) {
                logger.debug('Cache hit:', cacheKey);
                return JSON.parse(JSON.stringify(cachedResult)); // Deep clone
            }
        }

        // Execute query
        const result = await super._executeSparqlQuery(query, endpoint);
        
        // Cache result
        this.queryCache.set(cacheKey, result);
        this.cacheTimestamps.set(cacheKey, Date.now());
        
        // Manage cache size
        if (this.queryCache.size > this.maxCacheSize) {
            this.cleanupCache();
        }

        return result;
    }

    _generateCacheKey(query) {
        // Normalize query by removing whitespace
        return query.replace(/\s+/g, ' ').trim();
    }

    cleanupCache() {
        const now = Date.now();

        // Remove expired entries
        for (const [key, timestamp] of this.cacheTimestamps.entries()) {
            if (now - timestamp > this.cacheTTL) {
                this.queryCache.delete(key);
                this.cacheTimestamps.delete(key);
            }
        }

        // If still over size limit, remove oldest entries
        while (this.queryCache.size > this.maxCacheSize) {
            let oldestKey = null;
            let oldestTime = Infinity;

            for (const [key, timestamp] of this.cacheTimestamps.entries()) {
                if (timestamp < oldestTime) {
                    oldestTime = timestamp;
                    oldestKey = key;
                }
            }

            if (oldestKey) {
                this.queryCache.delete(oldestKey);
                this.cacheTimestamps.delete(oldestKey);
            }
        }
    }

    invalidateCache() {
        this.queryCache.clear();
        this.cacheTimestamps.clear();
    }

    async saveMemoryToHistory(memoryStore) {
        // Invalidate cache when data changes
        this.invalidateCache();
        return super.saveMemoryToHistory(memoryStore);
    }

    async close() {
        if (this.cleanupInterval) {
            clearInterval(this.cleanupInterval);
        }
        
        this.invalidateCache();
        return super.close();
    }
}

================
File: src/stores/InMemoryStore.js
================
import BaseStore from './BaseStore.js';
import { logger } from '../Utils.js';

export default class InMemoryStore extends BaseStore {
    constructor() {
        super();
        this.history = {
            shortTermMemory: [],
            longTermMemory: []
        };
    }

    async loadHistory() {
        logger.info('Loading history from in-memory storage');
        return [
            this.history.shortTermMemory || [],
            this.history.longTermMemory || []
        ];
    }

    async saveMemoryToHistory(memoryStore) {
        logger.info('Saving history to in-memory storage');

        this.history = {
            shortTermMemory: memoryStore.shortTermMemory.map((item, idx) => ({
                id: item.id,
                prompt: item.prompt,
                output: item.output,
                embedding: Array.from(memoryStore.embeddings[idx].flat()),
                timestamp: memoryStore.timestamps[idx],
                accessCount: memoryStore.accessCounts[idx],
                concepts: Array.from(memoryStore.conceptsList[idx]),
                decayFactor: item.decayFactor || 1.0
            })),
            longTermMemory: [...memoryStore.longTermMemory]
        };

        logger.info(`Saved ${this.history.shortTermMemory.length} short-term and ${this.history.longTermMemory.length} long-term memories`);
    }
}

================
File: src/stores/JSONStore.js
================
import { promises as fs } from 'fs'
import { dirname, join } from 'path'
import BaseStore from './BaseStore.js'
import { logger } from '../Utils.js'

export default class JSONStore extends BaseStore {
    constructor(filePath = 'interaction_history.json') {
        super()
        this.filePath = filePath
        this.tempPath = null
        this.backupPath = `${filePath}.bak`
        this.inTransaction = false
    }

    async ensureDirectory() {
        this.filePath = await Promise.resolve(this.filePath) // TODO unhackify
        const dir = dirname(this.filePath)
        await fs.mkdir(dir, { recursive: true })
    }

    async loadHistory() {

        try {
            await this.ensureDirectory()
            const exists = await fs.access(this.filePath).then(() => true).catch(() => false)

            if (!exists) {
                logger.info('No existing interaction history found in JSON. Starting fresh.')
                return [[], []]
            }

            // Try to read main file
            try {
                logger.info('Loading existing interaction history from JSON...')
                const data = await fs.readFile(this.filePath, 'utf8')
                const history = JSON.parse(data)
                return [
                    history.shortTermMemory || [],
                    history.longTermMemory || []
                ]
            } catch (mainError) {
                // If main file is corrupted, try backup
                logger.warn('Main file corrupted, attempting to load backup...')
                const backupExists = await fs.access(this.backupPath).then(() => true).catch(() => false)

                if (backupExists) {
                    const backupData = await fs.readFile(this.backupPath, 'utf8')
                    const history = JSON.parse(backupData)
                    // Restore from backup
                    await fs.copyFile(this.backupPath, this.filePath)
                    return [
                        history.shortTermMemory || [],
                        history.longTermMemory || []
                    ]
                }

                throw mainError
            }
        } catch (error) {
            logger.error('Error loading history:', error)
            return [[], []]
        }
    }

    async beginTransaction() {
        if (this.inTransaction) {
            throw new Error('Transaction already in progress')
        }
        this.inTransaction = true
        this.tempPath = `${this.filePath}.tmp`
    }

    async commitTransaction() {
        if (!this.inTransaction) {
            throw new Error('No transaction in progress')
        }

        try {
            // First backup the current file if it exists
            const exists = await fs.access(this.filePath).then(() => true).catch(() => false)
            if (exists) {
                await fs.copyFile(this.filePath, this.backupPath)
            }

            // Atomically rename temp file to main file
            await fs.rename(this.tempPath, this.filePath)

            // Clean up
            if (exists) {
                await fs.unlink(this.backupPath).catch(() => { })
            }
        } finally {
            this.inTransaction = false
            this.tempPath = null
        }
    }

    async rollbackTransaction() {
        if (!this.inTransaction) {
            throw new Error('No transaction in progress')
        }

        try {
            if (this.tempPath) {
                await fs.unlink(this.tempPath).catch(() => { })
            }
        } finally {
            this.inTransaction = false
            this.tempPath = null
        }
    }

    async verify() {
        try {
            const data = await fs.readFile(this.filePath, 'utf8')
            JSON.parse(data) // Try to parse
            return true
        } catch {
            return false
        }
    }

    async saveMemoryToHistory(memoryStore) {
        try {
            await this.ensureDirectory()
            await this.beginTransaction()

            const history = {
                shortTermMemory: memoryStore.shortTermMemory.map((item, idx) => ({
                    id: item.id,
                    prompt: item.prompt,
                    output: item.output,
                    embedding: Array.from(memoryStore.embeddings[idx]),
                    timestamp: memoryStore.timestamps[idx],
                    accessCount: memoryStore.accessCounts[idx],
                    concepts: Array.from(memoryStore.conceptsList[idx]),
                    decayFactor: item.decayFactor || 1.0
                })),
                longTermMemory: memoryStore.longTermMemory
            }

            // Write to temp file first
            await fs.writeFile(this.tempPath, JSON.stringify(history, null, 2))

            // Verify the written file
            if (!await this.verify()) {
                throw new Error('Data verification failed')
            }

            // Commit the transaction
            await this.commitTransaction()

            logger.info(`Saved interaction history to JSON. Short-term: ${history.shortTermMemory.length}, Long-term: ${history.longTermMemory.length}`)
        } catch (error) {
            await this.rollbackTransaction()
            logger.error('Error saving history:', error)
            throw error
        }
    }

    async close() {
        if (this.inTransaction) {
            await this.rollbackTransaction()
        }
        return Promise.resolve()
    }
}

================
File: src/stores/MemoryStore.js
================
import faiss from 'faiss-node'
import { createRequire } from 'module'
import { kmeans } from 'ml-kmeans'
import { logger, vectorOps } from '../Utils.js'

const require = createRequire(import.meta.url)
const { Graph } = require('graphology')

export default class MemoryStore {
    constructor(dimension = 1536) {
        this.dimension = dimension
        this.initializeIndex()
        this.shortTermMemory = []
        this.longTermMemory = []
        this.embeddings = []
        this.timestamps = []
        this.accessCounts = []
        this.conceptsList = []
        this.graph = new Graph({ multi: true, allowSelfLoops: false })
        this.semanticMemory = new Map()
        this.clusterLabels = []
    }

    initializeIndex() {
        try {
            this.index = new faiss.IndexFlatL2(this.dimension)
            if (!this.index || !this.index.getDimension) {
                throw new Error('Failed to initialize FAISS index')
            }
            logger.info(`Initialized FAISS index with dimension ${this.dimension}`)
        } catch (error) {
            logger.error('FAISS index initialization failed:', error)
            throw new Error('Failed to initialize FAISS index: ' + error.message)
        }
    }

    updateGraph(concepts) {
        // Add new nodes if they don't exist
        for (const concept of concepts) {
            if (!this.graph.hasNode(concept)) {
                this.graph.addNode(concept)
            }
        }

        // Add or update edges between concepts
        for (const concept1 of concepts) {
            for (const concept2 of concepts) {
                if (concept1 !== concept2) {
                    // Check for existing edges between the nodes
                    const existingEdges = this.graph.edges(concept1, concept2)

                    if (existingEdges.length > 0) {
                        // Update weight of first existing edge
                        const edgeWeight = this.graph.getEdgeAttribute(existingEdges[0], 'weight')
                        this.graph.setEdgeAttribute(existingEdges[0], 'weight', edgeWeight + 1)
                    } else {
                        // Create new edge with weight 1
                        this.graph.addEdge(concept1, concept2, { weight: 1 })
                    }
                }
            }
        }
    }

    classifyMemory() {
        this.shortTermMemory.forEach((interaction, idx) => {
            if (this.accessCounts[idx] > 10 &&
                !this.longTermMemory.some(ltm => ltm.id === interaction.id)) {
                this.longTermMemory.push(interaction)
                logger.info(`Moved interaction ${interaction.id} to long-term memory`)
            }
        })
    }

    async retrieve(queryEmbedding, queryConcepts, similarityThreshold = 40, excludeLastN = 0) {
        if (this.shortTermMemory.length === 0) {
            logger.info('No interactions available')
            return []
        }

        logger.info('Retrieving relevant interactions...')
        const relevantInteractions = []
        const currentTime = Date.now()
        const decayRate = 0.0001
        const relevantIndices = new Set()

        const normalizedQuery = vectorOps.normalize(queryEmbedding.flat())
        const normalizedEmbeddings = this.embeddings.map(e => vectorOps.normalize(Array.from(e)))

        for (let idx = 0; idx < this.shortTermMemory.length - excludeLastN; idx++) {
            const similarity = vectorOps.cosineSimilarity(normalizedQuery, normalizedEmbeddings[idx]) * 100
            const timeDiff = (currentTime - this.timestamps[idx]) / 1000
            const decayFactor = this.shortTermMemory[idx].decayFactor * Math.exp(-decayRate * timeDiff)
            const reinforcementFactor = Math.log1p(this.accessCounts[idx])
            const adjustedSimilarity = similarity * decayFactor * reinforcementFactor

            if (adjustedSimilarity >= similarityThreshold) {
                relevantIndices.add(idx)
                this.accessCounts[idx]++
                this.timestamps[idx] = currentTime
                this.shortTermMemory[idx].decayFactor *= 1.1

                relevantInteractions.push({
                    similarity: adjustedSimilarity,
                    interaction: this.shortTermMemory[idx],
                    concepts: this.conceptsList[idx]
                })
            }
        }

        // Apply decay to non-relevant interactions
        this.shortTermMemory.forEach((item, idx) => {
            if (!relevantIndices.has(idx)) {
                item.decayFactor *= 0.9
            }
        })

        const activatedConcepts = await this.spreadingActivation(queryConcepts)

        // Combine results
        return this.combineResults(relevantInteractions, activatedConcepts, normalizedQuery)
    }

    async spreadingActivation(queryConcepts) {
        const activatedNodes = new Map()
        const initialActivation = 1.0
        const decayFactor = 0.5

        queryConcepts.forEach(concept => {
            activatedNodes.set(concept, initialActivation)
        })

        // Spread activation for 2 steps
        for (let step = 0; step < 2; step++) {
            const newActivations = new Map()

            for (const [node, activation] of activatedNodes) {
                if (this.graph.hasNode(node)) {
                    this.graph.forEachNeighbor(node, (neighbor, attributes) => {
                        if (!activatedNodes.has(neighbor)) {
                            const weight = attributes.weight
                            const newActivation = activation * decayFactor * weight
                            newActivations.set(neighbor,
                                (newActivations.get(neighbor) || 0) + newActivation)
                        }
                    })
                }
            }

            newActivations.forEach((value, key) => {
                activatedNodes.set(key, value)
            })
        }

        return Object.fromEntries(activatedNodes)
    }

    clusterInteractions() {
        if (this.embeddings.length < 2) return

        const embeddingsMatrix = this.embeddings.map(e => Array.from(e))
        const numClusters = Math.min(10, this.embeddings.length)

        const { clusters } = kmeans(embeddingsMatrix, numClusters)
        this.clusterLabels = clusters

        this.semanticMemory.clear()
        clusters.forEach((label, idx) => {
            if (!this.semanticMemory.has(label)) {
                this.semanticMemory.set(label, [])
            }
            this.semanticMemory.get(label).push({
                embedding: this.embeddings[idx],
                interaction: this.shortTermMemory[idx]
            })
        })
    }

    combineResults(relevantInteractions, activatedConcepts, normalizedQuery) {
        const combined = relevantInteractions.map(({ similarity, interaction, concepts }) => {
            const activationScore = Array.from(concepts)
                .reduce((sum, c) => sum + (activatedConcepts[c] || 0), 0)
            return {
                ...interaction,
                totalScore: similarity + activationScore
            }
        })

        combined.sort((a, b) => b.totalScore - a.totalScore)

        // Add semantic memory results
        const semanticResults = this.retrieveFromSemanticMemory(normalizedQuery)
        return [...combined, ...semanticResults]
    }

    retrieveFromSemanticMemory(normalizedQuery) {
        if (this.semanticMemory.size === 0) return []

        // Find best matching cluster
        let bestCluster = -1
        let bestSimilarity = -1

        this.semanticMemory.forEach((items, label) => {
            const centroid = this.calculateCentroid(items.map(i => i.embedding))
            const similarity = vectorOps.cosineSimilarity(normalizedQuery, centroid)

            if (similarity > bestSimilarity) {
                bestSimilarity = similarity
                bestCluster = label
            }
        })

        if (bestCluster === -1) return []

        // Get top 5 interactions from best cluster
        return this.semanticMemory.get(bestCluster)
            .map(({ embedding, interaction }) => ({
                ...interaction,
                similarity: vectorOps.cosineSimilarity(normalizedQuery,
                    vectorOps.normalize(Array.from(embedding)))
            }))
            .sort((a, b) => b.similarity - a.similarity)
            .slice(0, 5)
    }

    calculateCentroid(embeddings) {
        const sum = embeddings.reduce((acc, curr) => {
            const arr = Array.from(curr)
            return acc.map((val, idx) => val + arr[idx])
        }, new Array(this.dimension).fill(0))

        return sum.map(val => val / embeddings.length)
    }
}

================
File: src/stores/SPARQLStore.js
================
import BaseStore from './BaseStore.js'
import logger from 'loglevel'

export default class SPARQLStore extends BaseStore {
    constructor(endpoint, options = {}) {
        super()
        this.endpoint = endpoint
        this.credentials = {
            user: options.user || 'admin',
            password: options.password || 'admin'
        }
        this.graphName = options.graphName || 'http://example.org/mcp/memory'
        this.inTransaction = false
        this.dimension = options.dimension || 1536
    }

    async _executeSparqlQuery(query, endpoint) {
        const auth = Buffer.from(`${this.credentials.user}:${this.credentials.password}`).toString('base64')
        logger.log(`endpoint = ${endpoint}`)
        try {
            const response = await fetch(endpoint, {
                method: 'POST',
                headers: {
                    'Authorization': `Basic ${auth}`,
                    'Content-Type': 'application/sparql-query',
                    'Accept': 'application/json'
                },
                body: query,
                credentials: 'include'
            })

            if (!response.ok) {
                const errorText = await response.text()
                throw new Error(`SPARQL query failed: ${response.status} - ${errorText}`)
            }

            return await response.json()
        } catch (error) {
            logger.error('SPARQL query error:', error)
            throw error
        }
    }

    async _executeSparqlUpdate(update, endpoint) {
        const auth = Buffer.from(`${this.credentials.user}:${this.credentials.password}`).toString('base64')

        try {
            const response = await fetch(endpoint, {
                method: 'POST',
                headers: {
                    'Authorization': `Basic ${auth}`,
                    'Content-Type': 'application/sparql-update',
                    'Accept': 'application/json'
                },
                body: update,
                credentials: 'include'
            })

            if (!response.ok) {
                const errorText = await response.text()
                throw new Error(`SPARQL update failed: ${response.status} - ${errorText}`)
            }

            return response
        } catch (error) {
            logger.error('SPARQL update error:', error)
            throw error
        }
    }

    validateEmbedding(embedding) {
        if (!Array.isArray(embedding)) {
            throw new TypeError('Embedding must be an array')
        }
        if (embedding.length !== this.dimension) {
            throw new Error(`Embedding dimension mismatch: expected ${this.dimension}, got ${embedding.length}`)
        }
        if (!embedding.every(x => typeof x === 'number' && !isNaN(x))) {
            throw new TypeError('Embedding must contain only valid numbers')
        }
    }

    async verify() {
        this.graphName = await Promise.resolve(this.graphName) // TODO unhackify
        try {
            try {
                const createQuery = `
                    CREATE SILENT GRAPH <${this.graphName}>;
                    INSERT DATA { GRAPH <${this.graphName}> {
                        <${this.graphName}> a <http://example.org/mcp/MemoryStore>
                    }}
                `
                await this._executeSparqlUpdate(createQuery, this.endpoint.update)
            } catch (error) {
                logger.debug('Graph creation skipped:', error.message)
            }

            const checkQuery = `ASK { GRAPH <${this.graphName}> { ?s ?p ?o } }`
            const result = await this._executeSparqlQuery(checkQuery, this.endpoint.query)
            return result.boolean
        } catch (error) {
            logger.error('Graph verification failed:', error)
            throw error
        }
    }

    async loadHistory() {
        await this.verify()

        const query = `
            PREFIX mcp: <http://purl.org/stuff/mcp/>
            PREFIX xsd: <http://www.w3.org/2001/XMLSchema#>

            SELECT ?id ?prompt ?output ?embedding ?timestamp ?accessCount ?concepts ?decayFactor ?memoryType
            FROM <${this.graphName}>
            WHERE {
                ?interaction a mcp:Interaction ;
                    mcp:id ?id ;
                    mcp:prompt ?prompt ;
                    mcp:output ?output ;
                    mcp:embedding ?embedding ;
                    mcp:timestamp ?timestamp ;
                    mcp:accessCount ?accessCount ;
                    mcp:decayFactor ?decayFactor ;
                    mcp:memoryType ?memoryType .
                OPTIONAL { ?interaction mcp:concepts ?concepts }
            }`

        try {
            const result = await this._executeSparqlQuery(query, this.endpoint.query)
            const shortTermMemory = []
            const longTermMemory = []

            for (const binding of result.results.bindings) {
                try {
                    let embedding = new Array(this.dimension).fill(0)
                    if (binding.embedding?.value && binding.embedding.value !== 'undefined') {
                        try {
                            embedding = JSON.parse(binding.embedding.value.trim())
                            this.validateEmbedding(embedding)
                        } catch (embeddingError) {
                            logger.error('Invalid embedding format:', embeddingError)
                        }
                    }

                    let concepts = []
                    if (binding.concepts?.value && binding.concepts.value !== 'undefined') {
                        try {
                            concepts = JSON.parse(binding.concepts.value.trim())
                            if (!Array.isArray(concepts)) {
                                throw new Error('Concepts must be an array')
                            }
                        } catch (conceptsError) {
                            logger.error('Invalid concepts format:', conceptsError)
                        }
                    }

                    const interaction = {
                        id: binding.id.value,
                        prompt: binding.prompt.value,
                        output: binding.output.value,
                        embedding,
                        timestamp: parseInt(binding.timestamp.value) || Date.now(),
                        accessCount: parseInt(binding.accessCount.value) || 1,
                        concepts,
                        decayFactor: parseFloat(binding.decayFactor.value) || 1.0
                    }

                    if (binding.memoryType.value === 'short-term') {
                        shortTermMemory.push(interaction)
                    } else {
                        longTermMemory.push(interaction)
                    }
                } catch (parseError) {
                    logger.error('Failed to parse interaction:', parseError, binding)
                }
            }

            logger.info(`Loaded ${shortTermMemory.length} short-term and ${longTermMemory.length} long-term memories from store ${this.endpoint.query} graph <${this.graphName}>`)
            return [shortTermMemory, longTermMemory]
        } catch (error) {
            logger.error('Error loading history:', error)
            return [[], []]
        }
    }

    async saveMemoryToHistory(memoryStore) {
        if (this.inTransaction) {
            throw new Error('Transaction already in progress')
        }

        try {
            await this.verify()
            await this.beginTransaction()

            const clearQuery = `
                PREFIX mcp: <http://purl.org/stuff/mcp/>
                CLEAR GRAPH <${this.graphName}>
            `
            await this._executeSparqlUpdate(clearQuery, this.endpoint.update)

            const insertQuery = `
                PREFIX mcp: <http://purl.org/stuff/mcp/>
                PREFIX xsd: <http://www.w3.org/2001/XMLSchema#>

                INSERT DATA {
                    GRAPH <${this.graphName}> {
                        ${this._generateInsertStatements(memoryStore.shortTermMemory, 'short-term')}
                        ${this._generateInsertStatements(memoryStore.longTermMemory, 'long-term')}
                    }
                }
            `

            await this._executeSparqlUpdate(insertQuery, this.endpoint.update)
            await this.commitTransaction()

            logger.info(`Saved memory to SPARQL store ${this.endpoint.update} graph <${this.graphName}>. Stats: ${memoryStore.shortTermMemory.length} short-term, ${memoryStore.longTermMemory.length} long-term memories`)
        } catch (error) {
            await this.rollbackTransaction()
            logger.error('Error saving to SPARQL store:', error)
            throw error
        }
    }

    _generateInsertStatements(memories, type) {
        return memories.map((interaction, index) => {
            // Ensure embedding is valid before saving
            let embeddingStr = '[]'
            if (Array.isArray(interaction.embedding)) {
                try {
                    this.validateEmbedding(interaction.embedding)
                    embeddingStr = JSON.stringify(interaction.embedding)
                } catch (error) {
                    logger.error('Invalid embedding in memory:', error)
                }
            }

            // Ensure concepts is valid before saving
            let conceptsStr = '[]'
            if (Array.isArray(interaction.concepts)) {
                conceptsStr = JSON.stringify(interaction.concepts)
            }

            return `
                _:interaction${type}${index} a mcp:Interaction ;
                    mcp:id "${interaction.id}" ;
                    mcp:prompt "${this._escapeSparqlString(interaction.prompt)}" ;
                    mcp:output "${this._escapeSparqlString(interaction.output)}" ;
                    mcp:embedding """${embeddingStr}""" ;
                    mcp:timestamp "${interaction.timestamp}"^^xsd:integer ;
                    mcp:accessCount "${interaction.accessCount}"^^xsd:integer ;
                    mcp:concepts """${conceptsStr}""" ;
                    mcp:decayFactor "${interaction.decayFactor}"^^xsd:decimal ;
                    mcp:memoryType "${type}" .
            `
        }).join('\n')
    }

    _escapeSparqlString(str) {
        return str.replace(/["\\]/g, '\\$&').replace(/\n/g, '\\n')
    }

    async beginTransaction() {
        if (this.inTransaction) {
            throw new Error('Transaction already in progress')
        }

        this.inTransaction = true

        const backupQuery = `
            PREFIX mcp: <http://purl.org/stuff/mcp/>
            COPY GRAPH <${this.graphName}> TO GRAPH <${this.graphName}.backup>
        `
        await this._executeSparqlUpdate(backupQuery, this.endpoint.update)
    }

    async commitTransaction() {
        if (!this.inTransaction) {
            throw new Error('No transaction in progress')
        }

        try {
            const dropBackup = `
                PREFIX mcp: <http://purl.org/stuff/mcp/>
                DROP SILENT GRAPH <${this.graphName}.backup>
            `
            await this._executeSparqlUpdate(dropBackup, this.endpoint.update)
        } finally {
            this.inTransaction = false
        }
    }

    async rollbackTransaction() {
        if (!this.inTransaction) {
            throw new Error('No transaction in progress')
        }

        try {
            const restoreQuery = `
                PREFIX mcp: <http://purl.org/stuff/mcp/>
                DROP SILENT GRAPH <${this.graphName}> ;
                MOVE GRAPH <${this.graphName}.backup> TO GRAPH <${this.graphName}>
            `
            await this._executeSparqlUpdate(restoreQuery, this.endpoint.update)
        } finally {
            this.inTransaction = false
        }
    }

    async close() {
        if (this.inTransaction) {
            await this.rollbackTransaction()
        }
    }
}

================
File: src/types/MemoryTypes.js
================
export const MemoryTypes = {
    SHORT_TERM: 'short-term',
    LONG_TERM: 'long-term'
}

export class Interaction {
    constructor({
        id,
        prompt,
        output,
        embedding,
        timestamp = Date.now(),
        accessCount = 1,
        concepts = [],
        decayFactor = 1.0
    }) {
        this.id = id
        this.prompt = prompt
        this.output = output
        this.embedding = embedding
        this.timestamp = timestamp
        this.accessCount = accessCount
        this.concepts = concepts
        this.decayFactor = decayFactor
    }
}

export class MemoryConfig {
    constructor({
        llmProvider,
        chatModel = 'qwen2:1.5b',
        embeddingModel = 'nomic-embed-text',
        storage = null,
        dimension = 1536,
        contextOptions = { maxTokens: 8192 },
        cacheOptions = { maxSize: 1000, ttl: 3600000 }
    }) {
        this.llmProvider = llmProvider
        this.chatModel = chatModel
        this.embeddingModel = embeddingModel
        this.storage = storage
        this.dimension = dimension
        this.contextOptions = contextOptions
        this.cacheOptions = cacheOptions
    }
}

================
File: src/types/MemoryTypes.ts
================
export interface LLMProvider {
    generateEmbedding(model: string, input: string): Promise<number[]>
    generateChat(model: string, messages: ChatMessage[], options?: Record<string, any>): Promise<string>
    generateCompletion(model: string, prompt: string, options?: Record<string, any>): Promise<string>
}

export interface ChatMessage {
    role: 'system' | 'user' | 'assistant'
    content: string
}

export interface CacheOptions {
    maxSize: number
    ttl: number
}

export interface ContextOptions {
    maxTokens: number
    overlapRatio?: number
}

export interface MemoryConfig {
    llmProvider: LLMProvider
    chatModel?: string
    embeddingModel?: string
    storage?: StorageProvider
    dimension?: number
    contextOptions?: ContextOptions
    cacheOptions?: CacheOptions
}

export interface StorageProvider {
    loadHistory(): Promise<[Interaction[], Interaction[]]>
    saveMemoryToHistory(store: MemoryStore): Promise<void>
    close?(): Promise<void>
}

export interface MemoryStore {
    shortTermMemory: Interaction[]
    longTermMemory: Interaction[]
    embeddings: number[][]
    timestamps: number[]
    accessCounts: number[]
    conceptsList: string[][]
}

export interface Interaction {
    id: string
    prompt: string
    output: string
    embedding: number[]
    timestamp: number
    accessCount: number
    concepts: string[]
    decayFactor: number
}

export enum MemoryType {
    ShortTerm = 'short-term',
    LongTerm = 'long-term'
}

================
File: src/utils/EmbeddingValidator.js
================
// Validates embeddings and handles dimension standardization
export class EmbeddingValidator {
    constructor(config = {}) {
        // Default dimensions for different models
        this.dimensionMap = {
            'nomic-embed-text': 768,
            'qwen2:1.5b': 1536,
            'llama2': 4096,
            'default': 1536
        }

        // Override defaults with config
        Object.assign(this.dimensionMap, config.dimensions || {})
    }

    getDimension(model) {
        return this.dimensionMap[model] || this.dimensionMap.default
    }

    validateEmbedding(embedding, expectedDimension) {
        if (!Array.isArray(embedding)) {
            throw new TypeError('Embedding must be an array')
        }

        if (!embedding.every(x => typeof x === 'number' && !isNaN(x))) {
            throw new TypeError('Embedding must contain only valid numbers')
        }

        const actual = embedding.length
        if (actual !== expectedDimension) {
            throw new Error(`Embedding dimension mismatch: expected ${expectedDimension}, got ${actual}`)
        }

        return true
    }

    standardizeEmbedding(embedding, targetDimension) {
        this.validateEmbedding(embedding, embedding.length)
        const current = embedding.length

        if (current === targetDimension) {
            return embedding
        }

        if (current < targetDimension) {
            // Pad with zeros
            return [...embedding, ...new Array(targetDimension - current).fill(0)]
        }

        // Truncate to target dimension
        return embedding.slice(0, targetDimension)
    }

    // Utility method to check if padding/truncation would be lossy
    wouldBeLossy(embedding, targetDimension) {
        if (embedding.length <= targetDimension) {
            return false
        }

        // Check if truncated values would be non-zero
        return embedding.slice(targetDimension).some(x => Math.abs(x) > 1e-7)
    }
}

================
File: src/utils/FusekiDiscovery.js
================
// src/utils/FusekiDiscovery.js
export class FusekiDiscovery {
    constructor(baseUrl, credentials) {
        this.baseUrl = baseUrl;
        this.auth = Buffer.from(`${credentials.user}:${credentials.password}`).toString('base64');
    }

    async discoverEndpoints(dataset) {
        const endpoints = {
            base: `${this.baseUrl}/${dataset}`,
            query: null,
            update: null,
            gsp: null,
            upload: null
        };

        try {
            // Test SPARQL endpoints
            const sparqlTest = await this.testSparqlEndpoint(`${endpoints.base}`);
            if (sparqlTest) {
                endpoints.query = endpoints.base;
                endpoints.update = endpoints.base;
            }

            // Test GSP endpoints
            const gspTest = await this.testGSPEndpoint(`${endpoints.base}/data`);
            if (gspTest) {
                endpoints.gsp = `${endpoints.base}/data`;
            }

            // Test upload endpoint
            const uploadTest = await this.testUploadEndpoint(`${endpoints.base}/upload`);
            if (uploadTest) {
                endpoints.upload = `${endpoints.base}/upload`;
            }

            return {
                success: true,
                endpoints: this.cleanEndpoints(endpoints)
            };
        } catch (error) {
            return {
                success: false,
                error: error.message,
                endpoints: null
            };
        }
    }

    async testSparqlEndpoint(url) {
        try {
            const response = await fetch(url, {
                method: 'POST',
                headers: {
                    'Authorization': `Basic ${this.auth}`,
                    'Content-Type': 'application/sparql-query',
                    'Accept': 'application/json'
                },
                body: 'ASK { ?s ?p ?o }'
            });
            return response.ok;
        } catch {
            return false;
        }
    }

    async testGSPEndpoint(url) {
        try {
            const response = await fetch(url, {
                method: 'GET',
                headers: {
                    'Authorization': `Basic ${this.auth}`,
                    'Accept': 'text/turtle'
                }
            });
            return response.ok || response.status === 404; // 404 is ok, might mean empty graph
        } catch {
            return false;
        }
    }

    async testUploadEndpoint(url) {
        try {
            const response = await fetch(url, {
                method: 'POST',
                headers: {
                    'Authorization': `Basic ${this.auth}`,
                    'Content-Type': 'text/turtle'
                },
                body: '@prefix test: <http://test.org/> .'
            });
            return response.ok || response.status === 400; // 400 is ok, might mean invalid turtle
        } catch {
            return false;
        }
    }

    cleanEndpoints(endpoints) {
        return Object.fromEntries(
            Object.entries(endpoints).filter(([_, value]) => value !== null)
        );
    }
}

// Usage example:
/*
const discovery = new FusekiDiscovery('http://localhost:4030', {
    user: 'admin',
    password: 'admin123'
});

const endpoints = await discovery.discoverEndpoints('test-mem');
console.log(endpoints);
*/

================
File: src/utils/SPARQLHelpers.js
================
export class SPARQLHelpers {
    static createAuthHeader(user, password) {
        const credentials = Buffer.from(`${user}:${password}`).toString('base64')
        return `Basic ${credentials}`
    }

    static async executeSPARQLUpdate(endpoint, query, auth) {
        const response = await fetch(endpoint, {
            method: 'POST',
            headers: {
                'Content-Type': 'application/sparql-update',
                'Authorization': auth
            },
            body: query
        })

        if (!response.ok) {
            throw new Error(`SPARQL update failed: ${response.status}`)
        }

        return response
    }

    static async executeSPARQLQuery(endpoint, query, auth) {
        const response = await fetch(endpoint, {
            method: 'GET',
            headers: {
                'Accept': 'application/sparql-results+json',
                'Authorization': auth
            },
            body: query
        })

        if (!response.ok) {
            throw new Error(`SPARQL query failed: ${response.status}`)
        }

        return response.json()
    }

    static getDatasetEndpoint(baseUrl, dataset, operation) {
        return `${baseUrl}/${dataset}/${operation}`
    }
}

================
File: src/Config.js
================
/**
 * Configuration management for Semem system
 */
export default class Config {
    static defaults = {
        storage: {
            type: 'memory',
            options: {
                path: 'interaction_history.json',
                endpoint: 'http://localhost:8080',
                apiKey: '',
                timeout: 5000
            }
        },
        models: {
            chat: {
                provider: 'ollama',
                model: 'qwen2:1.5b',
                options: {}
            },
            embedding: {
                provider: 'ollama',
                model: 'nomic-embed-text',
                options: {}
            }
        },
        memory: {
            dimension: 1536,
            similarityThreshold: 40,
            contextWindow: 3,
            decayRate: 0.0001
        },
        sparqlEndpoints: [{
            label: "test-mem",
            user: "admin",
            password: "admin123",
            urlBase: "http://localhost:4030",
            dataset: "test-mem",
            query: "/test-mem",
            update: "/test-mem",
            upload: "/test-mem/upload",
            gspRead: "/test-mem/data",
            gspWrite: "/test-mem/data"
        }]
    }

    constructor(userConfig = {}) {
        this.initialized = false
        this.config = {}
        this.userConfig = userConfig
    }

    async init() {
        if (this.initialized) return

        try {
            this.config = this.mergeConfigs(Config.defaults, this.userConfig)
            this.applyEnvironmentOverrides()
            this.validateConfig()
            this.initialized = true
        } catch (error) {
            throw new Error(`Config initialization failed: ${error.message}`)
        }
    }

    mergeConfigs(defaults, user) {
        const merged = { ...defaults }

        for (const [key, value] of Object.entries(user)) {
            if (value && typeof value === 'object' && !Array.isArray(value)) {
                merged[key] = this.mergeConfigs(merged[key] || {}, value)
            } else {
                merged[key] = value
            }
        }
        return merged
    }

    validateConfig() {
        // Required sections
        const required = ['storage', 'models', 'sparqlEndpoints']
        for (const key of required) {
            if (!this.config[key]) {
                throw new Error(`Missing required config section: ${key}`)
            }
        }

        // Storage validation
        const validStorageTypes = ['memory', 'json', 'sparql']
        if (!validStorageTypes.includes(this.config.storage.type)) {
            throw new Error('Invalid storage type')
        }

        // Model validation
        const models = this.config.models
        if (!models.chat?.provider || !models.chat?.model ||
            !models.embedding?.provider || !models.embedding?.model) {
            throw new Error('Invalid model configuration')
        }

        // SPARQL endpoint validation
        const endpoint = this.config.sparqlEndpoints[0]
        if (!endpoint?.urlBase || !endpoint?.query || !endpoint?.update) {
            throw new Error('Invalid SPARQL endpoint configuration')
        }
    }

    applyEnvironmentOverrides() {
        // Handle environment variables with SEMEM_ prefix
        for (const [key, value] of Object.entries(process.env)) {
            if (key.startsWith('SEMEM_')) {
                const configPath = key.slice(6).toLowerCase().split('_')
                this.set(configPath.join('.'), value)
            }
        }
    }

    get(path) {
        if (!this.initialized) {
            this.init()
        }

        return path.split('.').reduce((obj, key) => {
            if (obj === undefined) return undefined
            return obj[key]
        }, this.config)
    }

    set(path, value) {
        if (!this.initialized) {
            this.init()
        }

        const keys = path.split('.')
        const last = keys.pop()
        const target = keys.reduce((obj, key) => {
            if (!obj[key]) obj[key] = {}
            return obj[key]
        }, this.config)

        target[last] = value
    }

    static create(userConfig = {}) {
        const config = new Config(userConfig)
        config.init()
        return config
    }

    toJSON() {
        const { password, ...safeConfig } = this.config
        return safeConfig
    }
}

================
File: src/ContextManager.js
================
import ContextWindowManager from './ContextWindowManager.js'
import logger from 'loglevel'

/**
 * Manages context windows and summaries for LLM interactions
 */
export default class ContextManager {
    constructor(options = {}) {
        this.maxTokens = options.maxTokens || 8192
        this.maxTimeWindow = options.maxTimeWindow || 24 * 60 * 60 * 1000 // 24 hours
        this.relevanceThreshold = options.relevanceThreshold || 0.7
        this.maxContextSize = options.maxContextSize || 5
        this.contextBuffer = []

        this.windowManager = new ContextWindowManager({
            maxWindowSize: this.maxTokens,
            minWindowSize: Math.floor(this.maxTokens / 4),
            overlapRatio: options.overlapRatio || 0.1
        })
    }

    /**
     * Add interaction to context buffer with similarity score
     */
    addToContext(interaction, similarity = 1.0) {
        if (!interaction || typeof interaction !== 'object') {
            logger.warn('Invalid interaction provided to context')
            return
        }

        this.contextBuffer.push({
            ...interaction,
            similarity,
            addedAt: Date.now()
        })

        if (this.contextBuffer.length > this.maxContextSize * 2) {
            this.pruneContext()
        }
    }

    /**
     * Remove old or low-relevance items from context
     */
    pruneContext() {
        const now = Date.now()
        this.contextBuffer = this.contextBuffer
            .filter(item => {
                const age = now - item.addedAt
                return age < this.maxTimeWindow && item.similarity >= this.relevanceThreshold
            })
            .sort((a, b) => b.similarity - a.similarity)
            .slice(0, this.maxContextSize)
    }

    /**
     * Create a concise summary of interactions grouped by concept
     */
    summarizeContext(interactions) {
        if (!Array.isArray(interactions) || interactions.length === 0) {
            return ''
        }

        const groupedInteractions = {}

        for (const interaction of interactions) {
            if (!interaction) continue

            const mainConcept = interaction.concepts?.[0] || 'general'
            if (!groupedInteractions[mainConcept]) {
                groupedInteractions[mainConcept] = []
            }
            groupedInteractions[mainConcept].push(interaction)
        }

        const summaries = []
        for (const [concept, group] of Object.entries(groupedInteractions)) {
            if (group.length === 1) {
                summaries.push(this.formatSingleInteraction(group[0]))
            } else {
                summaries.push(this.formatGroupSummary(concept, group))
            }
        }

        return summaries.join('\n\n')
    }

    /**
     * Format a single interaction for display
     */
    formatSingleInteraction(interaction) {
        if (!interaction?.prompt || !interaction?.output) {
            return ''
        }

        return `Q: ${interaction.prompt}\nA: ${interaction.output}`
    }

    /**
     * Create summary for a group of related interactions
     */
    formatGroupSummary(concept, interactions) {
        if (!Array.isArray(interactions) || interactions.length === 0) {
            return ''
        }

        const summaryLines = interactions
            .slice(0, 3) // Limit examples per group
            .map(i => {
                if (!i?.prompt || !i?.output) return null
                const truncatedOutput = i.output.substring(0, 50)
                return `- ${i.prompt} → ${truncatedOutput}${truncatedOutput.length < i.output.length ? '...' : ''}`
            })
            .filter(Boolean)

        if (summaryLines.length === 0) return ''

        return `Topic: ${concept}\n${summaryLines.join('\n')}`
    }

    /**
     * Build complete context including history and current prompt
     */
    buildContext(currentPrompt, retrievals = [], recentInteractions = [], options = {}) {
        if (!currentPrompt) {
            logger.warn('No current prompt provided to buildContext')
            return ''
        }

        this.pruneContext()

        // Add new relevant interactions
        retrievals?.forEach(retrieval => {
            if (retrieval?.interaction) {
                this.addToContext(retrieval.interaction, retrieval.similarity)
            }
        })

        // Add recent interactions
        recentInteractions?.forEach(interaction => {
            if (interaction) {
                this.addToContext(interaction, 0.9)
            }
        })

        const contextParts = []

        // Add system context if provided
        if (options.systemContext) {
            contextParts.push(`System Context: ${options.systemContext}`)
        }

        // Add summarized historical context
        const historicalContext = this.summarizeContext(
            this.contextBuffer.slice(0, this.maxContextSize)
        )

        if (historicalContext) {
            contextParts.push('Relevant Context:', historicalContext)
        }

        const fullContext = contextParts.join('\n\n')

        // Process through window manager if needed
        if (this.windowManager.estimateTokens(fullContext) > this.maxTokens) {
            const windows = this.windowManager.processContext(fullContext)
            return this.windowManager.mergeOverlappingContent(windows)
        }

        return fullContext
    }
}

================
File: src/ContextWindowManager.js
================
export default class ContextWindowManager {
    constructor(options = {}) {
        this.minWindowSize = options.minWindowSize || 1024
        this.maxWindowSize = options.maxWindowSize || 8192
        this.overlapRatio = options.overlapRatio || 0.1
        this.avgTokenLength = options.avgTokenLength || 4
    }

    estimateTokens(text) {
        return Math.ceil(text.length / this.avgTokenLength)
    }

    calculateWindowSize(input) {
        const estimatedTokens = this.estimateTokens(input)
        return Math.min(
            this.maxWindowSize,
            Math.max(this.minWindowSize, estimatedTokens * 1.2)
        )
    }

    createWindows(text, windowSize) {
        const windows = []
        const overlapSize = Math.floor(windowSize * this.overlapRatio)
        const stride = windowSize - overlapSize

        let position = 0
        while (position < text.length) {
            const end = Math.min(position + windowSize, text.length)
            const window = {
                text: text.slice(position, end),
                start: position,
                end: end
            }
            windows.push(window)
            if (end === text.length) break

            // Find next word boundary for clean split
            position += Math.max(1, stride)
            while (position < text.length && !text[position].match(/\s/)) {
                position++
            }
        }

        return windows
    }

    processContext(context, options = {}) {
        const windowSize = this.calculateWindowSize(context)
        const windows = this.createWindows(context, windowSize)
        return options.includeMetadata ?
            windows.map(w => ({ ...w, tokenEstimate: this.estimateTokens(w.text) })) :
            windows
    }

    mergeOverlappingContent(windows) {
        if (!windows?.length) return ''
        if (windows.length === 1) return windows[0].text

        let result = windows[0].text
        for (let i = 1; i < windows.length; i++) {
            const currText = windows[i].text
            const overlap = this._findOverlap(result, currText)
            if (overlap > 0) {
                result += currText.slice(overlap)
            } else {
                result += ' ' + currText
            }
        }
        return result.trim()
    }

    _findOverlap(prev, curr) {
        const minOverlap = Math.min(10, Math.floor(curr.length * 0.1))
        for (let len = Math.min(prev.length, curr.length); len >= minOverlap; len--) {
            const prevEnd = prev.slice(-len)
            const currStart = curr.slice(0, len)

            if (prevEnd === currStart) {
                // Verify word boundary
                const beforeChar = prev[prev.length - len - 1]
                const afterChar = curr[len]
                if (!beforeChar?.match(/\w/) && !afterChar?.match(/\w/)) {
                    return len
                }
            }
        }
        return 0
    }
}

================
File: src/index.js
================
// index.js
import { config } from './_old/config.js'

async function init() {
  await config.load()
  // rest of application logic
}

init().catch(console.error)

================
File: src/MemoryManager.js
================
import { v4 as uuidv4 } from 'uuid'
import logger from 'loglevel'
import MemoryStore from './stores/MemoryStore.js'
import InMemoryStore from './stores/InMemoryStore.js'
import ContextManager from './ContextManager.js'
import EmbeddingHandler from './handlers/EmbeddingHandler.js'
import CacheManager from './handlers/CacheManager.js'
import LLMHandler from './handlers/LLMHandler.js'

/**
 * Manages semantic memory operations, embeddings, and LLM interactions
 */
export default class MemoryManager {
    constructor({
        llmProvider,
        chatModel = 'qwen2:1.5b',
        embeddingModel = 'nomic-embed-text',
        storage = null,
        dimension = 1536,
        contextOptions = {
            maxTokens: 8192
        },
        cacheOptions = {
            maxSize: 1000,
            ttl: 3600000
        }
    }) {
        if (!llmProvider) {
            throw new Error('LLM provider is required')
        }

        // Normalize model names
        this.chatModel = String(chatModel)
        this.embeddingModel = String(embeddingModel)

        // Initialize components
        this.cacheManager = new CacheManager(cacheOptions)
        this.embeddingHandler = new EmbeddingHandler(
            llmProvider,
            this.embeddingModel,
            dimension,
            this.cacheManager
        )

        this.llmHandler = new LLMHandler(llmProvider, this.chatModel)
        this.memStore = new MemoryStore(dimension)
        this.storage = storage || new InMemoryStore()
        this.contextManager = new ContextManager(contextOptions)

        this.initialize()
    }

    async initialize() {
        try {
            const [shortTerm, longTerm] = await this.storage.loadHistory()
            logger.info(`Loading memory history: ${shortTerm.length} short-term, ${longTerm.length} long-term items`)

            for (const interaction of shortTerm) {
                const embedding = this.embeddingHandler.standardizeEmbedding(interaction.embedding)
                interaction.embedding = embedding
                this.memStore.shortTermMemory.push(interaction)
                this.memStore.embeddings.push(embedding)
                this.memStore.timestamps.push(interaction.timestamp)
                this.memStore.accessCounts.push(interaction.accessCount)
                this.memStore.conceptsList.push(interaction.concepts)
            }

            this.memStore.longTermMemory.push(...longTerm)
            this.memStore.clusterInteractions()
            logger.info('Memory initialization complete')
        } catch (error) {
            logger.error('Memory initialization failed:', error)
            throw error
        }
    }

    async addInteraction(prompt, output, embedding, concepts) {
        try {
            const interaction = {
                id: uuidv4(),
                prompt,
                output,
                embedding: this.embeddingHandler.standardizeEmbedding(embedding),
                timestamp: Date.now(),
                accessCount: 1,
                concepts,
                decayFactor: 1.0
            }

            this.memStore.shortTermMemory.push(interaction)
            this.memStore.embeddings.push(interaction.embedding)
            this.memStore.timestamps.push(interaction.timestamp)
            this.memStore.accessCounts.push(interaction.accessCount)
            this.memStore.conceptsList.push(interaction.concepts)

            await this.storage.saveMemoryToHistory(this.memStore)
            logger.info('Interaction added successfully')
        } catch (error) {
            logger.error('Failed to add interaction:', error)
            throw error
        }
    }

    async retrieveRelevantInteractions(query, similarityThreshold = 40, excludeLastN = 0) {
        try {
            const queryEmbedding = await this.embeddingHandler.generateEmbedding(query)
            const queryConcepts = await this.llmHandler.extractConcepts(query)
            return this.memStore.retrieve(queryEmbedding, queryConcepts, similarityThreshold, excludeLastN)
        } catch (error) {
            logger.error('Failed to retrieve interactions:', error)
            throw error
        }
    }

    async generateResponse(prompt, lastInteractions = [], retrievals = [], contextWindow = 3) {
        try {
            const context = this.contextManager.buildContext(
                prompt,
                retrievals,
                lastInteractions,
                { systemContext: "You're a helpful assistant with memory of past interactions." }
            )

            return await this.llmHandler.generateResponse(prompt, context)
        } catch (error) {
            logger.error('Error generating response:', error)
            throw error
        }
    }

    async generateEmbedding(text) {
        return await this.embeddingHandler.generateEmbedding(text)
    }

    async extractConcepts(text) {
        return await this.llmHandler.extractConcepts(text)
    }

    async dispose() {
        try {
            await this.storage.saveMemoryToHistory(this.memStore)
            this.cacheManager.dispose()

            if (this.storage?.close) {
                await this.storage.close()
            }

            this.memStore = null
        } catch (error) {
            logger.error('Error during shutdown:', error)
            throw error
        }
    }
}

================
File: src/PromptTemplates.js
================
/**
 * Manages prompt templates for different LLM models
 */
export default class PromptTemplates {
    static templates = {
        'llama2': {
            chat: (system, context, query) => {
                const messages = [{
                    role: 'system',
                    content: system
                }]

                if (context) {
                    messages.push({
                        role: 'user',
                        content: context
                    })
                    messages.push({
                        role: 'assistant',
                        content: 'I understand the context provided. How can I help with your query?'
                    })
                }

                messages.push({
                    role: 'user',
                    content: query
                })

                return messages
            },
            completion: (context, query) => {
                return `[INST] ${context ? `Context:\n${context}\n\n` : ''}Query: ${query} [/INST]`
            },
            extractConcepts: (text) => {
                return `[INST] Extract key concepts from the following text and return them as a JSON array of strings only. Example: ["concept1", "concept2"]. Text: "${text}" [/INST]`
            }
        },

        'mistral': {
            chat: (system, context, query) => {
                const messages = [{
                    role: 'system',
                    content: system
                }]

                if (context) {
                    messages.push({
                        role: 'user',
                        content: `Previous Context:\n${context}`
                    })
                    messages.push({
                        role: 'assistant',
                        content: 'Context received. What would you like to know?'
                    })
                }

                messages.push({
                    role: 'user',
                    content: query
                })

                return messages
            },
            completion: (context, query) => {
                return `<s>[INST] ${context ? `${context}\n\n` : ''}${query} [/INST]`
            },
            extractConcepts: (text) => {
                return `<s>[INST] Extract and return only a JSON array of key concepts from: "${text}" [/INST]`
            }
        }
    };

    static getTemplateForModel(modelName) {
        if (typeof modelName !== 'string') {
            throw new TypeError('Model name must be a string')
        }
        const baseModel = modelName.split(':')[0].toLowerCase()
        const modelFamily = baseModel.replace(/[\d.]/g, '')
        return this.templates[modelFamily] || this.templates['llama2']
    }

    static formatChatPrompt(modelName, system, context, query) {
        const template = this.getTemplateForModel(modelName)
        return template.chat(system, context, query)
    }

    static formatCompletionPrompt(modelName, context, query) {
        const template = this.getTemplateForModel(modelName)
        return template.completion(context, query)
    }

    static formatConceptPrompt(modelName, text) {
        const template = this.getTemplateForModel(modelName)
        return template.extractConcepts(text)
    }

    static registerTemplate(modelName, template) {
        if (!template.chat || !template.completion || !template.extractConcepts) {
            throw new Error('Template must implement chat, completion, and extractConcepts methods')
        }
        this.templates[modelName.toLowerCase()] = template
    }
}

================
File: src/Utils.js
================
// Logging utility
export const logger = {
    info: (...args) => console.log('[INFO]', ...args),
    error: (...args) => console.error('[ERROR]', ...args),
    debug: (...args) => console.debug('[DEBUG]', ...args)
};

// Helper functions for vector operations
export const vectorOps = {
    normalize: (vector) => {
        const magnitude = Math.sqrt(vector.reduce((sum, val) => sum + val * val, 0));
        return vector.map(val => val / magnitude);
    },
    
    cosineSimilarity: (vec1, vec2) => {
        const dotProduct = vec1.reduce((sum, val, i) => sum + val * vec2[i], 0);
        const mag1 = Math.sqrt(vec1.reduce((sum, val) => sum + val * val, 0));
        const mag2 = Math.sqrt(vec2.reduce((sum, val) => sum + val * val, 0));
        return dotProduct / (mag1 * mag2);
    }
};

================
File: tests/bash/check_fuseki.sh
================
#!/bin/bash

echo -e "\nAdding test data..."
curl -v POST http://localhost:4030/test-mem \
  -H "Authorization: Basic $(echo -n 'admin:admin123' | base64)" \
  -H "Content-Type: application/sparql-update" \
  --data "INSERT DATA { <http://example/s> <http://example/p> <http://example/o> }"

echo -e "\nQuerying..."
curl -v GET http://localhost:4030/test-mem \
  -H "Authorization: Basic $(echo -n 'admin:admin123' | base64)" \
  -H "Content-Type: application/sparql-query" \
  -H "Accept: application/sparql-results+json" \
  --data "SELECT * WHERE { ?s ?p ?o }"


echo -e "\nQuerying data (SELECT)..."
curl -v POST http://localhost:4030/test-mem \
  -H "Authorization: Basic $(echo -n 'admin:admin123' | base64)" \
  -H "Content-Type: application/sparql-query" \
  -H "Accept: application/sparql-results+json" \
  --data "SELECT * WHERE { ?s ?p ?o }"




####################################
echo "Waiting for Fuseki to be ready..."
until curl -s http://localhost:4030/$/ping > /dev/null; do
    echo "Waiting for Fuseki..."
    sleep 2
done
echo "Fuseki is up!"

# Check datasets
echo "Checking datasets..."
curl -X GET http://localhost:4030/$/datasets \
  -H "Authorization: Basic $(echo -n 'admin:admin123' | base64)" && echo -e "\nDataset check - It works!"

echo -e "\nAdding test data..."
curl -X POST http://localhost:4030/ds \
  -H "Authorization: Basic $(echo -n 'admin:admin123' | base64)" \
  -H "Content-Type: application/sparql-update" \
  --data "INSERT DATA { <http://example/s> <http://example/p> <http://example/o> }" && echo "Insert - It works!"

echo -e "\nQuerying data (SELECT)..."
curl -X POST http://localhost:4030/ds \
  -H "Authorization: Basic $(echo -n 'admin:admin123' | base64)" \
  -H "Content-Type: application/sparql-query" \
  -H "Accept: application/sparql-results+json" \
  --data "SELECT * WHERE { ?s ?p ?o }" && echo "Select - It works!"

echo -e "\nQuerying data (CONSTRUCT)..."
curl -X POST http://localhost:4030/ds \
  -H "Authorization: Basic $(echo -n 'admin:admin123' | base64)" \
  -H "Content-Type: application/sparql-query" \
  -H "Accept: text/turtle" \
  --data "CONSTRUCT { ?s ?p ?o } WHERE { ?s ?p ?o }" && echo "Construct - It works!"

================
File: tests/bash/test-endpoints.sh
================
#!/bin/bash

# Configuration
BASE_URL="http://localhost:4030"
DATASET="test-mem"
AUTH_HEADER="Basic $(echo -n 'admin:admin123' | base64)"
TEST_GRAPH="http://example.org/test-graph"

# Color output
GREEN='\033[0;32m'
RED='\033[0;31m'
NC='\033[0m'

# Helper function for testing endpoints
test_endpoint() {
    local name=$1
    local method=$2
    local url=$3
    local content_type=$4
    local accept_type=$5
    local data=$6

    echo -e "\nTesting ${name}..."
    echo "URL: ${url}"
    echo "Method: ${method}"

    response=$(curl -v -s -w "\n%{http_code}" -X $method \
        -H "Authorization: $AUTH_HEADER" \
        ${content_type:+-H "Content-Type: $content_type"} \
        ${accept_type:+-H "Accept: $accept_type"} \
        ${data:+-d "$data"} \
        "$url")

    status_code=$(echo "$response" | tail -n1)
    response_body=$(echo "$response" | sed '$d')

    if [ "$status_code" -eq 200 ]; then
        echo -e "${GREEN}Success! Status: $status_code${NC}"
        echo "Response: $response_body"
    else
        echo -e "${RED}Failed! Status: $status_code${NC}"
        echo "Response: $response_body"
    fi
}

# 1. Test SPARQL Query endpoint
test_endpoint "SPARQL Query" "POST" \
    "$BASE_URL/$DATASET" \
    "application/sparql-query" \
    "application/json" \
    "SELECT * WHERE { ?s ?p ?o } LIMIT 1"

# 2. Test SPARQL Update endpoint
test_endpoint "SPARQL Update" "POST" \
    "$BASE_URL/$DATASET" \
    "application/sparql-update" \
    "application/json" \
    "INSERT DATA { GRAPH <$TEST_GRAPH> { <http://example/s> <http://example/p> 'test' } }"

# 3. Test Graph Store Protocol (GET)
test_endpoint "GSP Read" "GET" \
    "$BASE_URL/$DATASET/data?graph=$TEST_GRAPH" \
    "" \
    "text/turtle"

# 4. Test Graph Store Protocol (POST)
test_endpoint "GSP Write" "POST" \
    "$BASE_URL/$DATASET/data?graph=$TEST_GRAPH" \
    "text/turtle" \
    "application/json" \
    "@prefix ex: <http://example.org/> . ex:s ex:p 'test' ."

# 5. Test File Upload endpoint
test_endpoint "File Upload" "POST" \
    "$BASE_URL/$DATASET/upload" \
    "text/turtle" \
    "application/json" \
    "@prefix ex: <http://example.org/> . ex:s ex:p 'test' ."

# Additional useful endpoints
# 6. Test Dataset Info
test_endpoint "Dataset Info" "GET" \
    "$BASE_URL/$DATASET/stats" \
    "" \
    "application/json"

# 7. Test if dataset exists
test_endpoint "Dataset Existence" "GET" \
    "$BASE_URL/$DATASET" \
    "" \
    "application/json"

================
File: tests/helpers/jasmine_examples/SpecHelper.js
================
beforeEach(function () {
  jasmine.addMatchers({
    toBePlaying: function () {
      return {
        compare: function (actual, expected) {
          const player = actual;

          return {
            pass: player.currentlyPlayingSong === expected && player.isPlaying
          };
        }
      };
    }
  });
});

================
File: tests/helpers/reporter.js
================
import { SpecReporter } from 'jasmine-spec-reporter';

class CustomReporter {
    constructor() {
        this.specReporter = new SpecReporter({
            spec: {
                displayPending: true // Display pending (not fully implemented) specs
            }
        });
    }

    jasmineStarted() {
        this.specReporter.jasmineStarted.apply(this.specReporter, arguments);
    }

    suiteStarted() {
        this.specReporter.suiteStarted.apply(this.specReporter, arguments);
    }

    specStarted() {
        this.specReporter.specStarted.apply(this.specReporter, arguments);
    }

    specDone() {
        this.specReporter.specDone.apply(this.specReporter, arguments);
    }

    suiteDone() {
        this.specReporter.suiteDone.apply(this.specReporter, arguments);
    }

    jasmineDone() {
        this.specReporter.jasmineDone.apply(this.specReporter, arguments);
    }
}

export default CustomReporter;

/*
import { SpecReporter } from 'jasmine-spec-reporter';

jasmine.getEnv().clearReporters(); // Clear default console reporter
jasmine.getEnv().addReporter(new SpecReporter({
    spec: {
        displayPending: true // Display pending (not fully implemented) specs
    }
}));
*/

================
File: tests/helpers/setupGlobals.js
================
import fetch from 'node-fetch'
import { TextEncoder, TextDecoder } from 'util'

// Polyfill globals for Node.js environment
globalThis.fetch = fetch
globalThis.TextEncoder = TextEncoder
globalThis.TextDecoder = TextDecoder

================
File: tests/helpers/setupSPARQL.js
================
import { SPARQLHelpers } from '../../src/utils/SPARQLHelpers.js'

export async function setupSPARQLTestEnvironment(config) {
    const endpoints = await config.get('sparqlEndpoints')
    if (!endpoints?.length) throw new Error('No SPARQL endpoints configured')

    const sparqlConfig = endpoints[0]
    const { user, password, urlBase, dataset } = sparqlConfig

    if (!user || !password || !urlBase || !dataset) {
        throw new Error('Invalid SPARQL endpoint configuration')
    }

    const auth = SPARQLHelpers.createAuthHeader(user, password)
    return { baseUrl: urlBase, dataset, auth }
}

export async function initTestGraphs(config) {
    const { baseUrl, dataset, auth } = await setupSPARQLTestEnvironment(config)

    const testGraphs = [
        'test-mem',
        'test-backup-basic',
        'test-backup-advanced',
        'test-memory'
    ]

    for (const graph of testGraphs) {
        const endpoint = `${baseUrl}/${dataset}/update`
        const graphUri = `http://example.org/mcp/${graph}`

        try {
            const query = `
                DROP SILENT GRAPH <${graphUri}>;
                CREATE GRAPH <${graphUri}>
            `

            console.log(`Creating graph ${graphUri} at ${endpoint}`)
            await SPARQLHelpers.executeSPARQLUpdate(endpoint, query, auth)
        } catch (error) {
            console.error(`Failed to create graph ${graph}:`, error)
            throw error
        }
    }
}

================
File: tests/integration/examples/OllamaExample.spec.js
================
import Config from '../../../src/Config.js'
import MemoryManager from '../../../src/MemoryManager.js'

describe('OllamaExample Integration', () => {
    let config
    let mockOllama
    let mockStorage
    let memoryManager

    beforeEach(() => {
        mockOllama = {
            generateEmbedding: jasmine.createSpy('generateEmbedding')
                .and.resolveTo(new Array(1536).fill(0)),
            generateChat: jasmine.createSpy('generateChat')
                .and.resolveTo('test response'),
            generateCompletion: jasmine.createSpy('generateCompletion')
                .and.resolveTo('["concept"]')
        }

        mockStorage = {
            loadHistory: jasmine.createSpy('loadHistory').and.resolveTo([[], []]),
            saveMemoryToHistory: jasmine.createSpy('saveMemoryToHistory'),
            close: jasmine.createSpy('close')
        }

        config = Config.create({
            storage: {
                type: 'json',
                options: { path: 'test.json' }
            },
            models: {
                chat: {
                    provider: 'ollama',
                    model: 'test-chat'
                },
                embedding: {
                    provider: 'ollama',
                    model: 'test-embed'
                }
            }
        })
    })

    it('should initialize with config values', () => {
        memoryManager = new MemoryManager({
            llmProvider: mockOllama,
            chatModel: config.get('models.chat.model'),
            embeddingModel: config.get('models.embedding.model'),
            storage: mockStorage
        })

        expect(memoryManager.chatModel).toBe('test-chat')
        expect(memoryManager.embeddingModel).toBe('test-embed')
    })

    it('should handle full interaction flow', async () => {
        memoryManager = new MemoryManager({
            llmProvider: mockOllama,
            chatModel: config.get('models.chat.model'),
            embeddingModel: config.get('models.embedding.model'),
            storage: mockStorage
        })

        const prompt = 'test prompt'

        const relevantInteractions = await memoryManager.retrieveRelevantInteractions(prompt)
        expect(mockOllama.generateEmbedding).toHaveBeenCalled()

        const response = await memoryManager.generateResponse(prompt, [], relevantInteractions)
        expect(mockOllama.generateChat).toHaveBeenCalled()

        const embedding = await memoryManager.generateEmbedding(`${prompt} ${response}`)
        const concepts = await memoryManager.extractConcepts(`${prompt} ${response}`)

        await memoryManager.addInteraction(prompt, response, embedding, concepts)
        expect(mockStorage.saveMemoryToHistory).toHaveBeenCalled()
    })

    afterEach(async () => {
        if (memoryManager) {
            await memoryManager.dispose()
        }
    })
})

================
File: tests/integration/http/HTTPServer.integration.spec.js
================
// tests/integration/http/HTTPServer.integration.spec.js
import HTTPServer from '../../../src/api/http/server/HTTPServer.js'
import fetch from 'node-fetch'
import WebSocket from 'ws'

describe('HTTPServer Integration', () => {
    let server
    let baseUrl
    const PORT = 8082
    const AUTH_HEADER = Buffer.from('admin:admin123').toString('base64')

    beforeAll(async () => {
        server = new HTTPServer({ port: PORT })
        await server.initialize()
        baseUrl = `http://localhost:${PORT}`
    })

    afterAll(async () => {
        await server.shutdown()
    })

    describe('REST API', () => {
        it('should handle memory operations', async () => {
            const interaction = {
                prompt: 'test prompt',
                output: 'test output',
                embedding: new Array(1536).fill(0),
                timestamp: Date.now(),
                concepts: ['test']
            }

            const saveResponse = await fetch(`${baseUrl}/api/memory`, {
                method: 'POST',
                headers: {
                    'Authorization': `Basic ${AUTH_HEADER}`,
                    'Content-Type': 'application/json'
                },
                body: JSON.stringify(interaction)
            })
            expect(saveResponse.ok).toBeTrue()

            const searchResponse = await fetch(
                `${baseUrl}/api/memory/search?text=test&limit=1`,
                {
                    headers: { 'Authorization': `Basic ${AUTH_HEADER}` }
                }
            )
            const results = await searchResponse.json()
            expect(results.success).toBeTrue()
            expect(results.data.length).toBe(1)
        })

        it('should handle chat operations', async () => {
            const response = await fetch(`${baseUrl}/api/chat`, {
                method: 'POST',
                headers: {
                    'Authorization': `Basic ${AUTH_HEADER}`,
                    'Content-Type': 'application/json'
                },
                body: JSON.stringify({
                    prompt: 'Hello',
                    model: 'qwen2:1.5b'
                })
            })

            const result = await response.json()
            expect(result.success).toBeTrue()
            expect(result.data).toBeTruthy()
        })

        it('should enforce rate limits', async () => {
            const requests = Array(101).fill().map(() =>
                fetch(`${baseUrl}/api/health`)
            )

            const responses = await Promise.all(requests)
            const blocked = responses.filter(r => r.status === 429)
            expect(blocked.length).toBeGreaterThan(0)
        })
    })

    describe('Authentication', () => {
        it('should reject invalid credentials', async () => {
            const invalidAuth = Buffer.from('wrong:pass').toString('base64')
            const response = await fetch(`${baseUrl}/api/memory`, {
                method: 'POST',
                headers: {
                    'Authorization': `Basic ${invalidAuth}`,
                    'Content-Type': 'application/json'
                },
                body: JSON.stringify({})
            })

            expect(response.status).toBe(401)
        })

        it('should allow public health endpoints', async () => {
            const response = await fetch(`${baseUrl}/api/health`)
            expect(response.ok).toBeTrue()

            const health = await response.json()
            expect(health.status).toBe('healthy')
        })
    })

    describe('WebSocket Integration', () => {
        it('should handle WebSocket connections', async () => {
            const ws = new WebSocket(`ws://localhost:${PORT}/ws`, {
                headers: { 'Authorization': `Basic ${AUTH_HEADER}` }
            })

            const connected = await new Promise(resolve => {
                ws.once('open', () => resolve(true))
                ws.once('error', () => resolve(false))
            })

            expect(connected).toBeTrue()
            ws.close()
        })

        it('should handle message broadcasts', async () => {
            const ws = new WebSocket(`ws://localhost:${PORT}/ws`, {
                headers: { 'Authorization': `Basic ${AUTH_HEADER}` }
            })

            await new Promise(resolve => ws.once('open', resolve))

            ws.send(JSON.stringify({
                type: 'subscribe',
                topic: 'test'
            }))

            const message = await new Promise(resolve => {
                ws.once('message', data => {
                    resolve(JSON.parse(data.toString()))
                })
                server.wsServer.broadcast('test', { data: 'test' })
            })

            expect(message.topic).toBe('test')
            ws.close()
        })
    })

    describe('Error Handling', () => {
        it('should handle validation errors', async () => {
            const response = await fetch(`${baseUrl}/api/memory`, {
                method: 'POST',
                headers: {
                    'Authorization': `Basic ${AUTH_HEADER}`,
                    'Content-Type': 'application/json'
                },
                body: JSON.stringify({
                    invalid: 'data'
                })
            })

            const error = await response.json()
            expect(error.success).toBeFalse()
            expect(error.error).toBeTruthy()
        })

        it('should handle malformed requests', async () => {
            const response = await fetch(`${baseUrl}/api/chat`, {
                method: 'POST',
                headers: {
                    'Authorization': `Basic ${AUTH_HEADER}`,
                    'Content-Type': 'application/json'
                },
                body: 'invalid json'
            })

            expect(response.status).toBe(400)
        })
    })

    describe('Metrics', () => {
        it('should collect request metrics', async () => {
            await fetch(`${baseUrl}/api/metrics`, {
                headers: { 'Authorization': `Basic ${AUTH_HEADER}` }
            })

            const metricsResponse = await fetch(`${baseUrl}/api/metrics`, {
                headers: { 'Authorization': `Basic ${AUTH_HEADER}` }
            })
            const metrics = await metricsResponse.json()

            expect(metrics.success).toBeTrue()
            expect(metrics.data.http).toBeDefined()
            expect(metrics.data.http.requests).toBeGreaterThan(0)
        })

        it('should track response codes', async () => {
            const invalidPath = `${baseUrl}/api/invalid`
            await fetch(invalidPath, {
                headers: { 'Authorization': `Basic ${AUTH_HEADER}` }
            })

            const metricsResponse = await fetch(`${baseUrl}/api/metrics`, {
                headers: { 'Authorization': `Basic ${AUTH_HEADER}` }
            })
            const metrics = await metricsResponse.json()

            expect(metrics.data.http.status['404']).toBeGreaterThan(0)
        })
    })
})

================
File: tests/integration/http/websocket-integration.spec.js
================
// tests/integration/http/websocket-integration.spec.js
import { WebSocketServer, WebSocket } from 'ws'
import { EventEmitter } from 'events'
import MemoryWebSocketServer from '../../../src/api/http/server/WebSocketServer.js'
import MessageQueue from '../../../src/api/http/server/MessageQueue.js'

describe('WebSocket Integration', () => {
    const PORT = 8081
    const WS_URL = `ws://localhost:${PORT}/ws`
    const AUTH_HEADER = Buffer.from('admin:admin123').toString('base64')

    let server
    let mockHttpServer

    // Helper to create authenticated websocket connection
    const connectWS = (headers = {}) => new Promise((resolve, reject) => {
        const ws = new WebSocket(WS_URL, {
            headers: {
                'Authorization': `Basic ${AUTH_HEADER}`,
                ...headers
            }
        })
        const timeout = setTimeout(() => {
            ws.close()
            reject(new Error('Connection timeout'))
        }, 2000)

        ws.once('open', () => {
            clearTimeout(timeout)
            resolve(ws)
        })
        ws.once('error', reject)
    })

    beforeEach(() => {
        mockHttpServer = new EventEmitter()
        mockHttpServer.address = () => ({ port: PORT })
        server = new MemoryWebSocketServer(mockHttpServer)
    })

    afterEach(() => {
        server.close()
    })

    describe('Connection Management', () => {
        let ws

        afterEach(() => {
            if (ws?.readyState === WebSocket.OPEN) {
                ws.close()
            }
        })

        it('should authenticate connections with valid credentials', async () => {
            ws = await connectWS()
            expect(ws.readyState).toBe(WebSocket.OPEN)

            // Verify welcome message
            const message = await new Promise(resolve => {
                ws.once('message', data => {
                    resolve(JSON.parse(data.toString()))
                })
            })
            expect(message.type).toBe('connected')
            expect(message.clientId).toBeDefined()
        })

        it('should reject invalid credentials', async () => {
            const invalidAuth = Buffer.from('wrong:pass').toString('base64')
            await expectAsync(
                connectWS({ 'Authorization': `Basic ${invalidAuth}` })
            ).toBeRejected()
        })

        it('should handle disconnection cleanup', async () => {
            ws = await connectWS()
            const clientId = server.clients.keys().next().value

            ws.close()
            await new Promise(resolve => ws.once('close', resolve))

            expect(server.clients.has(clientId)).toBe(false)
        })
    })

    describe('Message Queue Management', () => {
        let ws
        let clientId

        beforeEach(async () => {
            ws = await connectWS()
            const msg = await new Promise(resolve => {
                ws.once('message', data => {
                    resolve(JSON.parse(data.toString()))
                })
            })
            clientId = msg.clientId
        })

        afterEach(() => {
            if (ws.readyState === WebSocket.OPEN) {
                ws.close()
            }
        })

        it('should handle topic subscriptions', async () => {
            ws.send(JSON.stringify({
                type: 'subscribe',
                topic: 'test-topic'
            }))

            // Send test message
            server.broadcast('test-topic', { data: 'test' })

            const message = await new Promise(resolve => {
                ws.once('message', data => {
                    resolve(JSON.parse(data.toString()))
                })
            })

            expect(message.topic).toBe('test-topic')
            expect(message.data.data).toBe('test')
        })

        it('should queue messages for offline clients', async () => {
            // Subscribe and close connection
            ws.send(JSON.stringify({
                type: 'subscribe',
                topic: 'test-topic'
            }))
            ws.close()
            await new Promise(resolve => ws.once('close', resolve))

            // Send message while offline
            server.broadcast('test-topic', { data: 'offline-test' })

            // Reconnect
            ws = await connectWS()

            // Should receive queued message
            const message = await new Promise(resolve => {
                ws.once('message', data => {
                    resolve(JSON.parse(data.toString()))
                })
            })

            expect(message.type).toBe('queued_message')
            expect(message.topic).toBe('test-topic')
            expect(message.message.data).toBe('offline-test')
        })

        it('should handle message acknowledgments', async () => {
            ws.send(JSON.stringify({
                type: 'subscribe',
                topic: 'test-topic'
            }))

            server.broadcast('test-topic', { data: 'test' })

            const message = await new Promise(resolve => {
                ws.once('message', data => {
                    resolve(JSON.parse(data.toString()))
                })
            })

            ws.send(JSON.stringify({
                type: 'ack',
                messageIds: [message.id]
            }))

            // Wait for ack processing
            await new Promise(resolve => setTimeout(resolve, 100))

            const queuedMessages = server.messageQueue.getMessages(clientId)
            expect(queuedMessages.length).toBe(0)
        })
    })

    describe('Error Handling', () => {
        let ws

        beforeEach(async () => {
            ws = await connectWS()
        })

        afterEach(() => {
            if (ws.readyState === WebSocket.OPEN) {
                ws.close()
            }
        })

        it('should handle malformed messages', async () => {
            ws.send('invalid json')

            const error = await new Promise(resolve => {
                ws.once('message', data => {
                    resolve(JSON.parse(data.toString()))
                })
            })

            expect(error.type).toBe('error')
            expect(error.error).toBe('Invalid message format')
        })

        it('should handle rate limiting', async () => {
            // Send messages rapidly
            for (let i = 0; i < 100; i++) {
                ws.send(JSON.stringify({ type: 'ping' }))
            }

            const error = await new Promise(resolve => {
                ws.once('message', data => {
                    resolve(JSON.parse(data.toString()))
                })
            })

            expect(error.type).toBe('error')
            expect(error.error).toContain('rate limit')
        })
    })
})

================
File: tests/integration/llms/LLMHandler.integration.spec.js
================
// tests/integration/llms/LLMHandler.integration.spec.js
import LLMHandler from '../../../src/handlers/LLMHandler.js'
import OllamaConnector from '../../../src/connectors/OllamaConnector.js'
import PromptTemplates from '../../../src/PromptTemplates.js'

describe('LLMHandler Integration', () => {
    let handler
    let llmProvider
    const chatModel = 'qwen2:1.5b'
    const timeout = 30000 // 30s timeout for LLM operations

    beforeAll(async () => {
        llmProvider = new OllamaConnector('http://localhost:11434')
        handler = new LLMHandler(llmProvider, chatModel)

        // Verify Ollama availability
        try {
            await fetch('http://localhost:11434/api/tags')
        } catch (e) {
            pending('Ollama server not available - skipping integration tests')
        }
    })

    describe('Chat Response Generation', () => {
        it('should generate coherent responses', async () => {
            const prompt = 'What is semantic memory?'
            const response = await handler.generateResponse(prompt)

            expect(response).toBeTruthy()
            expect(typeof response).toBe('string')
            expect(response.length).toBeGreaterThan(50)
        }, timeout)

        it('should incorporate context in responses', async () => {
            const context = 'Previous discussion was about neural networks.'
            const prompt = 'How does this relate to deep learning?'

            const response = await handler.generateResponse(prompt, context)

            expect(response).toBeTruthy()
            expect(response.toLowerCase()).toContain('neural')
        }, timeout)

        it('should respect temperature settings', async () => {
            handler.setTemperature(0.1) // More deterministic
            const prompt = 'Count from 1 to 5.'

            const response1 = await handler.generateResponse(prompt)
            const response2 = await handler.generateResponse(prompt)

            expect(response1).toBeTruthy()
            expect(response2).toBeTruthy()
            expect(response1).toEqual(response2)
        }, timeout)
    })

    describe('Concept Extraction', () => {
        it('should extract relevant concepts', async () => {
            const text = 'Neural networks are computational systems inspired by biological brains.'
            const concepts = await handler.extractConcepts(text)

            expect(Array.isArray(concepts)).toBeTrue()
            expect(concepts.length).toBeGreaterThan(0)
            expect(concepts).toContain(jasmine.stringMatching(/neural|network|brain/i))
        }, timeout)

        it('should handle empty or simple input', async () => {
            const concepts1 = await handler.extractConcepts('')
            expect(Array.isArray(concepts1)).toBeTrue()
            expect(concepts1.length).toBe(0)

            const concepts2 = await handler.extractConcepts('Simple test.')
            expect(Array.isArray(concepts2)).toBeTrue()
            expect(concepts2.length).toBeGreaterThan(0)
        }, timeout)

        it('should deduplicate similar concepts', async () => {
            const text = 'AI and artificial intelligence are the same thing'
            const concepts = await handler.extractConcepts(text)

            const aiRelated = concepts.filter(c =>
                /\b(ai|artificial intelligence)\b/i.test(c)
            )
            expect(aiRelated.length).toBe(1)
        }, timeout)
    })

    describe('Error Handling', () => {
        it('should handle network errors gracefully', async () => {
            const badProvider = new OllamaConnector('http://invalid-url:11434')
            const badHandler = new LLMHandler(badProvider, chatModel)

            await expectAsync(
                badHandler.generateResponse('test')
            ).toBeRejectedWithError(/network|connection/i)
        })

        it('should handle malformed responses', async () => {
            const mockProvider = {
                generateChat: () => Promise.resolve(null),
                generateCompletion: () => Promise.resolve('invalid json')
            }
            const mockHandler = new LLMHandler(mockProvider, chatModel)

            const concepts = await mockHandler.extractConcepts('test')
            expect(Array.isArray(concepts)).toBeTrue()
            expect(concepts.length).toBe(0)
        })

        it('should respect timeout limits', async () => {
            handler.setTimeout(100) // Very short timeout

            await expectAsync(
                handler.generateResponse('Write a very long essay.')
            ).toBeRejectedWithError(/timeout/i)
        })
    })

    describe('Template Handling', () => {
        it('should use correct templates for model', async () => {
            const prompt = 'test prompt'
            const context = 'test context'

            const messages = PromptTemplates.formatChatPrompt(
                chatModel,
                'system prompt',
                context,
                prompt
            )

            const response = await handler.generateResponse(prompt, context)
            expect(response).toBeTruthy()
        }, timeout)

        it('should format system prompts correctly', async () => {
            const systemPrompt = 'You are a helpful AI assistant.'
            const prompt = 'Who are you?'

            const response = await handler.generateResponse(
                prompt,
                null,
                systemPrompt
            )

            expect(response.toLowerCase()).toContain('help')
        }, timeout)
    })
})

================
File: tests/integration/llms/Ollama.spec.js
================
import fetch from 'node-fetch'
import OllamaConnector from '../../../src/connectors/OllamaConnector.js'
import { EmbeddingValidator } from '../../../src/utils/EmbeddingValidator.js'

globalThis.fetch = fetch

describe('OllamaConnector Integration', () => {
    jasmine.DEFAULT_TIMEOUT_INTERVAL = 30000 // 30 second timeout
    let api
    let validator
    let ollamaAvailable = false

    beforeAll(async () => {
        try {
            const response = await fetch('http://localhost:11434/api/tags')
            ollamaAvailable = response.ok
        } catch (e) {
            console.warn('Ollama server not available - skipping integration tests')
        }
    })

    beforeEach(() => {
        api = new OllamaConnector('http://localhost:11434')
        validator = new EmbeddingValidator({
            dimensions: {
                'nomic-embed-text': 768
            }
        })
    })

    it('should generate chat response', async () => {
        if (!ollamaAvailable) pending('Ollama server not available')

        const messages = [{
            role: 'user',
            content: 'Hello, how are you?'
        }]

        const response = await api.generateChat('qwen2:1.5b', messages)
        expect(typeof response).toBe('string')
        expect(response.length).toBeGreaterThan(0)
    })

    it('should generate embeddings', async () => {
        if (!ollamaAvailable) pending('Ollama server not available')

        const embedding = await api.generateEmbedding(
            'nomic-embed-text',
            'Test text for embedding'
        )

        expect(Array.isArray(embedding)).toBe(true)
        expect(embedding.length).toBe(768)
        expect(validator.validateEmbedding(embedding, 768)).toBe(true)
    })
})

================
File: tests/integration/sparql/sparql-advanced-backup-spec.js
================
import Config from '../../../src/Config.js';
import SPARQLStore from '../../../src/stores/SPARQLStore.js';
import { logger } from '../../../src/Utils.js';

describe('SPARQLStore Advanced Backup Integration', () => {
    let store;
    let config;
    const testGraph = 'http://example.org/mcp/test-backup-advanced';
    let originalData;

    beforeAll(async () => {
        config = new Config();
        const sparqlConfig = config.get('sparqlEndpoints')[0];

        store = new SPARQLStore({
            query: `${sparqlConfig.urlBase}${sparqlConfig.query}`,
            update: `${sparqlConfig.urlBase}${sparqlConfig.update}`
        }, {
            user: sparqlConfig.user,
            password: sparqlConfig.password,
            graphName: testGraph
        });

        // Test data
        originalData = {
            shortTermMemory: [{
                id: 'advanced-backup-1',
                prompt: 'advanced backup test',
                output: 'original output',
                embedding: new Array(1536).fill(0).map(() => Math.random()),
                timestamp: Date.now(),
                accessCount: 1,
                concepts: ['advanced', 'backup'],
                decayFactor: 1.0
            }],
            longTermMemory: []
        };

        // Setup test graph
        try {
            await store.beginTransaction();
            const setupQuery = `
                DROP SILENT GRAPH <${testGraph}>;
                CREATE GRAPH <${testGraph}>
            `;
            await store._executeSparqlUpdate(setupQuery, store.endpoint.update);
            await store.commitTransaction();

            // Save initial data
            await store.saveMemoryToHistory(originalData);
        } catch (error) {
            logger.error('Error in advanced backup test setup:', error);
            throw error;
        }
    });

    afterAll(async () => {
        try {
            await store.beginTransaction();
            const cleanupQuery = `
                DROP SILENT GRAPH <${testGraph}>;
                DROP SILENT GRAPH <${testGraph}.backup>
            `;
            await store._executeSparqlUpdate(cleanupQuery, store.endpoint.update);
            await store.commitTransaction();
        } finally {
            await store.close();
        }
    });

    it('should handle backup corruption', async () => {
        await store.beginTransaction();

        // Corrupt backup by inserting invalid data
        const corruptQuery = `
            INSERT DATA {
                GRAPH <${testGraph}.backup> {
                    _:corrupt a mcp:Invalid ;
                        mcp:invalidProp "test" .
                }
            }
        `;
        await store._executeSparqlUpdate(corruptQuery, store.endpoint.update);

        // Attempt operation that should detect corruption
        const modifiedData = {
            shortTermMemory: [{
                ...originalData.shortTermMemory[0],
                output: 'corrupt test output'
            }],
            longTermMemory: []
        };

        // Should fail gracefully and maintain data integrity
        try {
            await store.saveMemoryToHistory(modifiedData);
            fail('Should have detected corruption');
        } catch (error) {
            // Verify original data is intact
            const [shortTerm] = await store.loadHistory();
            expect(shortTerm[0].output).toBe('original output');
        }

        await store.rollbackTransaction();
    });

    it('should perform incremental backups', async () => {
        await store.beginTransaction();

        // Add new data incrementally
        const updates = [
            { id: 'incremental-1', output: 'first update' },
            { id: 'incremental-2', output: 'second update' }
        ];

        for (const update of updates) {
            const incrementalData = {
                shortTermMemory: [
                    ...originalData.shortTermMemory,
                    {
                        ...originalData.shortTermMemory[0],
                        ...update
                    }
                ],
                longTermMemory: []
            };

            await store.saveMemoryToHistory(incrementalData);

            // Verify backup contains incremental changes
            const verifyQuery = `
                PREFIX mcp: <http://purl.org/stuff/mcp/>
                ASK {
                    GRAPH <${testGraph}.backup> {
                        ?s mcp:id "${update.id}" ;
                           mcp:output "${update.output}" .
                    }
                }
            `;
            const result = await store._executeSparqlQuery(verifyQuery, store.endpoint.query);
            expect(result.boolean).toBe(true);
        }

        // Rollback should restore to original state
        await store.rollbackTransaction();

        const [shortTerm] = await store.loadHistory();
        expect(shortTerm.length).toBe(1);
        expect(shortTerm[0].id).toBe('advanced-backup-1');
    });

    it('should handle concurrent backup operations', async () => {
        const store2 = new SPARQLStore({
            query: store.endpoint.query,
            update: store.endpoint.update
        }, {
            user: store.credentials.user,
            password: store.credentials.password,
            graphName: testGraph
        });

        await store.beginTransaction();

        // Second store should detect existing backup
        await expectAsync(store2.beginTransaction())
            .toBeRejectedWithError(/Transaction already in progress/);

        await store.rollbackTransaction();
        await store2.close();
    });

    it('should verify backup integrity', async () => {
        await store.beginTransaction();

        // Verify backup matches original data
        const verifyQuery = `
            PREFIX mcp: <http://purl.org/stuff/mcp/>
            SELECT ?prop ?value
            WHERE {
                GRAPH <${testGraph}> {
                    ?s1 mcp:id "advanced-backup-1" ;
                        ?prop ?value .
                }
                GRAPH <${testGraph}.backup> {
                    ?s2 mcp:id "advanced-backup-1" ;
                        ?prop ?value2 .
                    FILTER(?value = ?value2)
                }
            }
        `;

        const results = await store._executeSparqlQuery(verifyQuery, store.endpoint.query);
        expect(results.results.bindings.length).toBeGreaterThan(0);

        await store.rollbackTransaction();
    });

    it('should handle large backup operations', async () => {
        await store.beginTransaction();

        // Create large dataset
        const largeData = {
            shortTermMemory: Array(100).fill(null).map((_, i) => ({
                id: `large-backup-${i}`,
                prompt: `large backup test ${i}`,
                output: `test output ${i}`,
                embedding: new Array(1536).fill(0).map(() => Math.random()),
                timestamp: Date.now(),
                accessCount: 1,
                concepts: ['large', 'backup', `test-${i}`],
                decayFactor: 1.0
            })),
            longTermMemory: []
        };

        await store.saveMemoryToHistory(largeData);

        // Verify backup contains all entries
        const countQuery = `
            SELECT (COUNT(?s) as ?count)
            WHERE {
                GRAPH <${testGraph}.backup> {
                    ?s a mcp:Interaction
                }
            }
        `;

        const results = await store._executeSparqlQuery(countQuery, store.endpoint.query);
        expect(parseInt(results.results.bindings[0].count.value)).toBe(100);

        await store.rollbackTransaction();
    });
});

================
File: tests/integration/sparql/sparql-basic-backup-spec.js
================
import Config from '../../../src/Config.js';
import SPARQLStore from '../../../src/stores/SPARQLStore.js';
import { logger } from '../../../src/Utils.js';

describe('SPARQLStore Basic Backup Integration', () => {
    let store;
    let config;
    const testGraph = 'http://example.org/mcp/test-backup-basic';
    let originalData;

    beforeAll(async () => {
        config = new Config();
        const sparqlConfig = config.get('sparqlEndpoints')[0];

        store = new SPARQLStore({
            query: `${sparqlConfig.urlBase}${sparqlConfig.query}`,
            update: `${sparqlConfig.urlBase}${sparqlConfig.update}`
        }, {
            user: sparqlConfig.user,
            password: sparqlConfig.password,
            graphName: testGraph
        });

        // Test data
        originalData = {
            shortTermMemory: [{
                id: 'backup-test-1',
                prompt: 'backup test prompt',
                output: 'backup test output',
                embedding: new Array(1536).fill(0).map(() => Math.random()),
                timestamp: Date.now(),
                accessCount: 1,
                concepts: ['backup', 'test'],
                decayFactor: 1.0
            }],
            longTermMemory: []
        };

        // Setup test graph
        try {
            await store.beginTransaction();
            const setupQuery = `
                DROP SILENT GRAPH <${testGraph}>;
                CREATE GRAPH <${testGraph}>
            `;
            await store._executeSparqlUpdate(setupQuery, store.endpoint.update);
            await store.commitTransaction();

            // Save initial data
            await store.saveMemoryToHistory(originalData);
        } catch (error) {
            logger.error('Error in backup test setup:', error);
            throw error;
        }
    });

    afterAll(async () => {
        try {
            await store.beginTransaction();
            const cleanupQuery = `
                DROP SILENT GRAPH <${testGraph}>;
                DROP SILENT GRAPH <${testGraph}.backup>
            `;
            await store._executeSparqlUpdate(cleanupQuery, store.endpoint.update);
            await store.commitTransaction();
        } finally {
            await store.close();
        }
    });

    it('should create backup during transaction', async () => {
        await store.beginTransaction();

        // Verify backup graph exists
        const verifyQuery = `
            ASK { GRAPH <${testGraph}.backup> { ?s ?p ?o } }
        `;
        const result = await store._executeSparqlQuery(verifyQuery, store.endpoint.query);
        expect(result.boolean).toBe(true);

        await store.commitTransaction();
    });

    it('should restore from backup on rollback', async () => {
        await store.beginTransaction();

        // Modify data
        const modifiedData = {
            shortTermMemory: [{
                ...originalData.shortTermMemory[0],
                output: 'modified output'
            }],
            longTermMemory: []
        };

        await store.saveMemoryToHistory(modifiedData);

        // Verify modification
        let [shortTerm] = await store.loadHistory();
        expect(shortTerm[0].output).toBe('modified output');

        // Rollback
        await store.rollbackTransaction();

        // Verify restoration
        [shortTerm] = await store.loadHistory();
        expect(shortTerm[0].output).toBe('backup test output');
    });

    it('should cleanup backup graphs after commit', async () => {
        await store.beginTransaction();
        await store.commitTransaction();

        // Verify backup graph is removed
        const verifyQuery = `
            ASK { GRAPH <${testGraph}.backup> { ?s ?p ?o } }
        `;
        const result = await store._executeSparqlQuery(verifyQuery, store.endpoint.query);
        expect(result.boolean).toBe(false);
    });

    it('should handle nested transaction attempts', async () => {
        await store.beginTransaction();

        await expectAsync(store.beginTransaction())
            .toBeRejectedWithError('Transaction already in progress');

        await store.rollbackTransaction();
    });

    it('should preserve backup during multiple operations', async () => {
        await store.beginTransaction();

        // Multiple modifications
        const modifications = [
            { output: 'first modification' },
            { output: 'second modification' },
            { output: 'third modification' }
        ];

        for (const mod of modifications) {
            const modData = {
                shortTermMemory: [{
                    ...originalData.shortTermMemory[0],
                    ...mod
                }],
                longTermMemory: []
            };
            await store.saveMemoryToHistory(modData);
        }

        // Rollback should restore original
        await store.rollbackTransaction();

        const [shortTerm] = await store.loadHistory();
        expect(shortTerm[0].output).toBe('backup test output');
    });
});

================
File: tests/integration/sparql/sparql-endpoint-spec.js
================
// tests/integration/sparql/sparql-endpoint-spec.js
import Config from '../../../src/Config.js'
import { SPARQLHelpers } from '../../../src/utils/SPARQLHelpers.js'

describe('SPARQL Endpoint Integration', () => {
    let config
    let endpoint
    let auth
    const testGraph = 'http://example.org/mcp/test-memory'

    beforeAll(async () => {
        config = new Config()
        await config.init()
        const sparqlConfig = config.get('sparqlEndpoints')[0]

        endpoint = {
            query: `${sparqlConfig.urlBase}${sparqlConfig.query}`,
            update: `${sparqlConfig.urlBase}${sparqlConfig.update}`
        }
        auth = SPARQLHelpers.createAuthHeader(sparqlConfig.user, sparqlConfig.password)
    })

    beforeEach(async () => {
        // Ensure clean test graph
        const clearQuery = `
            DROP SILENT GRAPH <${testGraph}>;
            CREATE GRAPH <${testGraph}>
        `
        await SPARQLHelpers.executeSPARQLUpdate(endpoint.update, clearQuery, auth)
    })

    afterAll(async () => {
        const dropQuery = `DROP SILENT GRAPH <${testGraph}>`
        await SPARQLHelpers.executeSPARQLUpdate(endpoint.update, dropQuery, auth)
    })

    describe('Graph Operations', () => {
        it('should create and verify graph existence', async () => {
            const verifyQuery = `ASK { GRAPH <${testGraph}> { ?s ?p ?o } }`
            const result = await SPARQLHelpers.executeSPARQLQuery(
                endpoint.query,
                verifyQuery,
                auth
            )
            const data = await result.json()
            expect(data.boolean).toBe(false) // Empty but exists
        })

        it('should insert and query data', async () => {
            const insertQuery = `
                PREFIX ex: <http://example.org/>
                INSERT DATA {
                    GRAPH <${testGraph}> {
                        ex:subject ex:predicate "test value" .
                    }
                }
            `
            await SPARQLHelpers.executeSPARQLUpdate(endpoint.update, insertQuery, auth)

            const selectQuery = `
                SELECT ?o
                WHERE {
                    GRAPH <${testGraph}> {
                        ex:subject ex:predicate ?o
                    }
                }
            `
            const response = await SPARQLHelpers.executeSPARQLQuery(
                endpoint.query,
                selectQuery,
                auth
            )
            const data = await response.json()
            expect(data.results.bindings[0].o.value).toBe('test value')
        })
    })

    describe('Transaction Management', () => {
        it('should handle atomic updates', async () => {
            const transaction = `
                PREFIX ex: <http://example.org/>
                INSERT DATA { GRAPH <${testGraph}> { ex:s1 ex:p "v1" } };
                INSERT DATA { GRAPH <${testGraph}> { ex:s2 ex:p "v2" } }
            `
            await SPARQLHelpers.executeSPARQLUpdate(endpoint.update, transaction, auth)

            const countQuery = `
                SELECT (COUNT(?s) as ?count)
                WHERE {
                    GRAPH <${testGraph}> { ?s ?p ?o }
                }
            `
            const response = await SPARQLHelpers.executeSPARQLQuery(
                endpoint.query,
                countQuery,
                auth
            )
            const data = await response.json()
            expect(parseInt(data.results.bindings[0].count.value)).toBe(2)
        })

        it('should rollback failed transactions', async () => {
            const invalidQuery = `
                PREFIX ex: <http://example.org/>
                INSERT DATA { GRAPH <${testGraph}> { ex:s1 ex:p "v1" } };
                INSERT DATA { GRAPH <${testGraph}> { INVALID SYNTAX } }
            `
            await expectAsync(
                SPARQLHelpers.executeSPARQLUpdate(endpoint.update, invalidQuery, auth)
            ).toBeRejected()

            const verifyQuery = `ASK { GRAPH <${testGraph}> { ?s ?p ?o } }`
            const response = await SPARQLHelpers.executeSPARQLQuery(
                endpoint.query,
                verifyQuery,
                auth
            )
            const data = await response.json()
            expect(data.boolean).toBe(false) // No data persisted
        })
    })

    describe('Authentication', () => {
        it('should reject invalid credentials', async () => {
            const invalidAuth = SPARQLHelpers.createAuthHeader('invalid', 'wrong')
            const query = 'SELECT * WHERE { ?s ?p ?o } LIMIT 1'

            await expectAsync(
                SPARQLHelpers.executeSPARQLQuery(endpoint.query, query, invalidAuth)
            ).toBeRejected()
        })

        it('should accept valid credentials', async () => {
            const query = 'ASK { ?s ?p ?o }'
            const response = await SPARQLHelpers.executeSPARQLQuery(
                endpoint.query,
                query,
                auth
            )
            expect(response.ok).toBe(true)
        })
    })

    describe('Content Negotiation', () => {
        it('should handle different RDF formats', async () => {
            const data = `
                PREFIX ex: <http://example.org/>
                INSERT DATA {
                    GRAPH <${testGraph}> {
                        ex:subject ex:predicate "test" .
                    }
                }
            `
            await SPARQLHelpers.executeSPARQLUpdate(endpoint.update, data, auth)

            const constructQuery = `
                CONSTRUCT { ?s ?p ?o }
                WHERE {
                    GRAPH <${testGraph}> { ?s ?p ?o }
                }
            `

            // Test Turtle format
            const turtleResponse = await SPARQLHelpers.executeSPARQLQuery(
                endpoint.query,
                constructQuery,
                auth,
                'text/turtle'
            )
            const turtle = await turtleResponse.text()
            expect(turtle).toContain('ex:subject')
            expect(turtle).toContain('ex:predicate')

            // Test JSON-LD format
            const jsonResponse = await SPARQLHelpers.executeSPARQLQuery(
                endpoint.query,
                constructQuery,
                auth,
                'application/ld+json'
            )
            const jsonld = await jsonResponse.json()
            expect(jsonld['@graph']).toBeDefined()
        })
    })
})

================
File: tests/integration/sparql/sparql-federation-spec.js
================
import Config from '../../../src/Config.js';
import SPARQLStore from '../../../src/stores/SPARQLStore.js';
import { logger } from '../../../src/Utils.js';

describe('SPARQLStore Federation Integration', () => {
    let store;
    let config;
    const testGraphs = {
        main: 'http://example.org/mcp/test-memory',
        metadata: 'http://example.org/mcp/test-metadata',
        archive: 'http://example.org/mcp/test-archive'
    };

    beforeAll(async () => {
        config = new Config();
        const sparqlConfig = config.get('sparqlEndpoints')[0];

        store = new SPARQLStore({
            query: `${sparqlConfig.urlBase}${sparqlConfig.query}`,
            update: `${sparqlConfig.urlBase}${sparqlConfig.update}`
        }, {
            user: sparqlConfig.user,
            password: sparqlConfig.password,
            graphName: testGraphs.main
        });

        // Initialize test graphs
        try {
            await store.beginTransaction();
            const setupQuery = `
                DROP SILENT GRAPH <${testGraphs.main}>;
                DROP SILENT GRAPH <${testGraphs.metadata}>;
                DROP SILENT GRAPH <${testGraphs.archive}>;
                CREATE GRAPH <${testGraphs.main}>;
                CREATE GRAPH <${testGraphs.metadata}>;
                CREATE GRAPH <${testGraphs.archive}>
            `;
            await store._executeSparqlUpdate(setupQuery, store.endpoint.update);

            // Add test data to metadata graph
            const metadataQuery = `
                INSERT DATA {
                    GRAPH <${testGraphs.metadata}> {
                        <${testGraphs.main}> a mcp:MemoryStore ;
                            mcp:hasVersion "1.0" ;
                            mcp:lastUpdated "${new Date().toISOString()}"^^xsd:dateTime .
                    }
                }
            `;
            await store._executeSparqlUpdate(metadataQuery, store.endpoint.update);
            await store.commitTransaction();
        } catch (error) {
            logger.error('Error in federation test setup:', error);
            throw error;
        }
    });

    afterAll(async () => {
        try {
            await store.beginTransaction();
            const cleanupQuery = `
                DROP SILENT GRAPH <${testGraphs.main}>;
                DROP SILENT GRAPH <${testGraphs.metadata}>;
                DROP SILENT GRAPH <${testGraphs.archive}>
            `;
            await store._executeSparqlUpdate(cleanupQuery, store.endpoint.update);
            await store.commitTransaction();
        } finally {
            await store.close();
        }
    });

    it('should query across multiple graphs', async () => {
        // Add test memory data
        const testMemory = {
            shortTermMemory: [{
                id: 'federation-test-1',
                prompt: 'federation test prompt',
                output: 'federation test output',
                embedding: new Array(1536).fill(0).map(() => Math.random()),
                timestamp: Date.now(),
                concepts: ['federation', 'test'],
                accessCount: 1,
                decayFactor: 1.0
            }],
            longTermMemory: []
        };

        await store.saveMemoryToHistory(testMemory);

        // Federated query across memory and metadata
        const federatedQuery = `
            PREFIX mcp: <http://purl.org/stuff/mcp/>
            SELECT ?interaction ?version ?updated
            WHERE {
                GRAPH <${testGraphs.main}> {
                    ?interaction a mcp:Interaction ;
                        mcp:id "federation-test-1" .
                }
                GRAPH <${testGraphs.metadata}> {
                    <${testGraphs.main}> mcp:hasVersion ?version ;
                        mcp:lastUpdated ?updated .
                }
            }
        `;

        const results = await store._executeSparqlQuery(federatedQuery, store.endpoint.query);
        expect(results.results.bindings.length).toBe(1);
        expect(results.results.bindings[0].version.value).toBe('1.0');
    });

    it('should handle cross-graph data relationships', async () => {
        // Add related data across graphs
        const setupQuery = `
            PREFIX mcp: <http://purl.org/stuff/mcp/>
            PREFIX qb: <http://purl.org/linked-data/cube#>

            INSERT DATA {
                GRAPH <${testGraphs.main}> {
                    _:interaction1 a mcp:Interaction ;
                        mcp:id "related-test-1" ;
                        mcp:relatedCube <cube1> .
                }

                GRAPH <${testGraphs.metadata}> {
                    <cube1> a qb:DataSet ;
                        qb:structure <dsd1> ;
                        rdfs:label "Test Cube" .
                }
            }
        `;

        await store._executeSparqlUpdate(setupQuery, store.endpoint.update);

        // Query relationship
        const relationQuery = `
            PREFIX mcp: <http://purl.org/stuff/mcp/>
            PREFIX qb: <http://purl.org/linked-data/cube#>

            SELECT ?id ?cubeLabel
            WHERE {
                GRAPH <${testGraphs.main}> {
                    ?interaction mcp:id ?id ;
                        mcp:relatedCube ?cube .
                }
                GRAPH <${testGraphs.metadata}> {
                    ?cube rdfs:label ?cubeLabel .
                }
            }
        `;

        const results = await store._executeSparqlQuery(relationQuery, store.endpoint.query);
        expect(results.results.bindings.length).toBe(1);
        expect(results.results.bindings[0].cubeLabel.value).toBe('Test Cube');
    });

    it('should support federated updates across graphs', async () => {
        await store.beginTransaction();
        try {
            const federatedUpdate = `
                PREFIX mcp: <http://purl.org/stuff/mcp/>

                WITH <${testGraphs.main}>
                DELETE { ?i mcp:accessCount ?oldCount }
                INSERT { ?i mcp:accessCount ?newCount }
                WHERE {
                    ?i mcp:id "federation-test-1" ;
                       mcp:accessCount ?oldCount .
                    BIND(?oldCount + 1 AS ?newCount)
                };

                WITH <${testGraphs.metadata}>
                DELETE { <${testGraphs.main}> mcp:lastUpdated ?old }
                INSERT { <${testGraphs.main}> mcp:lastUpdated "${new Date().toISOString()}"^^xsd:dateTime }
                WHERE {
                    <${testGraphs.main}> mcp:lastUpdated ?old
                }
            `;

            await store._executeSparqlUpdate(federatedUpdate, store.endpoint.update);
            await store.commitTransaction();

            // Verify update
            const [shortTerm] = await store.loadHistory();
            expect(shortTerm[0].accessCount).toBe(2);
        } catch (error) {
            await store.rollbackTransaction();
            throw error;
        }
    });

    it('should handle service-based federation', async () => {
        // Query using SERVICE keyword for explicit federation
        const serviceQuery = `
            PREFIX mcp: <http://purl.org/stuff/mcp/>

            SELECT ?interaction ?metadata
            WHERE {
                SERVICE <${store.endpoint.query}> {
                    GRAPH <${testGraphs.main}> {
                        ?interaction mcp:id "federation-test-1"
                    }
                }
                SERVICE <${store.endpoint.query}> {
                    GRAPH <${testGraphs.metadata}> {
                        <${testGraphs.main}> ?p ?metadata
                    }
                }
            }
        `;

        const results = await store._executeSparqlQuery(serviceQuery, store.endpoint.query);
        expect(results.results.bindings.length).toBeGreaterThan(0);
    });
});

================
File: tests/integration/sparql/sparql-store-integration-spec.js
================
import Config from '../../../src/Config.js';
import SPARQLStore from '../../../src/stores/SPARQLStore.js';
import { logger } from '../../../src/Utils.js';

describe('SPARQLStore Integration', () => {
    let store;
    let config;
    let testMemory;

    beforeAll(async () => {
        // Initialize with real config
        config = new Config();
        const sparqlConfig = config.get('sparqlEndpoints')[0];

        store = new SPARQLStore({
            query: `${sparqlConfig.urlBase}${sparqlConfig.query}`,
            update: `${sparqlConfig.urlBase}${sparqlConfig.update}`
        }, {
            user: sparqlConfig.user,
            password: sparqlConfig.password,
            graphName: 'http://example.org/mcp/test-memory'
        });

        // Test data
        testMemory = {
            shortTermMemory: [{
                id: 'test-integration-1',
                prompt: 'integration test prompt',
                output: 'integration test output',
                embedding: new Array(1536).fill(0).map(() => Math.random()),
                timestamp: Date.now(),
                accessCount: 1,
                concepts: ['test', 'integration'],
                decayFactor: 1.0
            }],
            longTermMemory: []
        };

        // Clear test graph before starting
        try {
            await store.beginTransaction();
            const clearQuery = `
                DROP SILENT GRAPH <http://example.org/mcp/test-memory>;
                CREATE GRAPH <http://example.org/mcp/test-memory>
            `;
            await store._executeSparqlUpdate(clearQuery, `${sparqlConfig.urlBase}${sparqlConfig.update}`);
            await store.commitTransaction();
        } catch (error) {
            logger.error('Error in test setup:', error);
            throw error;
        }
    });

    afterAll(async () => {
        // Cleanup test graph
        try {
            await store.beginTransaction();
            const dropQuery = `DROP SILENT GRAPH <http://example.org/mcp/test-memory>`;
            await store._executeSparqlUpdate(dropQuery, `${config.get('sparqlEndpoints')[0].urlBase}${config.get('sparqlEndpoints')[0].update}`);
            await store.commitTransaction();
        } finally {
            await store.close();
        }
    });

    it('should verify empty graph exists', async () => {
        const exists = await store.verify();
        expect(exists).toBe(true);
    });

    it('should save and load memory data', async () => {
        // Save test memory
        await store.saveMemoryToHistory(testMemory);

        // Load and verify
        const [shortTerm, longTerm] = await store.loadHistory();

        expect(shortTerm.length).toBe(1);
        expect(longTerm.length).toBe(0);

        const loaded = shortTerm[0];
        expect(loaded.id).toBe(testMemory.shortTermMemory[0].id);
        expect(loaded.prompt).toBe(testMemory.shortTermMemory[0].prompt);
        expect(loaded.concepts).toEqual(testMemory.shortTermMemory[0].concepts);
        expect(loaded.embedding.length).toBe(1536);
    });

    it('should handle transaction rollback', async () => {
        await store.beginTransaction();

        const badMemory = {
            shortTermMemory: [{
                id: 'test-rollback',
                prompt: 'should not persist',
                output: 'rollback test',
                embedding: new Array(1536).fill(0),
                timestamp: Date.now(),
                accessCount: 1,
                concepts: ['rollback'],
                decayFactor: 1.0
            }],
            longTermMemory: []
        };

        try {
            // Save data that will be rolled back
            await store.saveMemoryToHistory(badMemory);
            // Force a rollback by throwing an error
            throw new Error('Test rollback');
        } catch (error) {
            await store.rollbackTransaction();
        }

        // Verify original data is still intact
        const [shortTerm] = await store.loadHistory();
        expect(shortTerm.length).toBe(1);
        expect(shortTerm[0].id).toBe('test-integration-1');
    });

    it('should handle concurrent transactions', async () => {
        const store2 = new SPARQLStore(store.endpoint, {
            user: store.credentials.user,
            password: store.credentials.password,
            graphName: store.graphName
        });

        await store.beginTransaction();

        // Second transaction should fail while first is in progress
        await expectAsync(store2.beginTransaction())
            .toBeRejectedWithError(/Transaction already in progress/);

        await store.commitTransaction();
        await store2.close();
    });

    it('should support query pagination', async () => {
        // Add multiple memories
        const bulkMemory = {
            shortTermMemory: Array(5).fill(null).map((_, i) => ({
                id: `bulk-test-${i}`,
                prompt: `bulk test prompt ${i}`,
                output: `bulk test output ${i}`,
                embedding: new Array(1536).fill(0).map(() => Math.random()),
                timestamp: Date.now(),
                accessCount: 1,
                concepts: ['bulk', `test-${i}`],
                decayFactor: 1.0
            })),
            longTermMemory: []
        };

        await store.saveMemoryToHistory(bulkMemory);

        // Custom paginated query
        const pageSize = 2;
        const query = `
            PREFIX mcp: <http://purl.org/stuff/mcp/>
            SELECT ?id ?prompt
            FROM <${store.graphName}>
            WHERE {
                ?s mcp:id ?id ;
                   mcp:prompt ?prompt .
            }
            LIMIT ${pageSize}
        `;

        const results = await store._executeSparqlQuery(query, store.endpoint.query);
        expect(results.results.bindings.length).toBe(pageSize);
    });
});

================
File: tests/integration/ContextManager.integration.spec.js
================
// tests/integration/ContextManager.integration.spec.js
import ContextManager from '../../src/ContextManager.js'
import LLMHandler from '../../src/handlers/LLMHandler.js'
import OllamaConnector from '../../src/connectors/OllamaConnector.js'

describe('ContextManager Integration', () => {
    let manager
    let llmHandler
    const TEST_TIMEOUT = 30000

    beforeAll(async () => {
        llmHandler = new LLMHandler(
            new OllamaConnector('http://localhost:11434'),
            'qwen2:1.5b'
        )

        manager = new ContextManager({
            maxTokens: 8192,
            maxTimeWindow: 3600000,
            relevanceThreshold: 0.7,
            maxContextSize: 5
        })

        try {
            await fetch('http://localhost:11434/api/tags')
        } catch (e) {
            pending('Ollama server not available - skipping integration tests')
        }
    })

    describe('Context Building', () => {
        it('should build context with recent interactions', async () => {
            const recentInteractions = [{
                prompt: 'What is machine learning?',
                output: 'Machine learning is a subset of AI that enables systems to learn from data.',
                timestamp: Date.now(),
                concepts: ['machine learning', 'AI', 'data']
            }]

            const currentPrompt = 'How does deep learning relate to this?'
            const context = manager.buildContext(currentPrompt, [], recentInteractions)

            expect(context).toContain('machine learning')
            expect(context).toContain('AI')
        }, TEST_TIMEOUT)

        it('should integrate retrieved context with relevance scores', async () => {
            const retrievals = [{
                similarity: 0.9,
                interaction: {
                    prompt: 'Explain neural networks',
                    output: 'Neural networks are computational models inspired by biological neurons.',
                    concepts: ['neural networks', 'computation', 'biology']
                }
            }]

            const context = manager.buildContext('How do neural networks learn?', retrievals)
            expect(context).toContain('neural networks')
            expect(context).toContain('computational models')
        }, TEST_TIMEOUT)

        it('should handle system context integration', async () => {
            const systemContext = "You're a helpful AI assistant specializing in machine learning."
            const context = manager.buildContext(
                'What is backpropagation?',
                [],
                [],
                { systemContext }
            )

            expect(context).toContain('AI assistant')
            expect(context).toContain('machine learning')
        }, TEST_TIMEOUT)
    })

    describe('Context Management', () => {
        it('should prune old and irrelevant context', async () => {
            const oldTimestamp = Date.now() - 5000000
            manager.addToContext({
                prompt: 'Old question',
                output: 'Old answer',
                timestamp: oldTimestamp,
                concepts: ['old']
            }, 0.5)

            manager.addToContext({
                prompt: 'Recent question',
                output: 'Recent answer',
                timestamp: Date.now(),
                concepts: ['recent']
            }, 0.9)

            manager.pruneContext()
            const context = manager.buildContext('Current prompt')

            expect(context).not.toContain('Old question')
            expect(context).toContain('Recent question')
        })

        it('should maintain context size limits', async () => {
            for (let i = 0; i < 10; i++) {
                manager.addToContext({
                    prompt: `Question ${i}`,
                    output: `Answer ${i}`,
                    timestamp: Date.now(),
                    concepts: [`concept${i}`]
                }, 0.8)
            }

            const context = manager.buildContext('Test prompt')
            const contextParts = context.split('Q:').length - 1
            expect(contextParts).toBeLessThanOrEqual(manager.maxContextSize)
        })
    })

    describe('Context Summarization', () => {
        it('should group related interactions by concept', async () => {
            const mlInteractions = [
                {
                    prompt: 'What is ML?',
                    output: 'Machine learning basics...',
                    concepts: ['machine learning']
                },
                {
                    prompt: 'Explain training data',
                    output: 'Training data is used...',
                    concepts: ['machine learning', 'data']
                }
            ]

            const summary = manager.summarizeContext(mlInteractions)
            expect(summary).toContain('machine learning')
            expect(summary.split('Topic:').length).toBe(2) // One for ML, one for data
        })

        it('should handle single interaction summaries', async () => {
            const interaction = {
                prompt: 'What is gradient descent?',
                output: 'Gradient descent is an optimization algorithm...',
                concepts: ['optimization']
            }

            const summary = manager.summarizeContext([interaction])
            expect(summary).toContain('Q:')
            expect(summary).toContain('A:')
            expect(summary).toContain('gradient descent')
        })

        it('should truncate long outputs in summaries', async () => {
            const longInteraction = {
                prompt: 'Explain transformers',
                output: 'A'.repeat(1000),
                concepts: ['transformers']
            }

            const summary = manager.formatGroupSummary('transformers', [longInteraction])
            expect(summary.length).toBeLessThan(200)
            expect(summary).toContain('...')
        })
    })

    describe('LLM Integration', () => {
        it('should generate responses with context', async () => {
            manager.addToContext({
                prompt: 'What are tensors?',
                output: 'Tensors are multi-dimensional arrays...',
                concepts: ['tensors', 'mathematics']
            }, 0.9)

            const context = manager.buildContext('How are tensors used in deep learning?')
            const response = await llmHandler.generateResponse(
                'How are tensors used in deep learning?',
                context
            )

            expect(response).toBeTruthy()
            expect(response.toLowerCase()).toContain('tensor')
        }, TEST_TIMEOUT)

        it('should handle context window limits', async () => {
            const largeContext = 'A'.repeat(10000)
            const processedContext = manager.buildContext('test', [], [], {
                systemContext: largeContext
            })

            const response = await llmHandler.generateResponse('test', processedContext)
            expect(response).toBeTruthy()
        }, TEST_TIMEOUT)
    })
})

================
File: tests/mocks/Ollama.js
================
export class MockOllamaConnector {
    async generateEmbedding(model, input) {
        // Generate deterministic but unique embedding
        return new Array(1536).fill(0).map((_, i) =>
            Math.sin(i + input.length))
    }

    async generateChat(model, messages) {
        return 'This is a mock response specific to: ' +
            messages[messages.length - 1].content
    }

    async generateCompletion(model, prompt) {
        if (prompt.includes('concepts')) {
            // Mock concept extraction
            return '["test", "mock", "concept"]'
        }
        return 'Mock completion for: ' + prompt
    }
}

================
File: tests/support/jasmine.json
================
{
  "spec_dir": "spec",
  "spec_files": [
    "**/*[sS]pec.?(m)js"
  ],
  "helpers": [
    "helpers/**/*.?(m)js"
  ],
  "env": {
    "stopSpecOnExpectationFailure": false,
    "random": true
  }
}

================
File: tests/unit/api/APILogger.spec.js
================
// tests/unit/api/APILogger.spec.js
import APILogger from '../../../src/api/APILogger.js'

describe('APILogger', () => {
    let logger
    let originalConsole
    let consoleOutput

    beforeEach(() => {
        // Capture console output
        consoleOutput = {
            log: [],
            debug: [],
            info: [],
            warn: [],
            error: []
        }

        originalConsole = {
            log: console.log,
            debug: console.debug,
            info: console.info,
            warn: console.warn,
            error: console.error
        }

        Object.keys(consoleOutput).forEach(method => {
            console[method] = (...args) => consoleOutput[method].push(args.join(' '))
        })

        logger = new APILogger({
            name: 'TestLogger',
            level: 'debug',
            maxEntries: 100
        })
    })

    afterEach(() => {
        Object.assign(console, originalConsole)
        logger.dispose()
    })

    describe('Log Level Management', () => {
        it('should respect log levels', () => {
            logger.setLevel('warn')

            logger.debug('debug message')
            logger.info('info message')
            logger.warn('warn message')
            logger.error('error message')

            expect(consoleOutput.debug).toEqual([])
            expect(consoleOutput.info).toEqual([])
            expect(consoleOutput.warn.length).toBe(1)
            expect(consoleOutput.error.length).toBe(1)
        })

        it('should handle level changes', () => {
            logger.setLevel('error')
            logger.info('should not log')
            expect(consoleOutput.info).toEqual([])

            logger.setLevel('info')
            logger.info('should log')
            expect(consoleOutput.info.length).toBe(1)
        })

        it('should get current level', () => {
            logger.setLevel('warn')
            expect(logger.getLevel()).toBe('warn')
        })
    })

    describe('Log Entry Management', () => {
        it('should create formatted log entries', () => {
            const entry = logger.info('test message', { data: 'test' })

            expect(entry.timestamp).toBeDefined()
            expect(entry.level).toBe('info')
            expect(entry.message).toContain('test message')
            expect(entry.message).toContain('{"data":"test"}')
        })

        it('should handle error objects', () => {
            const error = new Error('Test error')
            const entry = logger.error('Error occurred', error)

            expect(entry.error).toBeDefined()
            expect(entry.error.name).toBe('Error')
            expect(entry.error.message).toBe('Test error')
            expect(entry.error.stack).toBeDefined()
        })

        it('should enforce max entries limit', () => {
            logger = new APILogger({ maxEntries: 2 })

            logger.info('first')
            logger.info('second')
            logger.info('third')

            const entries = logger.getEntries()
            expect(entries.length).toBe(2)
            expect(entries[0].message).toBe('second')
            expect(entries[1].message).toBe('third')
        })
    })

    describe('Entry Retrieval', () => {
        beforeEach(() => {
            logger.info('info message')
            logger.warn('warn message')
            logger.error('error message')
        })

        it('should filter by level', () => {
            const errorEntries = logger.getEntries({ level: 'error' })
            expect(errorEntries.length).toBe(1)
            expect(errorEntries[0].level).toBe('error')
        })

        it('should filter by time range', () => {
            const now = new Date()
            const past = new Date(now - 1000)
            const future = new Date(now + 1000)

            const entries = logger.getEntries({
                since: past,
                until: future
            })
            expect(entries.length).toBe(3)
        })

        it('should limit results', () => {
            for (let i = 0; i < 10; i++) {
                logger.info(`message ${i}`)
            }

            const entries = logger.getEntries({ limit: 5 })
            expect(entries.length).toBe(5)
        })
    })

    describe('Child Loggers', () => {
        it('should create child loggers', () => {
            const child = logger.createChild('Child')
            expect(child.name).toBe('TestLogger:Child')
            expect(child.getLevel()).toBe(logger.getLevel())
        })

        it('should inherit parent options', () => {
            const child = logger.createChild('Child', { level: 'warn' })
            expect(child.getLevel()).toBe('warn')
            expect(child.maxEntries).toBe(logger.maxEntries)
        })
    })

    describe('Event Emission', () => {
        it('should emit log events', (done) => {
            logger.once('log', (entry) => {
                expect(entry.level).toBe('info')
                expect(entry.message).toBe('test message')
                done()
            })

            logger.info('test message')
        })

        it('should include metadata in events', (done) => {
            logger.once('log', (entry) => {
                expect(entry.metadata.pid).toBeDefined()
                expect(entry.metadata.hostname).toBeDefined()
                done()
            })

            logger.info('test message')
        })
    })

    describe('Resource Management', () => {
        it('should clear entries', () => {
            logger.info('test message')
            expect(logger.getEntries().length).toBe(1)

            logger.clearEntries()
            expect(logger.getEntries().length).toBe(0)
        })

        it('should cleanup on dispose', () => {
            const listener = jasmine.createSpy('logListener')
            logger.on('log', listener)

            logger.dispose()
            logger.info('test message')

            expect(listener).not.toHaveBeenCalled()
            expect(logger.getEntries().length).toBe(0)
        })
    })
})

================
File: tests/unit/api/APIRegistry.spec.js
================
// tests/unit/api/APIRegistry.spec.js
import APIRegistry from '../../../src/api/common/APIRegistry.js'
import BaseAPI from '../../../src/api/common/BaseAPI.js'

class TestAPI extends BaseAPI {
    async initialize() {
        await super.initialize()
        this._emitMetric('test.initialized', 1)
    }

    async executeOperation(operation, params) {
        this._emitMetric('test.operation', 1)
        return { operation, params }
    }
}

describe('APIRegistry', () => {
    let registry

    beforeEach(() => {
        registry = new APIRegistry()
    })

    describe('API Registration', () => {
        it('should register valid API implementations', async () => {
            const api = await registry.register('test', TestAPI)
            expect(api).toBeInstanceOf(TestAPI)
            expect(registry.get('test')).toBe(api)
        })

        it('should prevent duplicate registration', async () => {
            await registry.register('test', TestAPI)
            await expectAsync(
                registry.register('test', TestAPI)
            ).toBeRejectedWithError('API test already registered')
        })

        it('should validate API inheritance', async () => {
            class InvalidAPI { }
            await expectAsync(
                registry.register('invalid', InvalidAPI)
            ).toBeRejectedWithError('API must extend BaseAPI')
        })

        it('should handle initialization failures', async () => {
            class FailingAPI extends BaseAPI {
                async initialize() {
                    throw new Error('Initialization failed')
                }
            }

            await expectAsync(
                registry.register('failing', FailingAPI)
            ).toBeRejectedWithError('Initialization failed')
        })
    })

    describe('API Access', () => {
        it('should retrieve registered APIs', async () => {
            await registry.register('test', TestAPI)
            const api = registry.get('test')
            expect(api).toBeInstanceOf(TestAPI)
        })

        it('should throw on missing APIs', () => {
            expect(() => registry.get('missing'))
                .toThrowError('API missing not found')
        })

        it('should list all registered APIs', async () => {
            await registry.register('test1', TestAPI)
            await registry.register('test2', TestAPI)

            const apis = registry.getAll()
            expect(apis.size).toBe(2)
            expect(apis.has('test1')).toBeTrue()
            expect(apis.has('test2')).toBeTrue()
        })
    })

    describe('Metric Collection', () => {
        it('should collect metrics from APIs', async () => {
            const api = await registry.register('test', TestAPI)
            await api.executeOperation('test', {})

            const metrics = registry.getMetrics()
            expect(metrics.apis.test.metrics['test.operation']).toBeDefined()
        })

        it('should track API status', async () => {
            await registry.register('test', TestAPI)
            const metrics = registry.getMetrics()

            expect(metrics.apis.test.status).toBe('active')
            expect(metrics.apiCount).toBe(1)
        })

        it('should aggregate metrics across APIs', async () => {
            const api1 = await registry.register('test1', TestAPI)
            const api2 = await registry.register('test2', TestAPI)

            await api1.executeOperation('op1', {})
            await api2.executeOperation('op2', {})

            const metrics = registry.getMetrics()
            expect(Object.keys(metrics.apis)).toContain('test1')
            expect(Object.keys(metrics.apis)).toContain('test2')
        })
    })

    describe('API Lifecycle', () => {
        it('should unregister APIs', async () => {
            const api = await registry.register('test', TestAPI)
            spyOn(api, 'shutdown').and.returnValue(Promise.resolve())

            await registry.unregister('test')
            expect(() => registry.get('test')).toThrow()
            expect(api.shutdown).toHaveBeenCalled()
        })

        it('should handle unregister errors', async () => {
            const api = await registry.register('test', TestAPI)
            spyOn(api, 'shutdown').and.rejectWith(new Error('Shutdown failed'))

            await expectAsync(registry.unregister('test'))
                .toBeRejectedWithError('Shutdown failed')
        })

        it('should shutdown all APIs', async () => {
            await registry.register('test1', TestAPI)
            await registry.register('test2', TestAPI)

            await registry.shutdownAll()
            expect(registry.getAll().size).toBe(0)
        })
    })

    describe('Error Handling', () => {
        it('should handle API operation errors', async () => {
            class ErrorAPI extends BaseAPI {
                async executeOperation() {
                    this._emitMetric('error.count', 1)
                    throw new Error('Operation failed')
                }
            }

            const api = await registry.register('error', ErrorAPI)
            await expectAsync(
                api.executeOperation('test', {})
            ).toBeRejected()

            const metrics = registry.getMetrics()
            expect(metrics.apis.error.metrics['error.count'].value).toBe(1)
        })

        it('should cleanup on registration failure', async () => {
            class CleanupAPI extends BaseAPI {
                async initialize() {
                    this._emitMetric('init', 1)
                    throw new Error('Init failed')
                }
            }

            await expectAsync(
                registry.register('cleanup', CleanupAPI)
            ).toBeRejected()

            expect(registry.getAll().size).toBe(0)
            expect(registry.metrics.size).toBe(0)
        })
    })
})

================
File: tests/unit/api/BaseAPI.spec.js
================
// tests/unit/api/BaseAPI.spec.js
import BaseAPI from '../../../src/api/common/BaseAPI.js'

class TestAPI extends BaseAPI {
    async executeOperation(operation, params) {
        this._validateParams(params)
        this._emitMetric('operation.count', 1)
        return { operation, params }
    }

    async storeInteraction(interaction) {
        this._validateParams(interaction)
        this._emitMetric('store.count', 1)
        return interaction
    }

    async retrieveInteractions(query) {
        this._validateParams(query)
        this._emitMetric('retrieve.count', 1)
        return [query]
    }
}

describe('BaseAPI', () => {
    let api

    beforeEach(() => {
        api = new TestAPI({ test: 'config' })
    })

    describe('Initialization', () => {
        it('should initialize with config', async () => {
            await api.initialize()
            expect(api.initialized).toBeTrue()
            expect(api.config.test).toBe('config')
        })

        it('should prevent duplicate initialization', async () => {
            await api.initialize()
            await expectAsync(api.initialize())
                .toBeRejectedWithError('API already initialized')
        })

        it('should track initialization state', async () => {
            expect(api.initialized).toBeFalse()
            await api.initialize()
            expect(api.initialized).toBeTrue()
        })
    })

    describe('Operation Management', () => {
        beforeEach(async () => {
            await api.initialize()
        })

        it('should execute operations', async () => {
            const result = await api.executeOperation('test', { param: 'value' })
            expect(result.operation).toBe('test')
            expect(result.params.param).toBe('value')
        })

        it('should validate parameters', async () => {
            await expectAsync(api.executeOperation('test', null))
                .toBeRejectedWithError('Invalid parameters')
        })

        it('should store interactions', async () => {
            const interaction = { data: 'test' }
            const result = await api.storeInteraction(interaction)
            expect(result).toEqual(interaction)
        })

        it('should retrieve interactions', async () => {
            const query = { text: 'test' }
            const results = await api.retrieveInteractions(query)
            expect(results).toContain(query)
        })
    })

    describe('Metrics Collection', () => {
        beforeEach(async () => {
            await api.initialize()
        })

        it('should emit metric events', (done) => {
            api.once('metric', (metric) => {
                expect(metric.name).toBe('test.metric')
                expect(metric.value).toBe(1)
                expect(metric.timestamp).toBeDefined()
                done()
            })

            api._emitMetric('test.metric', 1)
        })

        it('should collect system metrics', async () => {
            const metrics = await api.getMetrics()
            expect(metrics.timestamp).toBeDefined()
            expect(metrics.status).toBe('active')
            expect(metrics.memoryUsage).toBeDefined()
            expect(metrics.uptime).toBeGreaterThanOrEqual(0)
        })

        it('should track operation metrics', async () => {
            const listener = jasmine.createSpy('metricListener')
            api.on('metric', listener)

            await api.executeOperation('test', { param: 'value' })

            expect(listener).toHaveBeenCalledWith(
                jasmine.objectContaining({
                    name: 'operation.count',
                    value: 1
                })
            )
        })
    })

    describe('Lifecycle Management', () => {
        it('should handle shutdown', async () => {
            await api.initialize()
            await api.shutdown()
            expect(api.initialized).toBeFalse()
        })

        it('should prevent operations after shutdown', async () => {
            await api.initialize()
            await api.shutdown()

            await expectAsync(api.executeOperation('test', {}))
                .toBeRejectedWithError('API not initialized')
        })

        it('should prevent shutdown before initialization', async () => {
            await expectAsync(api.shutdown())
                .toBeRejectedWithError('API not initialized')
        })

        it('should cleanup on shutdown', async () => {
            const listener = jasmine.createSpy('metricListener')
            api.on('metric', listener)

            await api.initialize()
            await api.shutdown()

            api._emitMetric('test', 1)
            expect(listener).not.toHaveBeenCalled()
        })
    })

    describe('Error Handling', () => {
        beforeEach(async () => {
            await api.initialize()
        })

        it('should handle operation errors', async () => {
            class ErrorAPI extends BaseAPI {
                async executeOperation() {
                    this._emitMetric('error', 1)
                    throw new Error('Operation failed')
                }
            }

            const errorApi = new ErrorAPI()
            await errorApi.initialize()

            await expectAsync(errorApi.executeOperation('test', {}))
                .toBeRejectedWithError('Operation failed')
        })

        it('should validate input types', async () => {
            await expectAsync(api.executeOperation('test', 'invalid'))
                .toBeRejectedWithError('Invalid parameters')
        })

        it('should handle async validation', async () => {
            api._validateParams = async () => {
                throw new Error('Async validation failed')
            }

            await expectAsync(api.executeOperation('test', {}))
                .toBeRejectedWithError('Async validation failed')
        })
    })

    describe('Event Management', () => {
        it('should handle multiple metric listeners', async () => {
            const listener1 = jasmine.createSpy('listener1')
            const listener2 = jasmine.createSpy('listener2')

            api.on('metric', listener1)
            api.on('metric', listener2)

            api._emitMetric('test', 1)

            expect(listener1).toHaveBeenCalled()
            expect(listener2).toHaveBeenCalled()
        })

        it('should remove listeners on cleanup', async () => {
            const listener = jasmine.createSpy('listener')
            api.on('metric', listener)

            await api.initialize()
            await api.shutdown()

            expect(api.listenerCount('metric')).toBe(0)
        })
    })
})

================
File: tests/unit/api/MetricsCollector.spec.js
================
// tests/unit/api/MetricsCollector.spec.js
import MetricsCollector from '../../../src/api/MetricsCollector.js'

describe('MetricsCollector', () => {
    let collector

    beforeEach(() => {
        jasmine.clock().install()
        collector = new MetricsCollector({
            interval: 1000,  // 1 second
            maxHistory: 5
        })
    })

    afterEach(() => {
        jasmine.clock().uninstall()
        collector.dispose()
    })

    describe('Metric Collection', () => {
        it('should collect simple metrics', () => {
            collector.collect('test.counter', 1)

            const metrics = collector.getMetric('test.counter')
            expect(metrics.length).toBe(1)
            expect(metrics[0].value).toBe(1)
            expect(metrics[0].timestamp).toBeDefined()
        })

        it('should handle metrics with labels', () => {
            collector.collect('api.requests', 1, { method: 'GET', path: '/test' })

            const metrics = collector.getMetric('api.requests', { method: 'GET' })
            expect(metrics.length).toBe(1)
            expect(metrics[0].value).toBe(1)
        })

        it('should enforce maxHistory limit', () => {
            for (let i = 0; i < 10; i++) {
                collector.collect('test.series', i)
            }

            const metrics = collector.getMetric('test.series')
            expect(metrics.length).toBe(5)  // maxHistory from config
            expect(metrics[metrics.length - 1].value).toBe(9)
        })
    })

    describe('Metric Retrieval', () => {
        beforeEach(() => {
            collector.collect('test.value', 1)
            collector.collect('test.value', 2)
            collector.collect('test.value', 3)
        })

        it('should calculate summary statistics', () => {
            const summary = collector.getSummary('test.value')

            expect(summary.count).toBe(3)
            expect(summary.min).toBe(1)
            expect(summary.max).toBe(3)
            expect(summary.avg).toBe(2)
            expect(summary.last).toBe(3)
        })

        it('should handle missing metrics', () => {
            const summary = collector.getSummary('missing.metric')
            expect(summary).toBeNull()
        })

        it('should generate snapshots', () => {
            const snapshot = collector.getSnapshot()

            expect(snapshot.timestamp).toBeDefined()
            expect(snapshot.uptime).toBeGreaterThan(0)
            expect(snapshot.metrics['test.value']).toBeDefined()
        })
    })

    describe('Cleanup Operations', () => {
        it('should prune old metrics', () => {
            collector.collect('test.value', 1)
            jasmine.clock().tick(2000)  // Past interval

            collector.pruneMetrics()
            expect(collector.getMetric('test.value').length).toBe(0)
        })

        it('should remove empty series', () => {
            collector.collect('test.temp', 1)
            jasmine.clock().tick(2000)

            collector.pruneMetrics()
            const snapshot = collector.getSnapshot()
            expect(snapshot.metrics['test.temp']).toBeUndefined()
        })

        it('should retain recent metrics', () => {
            collector.collect('test.recent', 1)
            jasmine.clock().tick(500)  // Within interval

            collector.pruneMetrics()
            expect(collector.getMetric('test.recent').length).toBe(1)
        })
    })

    describe('Event Emission', () => {
        it('should emit metric events', (done) => {
            collector.once('metric', (data) => {
                expect(data.name).toBe('test.event')
                expect(data.value).toBe(1)
                expect(data.timestamp).toBeDefined()
                expect(data.labels).toEqual({ type: 'test' })
                done()
            })

            collector.collect('test.event', 1, { type: 'test' })
        })
    })

    describe('Resource Management', () => {
        it('should cleanup on reset', () => {
            collector.collect('test.value', 1)
            collector.reset()

            expect(collector.getSnapshot().metrics).toEqual({})
            expect(collector.getMetric('test.value').length).toBe(0)
        })

        it('should dispose cleanup timer', () => {
            spyOn(global, 'clearInterval')
            collector.dispose()
            expect(global.clearInterval).toHaveBeenCalled()
        })

        it('should remove listeners on dispose', () => {
            const listener = jasmine.createSpy('metricListener')
            collector.on('metric', listener)

            collector.dispose()
            collector.collect('test.value', 1)

            expect(listener).not.toHaveBeenCalled()
        })
    })

    describe('Label Management', () => {
        it('should generate consistent keys', () => {
            const key1 = collector.generateKey('test', { a: '1', b: '2' })
            const key2 = collector.generateKey('test', { b: '2', a: '1' })

            expect(key1).toBe(key2)
        })

        it('should handle missing labels', () => {
            const key = collector.generateKey('test')
            expect(key).toBe('test')
        })
    })

    describe('Time Series Operations', () => {
        it('should track metric series', () => {
            const timestamps = []
            for (let i = 0; i < 3; i++) {
                jasmine.clock().tick(100)
                collector.collect('test.series', i)
                timestamps.push(Date.now())
            }

            const metrics = collector.getMetric('test.series')
            expect(metrics.length).toBe(3)
            metrics.forEach((m, i) => {
                expect(m.timestamp).toBe(timestamps[i])
                expect(m.value).toBe(i)
            })
        })

        it('should handle rate calculations', () => {
            collector.collect('test.counter', 10)
            jasmine.clock().tick(1000)
            collector.collect('test.counter', 20)

            const summary = collector.getSummary('test.counter')
            expect(summary.last - summary.min).toBe(10)  // Rate over 1 second
        })
    })
})

================
File: tests/unit/handlers/ActiveHandler.spec.js
================
// tests/unit/handlers/ActiveHandler.spec.js
import ActiveHandler from '../../../src/api/features/ActiveHandler.js'
import APIRegistry from '../../../src/api/common/APIRegistry.js'
import BaseAPI from '../../../src/api/common/BaseAPI.js'

describe('ActiveHandler', () => {
    let handler
    let mockMemory
    let mockPassive
    let mockRegistry

    beforeEach(() => {
        mockMemory = new BaseAPI()
        Object.assign(mockMemory, {
            retrieveRelevantInteractions: jasmine.createSpy().and.resolveTo([{
                interaction: { prompt: 'test', output: 'response' },
                similarity: 0.8
            }]),
            generateEmbedding: jasmine.createSpy().and.resolveTo(new Array(1536).fill(0)),
            extractConcepts: jasmine.createSpy().and.resolveTo(['test']),
            addInteraction: jasmine.createSpy().and.resolveTo(true)
        })

        mockPassive = new BaseAPI()
        mockPassive.executeOperation = jasmine.createSpy().and.resolveTo('test response')

        mockRegistry = new APIRegistry()
        const mockGet = jasmine.createSpy('get')
        mockGet.and.callFake(name => {
            if (name === 'memory') return mockMemory
            if (name === 'passive') return mockPassive
            return null
        })
        mockRegistry.get = mockGet

        handler = new ActiveHandler({
            contextWindow: 3,
            similarityThreshold: 0.7
        })
        handler.registry = mockRegistry
    })

    describe('Interaction Management', () => {
        it('should handle complete interaction flow', async () => {
            const result = await handler.executeOperation('interact', {
                prompt: 'test question',
                context: []
            })

            expect(mockMemory.retrieveRelevantInteractions).toHaveBeenCalled()
            expect(mockPassive.executeOperation).toHaveBeenCalled()
            expect(mockMemory.generateEmbedding).toHaveBeenCalled()
            expect(mockMemory.extractConcepts).toHaveBeenCalled()
            expect(mockMemory.addInteraction).toHaveBeenCalled()

            expect(result.response).toBe('test response')
            expect(result.concepts).toEqual(['test'])
            expect(result.retrievals).toBeDefined()
        })

        it('should apply similarity threshold', async () => {
            await handler.executeOperation('interact', {
                prompt: 'test question'
            })

            expect(mockMemory.retrieveRelevantInteractions).toHaveBeenCalledWith(
                'test question',
                0.7
            )
        })

        it('should handle interaction errors', async () => {
            mockPassive.executeOperation.and.rejectWith(new Error('Chat failed'))
            spyOn(handler, '_emitMetric')

            await expectAsync(
                handler.executeOperation('interact', { prompt: 'test' })
            ).toBeRejected()

            expect(handler._emitMetric).toHaveBeenCalledWith(
                'interaction.errors',
                1
            )
        })
    })

    describe('Context Management', () => {
        it('should build context with retrievals', async () => {
            const retrievals = [{
                interaction: {
                    prompt: 'previous',
                    output: 'answer'
                },
                similarity: 0.9
            }]
            mockMemory.retrieveRelevantInteractions.and.resolveTo(retrievals)

            const result = await handler.executeOperation('interact', {
                prompt: 'test',
                context: []
            })

            expect(mockPassive.executeOperation).toHaveBeenCalledWith(
                'chat',
                jasmine.objectContaining({
                    context: jasmine.stringContaining('previous')
                })
            )
        })

        it('should respect context window size', async () => {
            const recentInteractions = Array(5).fill().map((_, i) => ({
                prompt: `q${i}`,
                output: `a${i}`
            }))

            await handler.executeOperation('interact', {
                prompt: 'test',
                context: recentInteractions
            })

            const chatCall = mockPassive.executeOperation.calls.mostRecent()
            const context = chatCall.args[1].context
            expect(context.split('Q:').length - 1).toBeLessThanOrEqual(3)
        })
    })

    describe('Search Operations', () => {
        it('should handle semantic search', async () => {
            const result = await handler.executeOperation('search', {
                query: 'test query',
                type: 'semantic',
                limit: 5
            })

            expect(mockMemory.generateEmbedding).toHaveBeenCalledWith('test query')
            expect(mockMemory.retrieveRelevantInteractions).toHaveBeenCalled()
            expect(result).toBeDefined()
        })

        it('should handle SPARQL search', async () => {
            await handler.executeOperation('search', {
                query: 'test',
                type: 'sparql',
                limit: 5
            })

            expect(mockPassive.executeOperation).toHaveBeenCalledWith(
                'query',
                jasmine.objectContaining({
                    sparql: jasmine.stringMatching(/SELECT.*WHERE/)
                })
            )
        })
    })

    describe('Analysis Operations', () => {
        it('should handle concept extraction', async () => {
            const result = await handler.executeOperation('analyze', {
                content: 'test content',
                type: 'concept'
            })

            expect(mockMemory.extractConcepts).toHaveBeenCalledWith('test content')
            expect(result).toEqual(['test'])
        })

        it('should handle embedding generation', async () => {
            await handler.executeOperation('analyze', {
                content: 'test content',
                type: 'embedding'
            })

            expect(mockMemory.generateEmbedding).toHaveBeenCalledWith('test content')
        })
    })

    describe('Metrics', () => {
        it('should track operation metrics', async () => {
            spyOn(handler, '_emitMetric')

            await handler.executeOperation('interact', {
                prompt: 'test'
            })

            expect(handler._emitMetric).toHaveBeenCalledWith(
                'interaction.count',
                1
            )
        })

        it('should aggregate operation statistics', async () => {
            const metrics = await handler.getMetrics()
            expect(metrics.operations).toBeDefined()
            expect(metrics.operations.interaction).toBeDefined()
            expect(metrics.operations.search).toBeDefined()
            expect(metrics.operations.analysis).toBeDefined()
        })
    })
})

================
File: tests/unit/handlers/CLIHandler.spec.js
================
// tests/unit/api/CLIHandler.spec.js
import CLIHandler from '../../../src/api/cli/CLIHandler.js'
import APIRegistry from '../../../src/api/common/APIRegistry.js'

describe('CLIHandler', () => {
    let handler
    let mockRegistry
    let mockChatAPI
    let mockStorageAPI
    let originalConsole
    let consoleOutput

    beforeEach(() => {
        // Mock APIs
        mockChatAPI = {
            executeOperation: jasmine.createSpy('executeOperation')
                .and.resolveTo('Test response'),
            initialized: true
        }

        mockStorageAPI = {
            storeInteraction: jasmine.createSpy('storeInteraction')
                .and.resolveTo({ success: true }),
            retrieveInteractions: jasmine.createSpy('retrieveInteractions')
                .and.resolveTo([{ data: 'test' }]),
            initialized: true
        }

        // Mock registry
        mockRegistry = new APIRegistry()
        spyOn(mockRegistry, 'get').and.callFake(name => {
            if (name === 'chat') return mockChatAPI
            if (name === 'storage') return mockStorageAPI
            return null
        })

        // Capture console output
        consoleOutput = {
            log: [],
            error: []
        }
        originalConsole = {
            log: console.log,
            error: console.error
        }
        console.log = (...args) => consoleOutput.log.push(args.join(' '))
        console.error = (...args) => consoleOutput.error.push(args.join(' '))

        handler = new CLIHandler({ test: 'config' })
        handler.registry = mockRegistry
    })

    afterEach(() => {
        console.log = originalConsole.log
        console.error = originalConsole.error
    })

    describe('Command Setup', () => {
        it('should register all commands', () => {
            const commands = handler.yargs.getCommandInstance().getCommands()
            expect(commands).toContain('chat')
            expect(commands).toContain('store')
            expect(commands).toContain('query')
            expect(commands).toContain('metrics')
        })

        it('should set command options', () => {
            const options = handler.yargs.getOptions()
            expect(options.key.color).toBeDefined()
            expect(options.key.verbose).toBeDefined()
        })
    })

    describe('Chat Operations', () => {
        it('should handle chat command', async () => {
            await handler.executeOperation('chat', {
                prompt: 'Hello',
                model: 'test-model'
            })

            expect(mockChatAPI.executeOperation).toHaveBeenCalledWith(
                'chat',
                jasmine.objectContaining({
                    prompt: 'Hello',
                    model: 'test-model'
                })
            )
            expect(consoleOutput.log[0]).toContain('Test response')
        })

        it('should handle chat errors', async () => {
            mockChatAPI.executeOperation.and.rejectWith(new Error('Chat failed'))

            await handler.executeOperation('chat', {
                prompt: 'Hello'
            })

            expect(consoleOutput.error[0]).toContain('Chat failed')
        })
    })

    describe('Storage Operations', () => {
        it('should handle store command', async () => {
            await handler.executeOperation('store', {
                data: 'test content',
                format: 'text'
            })

            expect(mockStorageAPI.storeInteraction).toHaveBeenCalledWith(
                jasmine.objectContaining({
                    content: 'test content',
                    format: 'text'
                })
            )
        })

        it('should handle query command', async () => {
            await handler.executeOperation('query', {
                query: 'test',
                limit: 5
            })

            expect(mockStorageAPI.retrieveInteractions).toHaveBeenCalledWith(
                jasmine.objectContaining({
                    text: 'test',
                    limit: 5
                })
            )
        })
    })

    describe('Output Formatting', () => {
        it('should format success output', () => {
            handler.formatOutput({
                success: true,
                data: 'test result'
            })

            expect(consoleOutput.log[0]).toContain('test result')
        })

        it('should format error output', () => {
            handler.formatOutput({
                success: false,
                error: 'test error'
            })

            expect(consoleOutput.error[0]).toContain('test error')
        })

        it('should format array results', () => {
            handler.formatOutput({
                success: true,
                data: [
                    { key: 'value1' },
                    { key: 'value2' }
                ]
            })

            expect(consoleOutput.log.length).toBe(4) // Header + 2 items + separator
            expect(consoleOutput.log.join('\n')).toContain('value1')
            expect(consoleOutput.log.join('\n')).toContain('value2')
        })

        it('should respect color option', () => {
            handler.formatOutput({
                success: true,
                data: 'test'
            }, { color: false })

            expect(consoleOutput.log[0]).toBe('test')
        })
    })

    describe('Metrics Handling', () => {
        it('should handle metrics command', async () => {
            await handler.executeOperation('metrics', {
                format: 'text'
            })

            const metrics = await handler.getMetrics()
            expect(consoleOutput.log.join('\n')).toContain(metrics.uptime)
        })

        it('should format metrics as JSON', async () => {
            await handler.executeOperation('metrics', {
                format: 'json'
            })

            const output = JSON.parse(consoleOutput.log[0])
            expect(output.success).toBeTrue()
            expect(output.data).toBeDefined()
        })
    })

    describe('Error Handling', () => {
        it('should handle unknown commands', async () => {
            await handler.executeOperation('unknown', {})
            expect(consoleOutput.error[0]).toContain('Unknown command')
        })

        it('should handle missing arguments', () => {
            expect(() => handler.yargs.parse(['chat']))
                .toThrow()
        })

        it('should validate required options', () => {
            const result = handler.yargs.parse(['chat', '--model', 'test'])
            expect(result.prompt).toBeUndefined()
        })
    })
})

================
File: tests/unit/handlers/EmbeddingHandler.spec.js
================
// tests/unit/handlers/EmbeddingHandler.spec.js
import EmbeddingHandler from '../../../src/handlers/EmbeddingHandler.js'
import CacheManager from '../../../src/handlers/CacheManager.js'

describe('EmbeddingHandler', () => {
    let handler
    let mockLLMProvider
    let mockCache
    const dimension = 1536
    const model = 'test-model'

    beforeEach(() => {
        mockLLMProvider = {
            generateEmbedding: jasmine.createSpy('generateEmbedding')
                .and.resolveTo(new Array(dimension).fill(0.1))
        }

        mockCache = new CacheManager({
            maxSize: 100,
            ttl: 1000
        })

        handler = new EmbeddingHandler(
            mockLLMProvider,
            model,
            dimension,
            mockCache
        )
    })

    afterEach(() => {
        mockCache.dispose()
    })

    describe('Embedding Generation', () => {
        it('should generate and cache embeddings', async () => {
            const text = 'test input'
            const embedding = await handler.generateEmbedding(text)

            expect(embedding.length).toBe(dimension)
            expect(mockLLMProvider.generateEmbedding)
                .toHaveBeenCalledWith(model, text)

            // Verify caching
            mockLLMProvider.generateEmbedding.calls.reset()
            const cachedEmbedding = await handler.generateEmbedding(text)
            expect(mockLLMProvider.generateEmbedding).not.toHaveBeenCalled()
            expect(cachedEmbedding).toEqual(embedding)
        })

        it('should handle API errors', async () => {
            mockLLMProvider.generateEmbedding
                .and.rejectWith(new Error('API Error'))

            await expectAsync(handler.generateEmbedding('test'))
                .toBeRejectedWithError('API Error')
        })

        it('should retry on certain errors', async () => {
            mockLLMProvider.generateEmbedding
                .and.rejectWith(new Error('Network Error'))
                .and.resolveTo(new Array(dimension).fill(0.1))

            const embedding = await handler.generateEmbedding('test')
            expect(embedding.length).toBe(dimension)
            expect(mockLLMProvider.generateEmbedding).toHaveBeenCalledTimes(2)
        })
    })

    describe('Embedding Validation', () => {
        it('should validate embedding arrays', () => {
            const validEmbedding = new Array(dimension).fill(0.1)
            expect(() => handler.validateEmbedding(validEmbedding))
                .not.toThrow()

            const nonArray = 'not an array'
            expect(() => handler.validateEmbedding(nonArray))
                .toThrowError('Embedding must be an array')
        })

        it('should validate numeric values', () => {
            const invalidValues = new Array(dimension).fill('not a number')
            expect(() => handler.validateEmbedding(invalidValues))
                .toThrowError('Embedding must contain only valid numbers')
        })

        it('should handle undefined values', () => {
            const hasUndefined = new Array(dimension).fill(0.1)
            hasUndefined[5] = undefined

            expect(() => handler.validateEmbedding(hasUndefined))
                .toThrowError('Embedding must contain only valid numbers')
        })
    })

    describe('Dimension Standardization', () => {
        it('should pad short embeddings', () => {
            const shortEmbedding = new Array(1000).fill(0.1)
            const standardized = handler.standardizeEmbedding(shortEmbedding)

            expect(standardized.length).toBe(dimension)
            expect(standardized.slice(0, 1000)).toEqual(shortEmbedding)
            expect(standardized.slice(1000)).toEqual(new Array(536).fill(0))
        })

        it('should truncate long embeddings', () => {
            const longEmbedding = new Array(2000).fill(0.1)
            const standardized = handler.standardizeEmbedding(longEmbedding)

            expect(standardized.length).toBe(dimension)
            expect(standardized).toEqual(longEmbedding.slice(0, dimension))
        })

        it('should preserve exact dimension', () => {
            const correctEmbedding = new Array(dimension).fill(0.1)
            const standardized = handler.standardizeEmbedding(correctEmbedding)

            expect(standardized).toBe(correctEmbedding)
        })
    })

    describe('Cache Management', () => {
        it('should handle cache misses', async () => {
            const text = 'test input'
            await handler.generateEmbedding(text)
            mockCache.clear()

            await handler.generateEmbedding(text)
            expect(mockLLMProvider.generateEmbedding).toHaveBeenCalledTimes(2)
        })

        it('should use cache key based on model and text', async () => {
            const text = 'test input'
            await handler.generateEmbedding(text)

            // Different model should bypass cache
            const handler2 = new EmbeddingHandler(
                mockLLMProvider,
                'different-model',
                dimension,
                mockCache
            )
            await handler2.generateEmbedding(text)

            expect(mockLLMProvider.generateEmbedding).toHaveBeenCalledTimes(2)
        })

        it('should handle concurrent requests', async () => {
            const text = 'test input'
            const promises = Array(5).fill().map(() =>
                handler.generateEmbedding(text)
            )

            const results = await Promise.all(promises)
            expect(mockLLMProvider.generateEmbedding).toHaveBeenCalledTimes(1)
            expect(results.every(r => r.length === dimension)).toBeTrue()
        })
    })
})

================
File: tests/unit/handlers/LLMHandler.spec.js
================
// tests/unit/handlers/LLMHandler.spec.js
import LLMHandler from '../../../src/handlers/LLMHandler.js'

describe('LLMHandler', () => {
    let handler
    let mockProvider

    beforeEach(() => {
        mockProvider = {
            generateEmbedding: jasmine.createSpy('generateEmbedding'),
            generateChat: jasmine.createSpy('generateChat'),
            generateCompletion: jasmine.createSpy('generateCompletion')
        }
        handler = new LLMHandler(mockProvider, 'test-model')
    })

    describe('generateResponse', () => {
        it('should generate chat response with correct parameters', async () => {
            const expectedResponse = 'Test response'
            mockProvider.generateChat.and.resolveTo(expectedResponse)

            const response = await handler.generateResponse(
                'test prompt',
                'test context'
            )

            expect(response).toBe(expectedResponse)
            expect(mockProvider.generateChat).toHaveBeenCalledWith(
                'test-model',
                jasmine.arrayContaining([
                    jasmine.objectContaining({ role: 'system' }),
                    jasmine.objectContaining({ role: 'user' })
                ]),
                jasmine.objectContaining({ temperature: 0.7 })
            )
        })

        it('should handle chat generation errors', async () => {
            mockProvider.generateChat.and.rejectWith(new Error('API Error'))

            await expectAsync(
                handler.generateResponse('test prompt', 'test context')
            ).toBeRejectedWithError('API Error')
        })
    })

    describe('extractConcepts', () => {
        it('should extract concepts from LLM response', async () => {
            const concepts = ['concept1', 'concept2']
            mockProvider.generateCompletion.and.resolveTo(
                `Some text ["${concepts.join('", "')}"] more text`
            )

            const result = await handler.extractConcepts('test text')

            expect(result).toEqual(concepts)
            expect(mockProvider.generateCompletion).toHaveBeenCalledWith(
                'test-model',
                jasmine.any(String),
                jasmine.objectContaining({ temperature: 0.2 })
            )
        })

        it('should return empty array when no concepts found', async () => {
            mockProvider.generateCompletion.and.resolveTo('Invalid response')

            const result = await handler.extractConcepts('test text')

            expect(result).toEqual([])
        })

        it('should handle invalid JSON in concept extraction', async () => {
            mockProvider.generateCompletion.and.resolveTo('[invalid json]')

            const result = await handler.extractConcepts('test text')

            expect(result).toEqual([])
        })
    })

    describe('generateEmbedding', () => {
        it('should generate embeddings successfully', async () => {
            const expectedEmbedding = [0.1, 0.2, 0.3]
            mockProvider.generateEmbedding.and.resolveTo(expectedEmbedding)

            const embedding = await handler.generateEmbedding(
                'test text',
                'embedding-model'
            )

            expect(embedding).toEqual(expectedEmbedding)
            expect(mockProvider.generateEmbedding).toHaveBeenCalledWith(
                'embedding-model',
                'test text'
            )
        })

        it('should retry failed embedding generations', async () => {
            mockProvider.generateEmbedding
                .and.rejectWith(new Error('Retry 1'))
                .and.rejectWith(new Error('Retry 2'))
                .and.resolveTo([0.1, 0.2, 0.3])

            const embedding = await handler.generateEmbedding(
                'test text',
                'embedding-model'
            )

            expect(embedding).toEqual([0.1, 0.2, 0.3])
            expect(mockProvider.generateEmbedding).toHaveBeenCalledTimes(3)
        })

        it('should fail after max retries', async () => {
            mockProvider.generateEmbedding.and.rejectWith(new Error('API Error'))

            await expectAsync(
                handler.generateEmbedding('test text', 'embedding-model')
            ).toBeRejectedWithError(/Failed to generate embedding after 3 attempts/)

            expect(mockProvider.generateEmbedding).toHaveBeenCalledTimes(3)
        })
    })

    describe('setTemperature', () => {
        it('should set valid temperature', () => {
            expect(() => handler.setTemperature(0.5)).not.toThrow()
        })

        it('should reject invalid temperatures', () => {
            expect(() => handler.setTemperature(-0.1)).toThrow()
            expect(() => handler.setTemperature(1.1)).toThrow()
        })
    })

    describe('model validation', () => {
        it('should validate model names', () => {
            expect(handler.validateModel('valid-model')).toBe(true)
            expect(handler.validateModel('')).toBe(false)
            expect(handler.validateModel(undefined)).toBe(false)
        })
    })
})

================
File: tests/unit/handlers/PassiveHandler.spec.js
================
// tests/unit/handlers/PassiveHandler.spec.js
import PassiveHandler from '../../../src/api/features/PassiveHandler.js'
import APIRegistry from '../../../src/api/common/APIRegistry.js'
import BaseAPI from '../../../src/api/common/BaseAPI.js'

describe('PassiveHandler', () => {
    let handler
    let mockLLMProvider
    let mockStorage
    let mockRegistry

    beforeEach(() => {
        mockLLMProvider = {
            generateChat: jasmine.createSpy('generateChat')
                .and.resolveTo('test response'),
            generateCompletion: jasmine.createSpy('generateCompletion')
                .and.resolveTo('test completion')
        }

        mockStorage = new BaseAPI()
        spyOn(mockStorage, 'executeOperation').and.resolveTo({ success: true })
        spyOn(mockStorage, 'storeInteraction').and.resolveTo({ success: true })

        mockRegistry = new APIRegistry()
        spyOn(mockRegistry, 'get').and.returnValue(mockStorage)

        handler = new PassiveHandler({
            llmProvider: mockLLMProvider,
            sparqlEndpoint: 'http://test.endpoint'
        })
        handler.registry = mockRegistry
    })

    describe('Chat Operations', () => {
        it('should handle chat requests', async () => {
            const result = await handler.executeOperation('chat', {
                prompt: 'test prompt',
                model: 'test-model'
            })

            expect(mockLLMProvider.generateChat).toHaveBeenCalledWith(
                'test-model',
                [{
                    role: 'user',
                    content: 'test prompt'
                }],
                jasmine.any(Object)
            )
            expect(result).toBe('test response')
        })

        it('should emit chat metrics', async () => {
            spyOn(handler, '_emitMetric')

            await handler.executeOperation('chat', {
                prompt: 'test',
                model: 'test-model'
            })

            expect(handler._emitMetric).toHaveBeenCalledWith(
                'chat.requests',
                1
            )
        })

        it('should handle chat errors', async () => {
            mockLLMProvider.generateChat.and.rejectWith(new Error('Chat failed'))
            spyOn(handler, '_emitMetric')

            await expectAsync(
                handler.executeOperation('chat', {
                    prompt: 'test',
                    model: 'test-model'
                })
            ).toBeRejected()

            expect(handler._emitMetric).toHaveBeenCalledWith(
                'chat.errors',
                1
            )
        })
    })

    describe('Query Operations', () => {
        it('should execute SPARQL queries', async () => {
            const query = 'SELECT * WHERE { ?s ?p ?o }'
            await handler.executeOperation('query', {
                sparql: query,
                format: 'json'
            })

            expect(mockStorage.executeOperation).toHaveBeenCalledWith(
                'query',
                {
                    sparql: query,
                    format: 'json'
                }
            )
        })

        it('should emit query metrics', async () => {
            spyOn(handler, '_emitMetric')

            await handler.executeOperation('query', {
                sparql: 'SELECT * WHERE { ?s ?p ?o }',
                format: 'json'
            })

            expect(handler._emitMetric).toHaveBeenCalledWith(
                'query.requests',
                1
            )
        })

        it('should handle query errors', async () => {
            mockStorage.executeOperation.and.rejectWith(new Error('Query failed'))
            spyOn(handler, '_emitMetric')

            await expectAsync(
                handler.executeOperation('query', {
                    sparql: 'INVALID QUERY',
                    format: 'json'
                })
            ).toBeRejected()

            expect(handler._emitMetric).toHaveBeenCalledWith(
                'query.errors',
                1
            )
        })
    })

    describe('Storage Operations', () => {
        it('should store interactions', async () => {
            const content = 'test content'
            await handler.executeOperation('store', {
                content,
                format: 'text'
            })

            expect(mockStorage.storeInteraction).toHaveBeenCalledWith({
                content,
                format: 'text',
                timestamp: jasmine.any(Number)
            })
        })

        it('should emit storage metrics', async () => {
            spyOn(handler, '_emitMetric')

            await handler.executeOperation('store', {
                content: 'test',
                format: 'text'
            })

            expect(handler._emitMetric).toHaveBeenCalledWith(
                'store.requests',
                1
            )
        })

        it('should handle storage errors', async () => {
            mockStorage.storeInteraction.and.rejectWith(new Error('Store failed'))
            spyOn(handler, '_emitMetric')

            await expectAsync(
                handler.executeOperation('store', {
                    content: 'test',
                    format: 'text'
                })
            ).toBeRejected()

            expect(handler._emitMetric).toHaveBeenCalledWith(
                'store.errors',
                1
            )
        })
    })

    describe('Metrics Collection', () => {
        it('should collect operation metrics', async () => {
            const metrics = await handler.getMetrics()

            expect(metrics.operations).toBeDefined()
            expect(metrics.operations.chat).toBeDefined()
            expect(metrics.operations.query).toBeDefined()
            expect(metrics.operations.store).toBeDefined()
        })

        it('should aggregate metrics by operation', async () => {
            await handler.executeOperation('chat', {
                prompt: 'test',
                model: 'test-model'
            })

            const metrics = await handler.getMetrics()
            expect(metrics.operations.chat.requests).toBe(1)
        })

        it('should track operation latency', async () => {
            spyOn(handler, '_getMetricValue').and.resolveTo(100)

            const metrics = await handler.getMetrics()
            expect(metrics.operations.chat.latency).toBe(100)
        })
    })
})

================
File: tests/unit/handlers/REPLHandler.spec.js
================
// tests/unit/api/REPLHandler.spec.js
import REPLHandler from '../../../src/api/repl/REPLHandler.js'
import APIRegistry from '../../../src/api/common/APIRegistry.js'
import { EventEmitter } from 'events'

describe('REPLHandler', () => {
    let handler
    let mockRegistry
    let mockReadline
    let mockChatAPI
    let mockStorageAPI

    beforeEach(() => {
        // Mock readline interface
        mockReadline = new EventEmitter()
        mockReadline.setPrompt = jasmine.createSpy('setPrompt')
        mockReadline.prompt = jasmine.createSpy('prompt')
        mockReadline.close = jasmine.createSpy('close')

        // Mock APIs
        mockChatAPI = {
            executeOperation: jasmine.createSpy('executeOperation')
                .and.resolveTo('Test response'),
            initialized: true
        }

        mockStorageAPI = {
            storeInteraction: jasmine.createSpy('storeInteraction')
                .and.resolveTo({ success: true }),
            initialized: true
        }

        // Mock registry
        mockRegistry = new APIRegistry()
        spyOn(mockRegistry, 'get').and.callFake(name => {
            if (name === 'chat') return mockChatAPI
            if (name === 'storage') return mockStorageAPI
            return null
        })

        handler = new REPLHandler({ test: 'config' })
        handler.registry = mockRegistry
        handler.rl = mockReadline
    })

    describe('Command Processing', () => {
        beforeEach(async () => {
            await handler.initialize()
        })

        it('should handle help command', async () => {
            spyOn(console, 'log')
            await handler.processInput('help')
            expect(console.log).toHaveBeenCalledWith(
                jasmine.stringMatching(/Available Commands/)
            )
        })

        it('should switch modes', async () => {
            await handler.processInput('mode chat')
            expect(handler.mode).toBe('chat')
            expect(mockReadline.setPrompt).toHaveBeenCalledWith(
                jasmine.stringMatching(/chat/)
            )
        })

        it('should reject invalid modes', async () => {
            spyOn(console, 'log')
            await handler.processInput('mode invalid')
            expect(console.log).toHaveBeenCalledWith(
                jasmine.stringMatching(/Invalid mode/)
            )
        })

        it('should show command history', async () => {
            spyOn(console, 'log')
            handler.history.push('test command')
            await handler.processInput('history')
            expect(console.log).toHaveBeenCalledWith(
                jasmine.stringMatching(/test command/)
            )
        })
    })

    describe('Chat Mode', () => {
        beforeEach(async () => {
            await handler.initialize()
            handler.mode = 'chat'
        })

        it('should process chat input', async () => {
            await handler.processInput('Hello')

            expect(mockChatAPI.executeOperation).toHaveBeenCalledWith(
                'chat',
                jasmine.objectContaining({
                    prompt: 'Hello',
                    mode: 'chat'
                })
            )
        })

        it('should store chat interactions', async () => {
            await handler.processInput('Hello')

            expect(mockStorageAPI.storeInteraction).toHaveBeenCalledWith(
                jasmine.objectContaining({
                    prompt: 'Hello',
                    output: 'Test response'
                })
            )
        })

        it('should handle chat errors', async () => {
            spyOn(console, 'error')
            mockChatAPI.executeOperation.and.rejectWith(new Error('Chat error'))

            await handler.processInput('Hello')
            expect(console.error).toHaveBeenCalledWith(
                jasmine.stringMatching(/Chat error/)
            )
        })
    })

    describe('RDF Mode', () => {
        beforeEach(async () => {
            await handler.initialize()
            handler.mode = 'rdf'
        })

        it('should process SPARQL queries', async () => {
            const query = 'SELECT * WHERE { ?s ?p ?o }'
            await handler.processInput(query)

            expect(mockStorageAPI.executeOperation).toHaveBeenCalledWith(
                'query',
                jasmine.objectContaining({ sparql: query })
            )
        })

        it('should handle update operations', async () => {
            const update = 'INSERT DATA { <s> <p> <o> }'
            await handler.processInput(update)

            expect(mockStorageAPI.executeOperation).toHaveBeenCalledWith(
                'update',
                jasmine.objectContaining({ sparql: update })
            )
        })

        it('should handle RDF errors', async () => {
            spyOn(console, 'error')
            mockStorageAPI.executeOperation.and.rejectWith(new Error('RDF error'))

            await handler.processInput('SELECT * WHERE { ?s ?p ?o }')
            expect(console.error).toHaveBeenCalledWith(
                jasmine.stringMatching(/RDF error/)
            )
        })
    })

    describe('History Management', () => {
        beforeEach(async () => {
            await handler.initialize()
        })

        it('should record command history', async () => {
            await handler.processInput('test command')
            expect(handler.history).toContain('test command')
        })

        it('should limit history size', async () => {
            for (let i = 0; i < 200; i++) {
                await handler.processInput(`command ${i}`)
            }
            expect(handler.history.length).toBeLessThanOrEqual(100)
        })

        it('should ignore empty commands', async () => {
            const initialLength = handler.history.length
            await handler.processInput('   ')
            expect(handler.history.length).toBe(initialLength)
        })
    })

    describe('Lifecycle Management', () => {
        it('should handle shutdown', async () => {
            spyOn(process, 'exit')
            await handler.shutdown()
            expect(mockReadline.close).toHaveBeenCalled()
            expect(process.exit).toHaveBeenCalledWith(0)
        })

        it('should handle SIGINT', () => {
            spyOn(handler, 'shutdown')
            mockReadline.emit('SIGINT')
            expect(handler.shutdown).toHaveBeenCalled()
        })
    })
})

================
File: tests/unit/handlers/SelfieHandler.spec.js
================
// tests/unit/handlers/SelfieHandler.spec.js
import SelfieHandler from '../../../src/api/features/SelfieHandler.js'
import APIRegistry from '../../../src/api/common/APIRegistry.js'
import BaseAPI from '../../../src/api/common/BaseAPI.js'

describe('SelfieHandler', () => {
    let handler
    let mockAPI
    let mockMeter
    let mockHistogram
    let mockCounter

    beforeEach(() => {
        mockHistogram = {
            record: jasmine.createSpy('record')
        }
        mockCounter = {
            add: jasmine.createSpy('add')
        }
        mockMeter = {
            createHistogram: () => mockHistogram,
            createCounter: () => mockCounter
        }

        mockAPI = new BaseAPI()
        spyOn(mockAPI, 'getMetrics').and.resolveTo({
            size: 100,
            operations: 50,
            latency: 150
        })

        const registry = new APIRegistry()
        spyOn(registry, 'get').and.returnValue(mockAPI)
        spyOn(registry, 'getAll').and.returnValue(new Map([['test', mockAPI]]))

        handler = new SelfieHandler({
            interval: 100,
            openTelemetry: {
                metrics: true
            }
        })
        handler.registry = registry
    })

    describe('Metric Collection', () => {
        it('should collect metrics from registered APIs', async () => {
            await handler.collectMetrics()
            const metrics = handler.getMetrics()

            expect(metrics.collectors.storage).toBeDefined()
            expect(metrics.collectors.storage.values.size).toBe(100)
            expect(metrics.collectors.storage.values.operations).toBe(50)
        })

        it('should track metric timestamps', async () => {
            await handler.collectMetrics()
            const metrics = handler.getMetrics()

            expect(metrics.timestamp).toBeDefined()
            expect(metrics.collectors.storage.timestamp).toBeDefined()
            expect(metrics.collectors.storage.timestamp).toBeLessThanOrEqual(Date.now())
        })

        it('should aggregate metrics over time', async () => {
            await handler.collectMetrics()
            mockAPI.getMetrics.and.resolveTo({
                size: 150,
                operations: 75,
                latency: 200
            })
            await handler.collectMetrics()

            const metrics = handler.getMetrics()
            expect(metrics.collectors.storage.values.operations).toBe(75)
        })
    })

    describe('Error Tracking', () => {
        it('should track error occurrences', () => {
            const error = new Error('Test error')
            handler.trackError('test', error)

            const metrics = handler.getMetrics()
            const errorEntry = metrics.errors.find(e => e.message === 'Test error')

            expect(errorEntry).toBeDefined()
            expect(errorEntry.count).toBe(1)
            expect(errorEntry.type).toBe('test')
        })

        it('should aggregate repeated errors', () => {
            const error = new Error('Repeated error')
            handler.trackError('test', error)
            handler.trackError('test', error)

            const metrics = handler.getMetrics()
            const errorEntry = metrics.errors.find(e => e.message === 'Repeated error')

            expect(errorEntry.count).toBe(2)
            expect(errorEntry.firstOccurred).toBeLessThan(errorEntry.lastOccurred)
        })
    })

    describe('OpenTelemetry Integration', () => {
        beforeEach(async () => {
            await handler.setupOpenTelemetry()
            handler.setupMetricInstruments(mockMeter)
        })

        it('should record memory metrics', async () => {
            await handler.collectMetrics()

            expect(mockHistogram.record).toHaveBeenCalledWith(
                jasmine.any(Number),
                { type: 'heap_used' }
            )
        })

        it('should track API latency', async () => {
            await handler.collectMetrics()

            expect(mockHistogram.record).toHaveBeenCalledWith(
                150, // from mockAPI metrics
                jasmine.objectContaining({ api: 'test' })
            )
        })

        it('should count storage operations', async () => {
            await handler.collectMetrics()

            expect(mockCounter.add).toHaveBeenCalledWith(
                50, // from mockAPI metrics
                { type: 'total' }
            )
        })
    })

    describe('Event Emission', () => {
        it('should emit metric events', (done) => {
            handler.onMetrics((data) => {
                expect(data.name).toBe('storage')
                expect(data.metrics).toBeDefined()
                expect(data.timestamp).toBeDefined()
                done()
            })

            handler.collectMetrics()
        })

        it('should emit error events', (done) => {
            handler.onError((data) => {
                expect(data.type).toBe('test')
                expect(data.error).toBeDefined()
                expect(data.count).toBe(1)
                done()
            })

            handler.trackError('test', new Error('Test error'))
        })
    })

    describe('Resource Management', () => {
        it('should cleanup resources on shutdown', async () => {
            const storageEndpoint = 'http://test.com/metrics'
            handler.config.storageEndpoint = storageEndpoint

            spyOn(global, 'fetch').and.resolveTo({
                ok: true
            })

            await handler.shutdown()

            expect(global.fetch).toHaveBeenCalledWith(
                storageEndpoint,
                jasmine.objectContaining({
                    method: 'POST',
                    headers: jasmine.objectContaining({
                        'Content-Type': 'application/json'
                    })
                })
            )
        })

        it('should handle storage errors during shutdown', async () => {
            handler.config.storageEndpoint = 'http://invalid'
            spyOn(global, 'fetch').and.rejectWith(new Error('Network error'))

            await expectAsync(handler.shutdown()).toBeResolved()
            expect(handler.errors.size).toBeGreaterThan(0)
        })
    })
})

================
File: tests/unit/http/message-queue.spec.js
================
// tests/unit/http/message-queue.spec.js
import MessageQueue from '../../../src/api/http/server/MessageQueue.js'

describe('MessageQueue', () => {
    let queue
    const clientId = 'test-client'
    const topic = 'test-topic'
    const mockMessage = { data: 'test' }

    beforeEach(() => {
        queue = new MessageQueue({
            maxQueueSize: 3,
            maxAge: 1000 // 1 second for testing
        })
        jasmine.clock().install()
    })

    afterEach(() => {
        queue.dispose()
        jasmine.clock().uninstall()
    })

    describe('Message Management', () => {
        it('should add and retrieve messages', () => {
            queue.addMessage(clientId, topic, mockMessage)
            const messages = queue.getMessages(clientId)

            expect(messages.length).toBe(1)
            expect(messages[0].message).toEqual(mockMessage)
            expect(messages[0].topic).toBe(topic)
            expect(messages[0].id).toBeDefined()
            expect(messages[0].timestamp).toBeDefined()
        })

        it('should enforce maxQueueSize', () => {
            for (let i = 0; i < 5; i++) {
                queue.addMessage(clientId, topic, { count: i })
            }

            const messages = queue.getMessages(clientId)
            expect(messages.length).toBe(3)
            expect(messages[0].message.count).toBe(2)
        })

        it('should filter messages by timestamp', () => {
            queue.addMessage(clientId, topic, { age: 'old' })
            jasmine.clock().tick(2000)
            queue.addMessage(clientId, topic, { age: 'new' })

            const messages = queue.getMessages(clientId, null, Date.now() - 1000)
            expect(messages.length).toBe(1)
            expect(messages[0].message.age).toBe('new')
        })
    })

    describe('Topic Management', () => {
        it('should handle topic subscriptions', () => {
            queue.subscribeTopic(clientId, topic)
            expect(queue.getClientTopics(clientId)).toContain(topic)
        })

        it('should handle topic unsubscriptions', () => {
            queue.subscribeTopic(clientId, topic)
            queue.unsubscribeTopic(clientId, topic)
            expect(queue.getClientTopics(clientId).length).toBe(0)
        })

        it('should filter messages by topic', () => {
            queue.addMessage(clientId, 'topic1', { data: 't1' })
            queue.addMessage(clientId, 'topic2', { data: 't2' })

            const messages = queue.getMessages(clientId, 'topic1')
            expect(messages.length).toBe(1)
            expect(messages[0].message.data).toBe('t1')
        })

        it('should cleanup empty topic subscriptions', () => {
            queue.subscribeTopic(clientId, topic)
            queue.addMessage(clientId, topic, mockMessage)
            queue.acknowledgeMessages(clientId, [queue.getMessages(clientId)[0].id])
            queue.unsubscribeTopic(clientId, topic)

            expect(queue.queues.has(clientId)).toBe(false)
        })
    })

    describe('Message Expiration', () => {
        it('should remove expired messages during cleanup', () => {
            queue.addMessage(clientId, topic, mockMessage)
            jasmine.clock().tick(2000)
            queue.pruneExpiredMessages()

            expect(queue.getMessages(clientId).length).toBe(0)
        })

        it('should cleanup empty queues after expiration', () => {
            queue.addMessage(clientId, topic, mockMessage)
            jasmine.clock().tick(2000)
            queue.pruneExpiredMessages()

            expect(queue.queues.has(clientId)).toBe(false)
        })

        it('should retain unexpired messages', () => {
            queue.addMessage(clientId, topic, { age: 'old' })
            jasmine.clock().tick(500)
            queue.addMessage(clientId, topic, { age: 'new' })
            queue.pruneExpiredMessages()

            const messages = queue.getMessages(clientId)
            expect(messages.length).toBe(2)
        })
    })

    describe('Message Acknowledgment', () => {
        it('should remove acknowledged messages', () => {
            queue.addMessage(clientId, topic, mockMessage)
            const messages = queue.getMessages(clientId)
            queue.acknowledgeMessages(clientId, [messages[0].id])

            expect(queue.getMessages(clientId).length).toBe(0)
        })

        it('should handle invalid message ids', () => {
            queue.addMessage(clientId, topic, mockMessage)
            queue.acknowledgeMessages(clientId, ['invalid-id'])

            expect(queue.getMessages(clientId).length).toBe(1)
        })

        it('should handle batch acknowledgments', () => {
            const ids = []
            for (let i = 0; i < 3; i++) {
                queue.addMessage(clientId, topic, { count: i })
                ids.push(queue.getMessages(clientId)[i].id)
            }

            queue.acknowledgeMessages(clientId, ids)
            expect(queue.getMessages(clientId).length).toBe(0)
        })
    })

    describe('Event Emission', () => {
        it('should emit messageQueued event', (done) => {
            queue.once('messageQueued', (data) => {
                expect(data.clientId).toBe(clientId)
                expect(data.topic).toBe(topic)
                expect(data.message).toEqual(mockMessage)
                done()
            })

            queue.addMessage(clientId, topic, mockMessage)
        })
    })
})

================
File: tests/unit/http/WebSocketServer.spec.js
================
import MemoryWebSocketServer from '../../../src/api/http/server/WebSocketServer.js';
import MessageQueue from '../../../src/api/http/server/MessageQueue.js';
import { EventEmitter } from 'events';
import { WebSocket, WebSocketServer } from 'ws';

describe('MemoryWebSocketServer', () => {
    let server;
    let wss;
    let mockHttpServer;

    beforeEach(() => {
        mockHttpServer = new EventEmitter();
        mockHttpServer.address = () => ({ port: 8080 });

        // Mock WebSocketServer
        wss = new WebSocketServer({ noServer: true });
        spyOn(WebSocketServer.prototype, 'on').and.callThrough();
        
        server = new MemoryWebSocketServer(mockHttpServer);
    });

    afterEach(() => {
        server.close();
        wss.close();
    });

    describe('connection handling', () => {
        it('should authenticate connections', () => {
            const mockWs = {
                close: jasmine.createSpy('close'),
                send: jasmine.createSpy('send')
            };
            const mockReq = {
                headers: {
                    'authorization': 'Basic ' + Buffer.from('admin:admin123').toString('base64')
                }
            };

            const result = server.authenticateConnection(mockWs, mockReq);
            expect(result).toBeTrue();
            expect(mockWs.close).not.toHaveBeenCalled();
        });

        it('should reject invalid credentials', () => {
            const mockWs = {
                close: jasmine.createSpy('close'),
                send: jasmine.createSpy('send')
            };
            const mockReq = {
                headers: {
                    'authorization': 'Basic ' + Buffer.from('wrong:creds').toString('base64')
                }
            };

            const result = server.authenticateConnection(mockWs, mockReq);
            expect(result).toBeFalse();
            expect(mockWs.close).toHaveBeenCalledWith(1008, 'Invalid credentials');
        });
    });

    describe('message handling', () => {
        let mockWs;
        let clientId;

        beforeEach(() => {
            mockWs = {
                send: jasmine.createSpy('send'),
                close: jasmine.createSpy('close'),
                readyState: 1
            };
            clientId = 'test-client';
            server.clients.set(clientId, {
                ws: mockWs,
                lastSeen: Date.now(),
                topics: new Set(['system'])
            });
        });

        it('should handle subscribe messages', () => {
            server.handleClientMessage(clientId, {
                type: 'subscribe',
                topic: 'memory'
            });

            const client = server.clients.get(clientId);
            expect(client.topics.has('memory')).toBeTrue();
        });

        it('should handle unsubscribe messages', () => {
            const client = server.clients.get(clientId);
            client.topics.add('memory');

            server.handleClientMessage(clientId, {
                type: 'unsubscribe',
                topic: 'memory'
            });

            expect(client.topics.has('memory')).toBeFalse();
        });

        it('should handle message acknowledgments', () => {
            spyOn(server.messageQueue, 'acknowledgeMessages');
            
            server.handleClientMessage(clientId, {
                type: 'ack',
                messageIds: ['msg1', 'msg2']
            });

            expect(server.messageQueue.acknowledgeMessages)
                .toHaveBeenCalledWith(clientId, ['msg1', 'msg2']);
        });
    });

    describe('broadcasting', () => {
        it('should broadcast messages to subscribed clients', () => {
            const mockWs1 = {
                send: jasmine.createSpy('send'),
                readyState: 1
            };
            const mockWs2 = {
                send: jasmine.createSpy('send'),
                readyState: 1
            };

            server.clients.set('client1', {
                ws: mockWs1,
                topics: new Set(['memory'])
            });
            server.clients.set('client2', {
                ws: mockWs2,
                topics: new Set(['other'])
            });

            server.broadcast('memory', { data: 'test' });

            expect(mockWs1.send).toHaveBeenCalled();
            expect(mockWs2.send).not.toHaveBeenCalled();
        });

        it('should queue messages for offline clients', () => {
            const mockWs = {
                send: jasmine.createSpy('send'),
                readyState: 3 // CLOSED
            };

            server.clients.set('client1', {
                ws: mockWs,
                topics: new Set(['memory'])
            });

            spyOn(server.messageQueue, 'addMessage');
            server.broadcast('memory', { data: 'test' });

            expect(mockWs.send).not.toHaveBeenCalled();
            expect(server.messageQueue.addMessage).toHaveBeenCalled();
        });
    });

    describe('cleanup', () => {
        it('should handle client disconnection', () => {
            const clientId = 'test-client';
            const disconnectSpy = jasmine.createSpy('clientDisconnected');
            
            server.on('clientDisconnected', disconnectSpy);
            server.clients.set(clientId, {
                ws: { close: () => {} },
                topics: new Set()
            });

            server.handleDisconnect(clientId);

            expect(server.clients.has(clientId)).toBeFalse();
            expect(disconnectSpy).toHaveBeenCalledWith(clientId);
        });

        it('should clean up resources on close', () => {
            const mockWs = {
                close: jasmine.createSpy('close')
            };
            server.clients.set('client1', {
                ws: mockWs,
                topics: new Set()
            });

            spyOn(server.messageQueue, 'dispose');
            server.close();

            expect(mockWs.close).toHaveBeenCalled();
            expect(server.clients.size).toBe(0);
            expect(server.messageQueue.dispose).toHaveBeenCalled();
        });
    });
});

================
File: tests/unit/utils/EmbeddingValidator.spec.js
================
// tests/unit/utils/EmbeddingValidator.spec.js
import { EmbeddingValidator } from '../../../src/utils/EmbeddingValidator.js'

describe('EmbeddingValidator', () => {
    let validator

    beforeEach(() => {
        validator = new EmbeddingValidator({
            dimensions: {
                'nomic-embed-text': 768,
                'qwen2:1.5b': 1536,
                'llama2': 4096,
                'default': 1536
            }
        })
    })

    describe('Dimension Management', () => {
        it('should get correct dimensions for models', () => {
            expect(validator.getDimension('nomic-embed-text')).toBe(768)
            expect(validator.getDimension('qwen2:1.5b')).toBe(1536)
            expect(validator.getDimension('llama2')).toBe(4096)
        })

        it('should use default dimension for unknown models', () => {
            expect(validator.getDimension('unknown-model')).toBe(1536)
        })

        it('should handle model name variations', () => {
            expect(validator.getDimension('NOMIC-embed-text')).toBe(768)
            expect(validator.getDimension('qwen2:1.5B')).toBe(1536)
        })
    })

    describe('Embedding Validation', () => {
        it('should validate correct embeddings', () => {
            const embedding = new Array(768).fill(0.1)
            expect(() => validator.validateEmbedding(embedding, 768)).not.toThrow()
        })

        it('should reject non-array inputs', () => {
            expect(() => validator.validateEmbedding('not an array', 768))
                .toThrowError('Embedding must be an array')
        })

        it('should reject invalid numeric values', () => {
            const invalidEmbedding = new Array(768).fill('not a number')
            expect(() => validator.validateEmbedding(invalidEmbedding, 768))
                .toThrowError('Embedding must contain only valid numbers')
        })

        it('should reject wrong dimensions', () => {
            const wrongSize = new Array(512).fill(0.1)
            expect(() => validator.validateEmbedding(wrongSize, 768))
                .toThrowError(/dimension mismatch/)
        })

        it('should handle edge cases', () => {
            // Empty array
            expect(() => validator.validateEmbedding([], 768))
                .toThrowError(/dimension mismatch/)

            // NaN values
            const nanEmbedding = [NaN, 0.1, 0.2]
            expect(() => validator.validateEmbedding(nanEmbedding, 3))
                .toThrowError('Embedding must contain only valid numbers')

            // Infinity values
            const infEmbedding = [Infinity, 0.1, 0.2]
            expect(() => validator.validateEmbedding(infEmbedding, 3))
                .toThrowError('Embedding must contain only valid numbers')
        })
    })

    describe('Dimension Standardization', () => {
        it('should pad short embeddings', () => {
            const shortEmbedding = new Array(500).fill(0.1)
            const standardized = validator.standardizeEmbedding(shortEmbedding, 768)

            expect(standardized.length).toBe(768)
            expect(standardized.slice(0, 500)).toEqual(shortEmbedding)
            expect(standardized.slice(500)).toEqual(new Array(268).fill(0))
        })

        it('should truncate long embeddings', () => {
            const longEmbedding = new Array(1000).fill(0.1)
            const standardized = validator.standardizeEmbedding(longEmbedding, 768)

            expect(standardized.length).toBe(768)
            expect(standardized).toEqual(longEmbedding.slice(0, 768))
        })

        it('should return original if dimension matches', () => {
            const correctEmbedding = new Array(768).fill(0.1)
            const standardized = validator.standardizeEmbedding(correctEmbedding, 768)

            expect(standardized).toBe(correctEmbedding)
        })

        it('should handle zero-length embeddings', () => {
            const standardized = validator.standardizeEmbedding([], 768)
            expect(standardized.length).toBe(768)
            expect(standardized).toEqual(new Array(768).fill(0))
        })
    })

    describe('Loss Detection', () => {
        it('should detect information loss', () => {
            const embedding = new Array(1000).fill(0.1)
            embedding[999] = 1.0 // Significant value that would be lost

            expect(validator.wouldBeLossy(embedding, 768)).toBeTrue()
        })

        it('should handle negligible values', () => {
            const embedding = new Array(1000).fill(1e-8)
            expect(validator.wouldBeLossy(embedding, 768)).toBeFalse()
        })

        it('should handle short embeddings', () => {
            const embedding = new Array(500).fill(0.1)
            expect(validator.wouldBeLossy(embedding, 768)).toBeFalse()
        })
    })

    describe('Model Compatibility', () => {
        it('should validate across model transitions', () => {
            // Create embedding for one model
            const nomicEmbedding = new Array(768).fill(0.1)
            expect(() => validator.validateEmbedding(nomicEmbedding,
                validator.getDimension('nomic-embed-text'))).not.toThrow()

            // Standardize for another model
            const standardized = validator.standardizeEmbedding(nomicEmbedding,
                validator.getDimension('qwen2:1.5b'))
            expect(standardized.length).toBe(1536)
        })

        it('should track dimension changes', () => {
            const embedding = new Array(768).fill(0.1)
            const transitions = [
                'nomic-embed-text',  // 768
                'qwen2:1.5b',        // 1536
                'llama2'             // 4096
            ]

            let current = embedding
            transitions.forEach(model => {
                const targetDim = validator.getDimension(model)
                current = validator.standardizeEmbedding(current, targetDim)
                expect(current.length).toBe(targetDim)
                expect(() => validator.validateEmbedding(current, targetDim))
                    .not.toThrow()
            })
        })
    })
})

================
File: tests/unit/utils/SPARQLHelpers.spec.js 
================
// tests/unit/utils/SPARQLHelpers.spec.js
import { SPARQLHelpers } from '../../../src/utils/SPARQLHelpers.js'

describe('SPARQLHelpers', () => {
    let mockFetch
    const testEndpoint = 'http://localhost:4030/test'
    const testAuth = 'Basic ' + Buffer.from('admin:admin123').toString('base64')

    beforeEach(() => {
        mockFetch = jasmine.createSpy('fetch').and.returnValue(
            Promise.resolve({
                ok: true,
                json: () => Promise.resolve({ results: { bindings: [] } }),
                text: () => Promise.resolve('')
            })
        )
        global.fetch = mockFetch
    })

    afterEach(() => {
        delete global.fetch
    })

    describe('Authentication', () => {
        it('should create valid auth headers', () => {
            const auth = SPARQLHelpers.createAuthHeader('user', 'pass')
            expect(auth).toMatch(/^Basic [A-Za-z0-9+/=]+$/)
            expect(atob(auth.split(' ')[1])).toBe('user:pass')
        })

        it('should handle special characters in credentials', () => {
            const auth = SPARQLHelpers.createAuthHeader('user@domain', 'pass#word')
            expect(() => atob(auth.split(' ')[1])).not.toThrow()
        })
    })

    describe('Query Execution', () => {
        it('should execute SPARQL queries', async () => {
            const query = 'SELECT * WHERE { ?s ?p ?o }'
            await SPARQLHelpers.executeSPARQLQuery(testEndpoint, query, testAuth)

            expect(mockFetch).toHaveBeenCalledWith(
                testEndpoint,
                jasmine.objectContaining({
                    method: 'GET',
                    headers: jasmine.objectContaining({
                        'Accept': 'application/sparql-results+json',
                        'Authorization': testAuth
                    }),
                    body: query
                })
            )
        })

        it('should handle query errors', async () => {
            mockFetch.and.returnValue(Promise.resolve({
                ok: false,
                status: 400,
                statusText: 'Bad Request'
            }))

            await expectAsync(
                SPARQLHelpers.executeSPARQLQuery(testEndpoint, 'INVALID QUERY', testAuth)
            ).toBeRejectedWithError(/SPARQL query failed: 400/)
        })

        it('should support different result formats', async () => {
            await SPARQLHelpers.executeSPARQLQuery(
                testEndpoint,
                'CONSTRUCT { ?s ?p ?o } WHERE { ?s ?p ?o }',
                testAuth,
                'text/turtle'
            )

            expect(mockFetch).toHaveBeenCalledWith(
                testEndpoint,
                jasmine.objectContaining({
                    headers: jasmine.objectContaining({
                        'Accept': 'text/turtle'
                    })
                })
            )
        })
    })

    describe('Update Operations', () => {
        it('should execute SPARQL updates', async () => {
            const update = 'INSERT DATA { <s> <p> <o> }'
            await SPARQLHelpers.executeSPARQLUpdate(testEndpoint, update, testAuth)

            expect(mockFetch).toHaveBeenCalledWith(
                testEndpoint,
                jasmine.objectContaining({
                    method: 'POST',
                    headers: jasmine.objectContaining({
                        'Content-Type': 'application/sparql-update',
                        'Authorization': testAuth
                    }),
                    body: update
                })
            )
        })

        it('should handle update errors', async () => {
            mockFetch.and.returnValue(Promise.resolve({
                ok: false,
                status: 500,
                statusText: 'Server Error'
            }))

            await expectAsync(
                SPARQLHelpers.executeSPARQLUpdate(testEndpoint, 'INVALID UPDATE', testAuth)
            ).toBeRejectedWithError(/SPARQL update failed: 500/)
        })
    })

    describe('Dataset Management', () => {
        it('should generate correct dataset endpoints', () => {
            const baseUrl = 'http://localhost:4030'
            const dataset = 'test'

            expect(SPARQLHelpers.getDatasetEndpoint(baseUrl, dataset, 'query'))
                .toBe('http://localhost:4030/test/query')

            expect(SPARQLHelpers.getDatasetEndpoint(baseUrl, dataset, 'update'))
                .toBe('http://localhost:4030/test/update')

            expect(SPARQLHelpers.getDatasetEndpoint(baseUrl, dataset, 'data'))
                .toBe('http://localhost:4030/test/data')
        })

        it('should handle trailing slashes', () => {
            const endpoint = SPARQLHelpers.getDatasetEndpoint(
                'http://localhost:4030/',
                'test',
                'query'
            )
            expect(endpoint).not.toContain('//')
        })
    })

    describe('Error Handling', () => {
        it('should handle network errors', async () => {
            mockFetch.and.returnValue(Promise.reject(new Error('Network error')))

            await expectAsync(
                SPARQLHelpers.executeSPARQLQuery(testEndpoint, 'SELECT *', testAuth)
            ).toBeRejected()
        })

        it('should handle malformed responses', async () => {
            mockFetch.and.returnValue(Promise.resolve({
                ok: true,
                json: () => Promise.reject(new Error('Invalid JSON'))
            }))

            await expectAsync(
                SPARQLHelpers.executeSPARQLQuery(testEndpoint, 'SELECT *', testAuth)
            ).toBeRejected()
        })

        it('should handle timeout errors', async () => {
            mockFetch.and.returnValue(new Promise((_, reject) =>
                setTimeout(() => reject(new Error('Timeout')), 100)
            ))

            await expectAsync(
                SPARQLHelpers.executeSPARQLQuery(testEndpoint, 'SELECT *', testAuth)
            ).toBeRejected()
        })
    })

    describe('Content Negotiation', () => {
        it('should support multiple response formats', async () => {
            const formats = [
                'application/sparql-results+json',
                'application/json',
                'text/turtle',
                'application/rdf+xml'
            ]

            for (const format of formats) {
                await SPARQLHelpers.executeSPARQLQuery(
                    testEndpoint,
                    'SELECT *',
                    testAuth,
                    format
                )

                expect(mockFetch).toHaveBeenCalledWith(
                    testEndpoint,
                    jasmine.objectContaining({
                        headers: jasmine.objectContaining({
                            'Accept': format
                        })
                    })
                )
            }
        })

        it('should default to JSON results format', async () => {
            await SPARQLHelpers.executeSPARQLQuery(testEndpoint, 'SELECT *', testAuth)

            expect(mockFetch).toHaveBeenCalledWith(
                testEndpoint,
                jasmine.objectContaining({
                    headers: jasmine.objectContaining({
                        'Accept': 'application/sparql-results+json'
                    })
                })
            )
        })
    })
})

================
File: tests/unit/cached-sparql-store-spec.js
================
// tests/unit/cached-sparql-store-spec.js
import CachedSPARQLStore from '../../src/stores/CachedSPARQLStore.js'

describe('CachedSPARQLStore', () => {
    let store
    let mockFetch
    let mockInterval
    let mockClearInterval

    const endpoint = {
        query: 'http://example.org/sparql/query',
        update: 'http://example.org/sparql/update'
    }

    const mockSparqlResult = {
        results: {
            bindings: [{
                id: { value: 'test-id' },
                prompt: { value: 'test prompt' },
                output: { value: 'test output' },
                embedding: { value: '[0,1,2]' },
                timestamp: { value: '1000' },
                accessCount: { value: '1' },
                concepts: { value: '["test"]' },
                decayFactor: { value: '1.0' },
                memoryType: { value: 'short-term' }
            }]
        }
    }

    beforeEach(() => {
        mockFetch = jasmine.createSpy('fetch').and.returnValue(
            Promise.resolve({
                ok: true,
                json: () => Promise.resolve(mockSparqlResult)
            })
        )
        global.fetch = mockFetch

        mockInterval = jasmine.createSpy('setInterval').and.returnValue(123)
        mockClearInterval = jasmine.createSpy('clearInterval')
        global.setInterval = mockInterval
        global.clearInterval = mockClearInterval

        store = new CachedSPARQLStore(endpoint, {
            user: 'test',
            password: 'test',
            graphName: 'http://test.org/graph',
            cacheTTL: 1000,
            maxCacheSize: 2
        })

        jasmine.clock().install()
    })

    afterEach(() => {
        delete global.fetch
        delete global.setInterval
        delete global.clearInterval
        jasmine.clock().uninstall()
    })

    describe('Cache Operations', () => {
        it('should cache query results', async () => {
            const query = 'SELECT * WHERE { ?s ?p ?o }'

            await store._executeSparqlQuery(query, endpoint.query)
            expect(mockFetch).toHaveBeenCalledTimes(1)

            mockFetch.calls.reset()
            const cachedResult = await store._executeSparqlQuery(query, endpoint.query)
            expect(mockFetch).not.toHaveBeenCalled()
            expect(cachedResult).toEqual(mockSparqlResult)
        })

        it('should expire cached entries after TTL', async () => {
            const query = 'SELECT * WHERE { ?s ?p ?o }'

            await store._executeSparqlQuery(query, endpoint.query)
            jasmine.clock().tick(1001)

            await store._executeSparqlQuery(query, endpoint.query)
            expect(mockFetch).toHaveBeenCalledTimes(2)
        })

        it('should maintain max cache size', async () => {
            for (let i = 0; i < 3; i++) {
                await store._executeSparqlQuery(`query${i}`, endpoint.query)
            }

            expect(store.queryCache.size).toBeLessThanOrEqual(2)
            expect([...store.queryCache.keys()]).not.toContain('query0')
        })

        it('should invalidate cache on updates', async () => {
            const query = 'SELECT * WHERE { ?s ?p ?o }'
            await store._executeSparqlQuery(query, endpoint.query)

            await store.saveMemoryToHistory({
                shortTermMemory: [],
                longTermMemory: []
            })

            expect(store.queryCache.size).toBe(0)
        })
    })

    describe('Query Generation', () => {
        it('should generate valid SPARQL queries', async () => {
            await store._executeSparqlQuery(
                'SELECT * WHERE { ?s ?p ?o }',
                endpoint.query
            )

            expect(mockFetch).toHaveBeenCalledWith(
                endpoint.query,
                jasmine.objectContaining({
                    method: 'POST',
                    headers: jasmine.objectContaining({
                        'Content-Type': 'application/sparql-query'
                    })
                })
            )
        })

        it('should handle query errors', async () => {
            mockFetch.and.returnValue(Promise.resolve({ ok: false, status: 400 }))

            await expectAsync(
                store._executeSparqlQuery('INVALID QUERY', endpoint.query)
            ).toBeRejectedWithError(/SPARQL query failed/)
        })
    })

    describe('Cache Cleanup', () => {
        it('should remove expired entries', () => {
            store.queryCache.set('test1', { data: 1 })
            store.cacheTimestamps.set('test1', Date.now() - 2000)
            store.queryCache.set('test2', { data: 2 })
            store.cacheTimestamps.set('test2', Date.now())

            store.cleanupCache()

            expect(store.queryCache.has('test1')).toBe(false)
            expect(store.queryCache.has('test2')).toBe(true)
        })

        it('should remove oldest entries when over size', () => {
            store.queryCache.set('test1', { data: 1 })
            store.cacheTimestamps.set('test1', 1000)
            store.queryCache.set('test2', { data: 2 })
            store.cacheTimestamps.set('test2', 2000)
            store.queryCache.set('test3', { data: 3 })
            store.cacheTimestamps.set('test3', 3000)

            store.cleanupCache()

            expect(store.queryCache.size).toBe(2)
            expect(store.queryCache.has('test1')).toBe(false)
            expect(store.queryCache.has('test3')).toBe(true)
        })
    })

    describe('Resource Management', () => {
        it('should clear interval and cache on close', async () => {
            await store.close()

            expect(mockClearInterval).toHaveBeenCalledWith(123)
            expect(store.queryCache.size).toBe(0)
            expect(store.cacheTimestamps.size).toBe(0)
        })

        it('should handle concurrent cache access', async () => {
            const promises = Array(5).fill().map(() =>
                store._executeSparqlQuery('SELECT * WHERE { ?s ?p ?o }', endpoint.query)
            )

            await expectAsync(Promise.all(promises)).toBeResolved()
            expect(store.queryCache.size).toBeLessThanOrEqual(2)
        })
    })
})

================
File: tests/unit/Config.spec.js
================
import Config from '../../src/Config.js'

describe('Config', () => {
    let config
    const validConfig = {
        storage: {
            type: 'sparql',
            options: {
                graphName: 'http://example.org/test'
            }
        },
        models: {
            chat: {
                provider: 'ollama',
                model: 'qwen2:1.5b'
            },
            embedding: {
                provider: 'ollama',
                model: 'nomic-embed-text'
            }
        },
        sparqlEndpoints: [{
            label: "test",
            urlBase: "http://localhost:4030",
            query: "/test-mem",
            update: "/test-mem",
            user: "admin",
            password: "admin123"
        }]
    }

    describe('Initialization', () => {
        it('should initialize with defaults when no config provided', async () => {
            config = new Config()
            await config.init()

            expect(config.get('models.chat.model')).toBe('qwen2:1.5b')
            expect(config.get('models.embedding.model')).toBe('nomic-embed-text')
            expect(config.get('storage.type')).toBe('memory')
        })

        it('should merge user config with defaults', async () => {
            config = new Config({
                storage: {
                    type: 'sparql',
                    options: { graphName: 'test' }
                }
            })
            await config.init()

            expect(config.get('storage.type')).toBe('sparql')
            expect(config.get('storage.options.graphName')).toBe('test')
            expect(config.get('models.chat.model')).toBe('qwen2:1.5b')
        })

        it('should validate required sections', async () => {
            const config = new Config({})
            await expectAsync(config.init())
                .toBeRejectedWithError(/Missing required config section/)
        })
    })

    describe('Configuration Access', () => {
        let config

        beforeEach(async () => {
            config = new Config(validConfig)
            await config.init()
        })

        it('should retrieve nested values', () => {
            expect(config.get('models.chat.provider')).toBe('ollama')
            expect(config.get('sparqlEndpoints.0.label')).toBe('test')
        })

        it('should handle missing paths', () => {
            expect(config.get('invalid.path')).toBeUndefined()
            expect(config.get('storage.invalid')).toBeUndefined()
        })

        it('should auto-initialize on first access', () => {
            const newConfig = new Config(validConfig)
            expect(newConfig.get('models.chat.provider')).toBe('ollama')
            expect(newConfig.initialized).toBeTrue()
        })
    })

    describe('Configuration Updates', () => {
        let config

        beforeEach(async () => {
            config = new Config(validConfig)
            await config.init()
        })

        it('should set nested values', () => {
            config.set('models.chat.model', 'new-model')
            expect(config.get('models.chat.model')).toBe('new-model')
        })

        it('should create intermediate objects', () => {
            config.set('new.nested.value', 'test')
            expect(config.get('new.nested.value')).toBe('test')
        })

        it('should handle array updates', () => {
            config.set('sparqlEndpoints.0.user', 'newuser')
            expect(config.get('sparqlEndpoints.0.user')).toBe('newuser')
        })
    })

    describe('Static Factory', () => {
        it('should create and initialize in one step', () => {
            const config = Config.create(validConfig)
            expect(config.initialized).toBeTrue()
            expect(config.get('storage.type')).toBe('sparql')
        })

        it('should validate during creation', () => {
            expect(() => Config.create({ invalid: true }))
                .toThrowError(/Missing required config/)
        })
    })

    describe('Schema Validation', () => {
        it('should validate storage configuration', async () => {
            const config = new Config({
                ...validConfig,
                storage: { type: 'invalid' }
            })
            await expectAsync(config.init())
                .toBeRejectedWithError(/Invalid storage type/)
        })

        it('should validate model configuration', async () => {
            const config = new Config({
                ...validConfig,
                models: { chat: {} }
            })
            await expectAsync(config.init())
                .toBeRejectedWithError(/Invalid model configuration/)
        })

        it('should validate SPARQL endpoints', async () => {
            const config = new Config({
                ...validConfig,
                sparqlEndpoints: [{ label: 'test' }]
            })
            await expectAsync(config.init())
                .toBeRejectedWithError(/Invalid SPARQL endpoint configuration/)
        })
    })

    describe('Environment Handling', () => {
        const originalEnv = process.env

        beforeEach(() => {
            process.env = { ...originalEnv }
        })

        afterEach(() => {
            process.env = originalEnv
        })

        it('should override config with environment variables', async () => {
            process.env.SEMEM_STORAGE_TYPE = 'memory'
            const config = new Config(validConfig)
            await config.init()

            expect(config.get('storage.type')).toBe('memory')
        })

        it('should handle sensitive data', async () => {
            process.env.SEMEM_SPARQL_PASSWORD = 'secret'
            const config = new Config(validConfig)
            await config.init()

            expect(config.get('sparqlEndpoints.0.password')).toBe('secret')
            expect(JSON.stringify(config)).not.toContain('secret')
        })
    })
})

================
File: tests/unit/ContextWindowManager.spec.js
================
// tests/unit/ContextWindowManager.spec.js
import ContextWindowManager from '../../src/ContextWindowManager.js'

describe('ContextWindowManager', () => {
    let manager

    beforeEach(() => {
        manager = new ContextWindowManager({
            minWindowSize: 100,
            maxWindowSize: 1000,
            overlapRatio: 0.1,
            avgTokenLength: 4
        })
    })

    describe('Window Sizing', () => {
        it('should calculate appropriate window size', () => {
            const shortText = 'a'.repeat(200)
            const shortSize = manager.calculateWindowSize(shortText)
            expect(shortSize).toBeLessThanOrEqual(1000)
            expect(shortSize).toBeGreaterThanOrEqual(100)

            const longText = 'a'.repeat(5000)
            const longSize = manager.calculateWindowSize(longText)
            expect(longSize).toBe(1000)
        })

        it('should respect minimum window size', () => {
            const tinyText = 'short'
            const size = manager.calculateWindowSize(tinyText)
            expect(size).toBe(100)
        })

        it('should apply overlap ratio correctly', () => {
            const text = 'a'.repeat(2000)
            const windows = manager.createWindows(text, 1000)

            const overlap = windows[0].text.length + windows[1].text.length - text.length
            expect(overlap).toBeGreaterThan(90) // ~10% overlap
            expect(overlap).toBeLessThan(110)
        })
    })

    describe('Token Estimation', () => {
        it('should estimate tokens based on average length', () => {
            const text = 'The quick brown fox jumps over the lazy dog'
            const tokens = manager.estimateTokens(text)
            expect(tokens).toBe(Math.ceil(text.length / 4))
        })

        it('should handle empty and short texts', () => {
            expect(manager.estimateTokens('')).toBe(0)
            expect(manager.estimateTokens('a')).toBe(1)
        })
    })

    describe('Window Creation', () => {
        it('should create overlapping windows', () => {
            const text = 'word '.repeat(300) // 1500 chars
            const windows = manager.createWindows(text, 1000)

            expect(windows.length).toBe(2)
            expect(windows[0].text.length).toBeLessThanOrEqual(1000)
            expect(windows[1].text.length).toBeLessThanOrEqual(1000)
        })

        it('should preserve word boundaries', () => {
            const text = 'word '.repeat(300)
            const windows = manager.createWindows(text, 1000)

            expect(windows[0].text.endsWith(' ')).toBeTrue()
            expect(windows[1].text.startsWith('word')).toBeTrue()
        })

        it('should handle single-window texts', () => {
            const text = 'word '.repeat(10)
            const windows = manager.createWindows(text, 1000)

            expect(windows.length).toBe(1)
            expect(windows[0].text).toBe(text)
        })
    })

    describe('Content Processing', () => {
        it('should process context within window limits', () => {
            const shortContext = 'short context'
            const shortResult = manager.processContext(shortContext)
            expect(shortResult.length).toBe(1)

            const longContext = 'word '.repeat(300)
            const longResult = manager.processContext(longContext)
            expect(longResult.length).toBeGreaterThan(1)
        })

        it('should include metadata when requested', () => {
            const context = 'test context'
            const result = manager.processContext(context, { includeMetadata: true })

            expect(result[0].tokenEstimate).toBeDefined()
            expect(result[0].start).toBe(0)
            expect(result[0].end).toBe(context.length)
        })
    })

    describe('Content Merging', () => {
        it('should merge overlapping content', () => {
            const windows = [
                { text: 'The quick brown' },
                { text: 'brown fox jumps' },
                { text: 'jumps over lazy' }
            ]

            const merged = manager.mergeOverlappingContent(windows)
            expect(merged).toBe('The quick brown fox jumps over lazy')
        })

        it('should handle non-overlapping content', () => {
            const windows = [
                { text: 'First part.' },
                { text: 'Second part.' }
            ]

            const merged = manager.mergeOverlappingContent(windows)
            expect(merged).toBe('First part. Second part.')
        })

        it('should find optimal overlap points', () => {
            const text = 'The quick brown fox jumps over the lazy dog'
            const windows = manager.createWindows(text, 20)
            const merged = manager.mergeOverlappingContent(windows)

            expect(merged).toBe(text)
            expect(merged.split(' ').length).toBe(text.split(' ').length)
        })

        it('should preserve special characters', () => {
            const specialText = 'Text with newlines\nand "quotes" and periods...'
            const windows = manager.createWindows(specialText, 20)
            const merged = manager.mergeOverlappingContent(windows)

            expect(merged).toBe(specialText)
        })
    })
})

================
File: tests/unit/MemoryManager.spec.js
================
import MemoryManager from '../../src/MemoryManager.js'

describe('MemoryManager', () => {
    let manager
    let mockLLMProvider
    let mockStorage
    let mockEmbedding

    beforeEach(() => {
        mockLLMProvider = {
            generateEmbedding: jasmine.createSpy('generateEmbedding'),
            generateChat: jasmine.createSpy('generateChat'),
            generateCompletion: jasmine.createSpy('generateCompletion')
        }

        mockStorage = {
            loadHistory: jasmine.createSpy('loadHistory').and.resolveTo([[], []]),
            saveMemoryToHistory: jasmine.createSpy('saveMemoryToHistory'),
            close: jasmine.createSpy('close')
        }

        mockEmbedding = new Array(1536).fill(0)

        manager = new MemoryManager({
            llmProvider: mockLLMProvider,
            storage: mockStorage
        })
    })

    describe('initialization', () => {
        it('should handle string model names', () => {
            const mgr = new MemoryManager({
                llmProvider: mockLLMProvider,
                chatModel: 'test-chat',
                embeddingModel: 'test-embed'
            })

            expect(mgr.chatModel).toBe('test-chat')
            expect(mgr.embeddingModel).toBe('test-embed')
        })

        it('should coerce non-string model names', () => {
            const mgr = new MemoryManager({
                llmProvider: mockLLMProvider,
                chatModel: ['test'],
                embeddingModel: { name: 'test' }
            })

            expect(typeof mgr.chatModel).toBe('string')
            expect(typeof mgr.embeddingModel).toBe('string')
        })

        it('should require llmProvider', () => {
            expect(() => new MemoryManager({}))
                .toThrowError('LLM provider is required')
        })
    })

    describe('memory operations', () => {
        beforeEach(async () => {
            mockLLMProvider.generateEmbedding.and.resolveTo(mockEmbedding)
            mockLLMProvider.generateCompletion.and.resolveTo('["test"]')
            mockLLMProvider.generateChat.and.resolveTo('test response')

            await manager.initialize()
        })

        it('should add interactions', async () => {
            await manager.addInteraction(
                'test prompt',
                'test output',
                mockEmbedding,
                ['test']
            )

            expect(mockStorage.saveMemoryToHistory).toHaveBeenCalled()
            expect(manager.memStore.shortTermMemory.length).toBe(1)
        })

        it('should retrieve relevant interactions', async () => {
            const relevantInteractions = await manager.retrieveRelevantInteractions('test query')

            expect(mockLLMProvider.generateEmbedding).toHaveBeenCalled()
            expect(mockLLMProvider.generateCompletion).toHaveBeenCalled()
        })

        it('should generate responses', async () => {
            const response = await manager.generateResponse('test prompt')

            expect(response).toBe('test response')
            expect(mockLLMProvider.generateChat).toHaveBeenCalled()
        })

        it('should handle embedding generation', async () => {
            const embedding = await manager.generateEmbedding('test text')

            expect(embedding).toEqual(mockEmbedding)
            expect(mockLLMProvider.generateEmbedding).toHaveBeenCalled()
        })
    })

    describe('disposal', () => {
        it('should clean up resources', async () => {
            await manager.dispose()

            expect(mockStorage.saveMemoryToHistory).toHaveBeenCalled()
            expect(mockStorage.close).toHaveBeenCalled()
            expect(manager.memStore).toBeNull()
        })

        it('should handle disposal errors', async () => {
            mockStorage.saveMemoryToHistory.and.rejectWith(new Error('Save failed'))

            await expectAsync(manager.dispose())
                .toBeRejectedWithError('Save failed')
        })
    })
})

================
File: tests/unit/sparql-endpoint-spec.js
================
// tests/unit/sparql-endpoint-spec.js
import Config from '../../src/Config.js'
import { SPARQLHelpers } from '../../src/utils/SPARQLHelpers.js'

describe('SPARQL Endpoint Integration', () => {
    let config
    let endpoint
    let auth
    let baseUrl
    const testGraph = 'http://example.org/test-graph'

    beforeAll(() => {
        config = new Config()
        const sparqlConfig = config.get('sparqlEndpoints')[0]
        baseUrl = sparqlConfig.urlBase  // Changed: Remove '/test' appendage
        endpoint = {
            query: `${baseUrl}${sparqlConfig.query}`,
            update: `${baseUrl}${sparqlConfig.update}`
        }
        auth = SPARQLHelpers.createAuthHeader(sparqlConfig.user, sparqlConfig.password)
    })

    beforeEach(async () => {
        // Clear test graph before each test
        const clearQuery = `
            DROP SILENT GRAPH <${testGraph}>;
            CREATE GRAPH <${testGraph}>
        `
        await SPARQLHelpers.executeSPARQLUpdate(endpoint.update, clearQuery, auth)
    })

    afterAll(async () => {
        // Clean up test graph
        const dropQuery = `DROP SILENT GRAPH <${testGraph}>`
        await SPARQLHelpers.executeSPARQLUpdate(endpoint.update, dropQuery, auth)
    })

    describe('SPARQL UPDATE operations', () => {
        it('should insert data into graph', async () => {
            const insertQuery = `
                PREFIX ex: <http://example.org/>
                INSERT DATA {
                    GRAPH <${testGraph}> {
                        ex:subject ex:predicate "test object" .
                    }
                }
            `

            await expectAsync(
                SPARQLHelpers.executeSPARQLUpdate(endpoint.update, insertQuery, auth)
            ).toBeResolved()
        })

        it('should delete data from graph', async () => {
            const deleteQuery = `
                PREFIX ex: <http://example.org/>
                DELETE DATA {
                    GRAPH <${testGraph}> {
                        ex:subject ex:predicate "test object" .
                    }
                }
            `

            await expectAsync(
                SPARQLHelpers.executeSPARQLUpdate(endpoint.update, deleteQuery, auth)
            ).toBeResolved()
        })
    })

    describe('SPARQL SELECT operations', () => {
        beforeEach(async () => {
            // Insert test data
            const setupQuery = `
                PREFIX ex: <http://example.org/>
                INSERT DATA {
                    GRAPH <${testGraph}> {
                        ex:subject1 ex:predicate "value1" .
                        ex:subject2 ex:predicate "value2" .
                    }
                }
            `
            await SPARQLHelpers.executeSPARQLUpdate(endpoint.update, setupQuery, auth)
        })

        it('should retrieve data with SELECT query', async () => {
            const selectQuery = `
                PREFIX ex: <http://example.org/>
                SELECT ?s ?o
                FROM <${testGraph}>
                WHERE {
                    ?s ex:predicate ?o .
                }
            `

            const response = await SPARQLHelpers.executeSPARQLQuery(endpoint.query, selectQuery, auth)
            const data = await response.json()
            expect(data.results.bindings.length).toBe(2)
        })
    })

    describe('Turtle operations', () => {
        const testTurtle = `
            @prefix ex: <http://example.org/> .
            ex:subject ex:predicate "test value" .
        `

        it('should upload Turtle data and return counts', async () => {
            const result = await SPARQLHelpers.uploadTurtle(baseUrl, testTurtle, auth, testGraph)

            expect(result.success).toBe(true)
            expect(result.counts.triples).toBe(1)
            expect(result.counts.total).toBe(1)

            // Verify the upload worked via SPARQL
            const verifyQuery = `
                ASK FROM <${testGraph}>
                WHERE {
                    ?s ?p "test value"
                }
            `
            const askResponse = await SPARQLHelpers.executeSPARQLQuery(endpoint.query, verifyQuery, auth)
            const askResult = await askResponse.json()
            expect(askResult.boolean).toBe(true)
        })

        it('should retrieve data as Turtle using CONSTRUCT', async () => {
            // First insert some data using SPARQL Update
            const insertQuery = `
                PREFIX ex: <http://example.org/>
                INSERT DATA {
                    GRAPH <${testGraph}> {
                        ex:subject ex:predicate "test value" .
                    }
                }
            `
            await SPARQLHelpers.executeSPARQLUpdate(endpoint.update, insertQuery, auth)

            const constructQuery = `
                CONSTRUCT {
                    ?s ?p ?o
                }
                FROM <${testGraph}>
                WHERE {
                    ?s ?p ?o
                }
            `

            const constructResponse = await SPARQLHelpers.executeSPARQLQuery(
                endpoint.query,
                constructQuery,
                auth,
                'text/turtle'
            )

            const turtle = await constructResponse.text()
            expect(turtle).toContain('http://example.org/subject')
        })
    })

    describe('Server interaction', () => {
        it('should handle authentication (note: auth currently not enforced)', async () => {
            const invalidAuth = SPARQLHelpers.createAuthHeader('invalid', 'credentials')
            const query = 'SELECT * WHERE { ?s ?p ?o } LIMIT 1'

            // Since auth is not enforced, this should succeed
            const queryResponse = await SPARQLHelpers.executeSPARQLQuery(endpoint.query, query, invalidAuth)
            const data = await queryResponse.json()
            expect(data.results.bindings.length).toBeGreaterThanOrEqual(0)
        })
    })
})

================
File: tests/unit/sparql-store-spec.js
================
// tests/unit/sparql-store-spec.js
import SPARQLStore from '../../src/stores/SPARQLStore.js'
import { v4 as uuidv4 } from 'uuid'

describe('SPARQLStore', () => {
    let store
    let mockFetch

    const endpoint = {
        query: 'http://example.org/sparql/query',
        update: 'http://example.org/sparql/update'
    }

    const mockInteraction = {
        id: uuidv4(),
        prompt: 'test prompt',
        output: 'test output',
        embedding: new Array(1536).fill(0),
        timestamp: Date.now(),
        accessCount: 1,
        concepts: ['test'],
        decayFactor: 1.0
    }

    const mockMemoryStore = {
        shortTermMemory: [mockInteraction],
        longTermMemory: []
    }

    beforeEach(() => {
        mockFetch = jasmine.createSpy('fetch').and.returnValue(
            Promise.resolve({
                ok: true,
                json: () => Promise.resolve({
                    results: { bindings: [] }
                }),
                text: () => Promise.resolve('')
            })
        )
        global.fetch = mockFetch

        store = new SPARQLStore(endpoint, {
            user: 'test',
            password: 'test',
            graphName: 'http://test.org/memory',
            dimension: 1536
        })
    })

    afterEach(() => {
        delete global.fetch
    })

    describe('Transaction Management', () => {
        it('should execute transaction lifecycle', async () => {
            await store.beginTransaction()
            expect(store.inTransaction).toBeTrue()

            await store.commitTransaction()
            expect(store.inTransaction).toBeFalse()
        })

        it('should prevent nested transactions', async () => {
            await store.beginTransaction()
            await expectAsync(store.beginTransaction())
                .toBeRejectedWithError('Transaction already in progress')
            await store.rollbackTransaction()
        })

        it('should rollback failed transactions', async () => {
            mockFetch.and.returnValues(
                Promise.resolve({ ok: true }), // begin
                Promise.resolve({ ok: false, status: 500 }), // operation
                Promise.resolve({ ok: true }) // rollback
            )

            await store.beginTransaction()
            await expectAsync(store.saveMemoryToHistory(mockMemoryStore))
                .toBeRejected()

            expect(store.inTransaction).toBeFalse()
            expect(mockFetch).toHaveBeenCalledTimes(3)
        })
    })

    describe('Graph Operations', () => {
        it('should verify graph existence', async () => {
            await store.verify()
            expect(mockFetch).toHaveBeenCalledWith(
                endpoint.update,
                jasmine.objectContaining({
                    body: jasmine.stringContaining('CREATE SILENT GRAPH')
                })
            )
        })

        it('should save memory to history', async () => {
            await store.saveMemoryToHistory(mockMemoryStore)

            expect(mockFetch).toHaveBeenCalledWith(
                endpoint.update,
                jasmine.objectContaining({
                    method: 'POST',
                    body: jasmine.stringContaining('INSERT DATA')
                })
            )
        })

        it('should load history', async () => {
            mockFetch.and.returnValue(Promise.resolve({
                ok: true,
                json: () => Promise.resolve({
                    results: {
                        bindings: [{
                            id: { value: mockInteraction.id },
                            prompt: { value: mockInteraction.prompt },
                            output: { value: mockInteraction.output },
                            embedding: { value: JSON.stringify(mockInteraction.embedding) },
                            timestamp: { value: mockInteraction.timestamp.toString() },
                            accessCount: { value: '1' },
                            concepts: { value: JSON.stringify(mockInteraction.concepts) },
                            decayFactor: { value: '1.0' },
                            memoryType: { value: 'short-term' }
                        }]
                    }
                })
            }))

            const [shortTerm, longTerm] = await store.loadHistory()

            expect(shortTerm.length).toBe(1)
            expect(longTerm.length).toBe(0)
            expect(shortTerm[0].id).toBe(mockInteraction.id)
        })
    })

    describe('Validation', () => {
        it('should validate embedding dimensions', () => {
            const validEmbedding = new Array(1536).fill(0)
            expect(() => store.validateEmbedding(validEmbedding)).not.toThrow()

            const invalidEmbedding = new Array(100).fill(0)
            expect(() => store.validateEmbedding(invalidEmbedding))
                .toThrowError('Embedding dimension mismatch')
        })

        it('should handle invalid embedding values', () => {
            const invalidEmbedding = new Array(1536).fill('not a number')
            expect(() => store.validateEmbedding(invalidEmbedding))
                .toThrowError('Embedding must contain only valid numbers')
        })
    })

    describe('Query Generation', () => {
        it('should generate valid SPARQL UPDATE', async () => {
            await store.saveMemoryToHistory(mockMemoryStore)

            const updateCall = mockFetch.calls.mostRecent()
            const updateBody = updateCall.args[1].body

            expect(updateBody).toContain('INSERT DATA')
            expect(updateBody).toContain(mockInteraction.id)
            expect(updateBody).toContain('mcp:Interaction')
            expect(updateBody).not.toContain('undefined')
        })

        it('should handle special characters in queries', async () => {
            const specialInteraction = {
                ...mockInteraction,
                prompt: 'test "quotes" and \\backslashes\\',
                output: "test 'apostrophes' and newlines\n"
            }

            await store.saveMemoryToHistory({
                shortTermMemory: [specialInteraction],
                longTermMemory: []
            })

            const updateBody = mockFetch.calls.mostRecent().args[1].body
            expect(() => updateBody.replace(/\\"/g, '"')).not.toThrow()
        })
    })

    describe('Resource Management', () => {
        it('should clean up on close', async () => {
            store.inTransaction = true
            await store.close()
            expect(store.inTransaction).toBeFalse()
        })

        it('should handle multiple operations in transaction', async () => {
            await store.beginTransaction()

            await store.saveMemoryToHistory({
                shortTermMemory: [mockInteraction],
                longTermMemory: []
            })

            await store._executeSparqlQuery('SELECT * WHERE { ?s ?p ?o }', endpoint.query)

            await store.commitTransaction()
            expect(mockFetch.calls.count()).toBe(3) // begin + query + commit
        })
    })
})

================
File: tests/about.md
================
npm test -- tests/unit/sparql-endpoint-spec.js

npm test -- tests/unit/sparql-store-spec.js

================
File: tests/test-list-structure_2025-01-26.md
================
# Core System

- npm test -- tests/unit/Config.spec.js
- npm test -- tests/unit/api/BaseAPI.spec.js
- npm test -- tests/unit/api/APIRegistry.spec.js
- npm test -- tests/unit/api/APILogger.spec.js
- npm test -- tests/unit/api/MetricsCollector.spec.js

# Storage & Memory

- npm test -- tests/unit/cached-sparql-store-spec.js
- npm test -- tests/unit/sparql-store-spec.js
- npm test -- tests/integration/sparql/sparql-store-integration-spec.js
- npm test -- tests/integration/sparql/sparql-advanced-backup-spec.js
- npm test -- tests/integration/sparql/sparql-basic-backup-spec.js
- npm test -- tests/integration/sparql/sparql-federation-spec.js

# Handlers

- npm test -- tests/unit/handlers/LLMHandler.spec.js
- npm test -- tests/unit/handlers/EmbeddingHandler.spec.js
- npm test -- tests/unit/handlers/PassiveHandler.spec.js
- npm test -- tests/unit/handlers/ActiveHandler.spec.js
- npm test -- tests/unit/handlers/SelfieHandler.spec.js
- npm test -- tests/integration/llms/LLMHandler.integration.spec.js

# Context & Windows

- npm test -- tests/unit/ContextManager.spec.js
- npm test -- tests/unit/ContextWindowManager.spec.js
- npm test -- tests/integration/ContextManager.integration.spec.js

# User Interfaces

- npm test -- tests/unit/api/REPLHandler.spec.js
- npm test -- tests/unit/api/CLIHandler.spec.js
- npm test -- tests/integration/http/HTTPServer.integration.spec.js
- npm test -- tests/integration/http/websocket-integration.spec.js

# Utilities

- npm test -- tests/unit/utils/EmbeddingValidator.spec.js
- npm test -- tests/unit/utils/SPARQLHelpers.spec.js

================
File: .git
================
gitdir: ../../.git/modules/packages/semem

================
File: .gitignore
================
# Logs
logs
*.log
npm-debug.log*
yarn-debug.log*
yarn-error.log*
lerna-debug.log*
.pnpm-debug.log*

# Diagnostic reports (https://nodejs.org/api/report.html)
report.[0-9]*.[0-9]*.[0-9]*.[0-9]*.json

# Runtime data
pids
*.pid
*.seed
*.pid.lock

# Directory for instrumented libs generated by jscoverage/JSCover
lib-cov

# Coverage directory used by tools like istanbul
coverage
*.lcov

# nyc test coverage
.nyc_output

# Grunt intermediate storage (https://gruntjs.com/creating-plugins#storing-task-files)
.grunt

# Bower dependency directory (https://bower.io/)
bower_components

# node-waf configuration
.lock-wscript

# Compiled binary addons (https://nodejs.org/api/addons.html)
build/Release

# Dependency directories
node_modules/
jspm_packages/

# Snowpack dependency directory (https://snowpack.dev/)
web_modules/

# TypeScript cache
*.tsbuildinfo

# Optional npm cache directory
.npm

# Optional eslint cache
.eslintcache

# Optional stylelint cache
.stylelintcache

# Microbundle cache
.rpt2_cache/
.rts2_cache_cjs/
.rts2_cache_es/
.rts2_cache_umd/

# Optional REPL history
.node_repl_history

# Output of 'npm pack'
*.tgz

# Yarn Integrity file
.yarn-integrity

# dotenv environment variable files
.env
.env.development.local
.env.test.local
.env.production.local
.env.local

# parcel-bundler cache (https://parceljs.org/)
.cache
.parcel-cache

# Next.js build output
.next
out

# Nuxt.js build / generate output
.nuxt
dist

# Gatsby files
.cache/
# Comment in the public line in if your project uses Gatsby and not Next.js
# https://nextjs.org/blog/next-9-1#public-directory-support
# public

# vuepress build output
.vuepress/dist

# vuepress v2.x temp and cache directory
.temp
.cache

# Docusaurus cache and generated files
.docusaurus

# Serverless directories
.serverless/

# FuseBox cache
.fusebox/

# DynamoDB Local files
.dynamodb/

# TernJS port file
.tern-port

# Stores VSCode versions used for testing VSCode extensions
.vscode-test

# yarn v2
.yarn/cache
.yarn/unplugged
.yarn/build-state.yml
.yarn/install-state.gz
.pnp.*

================
File: about.md
================
# About

Needs a SPARQL endpoint - like #:tbox

```sh
cd ~/github-danny/hyperdata/packages/tbox/

 docker-compose up -d
```

```sh
cd ~/github-danny/hyperdata/packages/semem

node src/OllamaExample.js

```

---

Needs SPARQL store, endpoint 127.0.0.1:4030

```sh
cd ~/github-danny/hyperdata/packages/tbox
docker-compose up -d

 node src/SPARQLExample.js

```

```sh
cd ~/github-danny/hyperdata/packages/tbox
docker-compose up -d
cd ~/github-danny/hyperdata/packages/semem
node src/OllamaClaudeExample.js

```

```sh
# ollama pull nomic-embed-text

curl http://localhost:11434/api/embeddings -d '{
  "model": "nomic-embed-text",
  "prompt": "The sky is blue because of Rayleigh scattering"
}'
```

```sh
npm test -- --filter="SPARQL Endpoint Integration"
npm test -- tests/unit/Config.spec.js
```

================
File: jasmine.json
================
{
    "spec_dir": "tests",
    "spec_files": [
        "unit/**/*.spec.js",
        "integration/**/*.spec.js"
    ],
    "helpers": [
        "helpers/setupGlobals.js",
        "helpers/setupSPARQL.js"
    ],
    "env": {
        "stopSpecOnExpectationFailure": false,
        "random": false
    }
}

================
File: jsconfig.json
================
{
  "compilerOptions": {
    "baseUrl": ".",
    "paths": {
      "@src/*": ["src/*"],
      "@tests/*": ["tests/*"]
    }
  }
}

================
File: jsdoc.json
================
{
    "source": {
        "include": [
            "src"
        ],
        "exclude": [
            "node_modules"
        ],
        "includePattern": ".+\\.js(doc|x)?$",
        "excludePattern": "(^|\\/|\\\\)_"
    },
    "opts": {
        "verbose": true,
        "recurse": true,
        "destination": "./docs/jsdoc"
    },
    "plugins": [
        "plugins/markdown"
    ]
}

================
File: LICENSE
================
MIT License

Copyright (c) 2024 Danny Ayers

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.

================
File: package copy.json
================
{
  "name": "semem",
  "version": "1.0.0",
  "description": "Semantic Memory",
  "type": "module",
  "main": "index.js",
  "engines": {
    "node": ">=20.11.0"
  },
  "scripts": {
    "tests": "jasmine --config=jasmine.json --reporter=tests/helpers/reporter.js",
    "cov": "nyc -a --include=src --reporter=lcov npm run test",
    "docs": "jsdoc -c jsdoc.json",
    "rp": "repomix -c repomix.config.json . "
  },
  "repository": {
    "type": "git",
    "url": "git+https://github.com/danja/semem.git"
  },
  "keywords": [
    "semantic",
    "memory",
    "llm",
    "rdf",
    "sparql"
  ],
  "author": "Danny Ayers",
  "license": "MIT",
  "bugs": {
    "url": "https://github.com/danja/semem/issues"
  },
  "homepage": "https://github.com/danja/semem#readme",
  "devDependencies": {
    "jasmine": "^5.5.0",
    "jasmine-spec-reporter": "^7.0.0",
    "jsdoc": "^4.0.4"
  },
  "dependencies": {
    "@anthropic-ai/sdk": "^0.36.2",
    "@langchain/core": "^0.3.19",
    "@langchain/openai": "^0.3.14",
    "faiss-node": "^0.5.1",
    "graphology": "^0.25.4",
    "ml-kmeans": "^6.0.0",
    "ollama": "^0.5.10"
  }
}

================
File: package-ref.json
================
{
    "name": "semem",
    "version": "1.0.0",
    "description": "Semantic Memory",
    "type": "module",
    "main": "index.js",
    "engines": {
        "node": ">=20.11.0"
    },
    "scripts": {
        "test": "jasmine --config=jasmine.json --reporter=tests/helpers/reporter.js",
        "cov": "nyc -a --include=src --reporter=lcov npm run test",
        "docs": "jsdoc -c jsdoc.json",
        "rp": "repomix -c repomix.config.json . "
    },
    "repository": {
        "type": "git",
        "url": "git+https://github.com/danja/semem.git"
    },
    "keywords": [
        "semantic",
        "memory",
        "llm",
        "rdf",
        "sparql"
    ],
    "author": "Danny Ayers",
    "license": "MIT",
    "bugs": {
        "url": "https://github.com/danja/semem/issues"
    },
    "homepage": "https://github.com/danja/semem#readme",
    "devDependencies": {
        "jasmine": "^5.5.0",
        "jasmine-spec-reporter": "^7.0.0",
        "jsdoc": "^4.0.4"
    },
    "dependencies": {
        "@langchain/core": "^0.3.19",
        "@langchain/openai": "^0.3.14",
        "faiss-node": "^0.5.1",
        "graphology": "^0.25.4",
        "ml-kmeans": "^6.0.0",
        "ollama": "^0.5.10"
    }
}

================
File: package.json
================
{
  "name": "semem",
  "version": "1.0.0",
  "description": "Semantic Memory",
  "type": "module",
  "main": "index.js",
  "engines": {
    "node": ">=20.11.0"
  },
  "scripts": {
    "test": "node scripts/run-tests.js",
    "test:unit": "node scripts/run-tests.js tests/unit",
    "test:integration": "node scripts/run-tests.js tests/integration",
    "test:debug": "node --inspect-brk scripts/run-tests.js",
    "cov": "nyc -a --include=src --reporter=lcov npm run test",
    "docs": "jsdoc -c jsdoc.json",
    "rp": "repomix -c repomix.config.json . && repomix -c repomix-docs.config.json . "
  },
  "repository": {
    "type": "git",
    "url": "git+https://github.com/danja/semem.git"
  },
  "keywords": [
    "semantic",
    "memory",
    "llm",
    "rdf",
    "sparql"
  ],
  "author": "Danny Ayers",
  "license": "MIT",
  "bugs": {
    "url": "https://github.com/danja/semem/issues"
  },
  "homepage": "https://github.com/danja/semem#readme",
  "devDependencies": {
    "jasmine": "^5.5.0",
    "jasmine-spec-reporter": "^7.0.0",
    "jsdoc": "^4.0.4"
  },
  "dependencies": {
    "@anthropic-ai/sdk": "^0.36.2",
    "@langchain/core": "^0.3.19",
    "@langchain/openai": "^0.3.14",
    "compression": "^1.7.5",
    "cors": "^2.8.5",
    "dotenv": "^16.4.7",
    "express": "^4.21.2",
    "express-rate-limit": "^7.5.0",
    "faiss-node": "^0.5.1",
    "graphology": "^0.25.4",
    "helmet": "^8.0.0",
    "loglevel": "^1.9.2",
    "ml-kmeans": "^6.0.0",
    "ollama": "^0.5.10",
    "swagger-ui-express": "^5.0.1"
  }
}

================
File: package.json.bak
================
{
  "name": "semem",
  "version": "1.0.0",
  "description": "Semantic Memory",
  "type": "module",
  "main": "index.js",
  "engines": {
    "node": ">=20.11.0"
  },
  "preinstall": "node -r ./config.js",
  "scripts": {
    "test": "jasmine --config=jasmine.json --reporter=tests/helpers/reporter.js",
    "cov": "nyc -a --include=src --reporter=lcov npm run test",
    "docs": "jsdoc -c jsdoc.json",
    "rp": "repomix -c repomix.config.json . "
  },
  "repository": {
    "type": "git",
    "url": "git+https://github.com/danja/semem.git"
  },
  "keywords": [
    "semantic",
    "memory",
    "llm",
    "rdf",
    "sparql"
  ],
  "author": "Danny Ayers",
  "license": "MIT",
  "bugs": {
    "url": "https://github.com/danja/semem/issues"
  },
  "homepage": "https://github.com/danja/semem#readme",
  "devDependencies": {
    "jasmine": "^5.5.0",
    "jasmine-spec-reporter": "^7.0.0",
    "jsdoc": "^4.0.4",
    "repomix": "^0.2.20"
  },
  "dependencies": {
    "@langchain/core": "^0.3.19",
    "@langchain/openai": "^0.3.14",
    "faiss-node": "^0.5.1",
    "graphology": "^0.25.4",
    "ml-kmeans": "^6.0.0",
    "ollama": "^0.5.10"
  }
}

================
File: repomix-docs.config.json
================
{
    "output": {
        "filePath": "./repomix-semem-docs.md",
        "headerText": "Semem docs",
        "removeComments": false
    },
    "include": [
        "**/*.md",
        "docs/postcraft/content-raw/articles/_description_pre_2025-01-25/**/*.md",
        "docs/postcraft/content-raw/articles/_description_2025-01-25/**/*.md"
    ],
    "ignore": {
        "useDefaultPatterns": false,
        "customPatterns": [
            "docs",
            "docs/postcraft/cache",
            "docs/postcraft/content-static",
            "docs/postcraft/layouts",
            "docs/postcraft/manifest.ttl",
            "docs/postcraft/media",
            "docs/postcraft/public",
            "data",
            ".nyc_output",
            ".env",
            "**/_*",
            "node_modules",
            "*.log",
            "**/*repomix*.txt",
            "**/*repomix*.md",
            "**/*.html",
            "**/data/*",
            "**/*copy*.js",
            "**/conversations.json"
        ]
    }
}

================
File: repomix.config.json
================
{
    "output": {
        "filePath": "./repomix-semem.md",
        "headerText": "Semem repo",
        "removeComments": false
    },
    "include": [
        "**/*"
    ],
    "ignore": {
        "useDefaultPatterns": false,
        "customPatterns": [
            "data",
            "docs",
            ".nyc_output",
            ".env",
            "**/_*",
            "node_modules",
            "*.log",
            "**/*repomix*.txt",
            "**/*repomix*.md",
            "**/*.html",
            "**/data/*",
            "**/*copy*.js",
            "**/conversations.json"
        ]
    }
}
