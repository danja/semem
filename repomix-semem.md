This file is a merged representation of the entire codebase, combining all repository files into a single document.
Generated by Repomix on: 2025-01-24T16:13:48.477Z

================================================================
File Summary
================================================================

Purpose:
--------
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

File Format:
------------
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Multiple file entries, each consisting of:
  a. A separator line (================)
  b. The file path (File: path/to/file)
  c. Another separator line
  d. The full contents of the file
  e. A blank line

Usage Guidelines:
-----------------
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
- Pay special attention to the Repository Description. These contain important context and guidelines specific to this project.

Notes:
------
- Some files may have been excluded based on .gitignore rules and Repomix's
  configuration.
- Binary files are not included in this packed representation. Please refer to
  the Repository Structure section for a complete list of file paths, including
  binary files.

Additional Info:
----------------
User Provided Header:
-----------------------
Semem repo

================================================================
Directory Structure
================================================================
_old-src/
  example.js
  memory-manager.js
  remote-storage.js
examples/
  ClaudeExample.js
  OllamaClaudeExample.js
  OllamaExample.js
misc/
  scripts/
    ollama-embedding-test.sh
    sparql-auth-test.sh
    sparql-upload-test.sh
scripts/
  run-tests.js
src/
  _old/
    config.js
  api/
    cli/
      about.md
      CLIHandler.js
    common/
      APIRegistry.js
      BaseAPI.js
      CustomValidators.js
      RDFParser.js
      RDFValidator.js
      types.d.ts.ts
    features/
      ActiveHandler.js
      PassiveHandler.js
      SelfieHandler.js
    http/
      client/
        SememClient.js
      server/
        HTTPServer.js
        openapi-schema.js
    repl/
      REPLHandler.js
    about.md
    APILogger.js
    MetricsCollector.js
  connectors/
    OllamaConnector.js
  stores/
    BaseStore.js
    CachedSPARQLStore.js
    InMemoryStore.js
    JSONStore.js
    MemoryStore.js
    SPARQLStore.js
  utils/
    EmbeddingValidator.js
    FusekiDiscovery.js
    SPARQLHelpers.js
  Config copy 2.js
  Config copy 3.js
  Config copy 4.js
  Config.js
  ContextManager.js
  ContextWindowManager.js
  index.js
  MemoryManager copy 2.js
  MemoryManager.js
  PromptTemplates.js
  SPARQLExample.js
  Utils.js
tests/
  bash/
    check_fuseki.sh
    test-endpoints.sh
  helpers/
    jasmine_examples/
      SpecHelper.js
    reporter.js
    setupGlobals.js
    setupSPARQL.js
  integration/
    llms/
      Ollama.spec.js
    sparql/
      sparql-advanced-backup-spec.js
      sparql-basic-backup-spec.js
      sparql-federation-spec.js
      sparql-store-integration-spec.js
  mocks/
    Ollama.js
  support/
    jasmine.json
  unit/
    cached-sparql-store-spec.js
    ContextWindowManager.spec.js
    MemoryManager.spec.js
    sparql-endpoint-spec.js
    sparql-store-spec.js
  about.md
.git
.gitignore
about.md
jasmine.json
jsconfig.json
jsdoc.json
LICENSE
package copy.json
package-ref.json
package.json
package.json.bak
repomix.config.json

================================================================
Files
================================================================

================
File: _old-src/example.js
================
import MemoryManager from './memoryManager.js';
import JSONStorage from './jsonStorage.js';
import RemoteStorage from './remoteStorage.js';
import Config from './config.js';

async function main() {
    // Initialize with custom configuration
    const config = new Config({
        storage: {
            type: 'remote',
            options: {
                endpoint: 'https://api.example.com/memory',
                apiKey: process.env.STORAGE_API_KEY
            }
        },
        models: {
            chat: {
                provider: 'openai',
                model: 'gpt-4-turbo-preview'
            },
            embedding: {
                provider: 'openai',
                model: 'text-embedding-3-small'
            }
        }
    });

    // Initialize storage based on configuration
    let storage;
    switch (config.get('storage.type')) {
        case 'json':
            storage = new JSONStorage(config.get('storage.options.path'));
            break;
        case 'remote':
            storage = new RemoteStorage(config.get('storage.options'));
            break;
        default:
            storage = new InMemoryStorage();
    }

    // Initialize memory manager
    const memoryManager = new MemoryManager({
        apiKey: process.env.OPENAI_API_KEY,
        chatModel: config.get('models.chat.provider'),
        chatModelName: config.get('models.chat.model'),
        embeddingModel: config.get('models.embedding.provider'),
        embeddingModelName: config.get('models.embedding.model'),
        storage
    });

    // Example interaction
    const prompt = "What's the current state of AI technology?";
    
    // Get relevant past interactions
    const relevantInteractions = await memoryManager.retrieveRelevantInteractions(prompt);
    
    // Generate response
    const response = await memoryManager.generateResponse(prompt, [], relevantInteractions);
    console.log('Response:', response);

    // Store the interaction
    const embedding = await memoryManager.getEmbedding(`${prompt} ${response}`);
    const concepts = await memoryManager.extractConcepts(`${prompt} ${response}`);
    await memoryManager.addInteraction(prompt, response, embedding, concepts);
}

main().catch(console.error);

================
File: _old-src/memory-manager.js
================
import { ChatOpenAI } from '@langchain/openai';
import { ChatOllama } from '@langchain/community/chat_models/ollama';
import { OpenAIEmbeddings } from '@langchain/openai';
import ollama from 'ollama';
import { v4 as uuidv4 } from 'uuid';
import MemoryStore from './memoryStore.js';
import InMemoryStorage from './inMemoryStorage.js';
import { logger } from './utils.js';

export default class MemoryManager {
    constructor({
        apiKey,
        chatModel = 'ollama',
        chatModelName = 'llama2',
        embeddingModel = 'ollama',
        embeddingModelName = 'nomic-embed-text',
        storage = null
    }) {
        this.apiKey = apiKey;
        this.chatModelName = chatModelName;
        this.embeddingModelName = embeddingModelName;
        this.dimension = 1536;  // Default dimension

        this.initializeChatModel(chatModel, chatModelName);
        this.initializeEmbeddingModel(embeddingModel, embeddingModelName);

        this.memoryStore = new MemoryStore(this.dimension);
        this.storage = storage || new InMemoryStorage();
        
        this.initialize();
    }

    initializeChatModel(chatModel, modelName) {
        if (chatModel.toLowerCase() === 'openai') {
            this.llm = new ChatOpenAI({
                modelName: modelName,
                apiKey: this.apiKey
            });
        } else if (chatModel.toLowerCase() === 'ollama') {
            this.llm = new ChatOllama({
                model: modelName,
                temperature: 0
            });
        } else {
            throw new Error(`Unsupported chat model: ${chatModel}`);
        }
    }

    async initializeEmbeddingModel(embeddingModel, modelName) {
        if (embeddingModel.toLowerCase() === 'openai') {
            this.embeddings = new OpenAIEmbeddings({
                modelName,
                apiKey: this.apiKey
            });
            this.dimension = modelName === 'text-embedding-3-small' ? 1536 : 1024;
        } else if (embeddingModel.toLowerCase() === 'ollama') {
            this.embeddings = async (text) => {
                const response = await ollama.embeddings({
                    model: modelName,
                    prompt: text
                });
                return response.embedding;
            };
            this.dimension = 1024;  // Default for Ollama
        } else {
            throw new Error(`Unsupported embedding model: ${embeddingModel}`);
        }
    }

    async initialize() {
        const [shortTerm, longTerm] = await this.storage.loadHistory();
        
        for (const interaction of shortTerm) {
            const embedding = this.standardizeEmbedding(interaction.embedding);
            interaction.embedding = embedding;
            this.memoryStore.addInteraction(interaction);
        }

        this.memoryStore.longTermMemory.push(...longTerm);
        this.memoryStore.clusterInteractions();
        
        logger.info(`Memory initialized with ${shortTerm.length} short-term and ${longTerm.length} long-term memories`);
    }

    standardizeEmbedding(embedding) {
        const current = embedding.length;
        if (current === this.dimension) return embedding;
        
        if (current < this.dimension) {
            return [...embedding, ...new Array(this.dimension - current).fill(0)];
        }
        return embedding.slice(0, this.dimension);
    }

    async getEmbedding(text) {
        logger.info('Generating embedding...');
        let embedding;
        
        try {
            if (typeof this.embeddings === 'function') {
                embedding = await this.embeddings(text);
            } else {
                embedding = await this.embeddings.embedQuery(text);
            }
            
            return this.standardizeEmbedding(embedding);
        } catch (error) {
            logger.error('Error generating embedding:', error);
            throw error;
        }
    }

    async extractConcepts(text) {
        logger.info('Extracting concepts...');
        
        const messages = [{
            role: 'system',
            content: 'Extract key concepts from the text. Return only an array of strings.'
        }, {
            role: 'user',
            content: text
        }];

        try {
            const response = await this.llm.call(messages);
            const concepts = JSON.parse(response.content);
            logger.info('Extracted concepts:', concepts);
            return concepts;
        } catch (error) {
            logger.error('Error extracting concepts:', error);
            return [];
        }
    }

    async addInteraction(prompt, output, embedding, concepts) {
        const interaction = {
            id: uuidv4(),
            prompt,
            output,
            embedding,
            timestamp: Date.now(),
            accessCount: 1,
            concepts,
            decayFactor: 1.0
        };

        this.memoryStore.addInteraction(interaction);
        await this.storage.saveMemoryToHistory(this.memoryStore);
    }

    async retrieveRelevantInteractions(query, similarityThreshold = 40, excludeLastN = 0) {
        const queryEmbedding = await this.getEmbedding(query);
        const queryConcepts = await this.extractConcepts(query);
        return this.memoryStore.retrieve(queryEmbedding, queryConcepts, similarityThreshold, excludeLastN);
    }

    async generateResponse(prompt, lastInteractions = [], retrievals = [], contextWindow = 3) {
        const context = this.buildContext(lastInteractions, retrievals, contextWindow);
        
        const messages = [{
            role: 'system',
            content: "You're a helpful assistant with memory of past interactions."
        }, {
            role: 'user',
            content: `${context}\nCurrent prompt: ${prompt}`
        }];

        try {
            const response = await this.llm.call(messages);
            return response.content.trim();
        } catch (error) {
            logger.error('Error generating response:', error);
            throw error;
        }
    }

    buildContext(lastInteractions, retrievals, contextWindow) {

================
File: _old-src/remote-storage.js
================
import BaseStorage from './storage.js';
import { logger } from './utils.js';

export default class RemoteStorage extends BaseStorage {
    constructor(options = {}) {
        super();
        this.endpoint = options.endpoint || 'http://localhost:8080';
        this.apiKey = options.apiKey;
        this.timeout = options.timeout || 5000;
    }

    async loadHistory() {
        try {
            const response = await fetch(`${this.endpoint}/memory`, {
                method: 'GET',
                headers: {
                    'Authorization': `Bearer ${this.apiKey}`,
                    'Content-Type': 'application/json'
                },
                timeout: this.timeout
            });

            if (!response.ok) {
                throw new Error(`HTTP error! status: ${response.status}`);
            }

            const data = await response.json();
            return [
                data.shortTermMemory || [],
                data.longTermMemory || []
            ];
        } catch (error) {
            logger.error('Error loading remote history:', error);
            throw error;
        }
    }

    async saveMemoryToHistory(memoryStore) {
        try {
            const history = {
                shortTermMemory: memoryStore.shortTermMemory.map((item, idx) => ({
                    id: item.id,
                    prompt: item.prompt,
                    output: item.output,
                    embedding: Array.from(memoryStore.embeddings[idx].flat()),
                    timestamp: memoryStore.timestamps[idx],
                    accessCount: memoryStore.accessCounts[idx],
                    concepts: Array.from(memoryStore.conceptsList[idx]),
                    decayFactor: item.decayFactor || 1.0
                })),
                longTermMemory: memoryStore.longTermMemory
            };

            const response = await fetch(`${this.endpoint}/memory`, {
                method: 'POST',
                headers: {
                    'Authorization': `Bearer ${this.apiKey}`,
                    'Content-Type': 'application/json'
                },
                body: JSON.stringify(history),
                timeout: this.timeout
            });

            if (!response.ok) {
                throw new Error(`HTTP error! status: ${response.status}`);
            }

            logger.info(`Saved memory to remote storage. Short-term: ${history.shortTermMemory.length}, Long-term: ${history.longTermMemory.length}`);
        } catch (error) {
            logger.error('Error saving to remote storage:', error);
            throw error;
        }
    }
}

================
File: examples/ClaudeExample.js
================
import MemoryManager from '../src/MemoryManager.js'
import JSONStore from '../src/stores/JSONStore.js'
import Config from '../src/Config.js'

class ClaudeConnector {
    constructor(apiKey, baseUrl = 'https://api.anthropic.com/v1') {
        this.apiKey = apiKey
        this.baseUrl = baseUrl
        this.defaultModel = 'claude-3-opus-20240229'
    }

    async generateEmbedding(model, input) {
        const response = await fetch(`${this.baseUrl}/messages`, {
            method: 'POST',
            headers: {
                'Content-Type': 'application/json',
                'x-api-key': this.apiKey,
                'anthropic-version': '2023-06-01'
            },
            body: JSON.stringify({
                model: this.defaultModel,
                messages: [{ role: 'user', content: input }],
                system: "Generate an embedding vector for the input text."
            })
        })

        if (!response.ok) {
            throw new Error(`Claude API error: ${response.status}`)
        }

        const data = await response.json()
        return data.embedding
    }

    async generateChat(model, messages, options = {}) {
        const response = await fetch(`${this.baseUrl}/messages`, {
            method: 'POST',
            headers: {
                'Content-Type': 'application/json',
                'x-api-key': this.apiKey,
                'anthropic-version': '2023-06-01'
            },
            body: JSON.stringify({
                model: this.defaultModel,
                messages: messages.map(msg => ({
                    role: msg.role,
                    content: msg.content
                })),
                ...options
            })
        })

        if (!response.ok) {
            throw new Error(`Claude API error: ${response.status}`)
        }

        const data = await response.json()
        return data.content[0].text
    }

    async generateCompletion(model, prompt, options = {}) {
        return this.generateChat(model, [{
            role: 'user',
            content: prompt
        }], options)
    }
}

// Handle graceful shutdown
let memoryManager = null

async function shutdown(signal) {
    console.log(`\nReceived ${signal}, starting graceful shutdown...`)
    if (memoryManager) {
        try {
            await memoryManager.dispose()
            console.log('Cleanup complete')
            process.exit(0)
        } catch (error) {
            console.error('Error during cleanup:', error)
            process.exit(1)
        }
    } else {
        process.exit(0)
    }
}

// Handle different termination signals
process.on('SIGTERM', () => shutdown('SIGTERM'))
process.on('SIGINT', () => shutdown('SIGINT'))
process.on('uncaughtException', async (error) => {
    console.error('Uncaught Exception:', error)
    await shutdown('uncaughtException')
})
process.on('unhandledRejection', async (reason, promise) => {
    console.error('Unhandled Rejection at:', promise, 'reason:', reason)
    await shutdown('unhandledRejection')
})

async function main() {
    // Load environment variables
    const CLAUDE_API_KEY = process.env.CLAUDE_API_KEY
    if (!CLAUDE_API_KEY) {
        throw new Error('CLAUDE_API_KEY environment variable is required')
    }

    const config = new Config({
        storage: {
            type: 'json',
            options: {
                path: 'data/memory.json'
            }
        },
        models: {
            chat: {
                provider: 'claude',
                model: 'claude-3-opus-20240229'
            },
            embedding: {
                provider: 'claude',
                model: 'claude-3-opus-20240229'
            }
        }
    })

    const storage = new JSONStore(config.get('storage.options.path'))
    const claude = new ClaudeConnector(CLAUDE_API_KEY)

    memoryManager = new MemoryManager({
        llmProvider: claude,
        chatModel: config.get('models.chat.model'),
        embeddingModel: config.get('models.embedding.model'),
        storage
    })

    const prompt = "What's the current state of AI technology?"

    try {
        const relevantInteractions = await memoryManager.retrieveRelevantInteractions(prompt)
        const response = await memoryManager.generateResponse(prompt, [], relevantInteractions)
        console.log('Response:', response)

        const embedding = await memoryManager.generateEmbedding(`${prompt} ${response}`)
        const concepts = await memoryManager.extractConcepts(`${prompt} ${response}`)
        await memoryManager.addInteraction(prompt, response, embedding, concepts)
    } catch (error) {
        console.error('Error during execution:', error)
        await shutdown('error')
    }
}

// Start the application
main().catch(async (error) => {
    console.error('Fatal error:', error)
    await shutdown('fatal error')
})

export default ClaudeConnector

================
File: examples/OllamaClaudeExample.js
================
import MemoryManager from '../src/MemoryManager.js'
import JSONStore from '../src/stores/JSONStore.js'
import Config from '../src/Config.js'
import Anthropic from '@anthropic-ai/sdk'

class HybridConnector {
    constructor(claudeApiKey, ollamaBaseUrl = 'http://localhost:11434') {
        this.anthropic = new Anthropic({ apiKey: claudeApiKey })
        this.ollamaBaseUrl = ollamaBaseUrl
    }

    async generateEmbedding(model, input) {
        const response = await fetch(`${this.ollamaBaseUrl}/api/embeddings`, {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({
                model: 'nomic-embed-text',
                prompt: input,
                options: { num_ctx: 8192 }
            })
        })

        if (!response.ok) {
            throw new Error(`Ollama embedding error: ${response.status}`)
        }

        const data = await response.json()
        return data.embedding
    }

    async generateChat(model, messages, options = {}) {
        // Extract system message if present
        const systemMessage = messages.find(msg => msg.role === 'system')?.content || ''

        // Convert to Claude's format
        const claudeMessages = messages
            .filter(msg => msg.role !== 'system')
            .map(msg => ({
                role: msg.role === 'assistant' ? 'assistant' : 'user',
                content: msg.content
            }))

        const response = await this.anthropic.messages.create({
            model: "claude-3-opus-20240229",
            max_tokens: options.max_tokens || 1024,
            messages: claudeMessages,
            system: systemMessage,
            temperature: options.temperature || 0.7
        })

        return response.content[0].text
    }

    async generateCompletion(model, prompt, options = {}) {
        return this.generateChat(model, [{
            role: 'user',
            content: prompt
        }], options)
    }
}

let memoryManager = null

async function shutdown(signal) {
    console.log(`\nReceived ${signal}, starting graceful shutdown...`)
    if (memoryManager) {
        try {
            await memoryManager.dispose()
            console.log('Cleanup complete')
            process.exit(0)
        } catch (error) {
            console.error('Error during cleanup:', error)
            process.exit(1)
        }
    } else {
        process.exit(0)
    }
}

process.on('SIGTERM', () => shutdown('SIGTERM'))
process.on('SIGINT', () => shutdown('SIGINT'))
process.on('uncaughtException', async (error) => {
    console.error('Uncaught Exception:', error)
    await shutdown('uncaughtException')
})
process.on('unhandledRejection', async (reason, promise) => {
    console.error('Unhandled Rejection at:', promise, 'reason:', reason)
    await shutdown('unhandledRejection')
})

async function main() {
    const CLAUDE_API_KEY = process.env.CLAUDE_API_KEY
    if (!CLAUDE_API_KEY) {
        throw new Error('CLAUDE_API_KEY environment variable is required')
    }

    const config = new Config({
        storage: {
            type: 'json',
            options: {
                path: 'data/memory.json'
            }
        },
        models: {
            chat: {
                provider: 'claude',
                model: 'claude-3-opus-20240229'
            },
            embedding: {
                provider: 'ollama',
                model: 'nomic-embed-text'
            }
        }
    })

    const storage = new JSONStore(config.get('storage.options.path'))
    const hybridProvider = new HybridConnector(CLAUDE_API_KEY)

    memoryManager = new MemoryManager({
        llmProvider: hybridProvider,
        chatModel: config.get('models.chat.model'),
        embeddingModel: config.get('models.embedding.model'),
        storage
    })

    const prompt = "What's the current state of AI technology?"

    try {
        const relevantInteractions = await memoryManager.retrieveRelevantInteractions(prompt)
        const response = await memoryManager.generateResponse(prompt, [], relevantInteractions)
        console.log('Response:', response)

        const embedding = await memoryManager.generateEmbedding(`${prompt} ${response}`)
        const concepts = await memoryManager.extractConcepts(`${prompt} ${response}`)
        await memoryManager.addInteraction(prompt, response, embedding, concepts)
    } catch (error) {
        console.error('Error during execution:', error)
        await shutdown('error')
    }
}

main().catch(async (error) => {
    console.error('Fatal error:', error)
    await shutdown('fatal error')
})

================
File: examples/OllamaExample.js
================
import MemoryManager from '../src/MemoryManager.js'
import JSONStore from '../src/stores/JSONStore.js'
import Config from '../src/Config.js'
import OllamaConnector from '../src/connectors/OllamaConnector.js'

// Handle graceful shutdown
let memoryManager = null

async function shutdown(signal) {
    console.log(`\nReceived ${signal}, starting graceful shutdown...`)
    if (memoryManager) {
        try {
            await memoryManager.dispose()
            console.log('Cleanup complete')
            process.exit(0)
        } catch (error) {
            console.error('Error during cleanup:', error)
            process.exit(1)
        }
    } else {
        process.exit(0)
    }
}

// Handle different termination signals
process.on('SIGTERM', () => shutdown('SIGTERM'))
process.on('SIGINT', () => shutdown('SIGINT'))
process.on('uncaughtException', async (error) => {
    console.error('Uncaught Exception:', error)
    await shutdown('uncaughtException')
})
process.on('unhandledRejection', async (reason, promise) => {
    console.error('Unhandled Rejection at:', promise, 'reason:', reason)
    await shutdown('unhandledRejection')
})

async function main() {
    const config = new Config({
        storage: {
            type: 'json',
            options: {
                path: 'data/memory.json'
            }
        },
        models: {
            chat: {
                provider: 'ollama',
                model: 'qwen2:1.5b'
            },
            embedding: {
                provider: 'ollama',
                model: 'nomic-embed-text'
            }
        }
    })

    const storage = new JSONStore(config.get('storage.options.path'))
    const ollama = new OllamaConnector()

    memoryManager = new MemoryManager({
        llmProvider: ollama,
        chatModel: config.get('models.chat.model'),
        embeddingModel: config.get('models.embedding.model'),
        storage
    })

    const prompt = "What's the current state of AI technology?"

    try {
        const relevantInteractions = await memoryManager.retrieveRelevantInteractions(prompt)
        const response = await memoryManager.generateResponse(prompt, [], relevantInteractions)
        console.log('Response:', response)

        const embedding = await memoryManager.generateEmbedding(`${prompt} ${response}`)
        const concepts = await memoryManager.extractConcepts(`${prompt} ${response}`)
        await memoryManager.addInteraction(prompt, response, embedding, concepts)
    } catch (error) {
        console.error('Error during execution:', error)
        await shutdown('error')
    }
}

// Start the application
main().catch(async (error) => {
    console.error('Fatal error:', error)
    await shutdown('fatal error')
})

================
File: misc/scripts/ollama-embedding-test.sh
================
#!/bin/sh

# ollama pull nomic-embed-text

curl http://localhost:11434/api/embeddings -d '{
  "model": "nomic-embed-text",
  "prompt": "The sky is blue because of Rayleigh scattering"
}'

================
File: misc/scripts/sparql-auth-test.sh
================
#!/bin/sh

curl -X POST \
  -H "Authorization: Basic $(echo -n 'invalid:credentials' | base64)" \
  -H "Content-Type: application/sparql-query" \
  -H "Accept: application/json" \
  --data 'SELECT * WHERE { ?s ?p ?o } LIMIT 1' \
  'http://localhost:4030/test/query'

================
File: misc/scripts/sparql-upload-test.sh
================
#!/bin/sh

curl -X POST \
  -H "Authorization: Basic $(echo -n 'admin:admin123' | base64)" \
  -H "Content-Type: text/turtle" \
  --data-binary '@-' \
  'http://localhost:4030/test/data?graph=http://example.org/test-graph' << 'EOF'
@prefix ex: <http://example.org/> .
ex:subject ex:predicate "test value" .
EOF

================
File: scripts/run-tests.js
================
import Jasmine from 'jasmine'
import { fileURLToPath } from 'url'
import { dirname, join } from 'path'
import Config from '../src/Config.js'
import { initTestGraphs } from '../tests/helpers/setupSPARQL.js'

const __dirname = dirname(fileURLToPath(import.meta.url))

async function runTests() {
    try {
        console.log('Initializing configuration...')
        const config = await Config.create()

        console.log('Initializing test environment...')
        await initTestGraphs(config)

        console.log('Running tests...')
        const jasmine = new Jasmine()
        const configPath = join(__dirname, '..', 'jasmine.json')

        console.log('Using config from:', configPath)
        jasmine.loadConfigFile(configPath)

        console.log('Executing specs from:', join(__dirname, '..', 'tests'))
        jasmine.execute(undefined, (failures) => {
            process.exit(failures ? 1 : 0)
        })
    } catch (error) {
        console.error('Test setup failed:', error)
        process.exit(1)
    }
}

runTests()

================
File: src/_old/config.js
================
// config.js
class Config {
  constructor() {
    this.environment = process.env.NODE_ENV || 'development';
    this.paths = {
      base: process.cwd(),
      config: './config'
    };
  }

  async load() {
    // Add configuration loading logic here
    return this;
  }
}

export const config = new Config();

================
File: src/api/cli/about.md
================
# Command line Interfaces

================
File: src/api/cli/CLIHandler.js
================
import yargs from 'yargs';
import { hideBin } from 'yargs/helpers';
import chalk from 'chalk';
import log from 'loglevel';
import { APIRegistry } from '../common/APIRegistry.js';
import BaseAPI from '../common/BaseAPI.js';

export default class CLIHandler extends BaseAPI {
    constructor(config = {}) {
        super(config);
        this.registry = new APIRegistry();
        this.setupCommands();
    }

    setupCommands() {
        this.yargs = yargs(hideBin(process.argv))
            .command('chat', 'Chat with the system', {
                prompt: {
                    alias: 'p',
                    type: 'string',
                    demandOption: true,
                    describe: 'Input prompt'
                },
                model: {
                    alias: 'm',
                    type: 'string',
                    default: 'qwen2:1.5b',
                    describe: 'Model to use'
                }
            })
            .command('store', 'Store data', {
                data: {
                    alias: 'd',
                    type: 'string',
                    demandOption: true,
                    describe: 'Data to store'
                },
                format: {
                    alias: 'f',
                    choices: ['text', 'turtle'],
                    default: 'text'
                }
            })
            .command('query', 'Query stored data', {
                query: {
                    alias: 'q',
                    type: 'string',
                    demandOption: true,
                    describe: 'Search query'
                },
                limit: {
                    alias: 'l',
                    type: 'number',
                    default: 10
                }
            })
            .command('metrics', 'Show system metrics', {
                format: {
                    choices: ['text', 'json'],
                    default: 'text'
                }
            })
            .option('color', {
                type: 'boolean',
                default: true,
                describe: 'Colorize output'
            })
            .option('verbose', {
                alias: 'v',
                type: 'boolean',
                describe: 'Run with verbose logging'
            })
            .help()
            .alias('h', 'help');
    }

    async initialize() {
        await super.initialize();
        
        // Set up logging based on verbosity
        if (this.yargs.argv.verbose) {
            log.setLevel('debug');
        }

        process.on('SIGINT', async () => {
            await this.shutdown();
            process.exit(0);
        });
    }

    async executeOperation(command, args) {
        try {
            switch (command) {
                case 'chat':
                    return this.handleChat(args);
                case 'store':
                    return this.handleStore(args);
                case 'query':
                    return this.handleQuery(args);
                case 'metrics':
                    return this.handleMetrics(args);
                default:
                    throw new Error(`Unknown command: ${command}`);
            }
        } catch (error) {
            this.logger.error('Operation failed:', error);
            this.formatOutput({
                success: false,
                error: error.message
            }, args);
        }
    }

    async handleChat({ prompt, model }) {
        const api = this.registry.get('chat');
        const response = await api.executeOperation('chat', {
            prompt,
            model
        });
        
        return this.formatOutput({
            success: true,
            data: response
        });
    }

    async handleStore({ data, format }) {
        const api = this.registry.get('storage');
        const stored = await api.storeInteraction({
            content: data,
            format,
            timestamp: Date.now()
        });
        
        return this.formatOutput({
            success: true,
            data: stored
        });
    }

    async handleQuery({ query, limit }) {
        const api = this.registry.get('storage');
        const results = await api.retrieveInteractions({
            text: query,
            limit
        });
        
        return this.formatOutput({
            success: true,
            data: results
        });
    }

    async handleMetrics({ format }) {
        const metrics = await this.getMetrics();
        return this.formatOutput({
            success: true,
            data: metrics
        }, { format });
    }

    formatOutput(result, { format = 'text', color = true } = {}) {
        const c = color ? chalk : (text => text);
        
        if (format === 'json') {
            return console.log(JSON.stringify(result, null, 2));
        }

        if (!result.success) {
            return console.error(c.red(`Error: ${result.error}`));
        }

        if (Array.isArray(result.data)) {
            result.data.forEach(item => {
                console.log(c.cyan('---'));
                Object.entries(item).forEach(([key, value]) => {
                    console.log(c.yellow(`${key}:`), value);
                });
            });
            return;
        }

        if (typeof result.data === 'object') {
            Object.entries(result.data).forEach(([key, value]) => {
                console.log(c.yellow(`${key}:`), value);
            });
            return;
        }

        console.log(result.data);
    }

    async run() {
        await this.initialize();
        const argv = await this.yargs.argv;
        const command = argv._[0];

        if (!command) {
            this.yargs.showHelp();
            process.exit(1);
        }

        await this.executeOperation(command, argv);
    }
}

================
File: src/api/common/APIRegistry.js
================
import log from 'loglevel';
import BaseAPI from './BaseAPI.js';

/**
 * Registry for managing API instances
 * @singleton
 */
export default class APIRegistry {
    constructor() {
        if (APIRegistry.instance) {
            return APIRegistry.instance;
        }
        APIRegistry.instance = this;
        
        this.apis = new Map();
        this.logger = log.getLogger('APIRegistry');
        this.metrics = new Map();
    }

    /**
     * Register a new API implementation
     * @param {string} name - Unique identifier for the API
     * @param {typeof BaseAPI} apiClass - API implementation class
     * @param {Object} config - Configuration for the API
     */
    async register(name, apiClass, config = {}) {
        if (this.apis.has(name)) {
            throw new Error(`API ${name} already registered`);
        }

        if (!(apiClass.prototype instanceof BaseAPI)) {
            throw new Error('API must extend BaseAPI');
        }

        try {
            const api = new apiClass(config);
            await api.initialize();
            
            // Set up metric collection
            api.on('metric', (metric) => {
                this.metrics.set(`${name}.${metric.name}`, {
                    value: metric.value,
                    timestamp: metric.timestamp
                });
            });

            this.apis.set(name, api);
            this.logger.info(`Registered API: ${name}`);
            
            return api;
        } catch (error) {
            this.logger.error(`Failed to register API ${name}:`, error);
            throw error;
        }
    }

    /**
     * Get an API instance by name
     * @param {string} name - API identifier
     * @returns {BaseAPI} API instance
     */
    get(name) {
        const api = this.apis.get(name);
        if (!api) {
            throw new Error(`API ${name} not found`);
        }
        return api;
    }

    /**
     * Remove an API instance
     * @param {string} name - API identifier 
     */
    async unregister(name) {
        const api = this.apis.get(name);
        if (api) {
            await api.shutdown();
            this.apis.delete(name);
            this.logger.info(`Unregistered API: ${name}`);
        }
    }

    /**
     * Get all registered API instances
     * @returns {Map<string, BaseAPI>}
     */
    getAll() {
        return new Map(this.apis);
    }

    /**
     * Get collected metrics
     * @returns {Object} Metrics data
     */
    getMetrics() {
        return {
            timestamp: Date.now(),
            apiCount: this.apis.size,
            apis: Object.fromEntries(
                Array.from(this.apis.entries()).map(([name, api]) => [
                    name,
                    {
                        status: api.initialized ? 'active' : 'inactive',
                        metrics: Object.fromEntries(
                            Array.from(this.metrics.entries())
                                .filter(([key]) => key.startsWith(name))
                                .map(([key, value]) => [
                                    key.split('.')[1],
                                    value
                                ])
                        )
                    }
                ])
            )
        };
    }

    /**
     * Shutdown all registered APIs
     */
    async shutdownAll() {
        const shutdowns = Array.from(this.apis.entries()).map(
            async ([name, api]) => {
                try {
                    await this.unregister(name);
                } catch (error) {
                    this.logger.error(`Error shutting down ${name}:`, error);
                }
            }
        );
        await Promise.all(shutdowns);
    }
}

================
File: src/api/common/BaseAPI.js
================
import log from 'loglevel';
import { EventEmitter } from 'events';

/**
 * Abstract base class for all Semem API implementations
 * @abstract
 */
export default class BaseAPI extends EventEmitter {
    constructor(config = {}) {
        super();
        this.config = config;
        this.logger = log.getLogger(this.constructor.name);
        this.initialized = false;
    }

    /**
     * Initialize the API instance
     * @abstract
     */
    async initialize() {
        if (this.initialized) {
            throw new Error('API already initialized');
        }
        this.initialized = true;
    }

    /**
     * Shutdown the API instance
     * @abstract
     */
    async shutdown() {
        if (!this.initialized) {
            throw new Error('API not initialized');
        }
        this.initialized = false;
    }

    /**
     * Execute a memory operation
     * @abstract
     * @param {string} operation - Operation name
     * @param {Object} params - Operation parameters
     */
    async executeOperation(operation, params) {
        throw new Error('executeOperation must be implemented');
    }

    /**
     * Store an interaction
     * @abstract
     * @param {Object} interaction - Interaction data
     */
    async storeInteraction(interaction) {
        throw new Error('storeInteraction must be implemented');
    }

    /**
     * Retrieve interactions
     * @abstract
     * @param {Object} query - Query parameters
     */
    async retrieveInteractions(query) {
        throw new Error('retrieveInteractions must be implemented');
    }

    /**
     * Get system metrics
     * @returns {Object} System metrics
     */
    async getMetrics() {
        return {
            timestamp: Date.now(),
            status: this.initialized ? 'active' : 'inactive',
            memoryUsage: process.memoryUsage(),
            uptime: process.uptime()
        };
    }

    /**
     * Validate operation parameters
     * @protected
     */
    _validateParams(params, schema) {
        // Basic validation - extend as needed
        if (!params || typeof params !== 'object') {
            throw new Error('Invalid parameters');
        }
    }
    
    /**
     * Emit a metric event
     * @protected
     */
    _emitMetric(name, value) {
        this.emit('metric', { name, value, timestamp: Date.now() });
    }
}

================
File: src/api/common/CustomValidators.js
================
/**
 * Manages custom validation functions for RDF data validation
 */
export default class CustomValidators {
    constructor() {
        this.validators = new Map();
        this.registerBuiltins();
    }

    registerBuiltins() {
        // Basic type validators
        this.register('uri', {
            validate: (value) => {
                try {
                    new URL(value);
                    return { valid: true };
                } catch {
                    return { 
                        valid: false, 
                        message: 'Invalid URI format' 
                    };
                }
            }
        });

        this.register('language', {
            validate: (value) => {
                const langPattern = /^[a-zA-Z]{2,3}(-[a-zA-Z]{2,4})?$/;
                return {
                    valid: langPattern.test(value),
                    message: langPattern.test(value) ? null : 'Invalid language tag'
                };
            }
        });

        // Semantic validators
        this.register('concept', {
            validate: (value, options = {}) => {
                if (!value.startsWith(options.namespace || 'http://')) {
                    return {
                        valid: false,
                        message: 'Concept URI must use correct namespace'
                    };
                }
                return { valid: true };
            }
        });

        // Temporal validators
        this.register('timerange', {
            validate: (value, options = {}) => {
                const { start, end } = value;
                const startDate = new Date(start);
                const endDate = new Date(end);

                if (isNaN(startDate.getTime()) || isNaN(endDate.getTime())) {
                    return {
                        valid: false,
                        message: 'Invalid date format'
                    };
                }

                if (startDate > endDate) {
                    return {
                        valid: false,
                        message: 'Start date must be before end date'
                    };
                }

                return { valid: true };
            }
        });
    }

    /**
     * Register a new validator
     * @param {string} name - Validator name
     * @param {Object} validator - Validator definition
     */
    register(name, validator) {
        if (typeof validator.validate !== 'function') {
            throw new Error('Validator must have a validate function');
        }

        this.validators.set(name, {
            ...validator,
            async: validator.validate.constructor.name === 'AsyncFunction'
        });
    }

    /**
     * Register multiple validators
     * @param {Object} validators - Map of validator names to definitions
     */
    registerBatch(validators) {
        for (const [name, validator] of Object.entries(validators)) {
            this.register(name, validator);
        }
    }

    /**
     * Get a registered validator
     * @param {string} name - Validator name
     */
    get(name) {
        const validator = this.validators.get(name);
        if (!validator) {
            throw new Error(`Validator not found: ${name}`);
        }
        return validator;
    }

    /**
     * Execute a validator
     * @param {string} name - Validator name
     * @param {*} value - Value to validate
     * @param {Object} options - Validator options
     */
    async execute(name, value, options = {}) {
        const validator = this.get(name);
        try {
            const result = await validator.validate(value, options);
            return {
                valid: result.valid,
                message: result.message,
                validator: name,
                value
            };
        } catch (error) {
            return {
                valid: false,
                message: error.message,
                validator: name,
                value,
                error
            };
        }
    }

    /**
     * Create a composite validator from multiple validators
     * @param {Array} validators - Array of validator names or definitions
     */
    compose(validators) {
        return {
            validate: async (value, options = {}) => {
                const results = [];
                for (const validator of validators) {
                    const name = typeof validator === 'string' ? 
                        validator : validator.name;
                    const validatorOptions = typeof validator === 'string' ? 
                        options : { ...options, ...validator.options };

                    const result = await this.execute(name, value, validatorOptions);
                    results.push(result);

                    if (!result.valid) break;
                }

                const valid = results.every(r => r.valid);
                return {
                    valid,
                    results,
                    message: valid ? null : results.find(r => !r.valid)?.message
                };
            }
        };
    }

    /**
     * Create a conditional validator
     * @param {Function} condition - Condition function
     * @param {string|Object} validator - Validator to apply if condition is true
     */
    conditional(condition, validator) {
        return {
            validate: async (value, options = {}) => {
                if (!await condition(value, options)) {
                    return { valid: true };
                }

                const name = typeof validator === 'string' ? 
                    validator : validator.name;
                const validatorOptions = typeof validator === 'string' ? 
                    options : { ...options, ...validator.options };

                return this.execute(name, value, validatorOptions);
            }
        };
    }

    /**
     * Create a recursive validator for nested structures
     * @param {string|Object} validator - Base validator
     * @param {Object} options - Recursion options
     */
    recursive(validator, options = {}) {
        return {
            validate: async (value, validatorOptions = {}) => {
                const results = [];
                const maxDepth = options.maxDepth || 10;

                const validateNode = async (node, depth = 0) => {
                    if (depth > maxDepth) {
                        throw new Error('Maximum recursion depth exceeded');
                    }

                    // Validate current node
                    const result = await this.execute(
                        typeof validator === 'string' ? validator : validator.name,
                        node,
                        typeof validator === 'string' ? 
                            validatorOptions : 
                            { ...validatorOptions, ...validator.options }
                    );
                    results.push(result);

                    // Recurse into children if any
                    if (node && typeof node === 'object') {
                        for (const child of Object.values(node)) {
                            if (child && typeof child === 'object') {
                                await validateNode(child, depth + 1);
                            }
                        }
                    }
                };

                await validateNode(value);

                const valid = results.every(r => r.valid);
                return {
                    valid,
                    results,
                    message: valid ? null : results.find(r => !r.valid)?.message
                };
            }
        };
    }
}

================
File: src/api/common/RDFParser.js
================
import { APIRegistry } from './APIRegistry.js';
import { SPARQLHelpers } from '../../utils/SPARQLHelpers.js';

export default class RDFParser {
    constructor(config = {}) {
        this.registry = new APIRegistry();
        this.prefixes = {
            mcp: 'http://purl.org/stuff/mcp/',
            rdf: 'http://www.w3.org/1999/02/22-rdf-syntax-ns#',
            rdfs: 'http://www.w3.org/2000/01/rdf-schema#',
            xsd: 'http://www.w3.org/2001/XMLSchema#',
            qb: 'http://purl.org/linked-data/cube#',
            skos: 'http://www.w3.org/2004/02/skos/core#',
            ...config.prefixes
        };
    }

    parse(input) {
        const lines = input.trim().split('\n');
        const commands = [];
        let currentCommand = '';

        for (const line of lines) {
            const trimmed = line.trim();
            if (!trimmed || trimmed.startsWith('#')) continue;

            if (trimmed.endsWith(';')) {
                currentCommand += ' ' + trimmed.slice(0, -1);
                commands.push(currentCommand.trim());
                currentCommand = '';
            } else {
                currentCommand += ' ' + trimmed;
            }
        }

        if (currentCommand) {
            commands.push(currentCommand.trim());
        }

        return commands.map(cmd => this.parseCommand(cmd));
    }

    parseCommand(command) {
        const tokens = command.split(' ');
        const action = tokens[0].toLowerCase();

        switch (action) {
            case 'store':
                return this.parseStoreCommand(tokens.slice(1));
            case 'query':
                return this.parseQueryCommand(tokens.slice(1));
            case 'update':
                return this.parseUpdateCommand(tokens.slice(1));
            case 'define':
                return this.parseDefineCommand(tokens.slice(1));
            default:
                throw new Error(`Unknown command: ${action}`);
        }
    }

    parseStoreCommand(tokens) {
        const options = this.parseOptions(tokens);
        const data = options.data || tokens.join(' ');
        
        return {
            type: 'store',
            data: this.expandPrefixes(data),
            format: options.format || 'turtle',
            graph: options.graph
        };
    }

    parseQueryCommand(tokens) {
        const options = this.parseOptions(tokens);
        let query = options.query || tokens.join(' ');

        // Handle simplified query syntax
        if (!query.toLowerCase().startsWith('select') && 
            !query.toLowerCase().startsWith('ask') &&
            !query.toLowerCase().startsWith('construct')) {
            query = this.buildSimpleQuery(query, options);
        }

        return {
            type: 'query',
            query: this.expandPrefixes(query),
            format: options.format || 'json'
        };
    }

    parseUpdateCommand(tokens) {
        const options = this.parseOptions(tokens);
        let update = options.update || tokens.join(' ');

        // Handle simplified update syntax
        if (!update.toLowerCase().startsWith('insert') &&
            !update.toLowerCase().startsWith('delete')) {
            update = this.buildSimpleUpdate(update, options);
        }

        return {
            type: 'update',
            update: this.expandPrefixes(update),
            graph: options.graph
        };
    }

    parseDefineCommand(tokens) {
        const name = tokens[0];
        const value = tokens.slice(1).join(' ');

        if (name && value) {
            this.prefixes[name] = value.replace(/[<>]/g, '');
        }

        return {
            type: 'define',
            prefix: name,
            uri: value
        };
    }

    parseOptions(tokens) {
        const options = {};
        let i = 0;

        while (i < tokens.length) {
            if (tokens[i].startsWith('--')) {
                const key = tokens[i].slice(2);
                i++;
                if (i < tokens.length && !tokens[i].startsWith('--')) {
                    options[key] = tokens[i];
                    i++;
                } else {
                    options[key] = true;
                }
            } else {
                i++;
            }
        }

        return options;
    }

    buildSimpleQuery(text, options) {
        const vars = options.vars?.split(',') || ['s', 'p', 'o'];
        const limit = options.limit || 10;
        const offset = options.offset || 0;

        return `
            SELECT ${vars.map(v => `?${v}`).join(' ')}
            ${options.graph ? `FROM <${options.graph}>` : ''}
            WHERE {
                ${text.includes(' ') ? text : `?s ?p ?o . FILTER(regex(str(?o), "${text}", "i"))`}
            }
            LIMIT ${limit}
            OFFSET ${offset}
        `;
    }

    buildSimpleUpdate(text, options) {
        const [subject, predicate, object] = text.split(' ');
        const graph = options.graph ? `GRAPH <${options.graph}>` : '';

        return `
            INSERT DATA {
                ${graph} {
                    ${this.expandPrefixes(`${subject} ${predicate} ${object}`)}
                }
            }
        `;
    }

    expandPrefixes(text) {
        let expanded = text;
        for (const [prefix, uri] of Object.entries(this.prefixes)) {
            const regex = new RegExp(`${prefix}:([\\w-]+)`, 'g');
            expanded = expanded.replace(regex, `<${uri}$1>`);
        }
        return expanded;
    }

    async execute(commands) {
        const results = [];
        const api = this.registry.get('storage');

        for (const command of commands) {
            try {
                switch (command.type) {
                    case 'store':
                        results.push(await api.storeInteraction({
                            content: command.data,
                            format: command.format,
                            graph: command.graph
                        }));
                        break;

                    case 'query':
                        results.push(await api.executeOperation('query', {
                            sparql: command.query,
                            format: command.format
                        }));
                        break;

                    case 'update':
                        results.push(await api.executeOperation('update', {
                            sparql: command.update,
                            graph: command.graph
                        }));
                        break;

                    case 'define':
                        results.push({
                            success: true,
                            prefix: command.prefix,
                            uri: command.uri
                        });
                        break;
                }
            } catch (error) {
                results.push({
                    success: false,
                    error: error.message,
                    command
                });
            }
        }

        return results;
    }
}

================
File: src/api/common/RDFValidator.js
================
import { SPARQLHelpers } from '../../utils/SPARQLHelpers.js';

export default class RDFValidator {
    constructor(config = {}) {
        this.shapes = new Map();
        this.constraints = new Map();
        this.loadShapes(config.shapes || {});
    }

    loadShapes(shapes) {
        for (const [name, shape] of Object.entries(shapes)) {
            this.registerShape(name, shape);
        }
    }

    registerShape(name, shape) {
        this.shapes.set(name, {
            ...shape,
            constraints: shape.constraints?.map(c => this.parseConstraint(c)) || []
        });
    }

    parseConstraint(constraint) {
        const parsed = {
            path: constraint.path,
            type: constraint.type,
            message: constraint.message
        };

        switch (constraint.type) {
            case 'datatype':
                parsed.datatype = constraint.datatype;
                break;
            case 'pattern':
                parsed.pattern = new RegExp(constraint.pattern);
                break;
            case 'range':
                parsed.min = constraint.min;
                parsed.max = constraint.max;
                break;
            case 'cardinality':
                parsed.min = constraint.min;
                parsed.max = constraint.max;
                break;
            case 'class':
                parsed.class = constraint.class;
                break;
            case 'in':
                parsed.values = new Set(constraint.values);
                break;
        }

        return parsed;
    }

    generateSHACL(shape) {
        const prefixes = {
            sh: 'http://www.w3.org/ns/shacl#',
            xsd: 'http://www.w3.org/2001/XMLSchema#'
        };

        let shacl = '';
        for (const prefix in prefixes) {
            shacl += `@prefix ${prefix}: <${prefixes[prefix]}> .\n`;
        }

        shacl += `\n${shape.targetClass} a sh:NodeShape ;\n`;

        for (const constraint of shape.constraints) {
            shacl += this.constraintToSHACL(constraint);
        }

        return shacl;
    }

    constraintToSHACL(constraint) {
        let shacl = `  sh:property [\n`;
        shacl += `    sh:path ${constraint.path} ;\n`;

        switch (constraint.type) {
            case 'datatype':
                shacl += `    sh:datatype ${constraint.datatype} ;\n`;
                break;
            case 'pattern':
                shacl += `    sh:pattern "${constraint.pattern.source}" ;\n`;
                break;
            case 'range':
                if (constraint.min !== undefined) {
                    shacl += `    sh:minInclusive ${constraint.min} ;\n`;
                }
                if (constraint.max !== undefined) {
                    shacl += `    sh:maxInclusive ${constraint.max} ;\n`;
                }
                break;
            case 'cardinality':
                if (constraint.min !== undefined) {
                    shacl += `    sh:minCount ${constraint.min} ;\n`;
                }
                if (constraint.max !== undefined) {
                    shacl += `    sh:maxCount ${constraint.max} ;\n`;
                }
                break;
            case 'class':
                shacl += `    sh:class ${constraint.class} ;\n`;
                break;
            case 'in':
                shacl += `    sh:in (${Array.from(constraint.values).join(' ')}) ;\n`;
                break;
        }

        if (constraint.message) {
            shacl += `    sh:message "${constraint.message}" ;\n`;
        }

        shacl += `  ] ;\n`;
        return shacl;
    }

    async validate(data, shapeName) {
        const shape = this.shapes.get(shapeName);
        if (!shape) {
            throw new Error(`Shape not found: ${shapeName}`);
        }

        const validationResults = {
            valid: true,
            errors: []
        };

        for (const constraint of shape.constraints) {
            try {
                const result = await this.validateConstraint(data, constraint);
                if (!result.valid) {
                    validationResults.valid = false;
                    validationResults.errors.push(result);
                }
            } catch (error) {
                validationResults.valid = false;
                validationResults.errors.push({
                    path: constraint.path,
                    message: error.message
                });
            }
        }

        return validationResults;
    }

    async validateConstraint(data, constraint) {
        const value = this.getValue(data, constraint.path);

        switch (constraint.type) {
            case 'datatype':
                return this.validateDatatype(value, constraint);
            case 'pattern':
                return this.validatePattern(value, constraint);
            case 'range':
                return this.validateRange(value, constraint);
            case 'cardinality':
                return this.validateCardinality(value, constraint);
            case 'class':
                return this.validateClass(value, constraint);
            case 'in':
                return this.validateIn(value, constraint);
            default:
                throw new Error(`Unknown constraint type: ${constraint.type}`);
        }
    }

    getValue(data, path) {
        const parts = path.split('.');
        let value = data;
        for (const part of parts) {
            value = value?.[part];
            if (value === undefined) break;
        }
        return value;
    }

    validateDatatype(value, constraint) {
        if (value === undefined) return { valid: true };

        const valid = this.checkDatatype(value, constraint.datatype);
        return {
            valid,
            path: constraint.path,
            message: valid ? null : 
                constraint.message || `Invalid datatype: expected ${constraint.datatype}`
        };
    }

    validatePattern(value, constraint) {
        if (value === undefined) return { valid: true };

        const valid = constraint.pattern.test(String(value));
        return {
            valid,
            path: constraint.path,
            message: valid ? null :
                constraint.message || `Value does not match pattern: ${constraint.pattern}`
        };
    }

    validateRange(value, constraint) {
        if (value === undefined) return { valid: true };

        const num = Number(value);
        const valid = !isNaN(num) &&
            (constraint.min === undefined || num >= constraint.min) &&
            (constraint.max === undefined || num <= constraint.max);

        return {
            valid,
            path: constraint.path,
            message: valid ? null :
                constraint.message || `Value out of range: ${constraint.min} - ${constraint.max}`
        };
    }

    validateCardinality(value, constraint) {
        const count = Array.isArray(value) ? value.length : (value === undefined ? 0 : 1);
        const valid = (constraint.min === undefined || count >= constraint.min) &&
                     (constraint.max === undefined || count <= constraint.max);

        return {
            valid,
            path: constraint.path,
            message: valid ? null :
                constraint.message || `Cardinality violation: expected ${constraint.min}-${constraint.max}`
        };
    }

    validateClass(value, constraint) {
        if (value === undefined) return { valid: true };
        
        const valid = value.type === constraint.class;
        return {
            valid,
            path: constraint.path,
            message: valid ? null :
                constraint.message || `Invalid class: expected ${constraint.class}`
        };
    }

    validateIn(value, constraint) {
        if (value === undefined) return { valid: true };

        const valid = constraint.values.has(value);
        return {
            valid,
            path: constraint.path,
            message: valid ? null :
                constraint.message || `Value not in allowed set: ${Array.from(constraint.values).join(', ')}`
        };
    }

    checkDatatype(value, type) {
        switch (type) {
            case 'xsd:string':
                return typeof value === 'string';
            case 'xsd:integer':
                return Number.isInteger(Number(value));
            case 'xsd:decimal':
            case 'xsd:float':
            case 'xsd:double':
                return !isNaN(Number(value));
            case 'xsd:boolean':
                return typeof value === 'boolean';
            case 'xsd:date':
            case 'xsd:dateTime':
                return !isNaN(Date.parse(value));
            default:
                return true;
        }
    }
}

================
File: src/api/common/types.d.ts.ts
================
import { EventEmitter } from 'events';

export interface APIConfig {
    storage?: StorageConfig;
    models?: ModelConfig;
    metrics?: MetricsConfig;
}

export interface StorageConfig {
    type: 'memory' | 'json' | 'sparql';
    options: {
        path?: string;
        endpoint?: string;
        graphName?: string;
    };
}

export interface ModelConfig {
    chat: {
        provider: 'ollama' | 'openai';
        model: string;
        options?: Record<string, any>;
    };
    embedding: {
        provider: 'ollama' | 'openai';
        model: string;
        options?: Record<string, any>;
    };
}

export interface MetricsConfig {
    enabled: boolean;
    interval?: number;
    storageEndpoint?: string;
}

export interface Interaction {
    id: string;
    prompt: string;
    output: string;
    embedding: number[];
    timestamp: number;
    accessCount: number;
    concepts: string[];
    decayFactor: number;
}

export interface Query {
    text?: string;
    concepts?: string[];
    similarity?: number;
    limit?: number;
    offset?: number;
}

export interface MetricEvent {
    name: string;
    value: number | string | boolean;
    timestamp: number;
    labels?: Record<string, string>;
}

export interface APIMetrics {
    timestamp: number;
    status: 'active' | 'inactive';
    memoryUsage: NodeJS.MemoryUsage;
    uptime: number;
}

export declare class BaseAPI extends EventEmitter {
    protected config: APIConfig;
    protected logger: any;
    protected initialized: boolean;

    constructor(config?: APIConfig);
    
    initialize(): Promise<void>;
    shutdown(): Promise<void>;
    
    executeOperation(operation: string, params: Record<string, any>): Promise<any>;
    storeInteraction(interaction: Interaction): Promise<void>;
    retrieveInteractions(query: Query): Promise<Interaction[]>;
    getMetrics(): Promise<APIMetrics>;

    protected _validateParams(params: unknown, schema: unknown): void;
    protected _emitMetric(name: string, value: MetricEvent['value']): void;
}

export declare class APIRegistry {
    private static instance: APIRegistry;
    private apis: Map<string, BaseAPI>;
    private metrics: Map<string, MetricEvent>;
    
    register(name: string, apiClass: typeof BaseAPI, config?: APIConfig): Promise<BaseAPI>;
    get(name: string): BaseAPI;
    unregister(name: string): Promise<void>;
    getAll(): Map<string, BaseAPI>;
    getMetrics(): Record<string, any>;
    shutdownAll(): Promise<void>;
}

// CLI Types
export interface CommandOptions {
    operation: string;
    params: Record<string, any>;
    format?: 'text' | 'json';
    color?: boolean;
}

// HTTP Types
export interface APIResponse<T = any> {
    success: boolean;
    data?: T;
    error?: string;
    metadata?: {
        timestamp: number;
        version: string;
    };
}

// REPL Types
export interface REPLContext {
    api: BaseAPI;
    history: string[];
    mode: 'chat' | 'rdf';
}

// Feature Set Types
export interface SelfieMetrics {
    storage: {
        size: number;
        operations: number;
        latency: number;
    };
    performance: {
        memory: NodeJS.MemoryUsage;
        cpu: number;
        uptime: number;
    };
    errors: Array<{
        type: string;
        count: number;
        lastOccurred: number;
    }>;
}

================
File: src/api/features/ActiveHandler.js
================
import BaseAPI from '../common/BaseAPI.js';
import { APIRegistry } from '../common/APIRegistry.js';
import { logger } from '../../Utils.js';

export default class ActiveHandler extends BaseAPI {
    constructor(config = {}) {
        super(config);
        this.registry = new APIRegistry();
        this.contextWindow = config.contextWindow || 3;
        this.similarityThreshold = config.similarityThreshold || 40;
    }

    async executeOperation(operation, params) {
        switch (operation) {
            case 'interact':
                return this.handleInteraction(params);
            case 'search':
                return this.handleSearch(params);
            case 'analyze':
                return this.handleAnalysis(params);
            default:
                throw new Error(`Unknown operation: ${operation}`);
        }
    }

    async handleInteraction({ prompt, context = [], options = {} }) {
        try {
            const memoryManager = this.registry.get('memory');
            const passive = this.registry.get('passive');

            // Get relevant past interactions
            const retrievals = await memoryManager.retrieveRelevantInteractions(
                prompt,
                this.similarityThreshold
            );

            // Generate response using chat
            const response = await passive.executeOperation('chat', {
                prompt,
                context: this._buildContext(context, retrievals),
                ...options
            });

            // Store interaction
            const embedding = await memoryManager.generateEmbedding(
                `${prompt} ${response}`
            );
            const concepts = await memoryManager.extractConcepts(
                `${prompt} ${response}`
            );

            await memoryManager.addInteraction(prompt, response, embedding, concepts);

            this._emitMetric('interaction.count', 1);
            return { response, concepts, retrievals };
        } catch (error) {
            this._emitMetric('interaction.errors', 1);
            throw error;
        }
    }

    async handleSearch({ query, type = 'semantic', limit = 10 }) {
        try {
            const memoryManager = this.registry.get('memory');
            const passive = this.registry.get('passive');

            let results;
            if (type === 'semantic') {
                const embedding = await memoryManager.generateEmbedding(query);
                results = await memoryManager.retrieveRelevantInteractions(
                    query,
                    this.similarityThreshold,
                    0,
                    limit
                );
            } else {
                results = await passive.executeOperation('query', {
                    sparql: this._buildSearchQuery(query, limit)
                });
            }

            this._emitMetric('search.count', 1);
            return results;
        } catch (error) {
            this._emitMetric('search.errors', 1);
            throw error;
        }
    }

    async handleAnalysis({ content, type = 'concept' }) {
        try {
            const memoryManager = this.registry.get('memory');

            let results;
            switch (type) {
                case 'concept':
                    results = await memoryManager.extractConcepts(content);
                    break;
                case 'embedding':
                    results = await memoryManager.generateEmbedding(content);
                    break;
                default:
                    throw new Error(`Unknown analysis type: ${type}`);
            }

            this._emitMetric('analysis.count', 1);
            return results;
        } catch (error) {
            this._emitMetric('analysis.errors', 1);
            throw error;
        }
    }

    _buildContext(context, retrievals) {
        return {
            previous: context.slice(-this.contextWindow),
            relevant: retrievals
                .slice(0, this.contextWindow)
                .map(r => ({
                    prompt: r.interaction.prompt,
                    response: r.interaction.output
                }))
        };
    }

    _buildSearchQuery(query, limit) {
        return `
            PREFIX mcp: <http://purl.org/stuff/mcp/>
            SELECT ?interaction ?prompt ?output ?timestamp
            WHERE {
                ?interaction a mcp:Interaction ;
                    mcp:prompt ?prompt ;
                    mcp:output ?output ;
                    mcp:timestamp ?timestamp .
                FILTER(CONTAINS(LCASE(?prompt), LCASE("${query}")) ||
                       CONTAINS(LCASE(?output), LCASE("${query}")))
            }
            ORDER BY DESC(?timestamp)
            LIMIT ${limit}
        `;
    }

    async getMetrics() {
        const baseMetrics = await super.getMetrics();
        return {
            ...baseMetrics,
            operations: {
                interaction: await this._getOperationMetrics('interaction'),
                search: await this._getOperationMetrics('search'),
                analysis: await this._getOperationMetrics('analysis')
            }
        };
    }

    async _getOperationMetrics(operation) {
        return {
            count: await this._getMetricValue(`${operation}.count`),
            errors: await this._getMetricValue(`${operation}.errors`),
            latency: await this._getMetricValue(`${operation}.latency`)
        };
    }
}

================
File: src/api/features/PassiveHandler.js
================
import BaseAPI from '../common/BaseAPI.js';
import { APIRegistry } from '../common/APIRegistry.js';
import { logger } from '../../Utils.js';

export default class PassiveHandler extends BaseAPI {
    constructor(config = {}) {
        super(config);
        this.registry = new APIRegistry();
        this.llmProvider = config.llmProvider;
        this.sparqlEndpoint = config.sparqlEndpoint;
    }

    async executeOperation(operation, params) {
        switch (operation) {
            case 'chat':
                return this.handleChat(params);
            case 'query':
                return this.handleQuery(params);
            case 'store':
                return this.handleStore(params);
            default:
                throw new Error(`Unknown operation: ${operation}`);
        }
    }

    async handleChat({ prompt, model = 'qwen2:1.5b', options = {} }) {
        try {
            const response = await this.llmProvider.generateChat(model, [{
                role: 'user',
                content: prompt
            }], options);

            this._emitMetric('chat.requests', 1);
            return response;
        } catch (error) {
            this._emitMetric('chat.errors', 1);
            throw error;
        }
    }

    async handleQuery({ sparql, format = 'json' }) {
        try {
            const storage = this.registry.get('storage');
            const results = await storage.executeOperation('query', {
                sparql,
                format
            });

            this._emitMetric('query.requests', 1);
            return results;
        } catch (error) {
            this._emitMetric('query.errors', 1);
            throw error;
        }
    }

    async handleStore({ content, format = 'text' }) {
        try {
            const storage = this.registry.get('storage');
            await storage.storeInteraction({
                content,
                format,
                timestamp: Date.now()
            });

            this._emitMetric('store.requests', 1);
            return { success: true };
        } catch (error) {
            this._emitMetric('store.errors', 1);
            throw error;
        }
    }

    async getMetrics() {
        const baseMetrics = await super.getMetrics();
        return {
            ...baseMetrics,
            operations: {
                chat: await this._getOperationMetrics('chat'),
                query: await this._getOperationMetrics('query'),
                store: await this._getOperationMetrics('store')
            }
        };
    }

    async _getOperationMetrics(operation) {
        return {
            requests: await this._getMetricValue(`${operation}.requests`),
            errors: await this._getMetricValue(`${operation}.errors`),
            latency: await this._getMetricValue(`${operation}.latency`)
        };
    }
}

================
File: src/api/features/SelfieHandler.js
================
import { EventEmitter } from 'events';
import log from 'loglevel';
import { APIRegistry } from '../common/APIRegistry.js';
import BaseAPI from '../common/BaseAPI.js';

export default class SelfieHandler extends BaseAPI {
    constructor(config = {}) {
        super(config);
        this.registry = new APIRegistry();
        this.metrics = new Map();
        this.errors = new Map();
        this.interval = config.interval || 60000;
        this.eventBus = new EventEmitter();
        this.setupMetricCollectors();
    }

    setupMetricCollectors() {
        this.collectors = {
            storage: {
                collect: async () => {
                    const api = this.registry.get('storage');
                    const metrics = await api.getMetrics();
                    return {
                        size: metrics.size || 0,
                        operations: metrics.operations || 0,
                        latency: metrics.latency || 0
                    };
                },
                labels: ['size', 'operations', 'latency']
            },
            performance: {
                collect: () => ({
                    memory: process.memoryUsage(),
                    cpu: process.cpuUsage(),
                    uptime: process.uptime()
                }),
                labels: ['memory', 'cpu', 'uptime']
            },
            api: {
                collect: async () => {
                    const apis = this.registry.getAll();
                    const metrics = {};
                    for (const [name, api] of apis) {
                        metrics[name] = await api.getMetrics();
                    }
                    return metrics;
                },
                labels: ['status', 'requests', 'errors']
            }
        };
    }

    async initialize() {
        await super.initialize();

        // Start metric collection
        this.collectionTimer = setInterval(
            () => this.collectMetrics(),
            this.interval
        );

        // Error event listeners
        process.on('uncaughtException', (error) => {
            this.trackError('uncaughtException', error);
        });

        process.on('unhandledRejection', (error) => {
            this.trackError('unhandledRejection', error);
        });

        // Set up OpenTelemetry if configured
        if (this.config.openTelemetry) {
            await this.setupOpenTelemetry();
        }

        this.logger.info('SelfieHandler initialized');
    }

    async setupOpenTelemetry() {
        // Basic OpenTelemetry setup - extend as needed
        const { trace, metrics } = await import('@opentelemetry/api');
        const { Resource } = await import('@opentelemetry/resources');
        const { SemanticResourceAttributes } = await import('@opentelemetry/semantic-conventions');

        const resource = new Resource({
            [SemanticResourceAttributes.SERVICE_NAME]: 'semem'
        });

        // Set up metrics export if configured
        if (this.config.openTelemetry.metrics) {
            const meter = metrics.getMeter('semem-metrics');
            this.setupMetricInstruments(meter);
        }
    }

    setupMetricInstruments(meter) {
        this.instruments = {
            memoryUsage: meter.createHistogram('memory_usage', {
                description: 'Memory usage statistics'
            }),
            apiLatency: meter.createHistogram('api_latency', {
                description: 'API request latency'
            }),
            storageOperations: meter.createCounter('storage_operations', {
                description: 'Storage operation count'
            })
        };
    }

    async collectMetrics() {
        try {
            for (const [name, collector] of Object.entries(this.collectors)) {
                const metrics = await collector.collect();
                this.metrics.set(name, {
                    timestamp: Date.now(),
                    values: metrics
                });

                // Emit metric events
                this.eventBus.emit('metrics', {
                    name,
                    metrics,
                    timestamp: Date.now()
                });

                // Update OpenTelemetry if configured
                if (this.instruments) {
                    this.updateOpenTelemetryMetrics(name, metrics);
                }
            }

            // Store metrics if configured
            if (this.config.storageEndpoint) {
                await this.storeMetrics();
            }
        } catch (error) {
            this.logger.error('Error collecting metrics:', error);
            this.trackError('metricCollection', error);
        }
    }

    updateOpenTelemetryMetrics(name, metrics) {
        switch (name) {
            case 'performance':
                this.instruments.memoryUsage.record(
                    metrics.memory.heapUsed,
                    { type: 'heap_used' }
                );
                break;
            case 'api':
                Object.entries(metrics).forEach(([api, apiMetrics]) => {
                    this.instruments.apiLatency.record(
                        apiMetrics.latency || 0,
                        { api }
                    );
                });
                break;
            case 'storage':
                this.instruments.storageOperations.add(
                    metrics.operations,
                    { type: 'total' }
                );
                break;
        }
    }

    async storeMetrics() {
        try {
            const metricsData = this.formatMetricsForStorage();
            const response = await fetch(this.config.storageEndpoint, {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json'
                },
                body: JSON.stringify(metricsData)
            });

            if (!response.ok) {
                throw new Error(`Failed to store metrics: ${response.status}`);
            }
        } catch (error) {
            this.logger.error('Error storing metrics:', error);
            this.trackError('metricStorage', error);
        }
    }

    formatMetricsForStorage() {
        return {
            timestamp: Date.now(),
            metrics: Object.fromEntries(this.metrics),
            errors: Array.from(this.errors.values())
        };
    }

    trackError(type, error) {
        const errorKey = `${type}:${error.message}`;
        const existing = this.errors.get(errorKey) || {
            type,
            message: error.message,
            count: 0,
            firstOccurred: Date.now(),
            lastOccurred: Date.now()
        };

        existing.count++;
        existing.lastOccurred = Date.now();
        this.errors.set(errorKey, existing);

        this.eventBus.emit('error', {
            type,
            error,
            count: existing.count
        });
    }

    getMetrics() {
        return {
            timestamp: Date.now(),
            collectors: Object.fromEntries(this.metrics),
            errors: Array.from(this.errors.values())
        };
    }

    onMetrics(callback) {
        this.eventBus.on('metrics', callback);
    }

    onError(callback) {
        this.eventBus.on('error', callback);
    }

    async shutdown() {
        if (this.collectionTimer) {
            clearInterval(this.collectionTimer);
        }

        // Store final metrics if configured
        if (this.config.storageEndpoint) {
            await this.storeMetrics();
        }

        this.eventBus.removeAllListeners();
        await super.shutdown();
    }
}

================
File: src/api/http/client/SememClient.js
================
/**
 * Client wrapper for Semem API
 */
export default class SememClient {
    constructor(config = {}) {
        this.baseUrl = config.baseUrl || 'http://localhost:3000/api';
        this.apiKey = config.apiKey;
        this.timeout = config.timeout || 30000;
        this.retries = config.retries || 3;
        this.retryDelay = config.retryDelay || 1000;
    }

    async request(endpoint, options = {}) {
        const controller = new AbortController();
        const timeoutId = setTimeout(() => controller.abort(), this.timeout);

        try {
            const response = await this.retryRequest(endpoint, {
                ...options,
                signal: controller.signal,
                headers: {
                    'Content-Type': 'application/json',
                    'X-API-Key': this.apiKey,
                    ...options.headers
                }
            });

            const data = await response.json();
            if (!data.success) {
                throw new Error(data.error || 'API request failed');
            }

            return data.data;
        } finally {
            clearTimeout(timeoutId);
        }
    }

    async retryRequest(endpoint, options) {
        let lastError;
        for (let attempt = 0; attempt < this.retries; attempt++) {
            try {
                const response = await fetch(`${this.baseUrl}${endpoint}`, options);
                if (response.ok) return response;
                
                lastError = new Error(`HTTP ${response.status}: ${response.statusText}`);
                if (!this.isRetryable(response.status)) throw lastError;
            } catch (error) {
                lastError = error;
                if (!this.isRetryable(error)) throw error;
            }

            await new Promise(resolve => 
                setTimeout(resolve, this.retryDelay * Math.pow(2, attempt))
            );
        }
        throw lastError;
    }

    isRetryable(statusOrError) {
        if (typeof statusOrError === 'number') {
            return [408, 429, 500, 502, 503, 504].includes(statusOrError);
        }
        return statusOrError.name === 'AbortError' || 
               statusOrError.name === 'NetworkError';
    }

    // Chat operations
    async chat(prompt, options = {}) {
        return this.request('/chat', {
            method: 'POST',
            body: JSON.stringify({
                prompt,
                model: options.model || 'qwen2:1.5b',
                ...options
            })
        });
    }

    // Storage operations
    async store(data, format = 'text') {
        return this.request('/store', {
            method: 'POST',
            body: JSON.stringify({ content: data, format })
        });
    }

    async storeInteraction(interaction) {
        return this.request('/store', {
            method: 'POST',
            body: JSON.stringify(interaction)
        });
    }

    // Query operations
    async query(options = {}) {
        const params = new URLSearchParams();
        if (options.text) params.set('text', options.text);
        if (options.concepts) params.set('concepts', JSON.stringify(options.concepts));
        if (options.similarity) params.set('similarity', options.similarity);
        if (options.limit) params.set('limit', options.limit);
        if (options.offset) params.set('offset', options.offset);

        return this.request(`/query?${params}`);
    }

    async sparqlQuery(query) {
        return this.request('/query', {
            method: 'POST',
            body: JSON.stringify({ sparql: query })
        });
    }

    // Metric operations
    async getMetrics() {
        return this.request('/metrics');
    }

    // Streaming operations
    async *streamChat(prompt, options = {}) {
        const response = await fetch(`${this.baseUrl}/chat/stream`, {
            method: 'POST',
            headers: {
                'Content-Type': 'application/json',
                'X-API-Key': this.apiKey
            },
            body: JSON.stringify({
                prompt,
                model: options.model || 'qwen2:1.5b',
                ...options
            })
        });

        if (!response.ok) {
            throw new Error(`HTTP ${response.status}: ${response.statusText}`);
        }

        const reader = response.body.getReader();
        const decoder = new TextDecoder();

        try {
            while (true) {
                const { value, done } = await reader.read();
                if (done) break;
                
                const chunk = decoder.decode(value, { stream: true });
                yield JSON.parse(chunk);
            }
        } finally {
            reader.releaseLock();
        }
    }

    // Batch operations
    async batchStore(interactions) {
        return this.request('/store/batch', {
            method: 'POST',
            body: JSON.stringify(interactions)
        });
    }

    async batchQuery(queries) {
        return this.request('/query/batch', {
            method: 'POST',
            body: JSON.stringify(queries)
        });
    }

    // Helper methods
    formatInteraction(prompt, response, options = {}) {
        return {
            prompt,
            output: response,
            timestamp: Date.now(),
            ...options
        };
    }

    buildQuery(text, options = {}) {
        return {
            text,
            similarity: 0.7,
            limit: 10,
            ...options
        };
    }
}

================
File: src/api/http/server/HTTPServer.js
================
import express from 'express';
import cors from 'cors';
import helmet from 'helmet';
import compression from 'compression';
import { rateLimit } from 'express-rate-limit';
import swaggerUi from 'swagger-ui-express';
import BaseAPI from '../../common/BaseAPI.js';
import { APIRegistry } from '../../common/APIRegistry.js';

export default class HTTPServer extends BaseAPI {
    constructor(config = {}) {
        super(config);
        this.app = express();
        this.registry = new APIRegistry();
        this.port = config.port || 3000;
        this.setupMiddleware();
        this.setupRoutes();
    }

    setupMiddleware() {
        // Security and optimization middleware
        this.app.use(helmet());
        this.app.use(cors());
        this.app.use(compression());
        this.app.use(express.json());
        
        // Rate limiting
        const limiter = rateLimit({
            windowMs: 15 * 60 * 1000,
            max: 100,
            standardHeaders: true,
            legacyHeaders: false
        });
        this.app.use(limiter);

        // Request logging
        this.app.use((req, res, next) => {
            this.logger.debug(`${req.method} ${req.path}`);
            const start = Date.now();
            res.on('finish', () => {
                const duration = Date.now() - start;
                this._emitMetric('http.request.duration', duration);
                this._emitMetric('http.request.status', res.statusCode);
            });
            next();
        });

        // Error handling
        this.app.use((err, req, res, next) => {
            this.logger.error('Server error:', err);
            res.status(500).json({
                success: false,
                error: err.message,
                metadata: {
                    timestamp: Date.now(),
                    path: req.path
                }
            });
        });
    }

    setupRoutes() {
        // API Documentation
        if (this.config.openapi) {
            this.app.use('/docs', swaggerUi.serve, 
                swaggerUi.setup(this.config.openapi));
        }

        // Chat endpoints
        this.app.post('/api/chat', async (req, res) => {
            try {
                const api = this.registry.get('chat');
                const response = await api.executeOperation('chat', req.body);
                res.json({
                    success: true,
                    data: response
                });
            } catch (error) {
                res.status(400).json({
                    success: false,
                    error: error.message
                });
            }
        });

        // Storage endpoints
        this.app.post('/api/store', async (req, res) => {
            try {
                const api = this.registry.get('storage');
                await api.storeInteraction(req.body);
                res.json({ success: true });
            } catch (error) {
                res.status(400).json({
                    success: false,
                    error: error.message
                });
            }
        });

        // Query endpoints
        this.app.get('/api/query', async (req, res) => {
            try {
                const api = this.registry.get('storage');
                const results = await api.retrieveInteractions(req.query);
                res.json({
                    success: true,
                    data: results
                });
            } catch (error) {
                res.status(400).json({
                    success: false,
                    error: error.message
                });
            }
        });

        // Metrics endpoint
        this.app.get('/api/metrics', async (req, res) => {
            try {
                const metrics = await this.getMetrics();
                res.json({
                    success: true,
                    data: metrics
                });
            } catch (error) {
                res.status(500).json({
                    success: false,
                    error: error.message
                });
            }
        });

        // Health check
        this.app.get('/health', (req, res) => {
            res.json({
                status: 'healthy',
                timestamp: Date.now(),
                uptime: process.uptime()
            });
        });
    }

    async initialize() {
        await super.initialize();
        return new Promise((resolve) => {
            this.server = this.app.listen(this.port, () => {
                this.logger.info(`HTTP server listening on port ${this.port}`);
                resolve();
            });
        });
    }

    async shutdown() {
        if (this.server) {
            await new Promise((resolve) => {
                this.server.close(resolve);
            });
            this.logger.info('HTTP server shut down');
        }
        await super.shutdown();
    }
}

================
File: src/api/http/server/openapi-schema.js
================
export default {
    openapi: '3.0.0',
    info: {
        title: 'Semem API',
        version: '1.0.0',
        description: 'Semantic Memory Management System API'
    },
    servers: [
        {
            url: 'http://localhost:3000',
            description: 'Development server'
        }
    ],
    components: {
        schemas: {
            Interaction: {
                type: 'object',
                required: ['prompt', 'output', 'embedding'],
                properties: {
                    id: { type: 'string', format: 'uuid' },
                    prompt: { type: 'string' },
                    output: { type: 'string' },
                    embedding: {
                        type: 'array',
                        items: { type: 'number' }
                    },
                    timestamp: { type: 'integer' },
                    accessCount: { type: 'integer' },
                    concepts: {
                        type: 'array',
                        items: { type: 'string' }
                    },
                    decayFactor: { type: 'number' }
                }
            },
            Query: {
                type: 'object',
                properties: {
                    text: { type: 'string' },
                    concepts: {
                        type: 'array',
                        items: { type: 'string' }
                    },
                    similarity: { type: 'number', minimum: 0, maximum: 100 },
                    limit: { type: 'integer', minimum: 1 },
                    offset: { type: 'integer', minimum: 0 }
                }
            },
            APIResponse: {
                type: 'object',
                required: ['success'],
                properties: {
                    success: { type: 'boolean' },
                    data: { type: 'object' },
                    error: { type: 'string' },
                    metadata: {
                        type: 'object',
                        properties: {
                            timestamp: { type: 'integer' },
                            version: { type: 'string' }
                        }
                    }
                }
            },
            Metrics: {
                type: 'object',
                properties: {
                    timestamp: { type: 'integer' },
                    status: {
                        type: 'string',
                        enum: ['active', 'inactive']
                    },
                    memoryUsage: {
                        type: 'object',
                        properties: {
                            heapTotal: { type: 'number' },
                            heapUsed: { type: 'number' },
                            external: { type: 'number' }
                        }
                    },
                    uptime: { type: 'number' }
                }
            }
        },
        securitySchemes: {
            apiKey: {
                type: 'apiKey',
                in: 'header',
                name: 'X-API-Key'
            }
        }
    },
    paths: {
        '/api/chat': {
            post: {
                summary: 'Chat with the system',
                tags: ['Chat'],
                security: [{ apiKey: [] }],
                requestBody: {
                    required: true,
                    content: {
                        'application/json': {
                            schema: {
                                type: 'object',
                                required: ['prompt'],
                                properties: {
                                    prompt: { type: 'string' },
                                    model: { type: 'string' },
                                    options: { type: 'object' }
                                }
                            }
                        }
                    }
                },
                responses: {
                    '200': {
                        description: 'Successful response',
                        content: {
                            'application/json': {
                                schema: { $ref: '#/components/schemas/APIResponse' }
                            }
                        }
                    }
                }
            }
        },
        '/api/store': {
            post: {
                summary: 'Store an interaction',
                tags: ['Storage'],
                security: [{ apiKey: [] }],
                requestBody: {
                    required: true,
                    content: {
                        'application/json': {
                            schema: { $ref: '#/components/schemas/Interaction' }
                        }
                    }
                },
                responses: {
                    '200': {
                        description: 'Successfully stored',
                        content: {
                            'application/json': {
                                schema: { $ref: '#/components/schemas/APIResponse' }
                            }
                        }
                    }
                }
            }
        },
        '/api/query': {
            get: {
                summary: 'Query stored interactions',
                tags: ['Storage'],
                security: [{ apiKey: [] }],
                parameters: [
                    {
                        name: 'text',
                        in: 'query',
                        schema: { type: 'string' }
                    },
                    {
                        name: 'concepts',
                        in: 'query',
                        schema: {
                            type: 'array',
                            items: { type: 'string' }
                        }
                    },
                    {
                        name: 'similarity',
                        in: 'query',
                        schema: { type: 'number' }
                    },
                    {
                        name: 'limit',
                        in: 'query',
                        schema: { type: 'integer' }
                    },
                    {
                        name: 'offset',
                        in: 'query',
                        schema: { type: 'integer' }
                    }
                ],
                responses: {
                    '200': {
                        description: 'Query results',
                        content: {
                            'application/json': {
                                schema: { $ref: '#/components/schemas/APIResponse' }
                            }
                        }
                    }
                }
            }
        },
        '/api/metrics': {
            get: {
                summary: 'Get system metrics',
                tags: ['Monitoring'],
                security: [{ apiKey: [] }],
                responses: {
                    '200': {
                        description: 'System metrics',
                        content: {
                            'application/json': {
                                schema: { $ref: '#/components/schemas/Metrics' }
                            }
                        }
                    }
                }
            }
        },
        '/health': {
            get: {
                summary: 'Health check',
                tags: ['Monitoring'],
                responses: {
                    '200': {
                        description: 'System health status',
                        content: {
                            'application/json': {
                                schema: {
                                    type: 'object',
                                    properties: {
                                        status: { type: 'string' },
                                        timestamp: { type: 'integer' },
                                        uptime: { type: 'number' }
                                    }
                                }
                            }
                        }
                    }
                }
            }
        }
    }
};

================
File: src/api/repl/REPLHandler.js
================
import { createInterface } from 'readline';
import chalk from 'chalk';
import BaseAPI from '../common/BaseAPI.js';
import { APIRegistry } from '../common/APIRegistry.js';

export default class REPLHandler extends BaseAPI {
    constructor(config = {}) {
        super(config);
        this.registry = new APIRegistry();
        this.history = [];
        this.mode = 'chat';
        this.commands = this.setupCommands();
    }

    setupCommands() {
        return {
            help: {
                desc: 'Show help menu',
                handler: () => this.showHelp()
            },
            mode: {
                desc: 'Switch mode (chat/rdf)',
                handler: (args) => this.switchMode(args[0])
            },
            clear: {
                desc: 'Clear screen',
                handler: () => console.clear()
            },
            history: {
                desc: 'Show command history',
                handler: () => this.showHistory()
            },
            exit: {
                desc: 'Exit REPL',
                handler: () => this.shutdown()
            }
        };
    }

    async initialize() {
        await super.initialize();
        
        this.rl = createInterface({
            input: process.stdin,
            output: process.stdout,
            prompt: this.getPrompt(),
            historySize: 100,
            removeHistoryDuplicates: true
        });

        this.rl.on('line', async (line) => {
            if (line.trim()) {
                this.history.push(line);
                await this.processInput(line);
            }
            this.rl.prompt();
        });

        this.rl.on('close', () => {
            this.shutdown();
        });

        console.clear();
        this.showWelcome();
        this.rl.prompt();
    }

    getPrompt() {
        return chalk.cyan(`semem(${this.mode})> `);
    }

    showWelcome() {
        console.log(chalk.green('Welcome to Semem Interactive Shell'));
        console.log(chalk.gray('Type "help" for available commands'));
        console.log();
    }

    showHelp() {
        console.log(chalk.yellow('\nAvailable Commands:'));
        Object.entries(this.commands).forEach(([cmd, info]) => {
            console.log(chalk.cyan(`  ${cmd.padEnd(10)} - ${info.desc}`));
        });
        console.log(chalk.yellow('\nModes:'));
        console.log(chalk.cyan('  chat      - Natural language interactions'));
        console.log(chalk.cyan('  rdf       - RDF/SPARQL queries'));
        console.log();
    }

    showHistory() {
        if (this.history.length === 0) {
            console.log(chalk.gray('No history available'));
            return;
        }

        console.log(chalk.yellow('\nCommand History:'));
        this.history.slice(-10).forEach((cmd, i) => {
            console.log(chalk.gray(`  ${i + 1}. ${cmd}`));
        });
        console.log();
    }

    switchMode(newMode) {
        const validModes = ['chat', 'rdf'];
        if (!validModes.includes(newMode)) {
            console.log(chalk.red(`Invalid mode. Valid modes: ${validModes.join(', ')}`));
            return;
        }

        this.mode = newMode;
        this.rl.setPrompt(this.getPrompt());
        console.log(chalk.green(`Switched to ${newMode} mode`));
    }

    async processInput(input) {
        const trimmed = input.trim();
        if (!trimmed) return;

        const [command, ...args] = trimmed.split(' ');

        // Check for built-in commands
        if (this.commands[command]) {
            await this.commands[command].handler(args);
            return;
        }

        try {
            // Handle mode-specific operations
            switch (this.mode) {
                case 'chat':
                    await this.handleChat(trimmed);
                    break;
                case 'rdf':
                    await this.handleRDF(trimmed);
                    break;
            }
        } catch (error) {
            console.error(chalk.red('Error:'), error.message);
        }
    }

    async handleChat(input) {
        try {
            const api = this.registry.get('chat');
            const response = await api.executeOperation('chat', {
                prompt: input,
                mode: 'chat'
            });
            
            // Format and display response
            console.log(chalk.green('\nAssistant:'), response);
            console.log();
            
            // Store interaction
            const storageApi = this.registry.get('storage');
            await storageApi.storeInteraction({
                prompt: input,
                output: response,
                timestamp: Date.now()
            });
        } catch (error) {
            console.error(chalk.red('Chat error:'), error.message);
        }
    }

    async handleRDF(input) {
        try {
            const api = this.registry.get('storage');
            let response;

            if (input.toLowerCase().startsWith('select') ||
                input.toLowerCase().startsWith('ask') ||
                input.toLowerCase().startsWith('construct')) {
                // Query operation
                response = await api.executeOperation('query', {
                    sparql: input
                });
            } else {
                // Update operation
                response = await api.executeOperation('update', {
                    sparql: input
                });
            }

            // Format and display response
            if (Array.isArray(response)) {
                console.log(chalk.yellow('\nResults:'));
                response.forEach(result => {
                    console.log(chalk.gray('-'), result);
                });
            } else {
                console.log(chalk.green('\nOperation completed successfully'));
            }
            console.log();
        } catch (error) {
            console.error(chalk.red('RDF error:'), error.message);
        }
    }

    async shutdown() {
        console.log(chalk.yellow('\nShutting down...'));
        if (this.rl) {
            this.rl.close();
        }
        await super.shutdown();
        process.exit(0);
    }
}

================
File: src/api/about.md
================
src/api/
├── common/
│ ├── BaseAPI.js # Abstract base interface
│ ├── APIRegistry.js # API registration/discovery
│ └── types.d.ts # TypeScript definitions
├── cli/
│ └── CLIHandler.js # Command line interface
├── repl/
│ └── REPLHandler.js # Interactive shell
├── http/
│ ├── server/
│ │ ├── HTTPServer.js # Express server
│ │ └── routes/ # API endpoints
│ └── client/
│ └── forms/ # Web interface
├── features/
│ ├── SelfieHandler.js # Metrics & monitoring
│ ├── PassiveHandler.js # Individual operations
│ └── ActiveHandler.js # Combined operations
└── utils/
├── MetricsCollector.js # Performance tracking
└── APILogger.js # Logging wrapper

================
File: src/api/APILogger.js
================
import log from 'loglevel';
import { EventEmitter } from 'events';

export default class APILogger extends EventEmitter {
    constructor(options = {}) {
        super();
        this.name = options.name || 'API';
        this.level = options.level || 'info';
        this.maxEntries = options.maxEntries || 1000;
        this.logEntries = [];
        
        this.logger = log.getLogger(this.name);
        this.logger.setLevel(this.level);
        
        this.setupMethods();
    }

    setupMethods() {
        const levels = ['trace', 'debug', 'info', 'warn', 'error'];
        
        levels.forEach(level => {
            this[level] = (...args) => {
                const entry = this.createLogEntry(level, ...args);
                this.logEntries.push(entry);
                
                if (this.logEntries.length > this.maxEntries) {
                    this.logEntries.shift();
                }
                
                this.emit('log', entry);
                this.logger[level](...args);
                
                return entry;
            };
        });
    }

    createLogEntry(level, ...args) {
        const entry = {
            timestamp: new Date().toISOString(),
            level,
            message: args.map(arg => 
                typeof arg === 'object' ? JSON.stringify(arg) : String(arg)
            ).join(' '),
            metadata: {
                pid: process.pid,
                hostname: require('os').hostname()
            }
        };

        // Extract error details if present
        const error = args.find(arg => arg instanceof Error);
        if (error) {
            entry.error = {
                name: error.name,
                message: error.message,
                stack: error.stack
            };
        }

        return entry;
    }

    getEntries(options = {}) {
        let entries = [...this.logEntries];
        
        if (options.level) {
            entries = entries.filter(entry => entry.level === options.level);
        }
        
        if (options.since) {
            entries = entries.filter(entry => 
                new Date(entry.timestamp) >= new Date(options.since)
            );
        }
        
        if (options.until) {
            entries = entries.filter(entry => 
                new Date(entry.timestamp) <= new Date(options.until)
            );
        }
        
        if (options.limit) {
            entries = entries.slice(-options.limit);
        }
        
        return entries;
    }

    clearEntries() {
        this.logEntries = [];
    }

    setLevel(level) {
        this.level = level;
        this.logger.setLevel(level);
    }

    getLevel() {
        return this.level;
    }

    createChild(name, options = {}) {
        return new APILogger({
            ...options,
            name: `${this.name}:${name}`,
            level: options.level || this.level
        });
    }

    dispose() {
        this.removeAllListeners();
        this.clearEntries();
    }
}

================
File: src/api/MetricsCollector.js
================
import { EventEmitter } from 'events';
import { logger } from '../Utils.js';

export default class MetricsCollector extends EventEmitter {
    constructor(options = {}) {
        super();
        this.metrics = new Map();
        this.interval = options.interval || 60000;
        this.maxHistory = options.maxHistory || 1000;
        this.startTime = Date.now();
        this.setupCleanup();
    }

    setupCleanup() {
        this.cleanupInterval = setInterval(() => {
            this.pruneMetrics();
        }, this.interval);
    }

    collect(name, value, labels = {}) {
        const timestamp = Date.now();
        const key = this.generateKey(name, labels);
        
        if (!this.metrics.has(key)) {
            this.metrics.set(key, []);
        }
        
        const series = this.metrics.get(key);
        series.push({ timestamp, value });
        
        this.emit('metric', { name, value, timestamp, labels });
        
        if (series.length > this.maxHistory) {
            series.shift();
        }
    }

    generateKey(name, labels) {
        const labelStr = Object.entries(labels)
            .sort(([a], [b]) => a.localeCompare(b))
            .map(([k, v]) => `${k}=${v}`)
            .join(',');
        return labelStr ? `${name}{${labelStr}}` : name;
    }

    getMetric(name, labels = {}) {
        const key = this.generateKey(name, labels);
        return this.metrics.get(key) || [];
    }

    getSummary(name, labels = {}) {
        const series = this.getMetric(name, labels);
        if (series.length === 0) return null;

        const values = series.map(point => point.value);
        return {
            count: values.length,
            min: Math.min(...values),
            max: Math.max(...values),
            avg: values.reduce((a, b) => a + b, 0) / values.length,
            last: values[values.length - 1]
        };
    }

    pruneMetrics() {
        const cutoff = Date.now() - this.interval;
        
        for (const [key, series] of this.metrics.entries()) {
            const filtered = series.filter(point => point.timestamp >= cutoff);
            if (filtered.length === 0) {
                this.metrics.delete(key);
            } else {
                this.metrics.set(key, filtered);
            }
        }
    }

    getSnapshot() {
        const snapshot = {
            timestamp: Date.now(),
            uptime: Date.now() - this.startTime,
            metrics: {}
        };

        for (const [key, series] of this.metrics.entries()) {
            snapshot.metrics[key] = this.getSummary(key);
        }

        return snapshot;
    }

    reset() {
        this.metrics.clear();
        this.startTime = Date.now();
    }

    dispose() {
        if (this.cleanupInterval) {
            clearInterval(this.cleanupInterval);
        }
        this.removeAllListeners();
        this.metrics.clear();
    }
}

================
File: src/connectors/OllamaConnector.js
================
import fetch from 'node-fetch';

export default class OllamaConnector {
    constructor(baseUrl = 'http://localhost:11434') {
        this.baseUrl = baseUrl;
    }

    async generateEmbedding(model, input) {
        const response = await fetch(`${this.baseUrl}/api/embeddings`, {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({
                model,
                prompt: input,
                options: {
                    num_ctx: 8192
                }
            })
        });

        if (!response.ok) {
            throw new Error(`Ollama API error: ${response.status}`);
        }

        const data = await response.json();
        return data.embedding;
    }

    async generateChat(model, messages, options = {}) {
        const response = await fetch(`${this.baseUrl}/api/chat`, {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({
                model,
                messages,
                stream: false,
                options
            })
        });

        if (!response.ok) {
            throw new Error(`Ollama API error: ${response.status}`);
        }

        const data = await response.json();
        return data.message.content;
    }

    async generateCompletion(model, prompt, options = {}) {
        const response = await fetch(`${this.baseUrl}/api/generate`, {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({
                model,
                prompt,
                stream: false,
                options
            })
        });

        if (!response.ok) {
            throw new Error(`Ollama API error: ${response.status}`);
        }

        const data = await response.json();
        return data.response;
    }
}

================
File: src/stores/BaseStore.js
================
export default class BaseStore {
    async loadHistory() {
        throw new Error('Method loadHistory() must be implemented');
    }

    async saveMemoryToHistory(memoryStore) {
        throw new Error('Method saveMemoryToHistory() must be implemented');
    }

    async beginTransaction() {
        throw new Error('Method beginTransaction() must be implemented');
    }

    async commitTransaction() {
        throw new Error('Method commitTransaction() must be implemented');
    }

    async rollbackTransaction() {
        throw new Error('Method rollbackTransaction() must be implemented');
    }

    async verify() {
        throw new Error('Method verify() must be implemented');
    }

    async close() {
        throw new Error('Method close() must be implemented');
    }
}

================
File: src/stores/CachedSPARQLStore.js
================
import SPARQLStore from './SPARQLStore.js';
import { logger } from '../Utils.js';

export default class CachedSPARQLStore extends SPARQLStore {
    constructor(endpoint, options = {}) {
        super(endpoint, options);
        
        // Cache configuration
        this.cacheEnabled = options.cacheEnabled ?? true;
        this.cacheTTL = options.cacheTTL || 300000; // 5 minutes default
        this.maxCacheSize = options.maxCacheSize || 100;
        
        // Initialize cache
        this.queryCache = new Map();
        this.cacheTimestamps = new Map();
        
        // Start cache cleanup interval
        this.cleanupInterval = setInterval(() => {
            this.cleanupCache();
        }, this.cacheTTL / 2);
    }

    async _executeSparqlQuery(query, endpoint) {
        if (!this.cacheEnabled) {
            return super._executeSparqlQuery(query, endpoint);
        }

        const cacheKey = this._generateCacheKey(query);

        // Check cache
        const cachedResult = this.queryCache.get(cacheKey);
        if (cachedResult) {
            const timestamp = this.cacheTimestamps.get(cacheKey);
            if (Date.now() - timestamp < this.cacheTTL) {
                logger.debug('Cache hit:', cacheKey);
                return JSON.parse(JSON.stringify(cachedResult)); // Deep clone
            }
        }

        // Execute query
        const result = await super._executeSparqlQuery(query, endpoint);
        
        // Cache result
        this.queryCache.set(cacheKey, result);
        this.cacheTimestamps.set(cacheKey, Date.now());
        
        // Manage cache size
        if (this.queryCache.size > this.maxCacheSize) {
            this.cleanupCache();
        }

        return result;
    }

    _generateCacheKey(query) {
        // Normalize query by removing whitespace
        return query.replace(/\s+/g, ' ').trim();
    }

    cleanupCache() {
        const now = Date.now();

        // Remove expired entries
        for (const [key, timestamp] of this.cacheTimestamps.entries()) {
            if (now - timestamp > this.cacheTTL) {
                this.queryCache.delete(key);
                this.cacheTimestamps.delete(key);
            }
        }

        // If still over size limit, remove oldest entries
        while (this.queryCache.size > this.maxCacheSize) {
            let oldestKey = null;
            let oldestTime = Infinity;

            for (const [key, timestamp] of this.cacheTimestamps.entries()) {
                if (timestamp < oldestTime) {
                    oldestTime = timestamp;
                    oldestKey = key;
                }
            }

            if (oldestKey) {
                this.queryCache.delete(oldestKey);
                this.cacheTimestamps.delete(oldestKey);
            }
        }
    }

    invalidateCache() {
        this.queryCache.clear();
        this.cacheTimestamps.clear();
    }

    async saveMemoryToHistory(memoryStore) {
        // Invalidate cache when data changes
        this.invalidateCache();
        return super.saveMemoryToHistory(memoryStore);
    }

    async close() {
        if (this.cleanupInterval) {
            clearInterval(this.cleanupInterval);
        }
        
        this.invalidateCache();
        return super.close();
    }
}

================
File: src/stores/InMemoryStore.js
================
import BaseStore from './BaseStore.js';
import { logger } from '../Utils.js';

export default class InMemoryStore extends BaseStore {
    constructor() {
        super();
        this.history = {
            shortTermMemory: [],
            longTermMemory: []
        };
    }

    async loadHistory() {
        logger.info('Loading history from in-memory storage');
        return [
            this.history.shortTermMemory || [],
            this.history.longTermMemory || []
        ];
    }

    async saveMemoryToHistory(memoryStore) {
        logger.info('Saving history to in-memory storage');

        this.history = {
            shortTermMemory: memoryStore.shortTermMemory.map((item, idx) => ({
                id: item.id,
                prompt: item.prompt,
                output: item.output,
                embedding: Array.from(memoryStore.embeddings[idx].flat()),
                timestamp: memoryStore.timestamps[idx],
                accessCount: memoryStore.accessCounts[idx],
                concepts: Array.from(memoryStore.conceptsList[idx]),
                decayFactor: item.decayFactor || 1.0
            })),
            longTermMemory: [...memoryStore.longTermMemory]
        };

        logger.info(`Saved ${this.history.shortTermMemory.length} short-term and ${this.history.longTermMemory.length} long-term memories`);
    }
}

================
File: src/stores/JSONStore.js
================
import { promises as fs } from 'fs';
import { dirname, join } from 'path';
import BaseStore from './BaseStore.js';
import { logger } from '../Utils.js';

export default class JSONStore extends BaseStore {
    constructor(filePath = 'interaction_history.json') {
        super();
        this.filePath = filePath;
        this.tempPath = null;
        this.backupPath = `${filePath}.bak`;
        this.inTransaction = false;
    }

    async ensureDirectory() {
        const dir = dirname(this.filePath);
        await fs.mkdir(dir, { recursive: true });
    }

    async loadHistory() {
        try {
            await this.ensureDirectory();
            const exists = await fs.access(this.filePath).then(() => true).catch(() => false);

            if (!exists) {
                logger.info('No existing interaction history found in JSON. Starting fresh.');
                return [[], []];
            }

            // Try to read main file
            try {
                logger.info('Loading existing interaction history from JSON...');
                const data = await fs.readFile(this.filePath, 'utf8');
                const history = JSON.parse(data);
                return [
                    history.shortTermMemory || [],
                    history.longTermMemory || []
                ];
            } catch (mainError) {
                // If main file is corrupted, try backup
                logger.warn('Main file corrupted, attempting to load backup...');
                const backupExists = await fs.access(this.backupPath).then(() => true).catch(() => false);

                if (backupExists) {
                    const backupData = await fs.readFile(this.backupPath, 'utf8');
                    const history = JSON.parse(backupData);
                    // Restore from backup
                    await fs.copyFile(this.backupPath, this.filePath);
                    return [
                        history.shortTermMemory || [],
                        history.longTermMemory || []
                    ];
                }

                throw mainError;
            }
        } catch (error) {
            logger.error('Error loading history:', error);
            return [[], []];
        }
    }

    async beginTransaction() {
        if (this.inTransaction) {
            throw new Error('Transaction already in progress');
        }
        this.inTransaction = true;
        this.tempPath = `${this.filePath}.tmp`;
    }

    async commitTransaction() {
        if (!this.inTransaction) {
            throw new Error('No transaction in progress');
        }

        try {
            // First backup the current file if it exists
            const exists = await fs.access(this.filePath).then(() => true).catch(() => false);
            if (exists) {
                await fs.copyFile(this.filePath, this.backupPath);
            }

            // Atomically rename temp file to main file
            await fs.rename(this.tempPath, this.filePath);

            // Clean up
            if (exists) {
                await fs.unlink(this.backupPath).catch(() => { });
            }
        } finally {
            this.inTransaction = false;
            this.tempPath = null;
        }
    }

    async rollbackTransaction() {
        if (!this.inTransaction) {
            throw new Error('No transaction in progress');
        }

        try {
            if (this.tempPath) {
                await fs.unlink(this.tempPath).catch(() => { });
            }
        } finally {
            this.inTransaction = false;
            this.tempPath = null;
        }
    }

    async verify() {
        try {
            const data = await fs.readFile(this.filePath, 'utf8');
            JSON.parse(data); // Try to parse
            return true;
        } catch {
            return false;
        }
    }

    async saveMemoryToHistory(memoryStore) {
        try {
            await this.ensureDirectory();
            await this.beginTransaction();

            const history = {
                shortTermMemory: memoryStore.shortTermMemory.map((item, idx) => ({
                    id: item.id,
                    prompt: item.prompt,
                    output: item.output,
                    embedding: Array.from(memoryStore.embeddings[idx]),
                    timestamp: memoryStore.timestamps[idx],
                    accessCount: memoryStore.accessCounts[idx],
                    concepts: Array.from(memoryStore.conceptsList[idx]),
                    decayFactor: item.decayFactor || 1.0
                })),
                longTermMemory: memoryStore.longTermMemory
            };

            // Write to temp file first
            await fs.writeFile(this.tempPath, JSON.stringify(history, null, 2));

            // Verify the written file
            if (!await this.verify()) {
                throw new Error('Data verification failed');
            }

            // Commit the transaction
            await this.commitTransaction();

            logger.info(`Saved interaction history to JSON. Short-term: ${history.shortTermMemory.length}, Long-term: ${history.longTermMemory.length}`);
        } catch (error) {
            await this.rollbackTransaction();
            logger.error('Error saving history:', error);
            throw error;
        }
    }

    async close() {
        if (this.inTransaction) {
            await this.rollbackTransaction();
        }
        return Promise.resolve();
    }
}

================
File: src/stores/MemoryStore.js
================
import faiss from 'faiss-node'
import { createRequire } from 'module'
import { kmeans } from 'ml-kmeans'
import { logger, vectorOps } from '../Utils.js'

const require = createRequire(import.meta.url)
const { Graph } = require('graphology')

export default class MemoryStore {
    constructor(dimension = 1536) {
        this.dimension = dimension
        this.initializeIndex()
        this.shortTermMemory = []
        this.longTermMemory = []
        this.embeddings = []
        this.timestamps = []
        this.accessCounts = []
        this.conceptsList = []
        this.graph = new Graph({ multi: true, allowSelfLoops: false })
        this.semanticMemory = new Map()
        this.clusterLabels = []
    }

    initializeIndex() {
        try {
            this.index = new faiss.IndexFlatL2(this.dimension)
            if (!this.index || !this.index.getDimension) {
                throw new Error('Failed to initialize FAISS index')
            }
            logger.info(`Initialized FAISS index with dimension ${this.dimension}`)
        } catch (error) {
            logger.error('FAISS index initialization failed:', error)
            throw new Error('Failed to initialize FAISS index: ' + error.message)
        }
    }

    updateGraph(concepts) {
        // Add new nodes if they don't exist
        for (const concept of concepts) {
            if (!this.graph.hasNode(concept)) {
                this.graph.addNode(concept)
            }
        }

        // Add or update edges between concepts
        for (const concept1 of concepts) {
            for (const concept2 of concepts) {
                if (concept1 !== concept2) {
                    // Check for existing edges between the nodes
                    const existingEdges = this.graph.edges(concept1, concept2)

                    if (existingEdges.length > 0) {
                        // Update weight of first existing edge
                        const edgeWeight = this.graph.getEdgeAttribute(existingEdges[0], 'weight')
                        this.graph.setEdgeAttribute(existingEdges[0], 'weight', edgeWeight + 1)
                    } else {
                        // Create new edge with weight 1
                        this.graph.addEdge(concept1, concept2, { weight: 1 })
                    }
                }
            }
        }
    }

    classifyMemory() {
        this.shortTermMemory.forEach((interaction, idx) => {
            if (this.accessCounts[idx] > 10 &&
                !this.longTermMemory.some(ltm => ltm.id === interaction.id)) {
                this.longTermMemory.push(interaction)
                logger.info(`Moved interaction ${interaction.id} to long-term memory`)
            }
        })
    }

    async retrieve(queryEmbedding, queryConcepts, similarityThreshold = 40, excludeLastN = 0) {
        if (this.shortTermMemory.length === 0) {
            logger.info('No interactions available')
            return []
        }

        logger.info('Retrieving relevant interactions...')
        const relevantInteractions = []
        const currentTime = Date.now()
        const decayRate = 0.0001
        const relevantIndices = new Set()

        const normalizedQuery = vectorOps.normalize(queryEmbedding.flat())
        const normalizedEmbeddings = this.embeddings.map(e => vectorOps.normalize(Array.from(e)))

        for (let idx = 0; idx < this.shortTermMemory.length - excludeLastN; idx++) {
            const similarity = vectorOps.cosineSimilarity(normalizedQuery, normalizedEmbeddings[idx]) * 100
            const timeDiff = (currentTime - this.timestamps[idx]) / 1000
            const decayFactor = this.shortTermMemory[idx].decayFactor * Math.exp(-decayRate * timeDiff)
            const reinforcementFactor = Math.log1p(this.accessCounts[idx])
            const adjustedSimilarity = similarity * decayFactor * reinforcementFactor

            if (adjustedSimilarity >= similarityThreshold) {
                relevantIndices.add(idx)
                this.accessCounts[idx]++
                this.timestamps[idx] = currentTime
                this.shortTermMemory[idx].decayFactor *= 1.1

                relevantInteractions.push({
                    similarity: adjustedSimilarity,
                    interaction: this.shortTermMemory[idx],
                    concepts: this.conceptsList[idx]
                })
            }
        }

        // Apply decay to non-relevant interactions
        this.shortTermMemory.forEach((item, idx) => {
            if (!relevantIndices.has(idx)) {
                item.decayFactor *= 0.9
            }
        })

        const activatedConcepts = await this.spreadingActivation(queryConcepts)

        // Combine results
        return this.combineResults(relevantInteractions, activatedConcepts, normalizedQuery)
    }

    async spreadingActivation(queryConcepts) {
        const activatedNodes = new Map()
        const initialActivation = 1.0
        const decayFactor = 0.5

        queryConcepts.forEach(concept => {
            activatedNodes.set(concept, initialActivation)
        })

        // Spread activation for 2 steps
        for (let step = 0; step < 2; step++) {
            const newActivations = new Map()

            for (const [node, activation] of activatedNodes) {
                if (this.graph.hasNode(node)) {
                    this.graph.forEachNeighbor(node, (neighbor, attributes) => {
                        if (!activatedNodes.has(neighbor)) {
                            const weight = attributes.weight
                            const newActivation = activation * decayFactor * weight
                            newActivations.set(neighbor,
                                (newActivations.get(neighbor) || 0) + newActivation)
                        }
                    })
                }
            }

            newActivations.forEach((value, key) => {
                activatedNodes.set(key, value)
            })
        }

        return Object.fromEntries(activatedNodes)
    }

    clusterInteractions() {
        if (this.embeddings.length < 2) return

        const embeddingsMatrix = this.embeddings.map(e => Array.from(e))
        const numClusters = Math.min(10, this.embeddings.length)

        const { clusters } = kmeans(embeddingsMatrix, numClusters)
        this.clusterLabels = clusters

        this.semanticMemory.clear()
        clusters.forEach((label, idx) => {
            if (!this.semanticMemory.has(label)) {
                this.semanticMemory.set(label, [])
            }
            this.semanticMemory.get(label).push({
                embedding: this.embeddings[idx],
                interaction: this.shortTermMemory[idx]
            })
        })
    }

    combineResults(relevantInteractions, activatedConcepts, normalizedQuery) {
        const combined = relevantInteractions.map(({ similarity, interaction, concepts }) => {
            const activationScore = Array.from(concepts)
                .reduce((sum, c) => sum + (activatedConcepts[c] || 0), 0)
            return {
                ...interaction,
                totalScore: similarity + activationScore
            }
        })

        combined.sort((a, b) => b.totalScore - a.totalScore)

        // Add semantic memory results
        const semanticResults = this.retrieveFromSemanticMemory(normalizedQuery)
        return [...combined, ...semanticResults]
    }

    retrieveFromSemanticMemory(normalizedQuery) {
        if (this.semanticMemory.size === 0) return []

        // Find best matching cluster
        let bestCluster = -1
        let bestSimilarity = -1

        this.semanticMemory.forEach((items, label) => {
            const centroid = this.calculateCentroid(items.map(i => i.embedding))
            const similarity = vectorOps.cosineSimilarity(normalizedQuery, centroid)

            if (similarity > bestSimilarity) {
                bestSimilarity = similarity
                bestCluster = label
            }
        })

        if (bestCluster === -1) return []

        // Get top 5 interactions from best cluster
        return this.semanticMemory.get(bestCluster)
            .map(({ embedding, interaction }) => ({
                ...interaction,
                similarity: vectorOps.cosineSimilarity(normalizedQuery,
                    vectorOps.normalize(Array.from(embedding)))
            }))
            .sort((a, b) => b.similarity - a.similarity)
            .slice(0, 5)
    }

    calculateCentroid(embeddings) {
        const sum = embeddings.reduce((acc, curr) => {
            const arr = Array.from(curr)
            return acc.map((val, idx) => val + arr[idx])
        }, new Array(this.dimension).fill(0))

        return sum.map(val => val / embeddings.length)
    }
}

================
File: src/stores/SPARQLStore.js
================
import BaseStore from './BaseStore.js';
import { logger } from '../Utils.js';

export default class SPARQLStore extends BaseStore {
    constructor(endpoint, options = {}) {
        super();
        this.endpoint = endpoint;
        this.credentials = {
            user: options.user || 'admin',
            password: options.password || 'admin'
        };
        this.graphName = options.graphName || 'http://example.org/mcp/memory';
        this.inTransaction = false;
        this.dimension = options.dimension || 1536;
    }

    async _executeSparqlQuery(query, endpoint) {
        const auth = Buffer.from(`${this.credentials.user}:${this.credentials.password}`).toString('base64');

        try {
            const response = await fetch(endpoint, {
                method: 'POST',
                headers: {
                    'Authorization': `Basic ${auth}`,
                    'Content-Type': 'application/sparql-query',
                    'Accept': 'application/json'
                },
                body: query,
                credentials: 'include'
            });

            if (!response.ok) {
                const errorText = await response.text();
                throw new Error(`SPARQL query failed: ${response.status} - ${errorText}`);
            }

            return await response.json();
        } catch (error) {
            logger.error('SPARQL query error:', error);
            throw error;
        }
    }

    async _executeSparqlUpdate(update, endpoint) {
        const auth = Buffer.from(`${this.credentials.user}:${this.credentials.password}`).toString('base64');

        try {
            const response = await fetch(endpoint, {
                method: 'POST',
                headers: {
                    'Authorization': `Basic ${auth}`,
                    'Content-Type': 'application/sparql-update',
                    'Accept': 'application/json'
                },
                body: update,
                credentials: 'include'
            });

            if (!response.ok) {
                const errorText = await response.text();
                throw new Error(`SPARQL update failed: ${response.status} - ${errorText}`);
            }

            return response;
        } catch (error) {
            logger.error('SPARQL update error:', error);
            throw error;
        }
    }

    validateEmbedding(embedding) {
        if (!Array.isArray(embedding)) {
            throw new TypeError('Embedding must be an array');
        }
        if (embedding.length !== this.dimension) {
            throw new Error(`Embedding dimension mismatch: expected ${this.dimension}, got ${embedding.length}`);
        }
        if (!embedding.every(x => typeof x === 'number' && !isNaN(x))) {
            throw new TypeError('Embedding must contain only valid numbers');
        }
    }

    async verify() {
        try {
            try {
                const createQuery = `
                    CREATE SILENT GRAPH <${this.graphName}>;
                    INSERT DATA { GRAPH <${this.graphName}> {
                        <${this.graphName}> a <http://example.org/mcp/MemoryStore>
                    }}
                `;
                await this._executeSparqlUpdate(createQuery, this.endpoint.update);
            } catch (error) {
                logger.debug('Graph creation skipped:', error.message);
            }

            const checkQuery = `ASK { GRAPH <${this.graphName}> { ?s ?p ?o } }`;
            const result = await this._executeSparqlQuery(checkQuery, this.endpoint.query);
            return result.boolean;
        } catch (error) {
            logger.error('Graph verification failed:', error);
            throw error;
        }
    }

    async loadHistory() {
        await this.verify();

        const query = `
            PREFIX mcp: <http://purl.org/stuff/mcp/>
            PREFIX xsd: <http://www.w3.org/2001/XMLSchema#>

            SELECT ?id ?prompt ?output ?embedding ?timestamp ?accessCount ?concepts ?decayFactor ?memoryType
            FROM <${this.graphName}>
            WHERE {
                ?interaction a mcp:Interaction ;
                    mcp:id ?id ;
                    mcp:prompt ?prompt ;
                    mcp:output ?output ;
                    mcp:embedding ?embedding ;
                    mcp:timestamp ?timestamp ;
                    mcp:accessCount ?accessCount ;
                    mcp:decayFactor ?decayFactor ;
                    mcp:memoryType ?memoryType .
                OPTIONAL { ?interaction mcp:concepts ?concepts }
            }`;

        try {
            const result = await this._executeSparqlQuery(query, this.endpoint.query);
            const shortTermMemory = [];
            const longTermMemory = [];

            for (const binding of result.results.bindings) {
                try {
                    let embedding = new Array(this.dimension).fill(0);
                    if (binding.embedding?.value && binding.embedding.value !== 'undefined') {
                        try {
                            embedding = JSON.parse(binding.embedding.value.trim());
                            this.validateEmbedding(embedding);
                        } catch (embeddingError) {
                            logger.error('Invalid embedding format:', embeddingError);
                        }
                    }

                    let concepts = [];
                    if (binding.concepts?.value && binding.concepts.value !== 'undefined') {
                        try {
                            concepts = JSON.parse(binding.concepts.value.trim());
                            if (!Array.isArray(concepts)) {
                                throw new Error('Concepts must be an array');
                            }
                        } catch (conceptsError) {
                            logger.error('Invalid concepts format:', conceptsError);
                        }
                    }

                    const interaction = {
                        id: binding.id.value,
                        prompt: binding.prompt.value,
                        output: binding.output.value,
                        embedding,
                        timestamp: parseInt(binding.timestamp.value) || Date.now(),
                        accessCount: parseInt(binding.accessCount.value) || 1,
                        concepts,
                        decayFactor: parseFloat(binding.decayFactor.value) || 1.0
                    };

                    if (binding.memoryType.value === 'short-term') {
                        shortTermMemory.push(interaction);
                    } else {
                        longTermMemory.push(interaction);
                    }
                } catch (parseError) {
                    logger.error('Failed to parse interaction:', parseError, binding);
                }
            }

            logger.info(`Loaded ${shortTermMemory.length} short-term and ${longTermMemory.length} long-term memories from store ${this.endpoint.query} graph <${this.graphName}>`);
            return [shortTermMemory, longTermMemory];
        } catch (error) {
            logger.error('Error loading history:', error);
            return [[], []];
        }
    }

    async saveMemoryToHistory(memoryStore) {
        if (this.inTransaction) {
            throw new Error('Transaction already in progress');
        }

        try {
            await this.verify();
            await this.beginTransaction();

            const clearQuery = `
                PREFIX mcp: <http://purl.org/stuff/mcp/>
                CLEAR GRAPH <${this.graphName}>
            `;
            await this._executeSparqlUpdate(clearQuery, this.endpoint.update);

            const insertQuery = `
                PREFIX mcp: <http://purl.org/stuff/mcp/>
                PREFIX xsd: <http://www.w3.org/2001/XMLSchema#>

                INSERT DATA {
                    GRAPH <${this.graphName}> {
                        ${this._generateInsertStatements(memoryStore.shortTermMemory, 'short-term')}
                        ${this._generateInsertStatements(memoryStore.longTermMemory, 'long-term')}
                    }
                }
            `;

            await this._executeSparqlUpdate(insertQuery, this.endpoint.update);
            await this.commitTransaction();

            logger.info(`Saved memory to SPARQL store ${this.endpoint.update} graph <${this.graphName}>. Stats: ${memoryStore.shortTermMemory.length} short-term, ${memoryStore.longTermMemory.length} long-term memories`);
        } catch (error) {
            await this.rollbackTransaction();
            logger.error('Error saving to SPARQL store:', error);
            throw error;
        }
    }

    _generateInsertStatements(memories, type) {
        return memories.map((interaction, index) => {
            // Ensure embedding is valid before saving
            let embeddingStr = '[]';
            if (Array.isArray(interaction.embedding)) {
                try {
                    this.validateEmbedding(interaction.embedding);
                    embeddingStr = JSON.stringify(interaction.embedding);
                } catch (error) {
                    logger.error('Invalid embedding in memory:', error);
                }
            }

            // Ensure concepts is valid before saving
            let conceptsStr = '[]';
            if (Array.isArray(interaction.concepts)) {
                conceptsStr = JSON.stringify(interaction.concepts);
            }

            return `
                _:interaction${type}${index} a mcp:Interaction ;
                    mcp:id "${interaction.id}" ;
                    mcp:prompt "${this._escapeSparqlString(interaction.prompt)}" ;
                    mcp:output "${this._escapeSparqlString(interaction.output)}" ;
                    mcp:embedding """${embeddingStr}""" ;
                    mcp:timestamp "${interaction.timestamp}"^^xsd:integer ;
                    mcp:accessCount "${interaction.accessCount}"^^xsd:integer ;
                    mcp:concepts """${conceptsStr}""" ;
                    mcp:decayFactor "${interaction.decayFactor}"^^xsd:decimal ;
                    mcp:memoryType "${type}" .
            `;
        }).join('\n');
    }

    _escapeSparqlString(str) {
        return str.replace(/["\\]/g, '\\$&').replace(/\n/g, '\\n');
    }

    async beginTransaction() {
        if (this.inTransaction) {
            throw new Error('Transaction already in progress');
        }

        this.inTransaction = true;

        const backupQuery = `
            PREFIX mcp: <http://purl.org/stuff/mcp/>
            COPY GRAPH <${this.graphName}> TO GRAPH <${this.graphName}.backup>
        `;
        await this._executeSparqlUpdate(backupQuery, this.endpoint.update);
    }

    async commitTransaction() {
        if (!this.inTransaction) {
            throw new Error('No transaction in progress');
        }

        try {
            const dropBackup = `
                PREFIX mcp: <http://purl.org/stuff/mcp/>
                DROP SILENT GRAPH <${this.graphName}.backup>
            `;
            await this._executeSparqlUpdate(dropBackup, this.endpoint.update);
        } finally {
            this.inTransaction = false;
        }
    }

    async rollbackTransaction() {
        if (!this.inTransaction) {
            throw new Error('No transaction in progress');
        }

        try {
            const restoreQuery = `
                PREFIX mcp: <http://purl.org/stuff/mcp/>
                DROP SILENT GRAPH <${this.graphName}> ;
                MOVE GRAPH <${this.graphName}.backup> TO GRAPH <${this.graphName}>
            `;
            await this._executeSparqlUpdate(restoreQuery, this.endpoint.update);
        } finally {
            this.inTransaction = false;
        }
    }

    async close() {
        if (this.inTransaction) {
            await this.rollbackTransaction();
        }
    }
}

================
File: src/utils/EmbeddingValidator.js
================
// Validates embeddings and handles dimension standardization
export class EmbeddingValidator {
    constructor(config = {}) {
        // Default dimensions for different models
        this.dimensionMap = {
            'nomic-embed-text': 768,
            'qwen2:1.5b': 1536,
            'llama2': 4096,
            'default': 1536
        }

        // Override defaults with config
        Object.assign(this.dimensionMap, config.dimensions || {})
    }

    getDimension(model) {
        return this.dimensionMap[model] || this.dimensionMap.default
    }

    validateEmbedding(embedding, expectedDimension) {
        if (!Array.isArray(embedding)) {
            throw new TypeError('Embedding must be an array')
        }

        if (!embedding.every(x => typeof x === 'number' && !isNaN(x))) {
            throw new TypeError('Embedding must contain only valid numbers')
        }

        const actual = embedding.length
        if (actual !== expectedDimension) {
            throw new Error(`Embedding dimension mismatch: expected ${expectedDimension}, got ${actual}`)
        }

        return true
    }

    standardizeEmbedding(embedding, targetDimension) {
        this.validateEmbedding(embedding, embedding.length)
        const current = embedding.length

        if (current === targetDimension) {
            return embedding
        }

        if (current < targetDimension) {
            // Pad with zeros
            return [...embedding, ...new Array(targetDimension - current).fill(0)]
        }

        // Truncate to target dimension
        return embedding.slice(0, targetDimension)
    }

    // Utility method to check if padding/truncation would be lossy
    wouldBeLossy(embedding, targetDimension) {
        if (embedding.length <= targetDimension) {
            return false
        }

        // Check if truncated values would be non-zero
        return embedding.slice(targetDimension).some(x => Math.abs(x) > 1e-7)
    }
}

================
File: src/utils/FusekiDiscovery.js
================
// src/utils/FusekiDiscovery.js
export class FusekiDiscovery {
    constructor(baseUrl, credentials) {
        this.baseUrl = baseUrl;
        this.auth = Buffer.from(`${credentials.user}:${credentials.password}`).toString('base64');
    }

    async discoverEndpoints(dataset) {
        const endpoints = {
            base: `${this.baseUrl}/${dataset}`,
            query: null,
            update: null,
            gsp: null,
            upload: null
        };

        try {
            // Test SPARQL endpoints
            const sparqlTest = await this.testSparqlEndpoint(`${endpoints.base}`);
            if (sparqlTest) {
                endpoints.query = endpoints.base;
                endpoints.update = endpoints.base;
            }

            // Test GSP endpoints
            const gspTest = await this.testGSPEndpoint(`${endpoints.base}/data`);
            if (gspTest) {
                endpoints.gsp = `${endpoints.base}/data`;
            }

            // Test upload endpoint
            const uploadTest = await this.testUploadEndpoint(`${endpoints.base}/upload`);
            if (uploadTest) {
                endpoints.upload = `${endpoints.base}/upload`;
            }

            return {
                success: true,
                endpoints: this.cleanEndpoints(endpoints)
            };
        } catch (error) {
            return {
                success: false,
                error: error.message,
                endpoints: null
            };
        }
    }

    async testSparqlEndpoint(url) {
        try {
            const response = await fetch(url, {
                method: 'POST',
                headers: {
                    'Authorization': `Basic ${this.auth}`,
                    'Content-Type': 'application/sparql-query',
                    'Accept': 'application/json'
                },
                body: 'ASK { ?s ?p ?o }'
            });
            return response.ok;
        } catch {
            return false;
        }
    }

    async testGSPEndpoint(url) {
        try {
            const response = await fetch(url, {
                method: 'GET',
                headers: {
                    'Authorization': `Basic ${this.auth}`,
                    'Accept': 'text/turtle'
                }
            });
            return response.ok || response.status === 404; // 404 is ok, might mean empty graph
        } catch {
            return false;
        }
    }

    async testUploadEndpoint(url) {
        try {
            const response = await fetch(url, {
                method: 'POST',
                headers: {
                    'Authorization': `Basic ${this.auth}`,
                    'Content-Type': 'text/turtle'
                },
                body: '@prefix test: <http://test.org/> .'
            });
            return response.ok || response.status === 400; // 400 is ok, might mean invalid turtle
        } catch {
            return false;
        }
    }

    cleanEndpoints(endpoints) {
        return Object.fromEntries(
            Object.entries(endpoints).filter(([_, value]) => value !== null)
        );
    }
}

// Usage example:
/*
const discovery = new FusekiDiscovery('http://localhost:4030', {
    user: 'admin',
    password: 'admin123'
});

const endpoints = await discovery.discoverEndpoints('test-mem');
console.log(endpoints);
*/

================
File: src/utils/SPARQLHelpers.js
================
export class SPARQLHelpers {
    static createAuthHeader(user, password) {
        const credentials = Buffer.from(`${user}:${password}`).toString('base64')
        return `Basic ${credentials}`
    }

    static async executeSPARQLUpdate(endpoint, query, auth) {
        const response = await fetch(endpoint, {
            method: 'POST',
            headers: {
                'Content-Type': 'application/sparql-update',
                'Authorization': auth
            },
            body: query
        })

        if (!response.ok) {
            throw new Error(`SPARQL update failed: ${response.status}`)
        }

        return response
    }

    static async executeSPARQLQuery(endpoint, query, auth) {
        const response = await fetch(endpoint, {
            method: 'GET',
            headers: {
                'Accept': 'application/sparql-results+json',
                'Authorization': auth
            },
            body: query
        })

        if (!response.ok) {
            throw new Error(`SPARQL query failed: ${response.status}`)
        }

        return response.json()
    }

    static getDatasetEndpoint(baseUrl, dataset, operation) {
        return `${baseUrl}/${dataset}/${operation}`
    }
}

================
File: src/Config copy 2.js
================
// src/Config.js
export default class Config {
    static defaults = {
        storage: {
            type: 'memory',
            options: {
                path: 'interaction_history.json',
                endpoint: 'http://localhost:8080',
                apiKey: '',
                timeout: 5000
            }
        },
        models: {
            chat: {
                provider: 'ollama',
                model: 'qwen2:1.5b',
                options: {}
            },
            embedding: {
                provider: 'ollama',
                model: 'nomic-embed-text',
                options: {}
            }
        },
        memory: {
            dimension: 1536,
            similarityThreshold: 40,
            contextWindow: 3,
            decayRate: 0.0001
        },
        sparqlEndpoints: [
            {
                label: "test-mem",
                user: "admin",
                password: "admin123",
                urlBase: "http://localhost:4030",
                query: "/test-mem",
                update: "/test-mem",
                upload: "/test-mem/upload",
                gspRead: "/test-mem/data",
                gspWrite: "/test-mem/data"
            }
        ]
    };

    constructor(userConfig = {}) {
        this.config = this.mergeConfigs(Config.defaults, userConfig)
    }

    mergeConfigs(defaults, user) {
        const merged = { ...defaults }
        for (const [key, value] of Object.entries(user)) {
            if (value && typeof value === 'object') {
                merged[key] = this.mergeConfigs(defaults[key] || {}, value)
            } else {
                merged[key] = value
            }
        }
        return merged
    }

    get(path) {
        return path.split('.').reduce((obj, key) => obj && obj[key], this.config)
    }

    set(path, value) {
        const keys = path.split('.')
        const last = keys.pop()
        const target = keys.reduce((obj, key) => obj[key] = obj[key] || {}, this.config)
        target[last] = value
    }
}

================
File: src/Config copy 3.js
================
export default class Config {
    static defaults = {
        storage: {
            type: 'memory',
            options: {
                path: 'interaction_history.json',
                endpoint: 'http://localhost:8080',
                apiKey: '',
                timeout: 5000
            }
        },
        models: {
            chat: {
                provider: 'ollama',
                model: 'qwen2:1.5b',
                options: {}
            },
            embedding: {
                provider: 'ollama',
                model: 'nomic-embed-text',
                options: {}
            }
        },
        memory: {
            dimension: 1536,
            similarityThreshold: 40,
            contextWindow: 3,
            decayRate: 0.0001
        },
        sparqlEndpoints: [
            {
                label: "test-mem",
                user: "admin",
                password: "admin123",
                urlBase: "http://localhost:4030",
                query: "/test-mem",
                update: "/test-mem",
                upload: "/test-mem/upload",
                gspRead: "/test-mem/data",
                gspWrite: "/test-mem/data"
            }
        ]
    };

    constructor(userConfig = {}) {
        this.initialized = false
        this.config = {}
    }

    async init() {
        if (this.initialized) return

        try {
            // Load environment variables if needed
            // await this.loadEnv();

            // Deep merge defaults with user config
            this.config = this.mergeConfigs(Config.defaults, this.userConfig)

            // Validate configuration
            this.validateConfig()

            this.initialized = true
        } catch (error) {
            throw new Error(`Config initialization failed: ${error.message}`)
        }
    }

    mergeConfigs(defaults, user) {
        const merged = { ...defaults }
        for (const [key, value] of Object.entries(user)) {
            if (value && typeof value === 'object') {
                merged[key] = this.mergeConfigs(defaults[key] || {}, value)
            } else {
                merged[key] = value
            }
        }
        return merged
    }

    validateConfig() {
        const required = ['storage', 'models', 'sparqlEndpoints']
        for (const key of required) {
            if (!this.config[key]) {
                throw new Error(`Missing required config section: ${key}`)
            }
        }
    }

    async get(path) {
        if (!this.initialized) {
            await this.init()
        }
        return path.split('.').reduce((obj, key) => obj && obj[key], this.config)
    }

    async set(path, value) {
        if (!this.initialized) {
            await this.init()
        }
        const keys = path.split('.')
        const last = keys.pop()
        const target = keys.reduce((obj, key) => obj[key] = obj[key] || {}, this.config)
        target[last] = value
    }

    static async create(userConfig = {}) {
        const config = new Config(userConfig)
        await config.init()
        return config
    }
}

================
File: src/Config copy 4.js
================
export default class Config {
    static defaults = {
        storage: {
            type: 'memory',
            options: {
                path: 'interaction_history.json',
                endpoint: 'http://localhost:8080',
                apiKey: '',
                timeout: 5000
            }
        },
        models: {
            chat: {
                provider: 'ollama',
                model: 'qwen2:1.5b',
                options: {}
            },
            embedding: {
                provider: 'ollama',
                model: 'nomic-embed-text',
                options: {}
            }
        },
        memory: {
            dimension: 1536,
            similarityThreshold: 40,
            contextWindow: 3,
            decayRate: 0.0001
        },
        sparqlEndpoints: [
            {
                label: "test-mem",
                user: "admin",
                password: "admin123",
                urlBase: "http://localhost:4030",
                query: "/test-mem",
                update: "/test-mem",
                upload: "/test-mem/upload",
                gspRead: "/test-mem/data",
                gspWrite: "/test-mem/data"
            }
        ]
    };

    constructor(userConfig = {}) {
        this.initialized = false
        this.config = {}
        this.userConfig = userConfig
    }

    async init() {
        if (this.initialized) return

        try {
            this.config = this.mergeConfigs(Config.defaults, this.userConfig || {})
            this.validateConfig()
            this.initialized = true
        } catch (error) {
            throw new Error(`Config initialization failed: ${error.message}`)
        }
    }

    mergeConfigs(defaults, user) {
        const merged = { ...defaults }

        for (const [key, value] of Object.entries(user)) {
            if (value && typeof value === 'object' && !Array.isArray(value)) {
                merged[key] = this.mergeConfigs(merged[key] || {}, value)
            } else {
                merged[key] = value
            }
        }
        return merged
    }

    validateConfig() {
        const required = ['storage', 'models', 'sparqlEndpoints']
        for (const key of required) {
            if (!this.config[key]) {
                throw new Error(`Missing required config section: ${key}`)
            }
        }
    }

    async get(path) {
        if (!this.initialized) {
            await this.init()
        }
        return path.split('.').reduce((obj, key) => obj && obj[key], this.config)
    }

    async set(path, value) {
        if (!this.initialized) {
            await this.init()
        }
        const keys = path.split('.')
        const last = keys.pop()
        const target = keys.reduce((obj, key) => {
            if (!obj[key]) obj[key] = {}
            return obj[key]
        }, this.config)
        target[last] = value
    }

    static async create(userConfig = {}) {
        const config = new Config(userConfig)
        await config.init()
        return config
    }
}

================
File: src/Config.js
================
export default class Config {
    static defaults = {

        storage: {
            type: 'memory',
            options: {
                path: 'interaction_history.json',
                endpoint: 'http://localhost:8080',
                apiKey: '',
                timeout: 5000
            }
        },
        models: {
            chat: {
                provider: 'ollama',
                model: 'qwen2:1.5b',
                options: {}
            },
            embedding: {
                provider: 'ollama',
                model: 'nomic-embed-text',
                options: {}
            }
        },
        memory: {
            dimension: 1536,
            similarityThreshold: 40,
            contextWindow: 3,
            decayRate: 0.0001
        },
        sparqlEndpoints: [
            {
                label: "test-mem",
                user: "admin",
                password: "admin123",
                urlBase: "http://localhost:4030",
                dataset: "test-mem"  // Match Fuseki dataset name
                //     query: "/test-mem",
                //   update: "/test-mem",
                // upload: "/test-mem/upload",
                // gspRead: "/test-mem/data",
                // gspWrite: "/test-mem/data"
            }
        ]
    };

    constructor(userConfig = {}) {
        this.initialized = false
        this.config = {}
        this.userConfig = userConfig
    }

    async init() {
        if (this.initialized) return

        try {
            this.config = this.mergeConfigs(Config.defaults, this.userConfig || {})
            this.validateConfig()
            this.initialized = true
        } catch (error) {
            throw new Error(`Config initialization failed: ${error.message}`)
        }
    }

    mergeConfigs(defaults, user) {
        const merged = { ...defaults }

        for (const [key, value] of Object.entries(user)) {
            if (value && typeof value === 'object' && !Array.isArray(value)) {
                merged[key] = this.mergeConfigs(merged[key] || {}, value)
            } else {
                merged[key] = value
            }
        }
        return merged
    }

    validateConfig() {
        const required = ['storage', 'models', 'sparqlEndpoints']
        for (const key of required) {
            if (!this.config[key]) {
                throw new Error(`Missing required config section: ${key}`)
            }
        }
    }

    async get(path) {
        if (!this.initialized) {
            await this.init()
        }
        return path.split('.').reduce((obj, key) => obj && obj[key], this.config)
    }

    async set(path, value) {
        if (!this.initialized) {
            await this.init()
        }
        const keys = path.split('.')
        const last = keys.pop()
        const target = keys.reduce((obj, key) => {
            if (!obj[key]) obj[key] = {}
            return obj[key]
        }, this.config)
        target[last] = value
    }

    static async create(userConfig = {}) {
        const config = new Config(userConfig)
        await config.init()
        return config
    }
}

================
File: src/ContextManager.js
================
import ContextWindowManager from './ContextWindowManager.js'
import { logger } from './Utils.js';

export default class ContextManager {
    constructor(options = {}) {
        this.maxTokens = options.maxTokens || 8192;
        this.maxTimeWindow = options.maxTimeWindow || 24 * 60 * 60 * 1000; // 24 hours
        this.relevanceThreshold = options.relevanceThreshold || 0.7;
        this.maxContextSize = options.maxContextSize || 5;
        this.contextBuffer = [];

        this.windowManager = new ContextWindowManager({
            maxWindowSize: this.maxTokens,
            minWindowSize: Math.floor(this.maxTokens / 4),
            overlapRatio: options.overlapRatio || 0.1
        });
    }

    addToContext(interaction, similarity = 1.0) {
        this.contextBuffer.push({
            ...interaction,
            similarity,
            addedAt: Date.now()
        });

        // Keep buffer size manageable
        if (this.contextBuffer.length > this.maxContextSize * 2) {
            this.pruneContext();
        }
    }

    pruneContext() {
        const now = Date.now();
        this.contextBuffer = this.contextBuffer
            .filter(item => {
                const age = now - item.addedAt;
                return age < this.maxTimeWindow && item.similarity >= this.relevanceThreshold;
            })
            .sort((a, b) => b.similarity - a.similarity)
            .slice(0, this.maxContextSize);
    }

    summarizeContext(interactions) {
        // Group interactions by topic/concept
        const groupedInteractions = {};

        for (const interaction of interactions) {
            const mainConcept = interaction.concepts?.[0] || 'general';
            if (!groupedInteractions[mainConcept]) {
                groupedInteractions[mainConcept] = [];
            }
            groupedInteractions[mainConcept].push(interaction);
        }

        // Create summaries for each group
        const summaries = [];
        for (const [concept, group] of Object.entries(groupedInteractions)) {
            if (group.length === 1) {
                summaries.push(this.formatSingleInteraction(group[0]));
            } else {
                summaries.push(this.formatGroupSummary(concept, group));
            }
        }

        return summaries.join('\n\n');
    }

    formatSingleInteraction(interaction) {
        return `Q: ${interaction.prompt}\nA: ${interaction.output}`;
    }

    formatGroupSummary(concept, interactions) {
        const summary = `Topic: ${concept}\n` +
            interactions
                .slice(0, 3) // Limit number of examples per group
                .map(i => `- ${i.prompt} → ${i.output.substring(0, 50)}...`)
                .join('\n');
        return summary;
    }

    buildContext(currentPrompt, retrievals = [], recentInteractions = [], options = {}) {
        this.pruneContext();

        // Add new relevant interactions to context
        retrievals.forEach(retrieval => {
            this.addToContext(retrieval.interaction, retrieval.similarity);
        });

        // Add recent interactions with high relevance
        recentInteractions.forEach(interaction => {
            this.addToContext(interaction, 0.9); // High base relevance for recent interactions
        });

        const contextParts = [];

        // Add system context if provided
        if (options.systemContext) {
            contextParts.push(`System Context: ${options.systemContext}`);
        }

        // Add summarized historical context
        const historicalContext = this.summarizeContext(
            this.contextBuffer.slice(0, this.maxContextSize)
        );

        if (historicalContext) {
            contextParts.push('Relevant Context:', historicalContext);
        }

        const fullContext = contextParts.join('\n\n');

        // Process context through window manager if it might exceed limits
        if (this.windowManager.estimateTokens(fullContext) > this.maxTokens) {
            const windows = this.windowManager.processContext(fullContext);
            return this.windowManager.mergeOverlappingContent(windows);
        }

        return fullContext;
    }
}

================
File: src/ContextWindowManager.js
================
// Manages sliding context windows with overlap
export default class ContextWindowManager {
    constructor(options = {}) {
        this.minWindowSize = options.minWindowSize || 1024
        this.maxWindowSize = options.maxWindowSize || 8192
        this.overlapRatio = options.overlapRatio || 0.1
        this.avgTokenLength = options.avgTokenLength || 4
    }

    estimateTokens(text) {
        return Math.ceil(text.length / this.avgTokenLength)
    }

    calculateWindowSize(input) {
        const estimatedTokens = this.estimateTokens(input)
        const windowSize = Math.min(
            this.maxWindowSize,
            Math.max(
                this.minWindowSize,
                estimatedTokens * 1.2
            )
        )
        return windowSize
    }

    createWindows(text, windowSize) {
        const windows = []
        const overlapSize = Math.floor(windowSize * this.overlapRatio)
        const stride = windowSize - overlapSize

        for (let position = 0; position < text.length; position += stride) {
            const window = {
                text: text.slice(position, position + windowSize),
                start: position,
                end: Math.min(position + windowSize, text.length)
            }
            windows.push(window)

            if (position + windowSize >= text.length) {
                if (position < text.length) {
                    windows.push({
                        text: text.slice(position),
                        start: position,
                        end: text.length
                    })
                }
                break
            }
        }

        return windows
    }

    mergeOverlappingContent(windows) {
        if (windows.length === 0) return ''
        if (windows.length === 1) return windows[0].text

        let merged = windows[0].text
        for (let i = 1; i < windows.length; i++) {
            const prevText = merged
            const currText = windows[i].text
            const overlapSize = this._findBestOverlap(
                prevText.slice(-this.maxWindowSize),
                currText,
                Math.floor(this.minWindowSize * this.overlapRatio)
            )

            // Only add non-overlapping portion
            merged += currText.slice(overlapSize)
        }

        return merged
    }

    _findBestOverlap(end, start, minOverlap = 10) {
        const maxCheck = Math.min(end.length, start.length)

        // Try to find largest matching section
        for (let overlap = maxCheck; overlap >= minOverlap; overlap--) {
            const endSlice = end.slice(-overlap)
            const startSlice = start.slice(0, overlap)

            // Full word boundary match if possible
            if (endSlice === startSlice) {
                const isWordBoundary = (
                    overlap === maxCheck ||
                    endSlice[0].match(/\s/) ||
                    startSlice[overlap - 1].match(/\s/)
                )
                if (isWordBoundary) {
                    return overlap
                }
            }
        }

        // Fallback to character-level match
        for (let overlap = maxCheck; overlap >= minOverlap; overlap--) {
            if (end.slice(-overlap) === start.slice(0, overlap)) {
                return overlap
            }
        }

        return 0
    }

    processContext(context, options = {}) {
        const windowSize = this.calculateWindowSize(context)
        const windows = this.createWindows(context, windowSize)

        if (options.includeMetadata) {
            return windows.map(window => ({
                ...window,
                tokenEstimate: this.estimateTokens(window.text)
            }))
        }

        return windows
    }
}

================
File: src/index.js
================
// index.js
import { config } from './_old/config.js'

async function init() {
  await config.load()
  // rest of application logic
}

init().catch(console.error)

================
File: src/MemoryManager copy 2.js
================
import { v4 as uuidv4 } from 'uuid'
import MemoryStore from './stores/MemoryStore.js'
import InMemoryStore from './stores/InMemoryStore.js'
import ContextManager from './ContextManager.js'
import PromptTemplates from './PromptTemplates.js'
import { logger } from './Utils.js'

export default class MemoryManager {
    constructor({
        llmProvider,
        chatModel = 'claude-3-opus-20240229',
        embeddingModel = 'claude-3-opus-20240229',
        storage = null,
        dimension = 1536,
        contextOptions = {
            maxTokens: 8192
        },
        cacheOptions = {
            maxSize: 1000,
            ttl: 3600000
        }
    }) {
        if (!llmProvider) {
            throw new Error('LLM provider is required')
        }

        this.llmProvider = llmProvider
        this.chatModel = chatModel
        this.embeddingModel = embeddingModel
        this.dimension = dimension
        this.cacheOptions = cacheOptions

        // Initialize embedding cache
        this.embeddingCache = new Map()
        this.cacheTimestamps = new Map()

        try {
            this.store = new MemoryStore(this.dimension)
            this.storage = storage || new InMemoryStore()
            this.contextManager = new ContextManager(contextOptions)
        } catch (error) {
            logger.error('Failed to initialize MemoryManager:', error)
            throw new Error('Memory manager initialization failed: ' + error.message)
        }

        this.initialize()

        // Set up cache cleanup interval
        this.cleanupInterval = setInterval(() => {
            this.cleanupCache()
        }, cacheOptions.ttl / 2)
    }

    async initialize() {
        try {
            const [shortTerm, longTerm] = await this.storage.loadHistory()

            for (const interaction of shortTerm) {
                const embedding = this.standardizeEmbedding(interaction.embedding)
                interaction.embedding = embedding
                this.store.addInteraction(interaction)
            }

            this.store.longTermMemory.push(...longTerm)
            this.store.clusterInteractions()

            logger.info(`Memory initialized with ${shortTerm.length} short-term and ${longTerm.length} long-term memories`)
        } catch (error) {
            logger.error('Memory initialization failed:', error)
            throw error
        }
    }

    cleanupCache() {
        const now = Date.now()
        for (const [key, timestamp] of this.cacheTimestamps.entries()) {
            if (now - timestamp > this.cacheOptions.ttl) {
                this.embeddingCache.delete(key)
                this.cacheTimestamps.delete(key)
            }
        }

        while (this.embeddingCache.size > this.cacheOptions.maxSize) {
            let oldestKey = null
            let oldestTime = Infinity

            for (const [key, timestamp] of this.cacheTimestamps.entries()) {
                if (timestamp < oldestTime) {
                    oldestTime = timestamp
                    oldestKey = key
                }
            }

            if (oldestKey) {
                this.embeddingCache.delete(oldestKey)
                this.cacheTimestamps.delete(oldestKey)
            }
        }
    }

    getCacheKey(text) {
        return `${this.embeddingModel}:${text.slice(0, 100)}`
    }

    async generateEmbedding(text) {
        const cacheKey = this.getCacheKey(text)

        if (this.embeddingCache.has(cacheKey)) {
            const cached = this.embeddingCache.get(cacheKey)
            this.cacheTimestamps.set(cacheKey, Date.now())
            return cached
        }

        try {
            const embedding = await this.llmProvider.generateEmbedding(
                this.embeddingModel,
                text
            )

            this.embeddingCache.set(cacheKey, embedding)
            this.cacheTimestamps.set(cacheKey, Date.now())

            if (this.embeddingCache.size > this.cacheOptions.maxSize) {
                this.cleanupCache()
            }

            return embedding
        } catch (error) {
            logger.error('Error generating embedding:', error)
            throw error
        }
    }

    validateEmbedding(embedding) {
        if (!Array.isArray(embedding)) {
            throw new TypeError('Embedding must be an array')
        }
        if (!embedding.every(x => typeof x === 'number' && !isNaN(x))) {
            throw new TypeError('Embedding must contain only valid numbers')
        }
    }

    standardizeEmbedding(embedding) {
        this.validateEmbedding(embedding)
        const current = embedding.length
        if (current === this.dimension) return embedding

        if (current < this.dimension) {
            return [...embedding, ...new Array(this.dimension - current).fill(0)]
        }
        return embedding.slice(0, this.dimension)
    }

    async addInteraction(prompt, output, embedding, concepts) {
        try {
            this.validateEmbedding(embedding)
            const standardizedEmbedding = this.standardizeEmbedding(embedding)

            const interaction = {
                id: uuidv4(),
                prompt,
                output,
                embedding: standardizedEmbedding,
                timestamp: Date.now(),
                accessCount: 1,
                concepts,
                decayFactor: 1.0
            }

            this.store.addInteraction(interaction)
            await this.storage.saveMemoryToHistory(this.store)
        } catch (error) {
            logger.error('Failed to add interaction:', error)
            throw error
        }
    }

    async retrieveRelevantInteractions(query, similarityThreshold = 40, excludeLastN = 0) {
        try {
            const queryEmbedding = await this.generateEmbedding(query)
            const queryConcepts = await this.extractConcepts(query)
            return this.store.retrieve(queryEmbedding, queryConcepts, similarityThreshold, excludeLastN)
        } catch (error) {
            logger.error('Failed to retrieve relevant interactions:', error)
            throw error
        }
    }

    async extractConcepts(text) {
        logger.info('Extracting concepts...')
        try {
            const prompt = PromptTemplates.formatConceptPrompt(this.chatModel, text)
            const response = await this.llmProvider.generateCompletion(
                this.chatModel,
                prompt,
                { temperature: 0.2 }
            )

            const match = response.match(/\[.*\]/)
            if (match) {
                const concepts = JSON.parse(match[0])
                logger.info('Extracted concepts:', concepts)
                return concepts
            }

            logger.info('No concepts extracted, returning empty array')
            return []
        } catch (error) {
            logger.error('Error extracting concepts:', error)
            return []
        }
    }

    async generateResponse(prompt, lastInteractions = [], retrievals = [], contextWindow = 3) {
        const context = this.contextManager.buildContext(
            prompt,
            retrievals,
            lastInteractions,
            { systemContext: "You're a helpful assistant with memory of past interactions." }
        )

        try {
            const messages = PromptTemplates.formatChatPrompt(
                this.chatModel,
                "You're a helpful assistant with memory of past interactions.",
                context,
                prompt
            )

            const response = await this.llmProvider.generateChat(
                this.chatModel,
                messages,
                { temperature: 0.7 }
            )

            return response.trim()
        } catch (error) {
            logger.error('Error generating response:', error)
            throw error
        }
    }

    async dispose() {
        logger.info('Starting MemoryManager shutdown...')

        if (this.cleanupInterval) {
            clearInterval(this.cleanupInterval)
        }

        try {
            await this.storage.saveMemoryToHistory(this.store)
            logger.info('Final memory state saved')
        } catch (error) {
            logger.error('Error saving final memory state:', error)
        }

        this.embeddingCache.clear()
        this.cacheTimestamps.clear()

        if (this.storage && typeof this.storage.close === 'function') {
            await this.storage.close()
        }

        this.store = null
        this.llmProvider = null

        logger.info('MemoryManager shutdown complete')
    }
}

================
File: src/MemoryManager.js
================
import { v4 as uuidv4 } from 'uuid'
import MemoryStore from './stores/MemoryStore.js'
import InMemoryStore from './stores/InMemoryStore.js'
import ContextManager from './ContextManager.js'
import PromptTemplates from './PromptTemplates.js'
import log from 'loglevel'

export default class MemoryManager {
    constructor({
        llmProvider,
        chatModel = 'claude-3-opus-20240229',
        embeddingModel = 'claude-3-opus-20240229',
        storage = null,
        dimension = 1536,
        contextOptions = {
            maxTokens: 8192
        },
        cacheOptions = {
            maxSize: 1000,
            ttl: 3600000
        }
    }) {
        if (!llmProvider) {
            throw new Error('LLM provider is required')
        }

        this.llmProvider = llmProvider
        this.chatModel = chatModel
        this.embeddingModel = embeddingModel
        this.dimension = dimension
        this.cacheOptions = cacheOptions
        this.logger = log.getLogger('MemoryManager')
        this.logger.setLevel('debug')

        // Initialize embedding cache
        this.embeddingCache = new Map()
        this.cacheTimestamps = new Map()
        this.memStore = new MemoryStore(this.dimension)
        this.storage = storage || new InMemoryStore()
        this.contextManager = new ContextManager(contextOptions)

        this.initialize()

        // Set up cache cleanup interval
        this.cleanupInterval = setInterval(() => {
            this.cleanupCache()
        }, cacheOptions.ttl / 2)
    }

    async initialize() {
        try {
            const [shortTerm, longTerm] = await this.storage.loadHistory()
            this.logger.info(`Loading memory history: ${shortTerm.length} short-term, ${longTerm.length} long-term items`)

            for (const interaction of shortTerm) {
                const embedding = this.standardizeEmbedding(interaction.embedding)
                interaction.embedding = embedding
                this.memStore.shortTermMemory.push(interaction)
                this.memStore.embeddings.push(embedding)
                this.memStore.timestamps.push(interaction.timestamp)
                this.memStore.accessCounts.push(interaction.accessCount)
                this.memStore.conceptsList.push(interaction.concepts)
            }

            this.memStore.longTermMemory.push(...longTerm)
            this.memStore.clusterInteractions()

            this.logger.info('Memory initialization complete')
        } catch (error) {
            this.logger.error('Memory initialization failed:', error)
            throw error
        }
    }

    cleanupCache() {
        const now = Date.now()
        let removed = 0

        for (const [key, timestamp] of this.cacheTimestamps.entries()) {
            if (now - timestamp > this.cacheOptions.ttl) {
                this.embeddingCache.delete(key)
                this.cacheTimestamps.delete(key)
                removed++
            }
        }

        if (removed > 0) {
            this.logger.debug(`Cache cleanup: removed ${removed} expired entries`)
        }

        while (this.embeddingCache.size > this.cacheOptions.maxSize) {
            let oldestKey = null
            let oldestTime = Infinity

            for (const [key, timestamp] of this.cacheTimestamps.entries()) {
                if (timestamp < oldestTime) {
                    oldestTime = timestamp
                    oldestKey = key
                }
            }

            if (oldestKey) {
                this.embeddingCache.delete(oldestKey)
                this.cacheTimestamps.delete(oldestKey)
                this.logger.debug('Cache cleanup: removed oldest entry to maintain size limit')
            }
        }
    }

    getCacheKey(text) {
        return `${this.embeddingModel}:${text.slice(0, 100)}`
    }

    async generateEmbedding(text) {
        const cacheKey = this.getCacheKey(text)
        this.logger.debug(`Generating embedding for text: ${text.slice(0, 50)}...`)

        if (this.embeddingCache.has(cacheKey)) {
            this.logger.debug('Using cached embedding')
            const cached = this.embeddingCache.get(cacheKey)
            this.cacheTimestamps.set(cacheKey, Date.now())
            return cached
        }

        try {
            const embedding = await this.llmProvider.generateEmbedding(
                this.embeddingModel,
                text
            )

            this.embeddingCache.set(cacheKey, embedding)
            this.cacheTimestamps.set(cacheKey, Date.now())

            if (this.embeddingCache.size > this.cacheOptions.maxSize) {
                this.cleanupCache()
            }

            return embedding
        } catch (error) {
            this.logger.error('Error generating embedding:', error)
            throw error
        }
    }

    validateEmbedding(embedding) {
        if (!Array.isArray(embedding)) {
            throw new TypeError('Embedding must be an array')
        }
        if (!embedding.every(x => typeof x === 'number' && !isNaN(x))) {
            throw new TypeError('Embedding must contain only valid numbers')
        }
    }

    standardizeEmbedding(embedding) {
        this.validateEmbedding(embedding)
        const current = embedding.length
        if (current === this.dimension) return embedding

        if (current < this.dimension) {
            return [...embedding, ...new Array(this.dimension - current).fill(0)]
        }
        return embedding.slice(0, this.dimension)
    }

    async addInteraction(prompt, output, embedding, concepts) {
        this.logger.debug(`Adding interaction: ${prompt.slice(0, 50)}...`)

        try {
            this.validateEmbedding(embedding)
            const standardizedEmbedding = this.standardizeEmbedding(embedding)

            const interaction = {
                id: uuidv4(),
                prompt,
                output,
                embedding: standardizedEmbedding,
                timestamp: Date.now(),
                accessCount: 1,
                concepts,
                decayFactor: 1.0
            }

            this.memStore.shortTermMemory.push(interaction)
            this.memStore.embeddings.push(standardizedEmbedding)
            this.memStore.timestamps.push(interaction.timestamp)
            this.memStore.accessCounts.push(interaction.accessCount)
            this.memStore.conceptsList.push(interaction.concepts)

            await this.storage.saveMemoryToHistory(this.memStore)
            this.logger.info('Interaction added successfully')

        } catch (error) {
            this.logger.error('Failed to add interaction:', error)
            throw error
        }
    }

    async retrieveRelevantInteractions(query, similarityThreshold = 40, excludeLastN = 0) {
        this.logger.debug(`Retrieving relevant interactions for: ${query.slice(0, 50)}...`)

        try {
            const queryEmbedding = await this.generateEmbedding(query)
            const queryConcepts = await this.extractConcepts(query)
            return this.memStore.retrieve(queryEmbedding, queryConcepts, similarityThreshold, excludeLastN)
        } catch (error) {
            this.logger.error('Failed to retrieve relevant interactions:', error)
            throw error
        }
    }

    async extractConcepts(text) {
        this.logger.info('Extracting concepts...')
        try {
            const prompt = PromptTemplates.formatConceptPrompt(this.chatModel, text)
            const response = await this.llmProvider.generateCompletion(
                this.chatModel,
                prompt,
                { temperature: 0.2 }
            )

            const match = response.match(/\[.*\]/)
            if (match) {
                const concepts = JSON.parse(match[0])
                this.logger.info('Extracted concepts:', concepts)
                return concepts
            }

            this.logger.info('No concepts extracted, returning empty array')
            return []
        } catch (error) {
            this.logger.error('Error extracting concepts:', error)
            return []
        }
    }

    async generateResponse(prompt, lastInteractions = [], retrievals = [], contextWindow = 3) {
        this.logger.debug(`Generating response for: ${prompt.slice(0, 50)}...`)

        const context = this.contextManager.buildContext(
            prompt,
            retrievals,
            lastInteractions,
            { systemContext: "You're a helpful assistant with memory of past interactions." }
        )

        try {
            const messages = PromptTemplates.formatChatPrompt(
                this.chatModel,
                "You're a helpful assistant with memory of past interactions.",
                context,
                prompt
            )

            const response = await this.llmProvider.generateChat(
                this.chatModel,
                messages,
                { temperature: 0.7 }
            )

            return response.trim()
        } catch (error) {
            this.logger.error('Error generating response:', error)
            throw error
        }
    }

    async dispose() {
        this.logger.info('Starting MemoryManager shutdown...')

        if (this.cleanupInterval) {
            clearInterval(this.cleanupInterval)
        }

        try {
            await this.storage.saveMemoryToHistory(this.memStore)
            this.logger.info('Final memory state saved')
        } catch (error) {
            this.logger.error('Error saving final memory state:', error)
        }

        this.embeddingCache.clear()
        this.cacheTimestamps.clear()

        if (this.storage && typeof this.storage.close === 'function') {
            await this.storage.close()
        }

        this.memStore = null
        this.llmProvider = null

        this.logger.info('MemoryManager shutdown complete')
    }
}

================
File: src/PromptTemplates.js
================
// src/promptTemplates.js
export default class PromptTemplates {
    static templates = {
        'llama2': {
            chat: (system, context, query) => {
                const messages = [{
                    role: 'system',
                    content: system
                }];

                if (context) {
                    messages.push({
                        role: 'user',
                        content: context
                    });
                    messages.push({
                        role: 'assistant',
                        content: 'I understand the context provided. How can I help with your query?'
                    });
                }

                messages.push({
                    role: 'user',
                    content: query
                });

                return messages;
            },
            completion: (context, query) => {
                return `[INST] ${context ? `Context:\n${context}\n\n` : ''}Query: ${query} [/INST]`;
            },
            extractConcepts: (text) => {
                return `[INST] Extract key concepts from the following text and return them as a JSON array of strings only. Example: ["concept1", "concept2"]. Text: "${text}" [/INST]`;
            }
        },

        'mistral': {
            chat: (system, context, query) => {
                const messages = [{
                    role: 'system',
                    content: system
                }];

                if (context) {
                    messages.push({
                        role: 'user',
                        content: `Previous Context:\n${context}`
                    });
                    messages.push({
                        role: 'assistant',
                        content: 'Context received. What would you like to know?'
                    });
                }

                messages.push({
                    role: 'user',
                    content: query
                });

                return messages;
            },
            completion: (context, query) => {
                return `<s>[INST] ${context ? `${context}\n\n` : ''}${query} [/INST]`;
            },
            extractConcepts: (text) => {
                return `<s>[INST] Extract and return only a JSON array of key concepts from: "${text}" [/INST]`;
            }
        }
    };

    static getTemplateForModel(modelName) {
        // Handle model name variants
        const baseModel = modelName.split(':')[0].toLowerCase();
        const modelFamily = baseModel.replace(/[\d.]/g, ''); // Remove version numbers
        return this.templates[modelFamily] || this.templates['llama2'];
    }

    static formatChatPrompt(modelName, system, context, query) {
        const template = this.getTemplateForModel(modelName);
        return template.chat(system, context, query);
    }

    static formatCompletionPrompt(modelName, context, query) {
        const template = this.getTemplateForModel(modelName);
        return template.completion(context, query);
    }

    static formatConceptPrompt(modelName, text) {
        const template = this.getTemplateForModel(modelName);
        return template.extractConcepts(text);
    }

    static registerTemplate(modelName, template) {
        if (!template.chat || !template.completion || !template.extractConcepts) {
            throw new Error('Template must implement chat, completion, and extractConcepts methods');
        }
        this.templates[modelName.toLowerCase()] = template;
    }
}

================
File: src/SPARQLExample.js
================
import Config from './Config.js';
import SPARQLStore from './stores/SPARQLStore.js';
import MemoryManager from './MemoryManager.js';
import OllamaConnector from './connectors/OllamaConnector.js';

async function main() {
    // Initialize configuration
    const config = new Config({
        storage: {
            type: 'sparql',
            options: {
                graphName: 'http://example.org/mcp/memory'
            }
        }
    });

    // Get SPARQL endpoint configuration
    const sparqlConfig = config.get('sparqlEndpoints')[0];

    // Initialize SPARQL store
    const store = new SPARQLStore({
        query: `${sparqlConfig.urlBase}${sparqlConfig.query}`,
        update: `${sparqlConfig.urlBase}${sparqlConfig.update}`
    }, {
        user: sparqlConfig.user,
        password: sparqlConfig.password,
        graphName: config.get('storage.options.graphName')
    });

    // Initialize other components
    const ollama = new OllamaConnector();
    const memoryManager = new MemoryManager({
        llmProvider: ollama,
        chatModel: config.get('models.chat.model'),
        embeddingModel: config.get('models.embedding.model'),
        storage: store
    });

    // Example usage
    const prompt = "How can Semantic Web technologies be used with AI?";
    try {
        const relevantInteractions = await memoryManager.retrieveRelevantInteractions(prompt);
        const response = await memoryManager.generateResponse(prompt, [], relevantInteractions);
        console.log('Response:', response);

        const embedding = await memoryManager.generateEmbedding(`${prompt} ${response}`);
        const concepts = await memoryManager.extractConcepts(`${prompt} ${response}`);
        await memoryManager.addInteraction(prompt, response, embedding, concepts);
    } catch (error) {
        console.error('Error:', error);
    } finally {
        await store.close();
    }
}

main().catch(console.error);

================
File: src/Utils.js
================
// Logging utility
export const logger = {
    info: (...args) => console.log('[INFO]', ...args),
    error: (...args) => console.error('[ERROR]', ...args),
    debug: (...args) => console.debug('[DEBUG]', ...args)
};

// Helper functions for vector operations
export const vectorOps = {
    normalize: (vector) => {
        const magnitude = Math.sqrt(vector.reduce((sum, val) => sum + val * val, 0));
        return vector.map(val => val / magnitude);
    },
    
    cosineSimilarity: (vec1, vec2) => {
        const dotProduct = vec1.reduce((sum, val, i) => sum + val * vec2[i], 0);
        const mag1 = Math.sqrt(vec1.reduce((sum, val) => sum + val * val, 0));
        const mag2 = Math.sqrt(vec2.reduce((sum, val) => sum + val * val, 0));
        return dotProduct / (mag1 * mag2);
    }
};

================
File: tests/bash/check_fuseki.sh
================
#!/bin/bash

echo -e "\nAdding test data..."
curl -v POST http://localhost:4030/test-mem \
  -H "Authorization: Basic $(echo -n 'admin:admin123' | base64)" \
  -H "Content-Type: application/sparql-update" \
  --data "INSERT DATA { <http://example/s> <http://example/p> <http://example/o> }"

echo -e "\nQuerying..."
curl -v GET http://localhost:4030/test-mem \
  -H "Authorization: Basic $(echo -n 'admin:admin123' | base64)" \
  -H "Content-Type: application/sparql-query" \
  -H "Accept: application/sparql-results+json" \
  --data "SELECT * WHERE { ?s ?p ?o }"


echo -e "\nQuerying data (SELECT)..."
curl -v POST http://localhost:4030/test-mem \
  -H "Authorization: Basic $(echo -n 'admin:admin123' | base64)" \
  -H "Content-Type: application/sparql-query" \
  -H "Accept: application/sparql-results+json" \
  --data "SELECT * WHERE { ?s ?p ?o }"




####################################
echo "Waiting for Fuseki to be ready..."
until curl -s http://localhost:4030/$/ping > /dev/null; do
    echo "Waiting for Fuseki..."
    sleep 2
done
echo "Fuseki is up!"

# Check datasets
echo "Checking datasets..."
curl -X GET http://localhost:4030/$/datasets \
  -H "Authorization: Basic $(echo -n 'admin:admin123' | base64)" && echo -e "\nDataset check - It works!"

echo -e "\nAdding test data..."
curl -X POST http://localhost:4030/ds \
  -H "Authorization: Basic $(echo -n 'admin:admin123' | base64)" \
  -H "Content-Type: application/sparql-update" \
  --data "INSERT DATA { <http://example/s> <http://example/p> <http://example/o> }" && echo "Insert - It works!"

echo -e "\nQuerying data (SELECT)..."
curl -X POST http://localhost:4030/ds \
  -H "Authorization: Basic $(echo -n 'admin:admin123' | base64)" \
  -H "Content-Type: application/sparql-query" \
  -H "Accept: application/sparql-results+json" \
  --data "SELECT * WHERE { ?s ?p ?o }" && echo "Select - It works!"

echo -e "\nQuerying data (CONSTRUCT)..."
curl -X POST http://localhost:4030/ds \
  -H "Authorization: Basic $(echo -n 'admin:admin123' | base64)" \
  -H "Content-Type: application/sparql-query" \
  -H "Accept: text/turtle" \
  --data "CONSTRUCT { ?s ?p ?o } WHERE { ?s ?p ?o }" && echo "Construct - It works!"

================
File: tests/bash/test-endpoints.sh
================
#!/bin/bash

# Configuration
BASE_URL="http://localhost:4030"
DATASET="test-mem"
AUTH_HEADER="Basic $(echo -n 'admin:admin123' | base64)"
TEST_GRAPH="http://example.org/test-graph"

# Color output
GREEN='\033[0;32m'
RED='\033[0;31m'
NC='\033[0m'

# Helper function for testing endpoints
test_endpoint() {
    local name=$1
    local method=$2
    local url=$3
    local content_type=$4
    local accept_type=$5
    local data=$6

    echo -e "\nTesting ${name}..."
    echo "URL: ${url}"
    echo "Method: ${method}"

    response=$(curl -v -s -w "\n%{http_code}" -X $method \
        -H "Authorization: $AUTH_HEADER" \
        ${content_type:+-H "Content-Type: $content_type"} \
        ${accept_type:+-H "Accept: $accept_type"} \
        ${data:+-d "$data"} \
        "$url")

    status_code=$(echo "$response" | tail -n1)
    response_body=$(echo "$response" | sed '$d')

    if [ "$status_code" -eq 200 ]; then
        echo -e "${GREEN}Success! Status: $status_code${NC}"
        echo "Response: $response_body"
    else
        echo -e "${RED}Failed! Status: $status_code${NC}"
        echo "Response: $response_body"
    fi
}

# 1. Test SPARQL Query endpoint
test_endpoint "SPARQL Query" "POST" \
    "$BASE_URL/$DATASET" \
    "application/sparql-query" \
    "application/json" \
    "SELECT * WHERE { ?s ?p ?o } LIMIT 1"

# 2. Test SPARQL Update endpoint
test_endpoint "SPARQL Update" "POST" \
    "$BASE_URL/$DATASET" \
    "application/sparql-update" \
    "application/json" \
    "INSERT DATA { GRAPH <$TEST_GRAPH> { <http://example/s> <http://example/p> 'test' } }"

# 3. Test Graph Store Protocol (GET)
test_endpoint "GSP Read" "GET" \
    "$BASE_URL/$DATASET/data?graph=$TEST_GRAPH" \
    "" \
    "text/turtle"

# 4. Test Graph Store Protocol (POST)
test_endpoint "GSP Write" "POST" \
    "$BASE_URL/$DATASET/data?graph=$TEST_GRAPH" \
    "text/turtle" \
    "application/json" \
    "@prefix ex: <http://example.org/> . ex:s ex:p 'test' ."

# 5. Test File Upload endpoint
test_endpoint "File Upload" "POST" \
    "$BASE_URL/$DATASET/upload" \
    "text/turtle" \
    "application/json" \
    "@prefix ex: <http://example.org/> . ex:s ex:p 'test' ."

# Additional useful endpoints
# 6. Test Dataset Info
test_endpoint "Dataset Info" "GET" \
    "$BASE_URL/$DATASET/stats" \
    "" \
    "application/json"

# 7. Test if dataset exists
test_endpoint "Dataset Existence" "GET" \
    "$BASE_URL/$DATASET" \
    "" \
    "application/json"

================
File: tests/helpers/jasmine_examples/SpecHelper.js
================
beforeEach(function () {
  jasmine.addMatchers({
    toBePlaying: function () {
      return {
        compare: function (actual, expected) {
          const player = actual;

          return {
            pass: player.currentlyPlayingSong === expected && player.isPlaying
          };
        }
      };
    }
  });
});

================
File: tests/helpers/reporter.js
================
import { SpecReporter } from 'jasmine-spec-reporter';

class CustomReporter {
    constructor() {
        this.specReporter = new SpecReporter({
            spec: {
                displayPending: true // Display pending (not fully implemented) specs
            }
        });
    }

    jasmineStarted() {
        this.specReporter.jasmineStarted.apply(this.specReporter, arguments);
    }

    suiteStarted() {
        this.specReporter.suiteStarted.apply(this.specReporter, arguments);
    }

    specStarted() {
        this.specReporter.specStarted.apply(this.specReporter, arguments);
    }

    specDone() {
        this.specReporter.specDone.apply(this.specReporter, arguments);
    }

    suiteDone() {
        this.specReporter.suiteDone.apply(this.specReporter, arguments);
    }

    jasmineDone() {
        this.specReporter.jasmineDone.apply(this.specReporter, arguments);
    }
}

export default CustomReporter;

/*
import { SpecReporter } from 'jasmine-spec-reporter';

jasmine.getEnv().clearReporters(); // Clear default console reporter
jasmine.getEnv().addReporter(new SpecReporter({
    spec: {
        displayPending: true // Display pending (not fully implemented) specs
    }
}));
*/

================
File: tests/helpers/setupGlobals.js
================
import fetch from 'node-fetch'
import { TextEncoder, TextDecoder } from 'util'

// Polyfill globals for Node.js environment
globalThis.fetch = fetch
globalThis.TextEncoder = TextEncoder
globalThis.TextDecoder = TextDecoder

================
File: tests/helpers/setupSPARQL.js
================
import { SPARQLHelpers } from '../../src/utils/SPARQLHelpers.js'

export async function setupSPARQLTestEnvironment(config) {
    const endpoints = await config.get('sparqlEndpoints')
    if (!endpoints?.length) throw new Error('No SPARQL endpoints configured')

    const sparqlConfig = endpoints[0]
    const { user, password, urlBase, dataset } = sparqlConfig

    if (!user || !password || !urlBase || !dataset) {
        throw new Error('Invalid SPARQL endpoint configuration')
    }

    const auth = SPARQLHelpers.createAuthHeader(user, password)
    return { baseUrl: urlBase, dataset, auth }
}

export async function initTestGraphs(config) {
    const { baseUrl, dataset, auth } = await setupSPARQLTestEnvironment(config)

    const testGraphs = [
        'test-mem',
        'test-backup-basic',
        'test-backup-advanced',
        'test-memory'
    ]

    for (const graph of testGraphs) {
        const endpoint = `${baseUrl}/${dataset}/update`
        const graphUri = `http://example.org/mcp/${graph}`

        try {
            const query = `
                DROP SILENT GRAPH <${graphUri}>;
                CREATE GRAPH <${graphUri}>
            `

            console.log(`Creating graph ${graphUri} at ${endpoint}`)
            await SPARQLHelpers.executeSPARQLUpdate(endpoint, query, auth)
        } catch (error) {
            console.error(`Failed to create graph ${graph}:`, error)
            throw error
        }
    }
}

================
File: tests/integration/llms/Ollama.spec.js
================
import fetch from 'node-fetch'
import OllamaConnector from '../../../src/connectors/OllamaConnector.js'
import { EmbeddingValidator } from '../../../src/utils/EmbeddingValidator.js'

globalThis.fetch = fetch

describe('OllamaConnector Integration', () => {
    let api
    let validator

    beforeEach(() => {
        api = new OllamaConnector('http://localhost:11434')
        validator = new EmbeddingValidator({
            dimensions: {
                'nomic-embed-text': 768
            }
        })
    })

    it('should generate chat response', async () => {
        const messages = [{
            role: 'user',
            content: 'Hello, how are you?'
        }]

        const response = await api.generateChat('llama2', messages)
        expect(typeof response).toBe('string')
        expect(response.length).toBeGreaterThan(0)
    })

    it('should generate embeddings', async () => {
        const embedding = await api.generateEmbedding(
            'nomic-embed-text',
            'Test text for embedding'
        )

        expect(Array.isArray(embedding)).toBe(true)
        expect(embedding.length).toBe(768)
        expect(validator.validateEmbedding(embedding, 768)).toBe(true)
    })
})

================
File: tests/integration/sparql/sparql-advanced-backup-spec.js
================
import Config from '../../../src/Config.js';
import SPARQLStore from '../../../src/stores/SPARQLStore.js';
import { logger } from '../../../src/Utils.js';

describe('SPARQLStore Advanced Backup Integration', () => {
    let store;
    let config;
    const testGraph = 'http://example.org/mcp/test-backup-advanced';
    let originalData;

    beforeAll(async () => {
        config = new Config();
        const sparqlConfig = config.get('sparqlEndpoints')[0];

        store = new SPARQLStore({
            query: `${sparqlConfig.urlBase}${sparqlConfig.query}`,
            update: `${sparqlConfig.urlBase}${sparqlConfig.update}`
        }, {
            user: sparqlConfig.user,
            password: sparqlConfig.password,
            graphName: testGraph
        });

        // Test data
        originalData = {
            shortTermMemory: [{
                id: 'advanced-backup-1',
                prompt: 'advanced backup test',
                output: 'original output',
                embedding: new Array(1536).fill(0).map(() => Math.random()),
                timestamp: Date.now(),
                accessCount: 1,
                concepts: ['advanced', 'backup'],
                decayFactor: 1.0
            }],
            longTermMemory: []
        };

        // Setup test graph
        try {
            await store.beginTransaction();
            const setupQuery = `
                DROP SILENT GRAPH <${testGraph}>;
                CREATE GRAPH <${testGraph}>
            `;
            await store._executeSparqlUpdate(setupQuery, store.endpoint.update);
            await store.commitTransaction();

            // Save initial data
            await store.saveMemoryToHistory(originalData);
        } catch (error) {
            logger.error('Error in advanced backup test setup:', error);
            throw error;
        }
    });

    afterAll(async () => {
        try {
            await store.beginTransaction();
            const cleanupQuery = `
                DROP SILENT GRAPH <${testGraph}>;
                DROP SILENT GRAPH <${testGraph}.backup>
            `;
            await store._executeSparqlUpdate(cleanupQuery, store.endpoint.update);
            await store.commitTransaction();
        } finally {
            await store.close();
        }
    });

    it('should handle backup corruption', async () => {
        await store.beginTransaction();

        // Corrupt backup by inserting invalid data
        const corruptQuery = `
            INSERT DATA {
                GRAPH <${testGraph}.backup> {
                    _:corrupt a mcp:Invalid ;
                        mcp:invalidProp "test" .
                }
            }
        `;
        await store._executeSparqlUpdate(corruptQuery, store.endpoint.update);

        // Attempt operation that should detect corruption
        const modifiedData = {
            shortTermMemory: [{
                ...originalData.shortTermMemory[0],
                output: 'corrupt test output'
            }],
            longTermMemory: []
        };

        // Should fail gracefully and maintain data integrity
        try {
            await store.saveMemoryToHistory(modifiedData);
            fail('Should have detected corruption');
        } catch (error) {
            // Verify original data is intact
            const [shortTerm] = await store.loadHistory();
            expect(shortTerm[0].output).toBe('original output');
        }

        await store.rollbackTransaction();
    });

    it('should perform incremental backups', async () => {
        await store.beginTransaction();

        // Add new data incrementally
        const updates = [
            { id: 'incremental-1', output: 'first update' },
            { id: 'incremental-2', output: 'second update' }
        ];

        for (const update of updates) {
            const incrementalData = {
                shortTermMemory: [
                    ...originalData.shortTermMemory,
                    {
                        ...originalData.shortTermMemory[0],
                        ...update
                    }
                ],
                longTermMemory: []
            };

            await store.saveMemoryToHistory(incrementalData);

            // Verify backup contains incremental changes
            const verifyQuery = `
                PREFIX mcp: <http://purl.org/stuff/mcp/>
                ASK {
                    GRAPH <${testGraph}.backup> {
                        ?s mcp:id "${update.id}" ;
                           mcp:output "${update.output}" .
                    }
                }
            `;
            const result = await store._executeSparqlQuery(verifyQuery, store.endpoint.query);
            expect(result.boolean).toBe(true);
        }

        // Rollback should restore to original state
        await store.rollbackTransaction();

        const [shortTerm] = await store.loadHistory();
        expect(shortTerm.length).toBe(1);
        expect(shortTerm[0].id).toBe('advanced-backup-1');
    });

    it('should handle concurrent backup operations', async () => {
        const store2 = new SPARQLStore({
            query: store.endpoint.query,
            update: store.endpoint.update
        }, {
            user: store.credentials.user,
            password: store.credentials.password,
            graphName: testGraph
        });

        await store.beginTransaction();

        // Second store should detect existing backup
        await expectAsync(store2.beginTransaction())
            .toBeRejectedWithError(/Transaction already in progress/);

        await store.rollbackTransaction();
        await store2.close();
    });

    it('should verify backup integrity', async () => {
        await store.beginTransaction();

        // Verify backup matches original data
        const verifyQuery = `
            PREFIX mcp: <http://purl.org/stuff/mcp/>
            SELECT ?prop ?value
            WHERE {
                GRAPH <${testGraph}> {
                    ?s1 mcp:id "advanced-backup-1" ;
                        ?prop ?value .
                }
                GRAPH <${testGraph}.backup> {
                    ?s2 mcp:id "advanced-backup-1" ;
                        ?prop ?value2 .
                    FILTER(?value = ?value2)
                }
            }
        `;

        const results = await store._executeSparqlQuery(verifyQuery, store.endpoint.query);
        expect(results.results.bindings.length).toBeGreaterThan(0);

        await store.rollbackTransaction();
    });

    it('should handle large backup operations', async () => {
        await store.beginTransaction();

        // Create large dataset
        const largeData = {
            shortTermMemory: Array(100).fill(null).map((_, i) => ({
                id: `large-backup-${i}`,
                prompt: `large backup test ${i}`,
                output: `test output ${i}`,
                embedding: new Array(1536).fill(0).map(() => Math.random()),
                timestamp: Date.now(),
                accessCount: 1,
                concepts: ['large', 'backup', `test-${i}`],
                decayFactor: 1.0
            })),
            longTermMemory: []
        };

        await store.saveMemoryToHistory(largeData);

        // Verify backup contains all entries
        const countQuery = `
            SELECT (COUNT(?s) as ?count)
            WHERE {
                GRAPH <${testGraph}.backup> {
                    ?s a mcp:Interaction
                }
            }
        `;

        const results = await store._executeSparqlQuery(countQuery, store.endpoint.query);
        expect(parseInt(results.results.bindings[0].count.value)).toBe(100);

        await store.rollbackTransaction();
    });
});

================
File: tests/integration/sparql/sparql-basic-backup-spec.js
================
import Config from '../../../src/Config.js';
import SPARQLStore from '../../../src/stores/SPARQLStore.js';
import { logger } from '../../../src/Utils.js';

describe('SPARQLStore Basic Backup Integration', () => {
    let store;
    let config;
    const testGraph = 'http://example.org/mcp/test-backup-basic';
    let originalData;

    beforeAll(async () => {
        config = new Config();
        const sparqlConfig = config.get('sparqlEndpoints')[0];

        store = new SPARQLStore({
            query: `${sparqlConfig.urlBase}${sparqlConfig.query}`,
            update: `${sparqlConfig.urlBase}${sparqlConfig.update}`
        }, {
            user: sparqlConfig.user,
            password: sparqlConfig.password,
            graphName: testGraph
        });

        // Test data
        originalData = {
            shortTermMemory: [{
                id: 'backup-test-1',
                prompt: 'backup test prompt',
                output: 'backup test output',
                embedding: new Array(1536).fill(0).map(() => Math.random()),
                timestamp: Date.now(),
                accessCount: 1,
                concepts: ['backup', 'test'],
                decayFactor: 1.0
            }],
            longTermMemory: []
        };

        // Setup test graph
        try {
            await store.beginTransaction();
            const setupQuery = `
                DROP SILENT GRAPH <${testGraph}>;
                CREATE GRAPH <${testGraph}>
            `;
            await store._executeSparqlUpdate(setupQuery, store.endpoint.update);
            await store.commitTransaction();

            // Save initial data
            await store.saveMemoryToHistory(originalData);
        } catch (error) {
            logger.error('Error in backup test setup:', error);
            throw error;
        }
    });

    afterAll(async () => {
        try {
            await store.beginTransaction();
            const cleanupQuery = `
                DROP SILENT GRAPH <${testGraph}>;
                DROP SILENT GRAPH <${testGraph}.backup>
            `;
            await store._executeSparqlUpdate(cleanupQuery, store.endpoint.update);
            await store.commitTransaction();
        } finally {
            await store.close();
        }
    });

    it('should create backup during transaction', async () => {
        await store.beginTransaction();

        // Verify backup graph exists
        const verifyQuery = `
            ASK { GRAPH <${testGraph}.backup> { ?s ?p ?o } }
        `;
        const result = await store._executeSparqlQuery(verifyQuery, store.endpoint.query);
        expect(result.boolean).toBe(true);

        await store.commitTransaction();
    });

    it('should restore from backup on rollback', async () => {
        await store.beginTransaction();

        // Modify data
        const modifiedData = {
            shortTermMemory: [{
                ...originalData.shortTermMemory[0],
                output: 'modified output'
            }],
            longTermMemory: []
        };

        await store.saveMemoryToHistory(modifiedData);

        // Verify modification
        let [shortTerm] = await store.loadHistory();
        expect(shortTerm[0].output).toBe('modified output');

        // Rollback
        await store.rollbackTransaction();

        // Verify restoration
        [shortTerm] = await store.loadHistory();
        expect(shortTerm[0].output).toBe('backup test output');
    });

    it('should cleanup backup graphs after commit', async () => {
        await store.beginTransaction();
        await store.commitTransaction();

        // Verify backup graph is removed
        const verifyQuery = `
            ASK { GRAPH <${testGraph}.backup> { ?s ?p ?o } }
        `;
        const result = await store._executeSparqlQuery(verifyQuery, store.endpoint.query);
        expect(result.boolean).toBe(false);
    });

    it('should handle nested transaction attempts', async () => {
        await store.beginTransaction();

        await expectAsync(store.beginTransaction())
            .toBeRejectedWithError('Transaction already in progress');

        await store.rollbackTransaction();
    });

    it('should preserve backup during multiple operations', async () => {
        await store.beginTransaction();

        // Multiple modifications
        const modifications = [
            { output: 'first modification' },
            { output: 'second modification' },
            { output: 'third modification' }
        ];

        for (const mod of modifications) {
            const modData = {
                shortTermMemory: [{
                    ...originalData.shortTermMemory[0],
                    ...mod
                }],
                longTermMemory: []
            };
            await store.saveMemoryToHistory(modData);
        }

        // Rollback should restore original
        await store.rollbackTransaction();

        const [shortTerm] = await store.loadHistory();
        expect(shortTerm[0].output).toBe('backup test output');
    });
});

================
File: tests/integration/sparql/sparql-federation-spec.js
================
import Config from '../../../src/Config.js';
import SPARQLStore from '../../../src/stores/SPARQLStore.js';
import { logger } from '../../../src/Utils.js';

describe('SPARQLStore Federation Integration', () => {
    let store;
    let config;
    const testGraphs = {
        main: 'http://example.org/mcp/test-memory',
        metadata: 'http://example.org/mcp/test-metadata',
        archive: 'http://example.org/mcp/test-archive'
    };

    beforeAll(async () => {
        config = new Config();
        const sparqlConfig = config.get('sparqlEndpoints')[0];

        store = new SPARQLStore({
            query: `${sparqlConfig.urlBase}${sparqlConfig.query}`,
            update: `${sparqlConfig.urlBase}${sparqlConfig.update}`
        }, {
            user: sparqlConfig.user,
            password: sparqlConfig.password,
            graphName: testGraphs.main
        });

        // Initialize test graphs
        try {
            await store.beginTransaction();
            const setupQuery = `
                DROP SILENT GRAPH <${testGraphs.main}>;
                DROP SILENT GRAPH <${testGraphs.metadata}>;
                DROP SILENT GRAPH <${testGraphs.archive}>;
                CREATE GRAPH <${testGraphs.main}>;
                CREATE GRAPH <${testGraphs.metadata}>;
                CREATE GRAPH <${testGraphs.archive}>
            `;
            await store._executeSparqlUpdate(setupQuery, store.endpoint.update);

            // Add test data to metadata graph
            const metadataQuery = `
                INSERT DATA {
                    GRAPH <${testGraphs.metadata}> {
                        <${testGraphs.main}> a mcp:MemoryStore ;
                            mcp:hasVersion "1.0" ;
                            mcp:lastUpdated "${new Date().toISOString()}"^^xsd:dateTime .
                    }
                }
            `;
            await store._executeSparqlUpdate(metadataQuery, store.endpoint.update);
            await store.commitTransaction();
        } catch (error) {
            logger.error('Error in federation test setup:', error);
            throw error;
        }
    });

    afterAll(async () => {
        try {
            await store.beginTransaction();
            const cleanupQuery = `
                DROP SILENT GRAPH <${testGraphs.main}>;
                DROP SILENT GRAPH <${testGraphs.metadata}>;
                DROP SILENT GRAPH <${testGraphs.archive}>
            `;
            await store._executeSparqlUpdate(cleanupQuery, store.endpoint.update);
            await store.commitTransaction();
        } finally {
            await store.close();
        }
    });

    it('should query across multiple graphs', async () => {
        // Add test memory data
        const testMemory = {
            shortTermMemory: [{
                id: 'federation-test-1',
                prompt: 'federation test prompt',
                output: 'federation test output',
                embedding: new Array(1536).fill(0).map(() => Math.random()),
                timestamp: Date.now(),
                concepts: ['federation', 'test'],
                accessCount: 1,
                decayFactor: 1.0
            }],
            longTermMemory: []
        };

        await store.saveMemoryToHistory(testMemory);

        // Federated query across memory and metadata
        const federatedQuery = `
            PREFIX mcp: <http://purl.org/stuff/mcp/>
            SELECT ?interaction ?version ?updated
            WHERE {
                GRAPH <${testGraphs.main}> {
                    ?interaction a mcp:Interaction ;
                        mcp:id "federation-test-1" .
                }
                GRAPH <${testGraphs.metadata}> {
                    <${testGraphs.main}> mcp:hasVersion ?version ;
                        mcp:lastUpdated ?updated .
                }
            }
        `;

        const results = await store._executeSparqlQuery(federatedQuery, store.endpoint.query);
        expect(results.results.bindings.length).toBe(1);
        expect(results.results.bindings[0].version.value).toBe('1.0');
    });

    it('should handle cross-graph data relationships', async () => {
        // Add related data across graphs
        const setupQuery = `
            PREFIX mcp: <http://purl.org/stuff/mcp/>
            PREFIX qb: <http://purl.org/linked-data/cube#>

            INSERT DATA {
                GRAPH <${testGraphs.main}> {
                    _:interaction1 a mcp:Interaction ;
                        mcp:id "related-test-1" ;
                        mcp:relatedCube <cube1> .
                }

                GRAPH <${testGraphs.metadata}> {
                    <cube1> a qb:DataSet ;
                        qb:structure <dsd1> ;
                        rdfs:label "Test Cube" .
                }
            }
        `;

        await store._executeSparqlUpdate(setupQuery, store.endpoint.update);

        // Query relationship
        const relationQuery = `
            PREFIX mcp: <http://purl.org/stuff/mcp/>
            PREFIX qb: <http://purl.org/linked-data/cube#>

            SELECT ?id ?cubeLabel
            WHERE {
                GRAPH <${testGraphs.main}> {
                    ?interaction mcp:id ?id ;
                        mcp:relatedCube ?cube .
                }
                GRAPH <${testGraphs.metadata}> {
                    ?cube rdfs:label ?cubeLabel .
                }
            }
        `;

        const results = await store._executeSparqlQuery(relationQuery, store.endpoint.query);
        expect(results.results.bindings.length).toBe(1);
        expect(results.results.bindings[0].cubeLabel.value).toBe('Test Cube');
    });

    it('should support federated updates across graphs', async () => {
        await store.beginTransaction();
        try {
            const federatedUpdate = `
                PREFIX mcp: <http://purl.org/stuff/mcp/>

                WITH <${testGraphs.main}>
                DELETE { ?i mcp:accessCount ?oldCount }
                INSERT { ?i mcp:accessCount ?newCount }
                WHERE {
                    ?i mcp:id "federation-test-1" ;
                       mcp:accessCount ?oldCount .
                    BIND(?oldCount + 1 AS ?newCount)
                };

                WITH <${testGraphs.metadata}>
                DELETE { <${testGraphs.main}> mcp:lastUpdated ?old }
                INSERT { <${testGraphs.main}> mcp:lastUpdated "${new Date().toISOString()}"^^xsd:dateTime }
                WHERE {
                    <${testGraphs.main}> mcp:lastUpdated ?old
                }
            `;

            await store._executeSparqlUpdate(federatedUpdate, store.endpoint.update);
            await store.commitTransaction();

            // Verify update
            const [shortTerm] = await store.loadHistory();
            expect(shortTerm[0].accessCount).toBe(2);
        } catch (error) {
            await store.rollbackTransaction();
            throw error;
        }
    });

    it('should handle service-based federation', async () => {
        // Query using SERVICE keyword for explicit federation
        const serviceQuery = `
            PREFIX mcp: <http://purl.org/stuff/mcp/>

            SELECT ?interaction ?metadata
            WHERE {
                SERVICE <${store.endpoint.query}> {
                    GRAPH <${testGraphs.main}> {
                        ?interaction mcp:id "federation-test-1"
                    }
                }
                SERVICE <${store.endpoint.query}> {
                    GRAPH <${testGraphs.metadata}> {
                        <${testGraphs.main}> ?p ?metadata
                    }
                }
            }
        `;

        const results = await store._executeSparqlQuery(serviceQuery, store.endpoint.query);
        expect(results.results.bindings.length).toBeGreaterThan(0);
    });
});

================
File: tests/integration/sparql/sparql-store-integration-spec.js
================
import Config from '../../../src/Config.js';
import SPARQLStore from '../../../src/stores/SPARQLStore.js';
import { logger } from '../../../src/Utils.js';

describe('SPARQLStore Integration', () => {
    let store;
    let config;
    let testMemory;

    beforeAll(async () => {
        // Initialize with real config
        config = new Config();
        const sparqlConfig = config.get('sparqlEndpoints')[0];

        store = new SPARQLStore({
            query: `${sparqlConfig.urlBase}${sparqlConfig.query}`,
            update: `${sparqlConfig.urlBase}${sparqlConfig.update}`
        }, {
            user: sparqlConfig.user,
            password: sparqlConfig.password,
            graphName: 'http://example.org/mcp/test-memory'
        });

        // Test data
        testMemory = {
            shortTermMemory: [{
                id: 'test-integration-1',
                prompt: 'integration test prompt',
                output: 'integration test output',
                embedding: new Array(1536).fill(0).map(() => Math.random()),
                timestamp: Date.now(),
                accessCount: 1,
                concepts: ['test', 'integration'],
                decayFactor: 1.0
            }],
            longTermMemory: []
        };

        // Clear test graph before starting
        try {
            await store.beginTransaction();
            const clearQuery = `
                DROP SILENT GRAPH <http://example.org/mcp/test-memory>;
                CREATE GRAPH <http://example.org/mcp/test-memory>
            `;
            await store._executeSparqlUpdate(clearQuery, `${sparqlConfig.urlBase}${sparqlConfig.update}`);
            await store.commitTransaction();
        } catch (error) {
            logger.error('Error in test setup:', error);
            throw error;
        }
    });

    afterAll(async () => {
        // Cleanup test graph
        try {
            await store.beginTransaction();
            const dropQuery = `DROP SILENT GRAPH <http://example.org/mcp/test-memory>`;
            await store._executeSparqlUpdate(dropQuery, `${config.get('sparqlEndpoints')[0].urlBase}${config.get('sparqlEndpoints')[0].update}`);
            await store.commitTransaction();
        } finally {
            await store.close();
        }
    });

    it('should verify empty graph exists', async () => {
        const exists = await store.verify();
        expect(exists).toBe(true);
    });

    it('should save and load memory data', async () => {
        // Save test memory
        await store.saveMemoryToHistory(testMemory);

        // Load and verify
        const [shortTerm, longTerm] = await store.loadHistory();

        expect(shortTerm.length).toBe(1);
        expect(longTerm.length).toBe(0);

        const loaded = shortTerm[0];
        expect(loaded.id).toBe(testMemory.shortTermMemory[0].id);
        expect(loaded.prompt).toBe(testMemory.shortTermMemory[0].prompt);
        expect(loaded.concepts).toEqual(testMemory.shortTermMemory[0].concepts);
        expect(loaded.embedding.length).toBe(1536);
    });

    it('should handle transaction rollback', async () => {
        await store.beginTransaction();

        const badMemory = {
            shortTermMemory: [{
                id: 'test-rollback',
                prompt: 'should not persist',
                output: 'rollback test',
                embedding: new Array(1536).fill(0),
                timestamp: Date.now(),
                accessCount: 1,
                concepts: ['rollback'],
                decayFactor: 1.0
            }],
            longTermMemory: []
        };

        try {
            // Save data that will be rolled back
            await store.saveMemoryToHistory(badMemory);
            // Force a rollback by throwing an error
            throw new Error('Test rollback');
        } catch (error) {
            await store.rollbackTransaction();
        }

        // Verify original data is still intact
        const [shortTerm] = await store.loadHistory();
        expect(shortTerm.length).toBe(1);
        expect(shortTerm[0].id).toBe('test-integration-1');
    });

    it('should handle concurrent transactions', async () => {
        const store2 = new SPARQLStore(store.endpoint, {
            user: store.credentials.user,
            password: store.credentials.password,
            graphName: store.graphName
        });

        await store.beginTransaction();

        // Second transaction should fail while first is in progress
        await expectAsync(store2.beginTransaction())
            .toBeRejectedWithError(/Transaction already in progress/);

        await store.commitTransaction();
        await store2.close();
    });

    it('should support query pagination', async () => {
        // Add multiple memories
        const bulkMemory = {
            shortTermMemory: Array(5).fill(null).map((_, i) => ({
                id: `bulk-test-${i}`,
                prompt: `bulk test prompt ${i}`,
                output: `bulk test output ${i}`,
                embedding: new Array(1536).fill(0).map(() => Math.random()),
                timestamp: Date.now(),
                accessCount: 1,
                concepts: ['bulk', `test-${i}`],
                decayFactor: 1.0
            })),
            longTermMemory: []
        };

        await store.saveMemoryToHistory(bulkMemory);

        // Custom paginated query
        const pageSize = 2;
        const query = `
            PREFIX mcp: <http://purl.org/stuff/mcp/>
            SELECT ?id ?prompt
            FROM <${store.graphName}>
            WHERE {
                ?s mcp:id ?id ;
                   mcp:prompt ?prompt .
            }
            LIMIT ${pageSize}
        `;

        const results = await store._executeSparqlQuery(query, store.endpoint.query);
        expect(results.results.bindings.length).toBe(pageSize);
    });
});

================
File: tests/mocks/Ollama.js
================
export class MockOllamaConnector {
    async generateEmbedding(model, input) {
        return new Array(1536).fill(0).map(() => Math.random());
    }

    async generateChat(model, messages) {
        return 'Mock response';
    }

    async generateCompletion(model, prompt) {
        return 'Mock completion';
    }
}

================
File: tests/support/jasmine.json
================
{
  "spec_dir": "spec",
  "spec_files": [
    "**/*[sS]pec.?(m)js"
  ],
  "helpers": [
    "helpers/**/*.?(m)js"
  ],
  "env": {
    "stopSpecOnExpectationFailure": false,
    "random": true
  }
}

================
File: tests/unit/cached-sparql-store-spec.js
================
import CachedSPARQLStore from '../../src/stores/CachedSPARQLStore.js';

describe('CachedSPARQLStore', () => {
    let store;
    let mockFetch;
    let originalSetInterval;
    let mockSetInterval;

    const endpoint = {
        query: 'http://example.org/sparql/query',
        update: 'http://example.org/sparql/update'
    };

    beforeEach(() => {
        // Mock interval timer
        originalSetInterval = global.setInterval;
        mockSetInterval = jasmine.createSpy('setInterval').and.returnValue(123);
        global.setInterval = mockSetInterval;

        // Mock fetch API
        mockFetch = jasmine.createSpy('fetch').and.returnValue(
            Promise.resolve({
                ok: true,
                json: () => Promise.resolve({
                    results: { bindings: [] }
                })
            })
        );
        global.fetch = mockFetch;
        global.Buffer = {
            from: (str) => ({ toString: () => 'mock-base64' })
        };

        store = new CachedSPARQLStore(endpoint, {
            user: 'testuser',
            password: 'testpass',
            graphName: 'http://test.org/memory',
            cacheTTL: 1000,
            maxCacheSize: 2
        });

        jasmine.clock().install();
    });

    afterEach(() => {
        delete global.fetch;
        delete global.Buffer;
        global.setInterval = originalSetInterval;
        jasmine.clock().uninstall();
    });

    describe('cache operations', () => {
        it('should cache query results', async () => {
            const query = 'SELECT * WHERE { ?s ?p ?o }';
            const mockResult = { results: { bindings: [{ s: { value: 'test' } }] } };

            mockFetch.and.returnValue(
                Promise.resolve({
                    ok: true,
                    json: () => Promise.resolve(mockResult)
                })
            );

            // First call should hit the network
            await store._executeSparqlQuery(query, endpoint.query);
            expect(mockFetch).toHaveBeenCalledTimes(1);

            // Second call should use cache
            mockFetch.calls.reset();
            const cachedResult = await store._executeSparqlQuery(query, endpoint.query);
            expect(mockFetch).not.toHaveBeenCalled();
            expect(cachedResult).toEqual(mockResult);
        });

        it('should expire cache entries after TTL', async () => {
            const query = 'SELECT * WHERE { ?s ?p ?o }';

            // First call
            await store._executeSparqlQuery(query, endpoint.query);
            expect(mockFetch).toHaveBeenCalledTimes(1);

            // Advance time past TTL
            jasmine.clock().tick(1001);

            // Should make new request
            mockFetch.calls.reset();
            await store._executeSparqlQuery(query, endpoint.query);
            expect(mockFetch).toHaveBeenCalledTimes(1);
        });

        it('should respect max cache size', async () => {
            // Fill cache beyond max size
            await store._executeSparqlQuery('query1', endpoint.query);
            await store._executeSparqlQuery('query2', endpoint.query);
            await store._executeSparqlQuery('query3', endpoint.query);

            expect(store.queryCache.size).toBeLessThanOrEqual(2);
        });

        it('should invalidate cache on data updates', async () => {
            // Cache a query
            await store._executeSparqlQuery('SELECT * WHERE { ?s ?p ?o }', endpoint.query);
            expect(store.queryCache.size).toBe(1);

            // Update should clear cache
            await store.saveMemoryToHistory({ shortTermMemory: [], longTermMemory: [] });
            expect(store.queryCache.size).toBe(0);
        });
    });

    describe('cache cleanup', () => {
        it('should remove expired entries during cleanup', () => {
            // Add cache entries
            store.queryCache.set('test1', { data: 1 });
            store.cacheTimestamps.set('test1', Date.now() - 2000); // Expired
            store.queryCache.set('test2', { data: 2 });
            store.cacheTimestamps.set('test2', Date.now()); // Current

            store.cleanupCache();

            expect(store.queryCache.has('test1')).toBeFalse();
            expect(store.queryCache.has('test2')).toBeTrue();
        });

        it('should remove oldest entries when over size limit', () => {
            // Add entries
            store.queryCache.set('test1', { data: 1 });
            store.cacheTimestamps.set('test1', 1000);
            store.queryCache.set('test2', { data: 2 });
            store.cacheTimestamps.set('test2', 2000);
            store.queryCache.set('test3', { data: 3 });
            store.cacheTimestamps.set('test3', 3000);

            store.cleanupCache();

            expect(store.queryCache.size).toBe(2);
            expect(store.queryCache.has('test1')).toBeFalse();
            expect(store.queryCache.has('test3')).toBeTrue();
        });
    });

    describe('cleanup on close', () => {
        it('should clear interval and cache on close', async () => {
            const mockClearInterval = jasmine.createSpy('clearInterval');
            global.clearInterval = mockClearInterval;

            await store.close();

            expect(mockClearInterval).toHaveBeenCalledWith(123);
            expect(store.queryCache.size).toBe(0);
            expect(store.cacheTimestamps.size).toBe(0);
        });
    });
});

================
File: tests/unit/ContextWindowManager.spec.js
================
import ContextWindowManager from '../../src/ContextWindowManager.js'

describe('ContextWindowManager', () => {
    let windowManager

    beforeEach(() => {
        windowManager = new ContextWindowManager({
            maxWindowSize: 1000,
            minWindowSize: 250,
            overlapRatio: 0.1
        })
    })

    it('should calculate correct window size', () => {
        const size = windowManager.calculateWindowSize('x'.repeat(1000))
        expect(size).toBeLessThanOrEqual(1000)
        expect(size).toBeGreaterThanOrEqual(250)
    })

    it('should create overlapping windows', () => {
        const text = 'x'.repeat(2000)
        const windows = windowManager.createWindows(text, 1000)
        expect(windows.length).toBeGreaterThan(1)
        expect(windows[0].text.length).toBeLessThanOrEqual(1000)
    })

    it('should merge overlapping content correctly', () => {
        const windows = [
            { text: 'Hello world' },
            { text: 'world and universe' }
        ]
        const merged = windowManager.mergeOverlappingContent(windows)
        expect(merged).toBe('Hello world and universe')
    })

    it('should handle word boundaries during merge', () => {
        const windows = [
            { text: 'The quick brown' },
            { text: 'brown fox jumps' },
            { text: 'jumps over lazy' }
        ]
        const merged = windowManager.mergeOverlappingContent(windows)
        expect(merged).toBe('The quick brown fox jumps over lazy')
    })
})

================
File: tests/unit/MemoryManager.spec.js
================
// spec/unit/MemoryManager.spec.js
import MemoryManager from '../../src/MemoryManager.js';
import { MockOllamaConnector } from '../mocks/Ollama.js';
import InMemoryStore from '../../src/stores/InMemoryStore.js';

describe('MemoryManager', () => {
    let manager;
    let mockOllama;

    beforeEach(() => {
        mockOllama = new MockOllamaConnector();
        manager = new MemoryManager({
            llmProvider: mockOllama,
            chatModel: 'qwen2:1.5b', // was llama2
            embeddingModel: 'nomic-embed-text',
            storage: new InMemoryStorage()
        });
    });

    it('should generate embeddings', async () => {
        const embedding = await manager.getEmbedding('test text');
        expect(embedding.length).toBe(1536);
        expect(Array.isArray(embedding)).toBe(true);
    });

    it('should extract concepts', async () => {
        const concepts = await manager.extractConcepts('AI and machine learning');
        expect(Array.isArray(concepts)).toBe(true);
        expect(concepts.length).toBeGreaterThan(0);
    });

    it('should add and retrieve interactions', async () => {
        const prompt = 'test prompt';
        const response = 'test response';
        const embedding = new Array(1536).fill(0);
        const concepts = ['test'];

        await manager.addInteraction(prompt, response, embedding, concepts);
        const retrievals = await manager.retrieveRelevantInteractions(prompt);

        expect(retrievals.length).toBeGreaterThan(0);
        expect(retrievals[0].interaction.prompt).toBe(prompt);
    });
});

================
File: tests/unit/sparql-endpoint-spec.js
================
// tests/unit/sparql-endpoint-spec.js
import Config from '../../src/Config.js'
import { SPARQLHelpers } from '../../src/utils/SPARQLHelpers.js'

describe('SPARQL Endpoint Integration', () => {
    let config
    let endpoint
    let auth
    let baseUrl
    const testGraph = 'http://example.org/test-graph'

    beforeAll(() => {
        config = new Config()
        const sparqlConfig = config.get('sparqlEndpoints')[0]
        baseUrl = sparqlConfig.urlBase  // Changed: Remove '/test' appendage
        endpoint = {
            query: `${baseUrl}${sparqlConfig.query}`,
            update: `${baseUrl}${sparqlConfig.update}`
        }
        auth = SPARQLHelpers.createAuthHeader(sparqlConfig.user, sparqlConfig.password)
    })

    beforeEach(async () => {
        // Clear test graph before each test
        const clearQuery = `
            DROP SILENT GRAPH <${testGraph}>;
            CREATE GRAPH <${testGraph}>
        `
        await SPARQLHelpers.executeSPARQLUpdate(endpoint.update, clearQuery, auth)
    })

    afterAll(async () => {
        // Clean up test graph
        const dropQuery = `DROP SILENT GRAPH <${testGraph}>`
        await SPARQLHelpers.executeSPARQLUpdate(endpoint.update, dropQuery, auth)
    })

    describe('SPARQL UPDATE operations', () => {
        it('should insert data into graph', async () => {
            const insertQuery = `
                PREFIX ex: <http://example.org/>
                INSERT DATA {
                    GRAPH <${testGraph}> {
                        ex:subject ex:predicate "test object" .
                    }
                }
            `

            await expectAsync(
                SPARQLHelpers.executeSPARQLUpdate(endpoint.update, insertQuery, auth)
            ).toBeResolved()
        })

        it('should delete data from graph', async () => {
            const deleteQuery = `
                PREFIX ex: <http://example.org/>
                DELETE DATA {
                    GRAPH <${testGraph}> {
                        ex:subject ex:predicate "test object" .
                    }
                }
            `

            await expectAsync(
                SPARQLHelpers.executeSPARQLUpdate(endpoint.update, deleteQuery, auth)
            ).toBeResolved()
        })
    })

    describe('SPARQL SELECT operations', () => {
        beforeEach(async () => {
            // Insert test data
            const setupQuery = `
                PREFIX ex: <http://example.org/>
                INSERT DATA {
                    GRAPH <${testGraph}> {
                        ex:subject1 ex:predicate "value1" .
                        ex:subject2 ex:predicate "value2" .
                    }
                }
            `
            await SPARQLHelpers.executeSPARQLUpdate(endpoint.update, setupQuery, auth)
        })

        it('should retrieve data with SELECT query', async () => {
            const selectQuery = `
                PREFIX ex: <http://example.org/>
                SELECT ?s ?o
                FROM <${testGraph}>
                WHERE {
                    ?s ex:predicate ?o .
                }
            `

            const response = await SPARQLHelpers.executeSPARQLQuery(endpoint.query, selectQuery, auth)
            const data = await response.json()
            expect(data.results.bindings.length).toBe(2)
        })
    })

    describe('Turtle operations', () => {
        const testTurtle = `
            @prefix ex: <http://example.org/> .
            ex:subject ex:predicate "test value" .
        `

        it('should upload Turtle data and return counts', async () => {
            const result = await SPARQLHelpers.uploadTurtle(baseUrl, testTurtle, auth, testGraph)

            expect(result.success).toBe(true)
            expect(result.counts.triples).toBe(1)
            expect(result.counts.total).toBe(1)

            // Verify the upload worked via SPARQL
            const verifyQuery = `
                ASK FROM <${testGraph}>
                WHERE {
                    ?s ?p "test value"
                }
            `
            const askResponse = await SPARQLHelpers.executeSPARQLQuery(endpoint.query, verifyQuery, auth)
            const askResult = await askResponse.json()
            expect(askResult.boolean).toBe(true)
        })

        it('should retrieve data as Turtle using CONSTRUCT', async () => {
            // First insert some data using SPARQL Update
            const insertQuery = `
                PREFIX ex: <http://example.org/>
                INSERT DATA {
                    GRAPH <${testGraph}> {
                        ex:subject ex:predicate "test value" .
                    }
                }
            `
            await SPARQLHelpers.executeSPARQLUpdate(endpoint.update, insertQuery, auth)

            const constructQuery = `
                CONSTRUCT {
                    ?s ?p ?o
                }
                FROM <${testGraph}>
                WHERE {
                    ?s ?p ?o
                }
            `

            const constructResponse = await SPARQLHelpers.executeSPARQLQuery(
                endpoint.query,
                constructQuery,
                auth,
                'text/turtle'
            )

            const turtle = await constructResponse.text()
            expect(turtle).toContain('http://example.org/subject')
        })
    })

    describe('Server interaction', () => {
        it('should handle authentication (note: auth currently not enforced)', async () => {
            const invalidAuth = SPARQLHelpers.createAuthHeader('invalid', 'credentials')
            const query = 'SELECT * WHERE { ?s ?p ?o } LIMIT 1'

            // Since auth is not enforced, this should succeed
            const queryResponse = await SPARQLHelpers.executeSPARQLQuery(endpoint.query, query, invalidAuth)
            const data = await queryResponse.json()
            expect(data.results.bindings.length).toBeGreaterThanOrEqual(0)
        })
    })
})

================
File: tests/unit/sparql-store-spec.js
================
import SPARQLStore from '../../src/stores/SPARQLStore.js';

describe('SPARQLStore', () => {
    let store;
    let mockFetch;
    
    const endpoint = {
        query: 'http://example.org/sparql/query',
        update: 'http://example.org/sparql/update'
    };

    beforeEach(() => {
        // Mock fetch API
        mockFetch = jasmine.createSpy('fetch').and.returnValue(
            Promise.resolve({
                ok: true,
                json: () => Promise.resolve({
                    results: {
                        bindings: [{
                            id: { value: 'test-id' },
                            prompt: { value: 'test prompt' },
                            output: { value: 'test output' },
                            embedding: { value: '[0,1,2]' },
                            timestamp: { value: '1234567890' },
                            accessCount: { value: '1' },
                            concepts: { value: '["test"]' },
                            decayFactor: { value: '1.0' },
                            memoryType: { value: 'short-term' }
                        }]
                    }
                })
            })
        );
        global.fetch = mockFetch;
        global.Buffer = {
            from: (str) => ({ toString: () => 'mock-base64' })
        };

        store = new SPARQLStore(endpoint, {
            user: 'testuser',
            password: 'testpass',
            graphName: 'http://test.org/memory'
        });
    });

    afterEach(() => {
        delete global.fetch;
        delete global.Buffer;
    });

    describe('loadHistory', () => {
        it('should load and parse memory data correctly', async () => {
            const [shortTerm, longTerm] = await store.loadHistory();

            expect(shortTerm.length).toBe(1);
            expect(longTerm.length).toBe(0);
            
            const memory = shortTerm[0];
            expect(memory.id).toBe('test-id');
            expect(memory.prompt).toBe('test prompt');
            expect(memory.embedding).toEqual([0,1,2]);
            expect(memory.timestamp).toBe(1234567890);
            expect(memory.concepts).toEqual(['test']);
        });

        it('should handle query errors', async () => {
            mockFetch.and.returnValue(Promise.resolve({ ok: false, status: 500 }));
            
            await expectAsync(store.loadHistory())
                .toBeRejectedWithError('SPARQL query failed: 500');
        });
    });

    describe('saveMemoryToHistory', () => {
        const mockMemoryStore = {
            shortTermMemory: [{
                id: 'test-id',
                prompt: 'test prompt',
                output: 'test output',
                embedding: [0,1,2],
                timestamp: 1234567890,
                accessCount: 1,
                concepts: ['test'],
                decayFactor: 1.0
            }],
            longTermMemory: []
        };

        it('should save memory data correctly', async () => {
            await store.saveMemoryToHistory(mockMemoryStore);

            expect(mockFetch).toHaveBeenCalledWith(
                endpoint.update,
                jasmine.objectContaining({
                    method: 'POST',
                    headers: jasmine.objectContaining({
                        'Content-Type': 'application/sparql-update'
                    })
                })
            );
        });

        it('should handle update errors', async () => {
            mockFetch.and.returnValue(Promise.resolve({ ok: false, status: 500 }));
            
            await expectAsync(store.saveMemoryToHistory(mockMemoryStore))
                .toBeRejectedWithError('SPARQL update failed: 500');
        });
    });

    describe('transaction handling', () => {
        it('should manage transactions correctly', async () => {
            await store.beginTransaction();
            expect(store.inTransaction).toBeTrue();
            
            await store.commitTransaction();
            expect(store.inTransaction).toBeFalse();
        });

        it('should handle transaction rollback', async () => {
            await store.beginTransaction();
            await store.rollbackTransaction();
            expect(store.inTransaction).toBeFalse();
        });

        it('should prevent nested transactions', async () => {
            await store.beginTransaction();
            await expectAsync(store.beginTransaction())
                .toBeRejectedWithError('Transaction already in progress');
        });
    });

    describe('verify', () => {
        it('should verify graph existence', async () => {
            mockFetch.and.returnValue(
                Promise.resolve({
                    ok: true,
                    json: () => Promise.resolve({ boolean: true })
                })
            );

            const isValid = await store.verify();
            expect(isValid).toBeTrue();
        });

        it('should handle verification failures', async () => {
            mockFetch.and.returnValue(Promise.resolve({ ok: false }));
            
            const isValid = await store.verify();
            expect(isValid).toBeFalse();
        });
    });

    describe('cleanup', () => {
        it('should clean up transaction state on close', async () => {
            await store.beginTransaction();
            await store.close();
            expect(store.inTransaction).toBeFalse();
        });
    });
});

================
File: tests/about.md
================
npm test -- tests/unit/sparql-endpoint-spec.js

npm test -- tests/unit/sparql-store-spec.js

================
File: .git
================
gitdir: ../../.git/modules/packages/semem

================
File: .gitignore
================
# Logs
logs
*.log
npm-debug.log*
yarn-debug.log*
yarn-error.log*
lerna-debug.log*
.pnpm-debug.log*

# Diagnostic reports (https://nodejs.org/api/report.html)
report.[0-9]*.[0-9]*.[0-9]*.[0-9]*.json

# Runtime data
pids
*.pid
*.seed
*.pid.lock

# Directory for instrumented libs generated by jscoverage/JSCover
lib-cov

# Coverage directory used by tools like istanbul
coverage
*.lcov

# nyc test coverage
.nyc_output

# Grunt intermediate storage (https://gruntjs.com/creating-plugins#storing-task-files)
.grunt

# Bower dependency directory (https://bower.io/)
bower_components

# node-waf configuration
.lock-wscript

# Compiled binary addons (https://nodejs.org/api/addons.html)
build/Release

# Dependency directories
node_modules/
jspm_packages/

# Snowpack dependency directory (https://snowpack.dev/)
web_modules/

# TypeScript cache
*.tsbuildinfo

# Optional npm cache directory
.npm

# Optional eslint cache
.eslintcache

# Optional stylelint cache
.stylelintcache

# Microbundle cache
.rpt2_cache/
.rts2_cache_cjs/
.rts2_cache_es/
.rts2_cache_umd/

# Optional REPL history
.node_repl_history

# Output of 'npm pack'
*.tgz

# Yarn Integrity file
.yarn-integrity

# dotenv environment variable files
.env
.env.development.local
.env.test.local
.env.production.local
.env.local

# parcel-bundler cache (https://parceljs.org/)
.cache
.parcel-cache

# Next.js build output
.next
out

# Nuxt.js build / generate output
.nuxt
dist

# Gatsby files
.cache/
# Comment in the public line in if your project uses Gatsby and not Next.js
# https://nextjs.org/blog/next-9-1#public-directory-support
# public

# vuepress build output
.vuepress/dist

# vuepress v2.x temp and cache directory
.temp
.cache

# Docusaurus cache and generated files
.docusaurus

# Serverless directories
.serverless/

# FuseBox cache
.fusebox/

# DynamoDB Local files
.dynamodb/

# TernJS port file
.tern-port

# Stores VSCode versions used for testing VSCode extensions
.vscode-test

# yarn v2
.yarn/cache
.yarn/unplugged
.yarn/build-state.yml
.yarn/install-state.gz
.pnp.*

================
File: about.md
================
# About

Needs a SPARQL endpoint - like #:tbox

```sh
cd ~/github-danny/hyperdata/packages/tbox/

 docker-compose up -d
```

```sh
cd ~/github-danny/hyperdata/packages/semem

node src/OllamaExample.js

```

---

Needs SPARQL store, endpoint 127.0.0.1:4030

```sh
cd ~/github-danny/hyperdata/packages/tbox
docker-compose up -d

 node src/SPARQLExample.js

```

```sh
cd ~/github-danny/hyperdata/packages/tbox
docker-compose up -d
cd ~/github-danny/hyperdata/packages/semem
node src/OllamaClaudeExample.js

```

```sh
# ollama pull nomic-embed-text

curl http://localhost:11434/api/embeddings -d '{
  "model": "nomic-embed-text",
  "prompt": "The sky is blue because of Rayleigh scattering"
}'
```

```sh
npm test -- --filter="SPARQL Endpoint Integration"
```

================
File: jasmine.json
================
{
    "spec_dir": "tests",
    "spec_files": [
        "unit/**/*[sS]pec.js",
        "integration/**/*[sS]pec.js"
    ],
    "helpers": [
        "helpers/setupGlobals.js",
        "helpers/setupSPARQL.js"
    ],
    "env": {
        "stopSpecOnExpectationFailure": false,
        "random": false
    },
    "moduleDirectory": [
        "node_modules"
    ]
}

================
File: jsconfig.json
================
{
  "compilerOptions": {
    "baseUrl": ".",
    "paths": {
      "@src/*": ["src/*"],
      "@tests/*": ["tests/*"]
    }
  }
}

================
File: jsdoc.json
================
{
    "source": {
        "include": [
            "src"
        ],
        "exclude": [
            "node_modules"
        ],
        "includePattern": ".+\\.js(doc|x)?$",
        "excludePattern": "(^|\\/|\\\\)_"
    },
    "opts": {
        "verbose": true,
        "recurse": true,
        "destination": "./docs/jsdoc"
    },
    "plugins": [
        "plugins/markdown"
    ]
}

================
File: LICENSE
================
MIT License

Copyright (c) 2024 Danny Ayers

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.

================
File: package copy.json
================
{
  "name": "semem",
  "version": "1.0.0",
  "description": "Semantic Memory",
  "type": "module",
  "main": "index.js",
  "engines": {
    "node": ">=20.11.0"
  },
  "scripts": {
    "tests": "jasmine --config=jasmine.json --reporter=tests/helpers/reporter.js",
    "cov": "nyc -a --include=src --reporter=lcov npm run test",
    "docs": "jsdoc -c jsdoc.json",
    "rp": "repomix -c repomix.config.json . "
  },
  "repository": {
    "type": "git",
    "url": "git+https://github.com/danja/semem.git"
  },
  "keywords": [
    "semantic",
    "memory",
    "llm",
    "rdf",
    "sparql"
  ],
  "author": "Danny Ayers",
  "license": "MIT",
  "bugs": {
    "url": "https://github.com/danja/semem/issues"
  },
  "homepage": "https://github.com/danja/semem#readme",
  "devDependencies": {
    "jasmine": "^5.5.0",
    "jasmine-spec-reporter": "^7.0.0",
    "jsdoc": "^4.0.4"
  },
  "dependencies": {
    "@anthropic-ai/sdk": "^0.36.2",
    "@langchain/core": "^0.3.19",
    "@langchain/openai": "^0.3.14",
    "faiss-node": "^0.5.1",
    "graphology": "^0.25.4",
    "ml-kmeans": "^6.0.0",
    "ollama": "^0.5.10"
  }
}

================
File: package-ref.json
================
{
    "name": "semem",
    "version": "1.0.0",
    "description": "Semantic Memory",
    "type": "module",
    "main": "index.js",
    "engines": {
        "node": ">=20.11.0"
    },
    "scripts": {
        "test": "jasmine --config=jasmine.json --reporter=tests/helpers/reporter.js",
        "cov": "nyc -a --include=src --reporter=lcov npm run test",
        "docs": "jsdoc -c jsdoc.json",
        "rp": "repomix -c repomix.config.json . "
    },
    "repository": {
        "type": "git",
        "url": "git+https://github.com/danja/semem.git"
    },
    "keywords": [
        "semantic",
        "memory",
        "llm",
        "rdf",
        "sparql"
    ],
    "author": "Danny Ayers",
    "license": "MIT",
    "bugs": {
        "url": "https://github.com/danja/semem/issues"
    },
    "homepage": "https://github.com/danja/semem#readme",
    "devDependencies": {
        "jasmine": "^5.5.0",
        "jasmine-spec-reporter": "^7.0.0",
        "jsdoc": "^4.0.4"
    },
    "dependencies": {
        "@langchain/core": "^0.3.19",
        "@langchain/openai": "^0.3.14",
        "faiss-node": "^0.5.1",
        "graphology": "^0.25.4",
        "ml-kmeans": "^6.0.0",
        "ollama": "^0.5.10"
    }
}

================
File: package.json
================
{
  "name": "semem",
  "version": "1.0.0",
  "description": "Semantic Memory",
  "type": "module",
  "main": "index.js",
  "engines": {
    "node": ">=20.11.0"
  },
  "scripts": {
    "test": "node scripts/run-tests.js",
    "test:unit": "node scripts/run-tests.js tests/unit",
    "test:integration": "node scripts/run-tests.js tests/integration",
    "cov": "nyc -a --include=src --reporter=lcov npm run test",
    "docs": "jsdoc -c jsdoc.json",
    "rp": "repomix -c repomix.config.json . "
  },
  "repository": {
    "type": "git",
    "url": "git+https://github.com/danja/semem.git"
  },
  "keywords": [
    "semantic",
    "memory",
    "llm",
    "rdf",
    "sparql"
  ],
  "author": "Danny Ayers",
  "license": "MIT",
  "bugs": {
    "url": "https://github.com/danja/semem/issues"
  },
  "homepage": "https://github.com/danja/semem#readme",
  "devDependencies": {
    "jasmine": "^5.5.0",
    "jasmine-spec-reporter": "^7.0.0",
    "jsdoc": "^4.0.4"
  },
  "dependencies": {
    "@anthropic-ai/sdk": "^0.36.2",
    "@langchain/core": "^0.3.19",
    "@langchain/openai": "^0.3.14",
    "faiss-node": "^0.5.1",
    "graphology": "^0.25.4",
    "ml-kmeans": "^6.0.0",
    "ollama": "^0.5.10"
  }
}

================
File: package.json.bak
================
{
  "name": "semem",
  "version": "1.0.0",
  "description": "Semantic Memory",
  "type": "module",
  "main": "index.js",
  "engines": {
    "node": ">=20.11.0"
  },
  "preinstall": "node -r ./config.js",
  "scripts": {
    "test": "jasmine --config=jasmine.json --reporter=tests/helpers/reporter.js",
    "cov": "nyc -a --include=src --reporter=lcov npm run test",
    "docs": "jsdoc -c jsdoc.json",
    "rp": "repomix -c repomix.config.json . "
  },
  "repository": {
    "type": "git",
    "url": "git+https://github.com/danja/semem.git"
  },
  "keywords": [
    "semantic",
    "memory",
    "llm",
    "rdf",
    "sparql"
  ],
  "author": "Danny Ayers",
  "license": "MIT",
  "bugs": {
    "url": "https://github.com/danja/semem/issues"
  },
  "homepage": "https://github.com/danja/semem#readme",
  "devDependencies": {
    "jasmine": "^5.5.0",
    "jasmine-spec-reporter": "^7.0.0",
    "jsdoc": "^4.0.4",
    "repomix": "^0.2.20"
  },
  "dependencies": {
    "@langchain/core": "^0.3.19",
    "@langchain/openai": "^0.3.14",
    "faiss-node": "^0.5.1",
    "graphology": "^0.25.4",
    "ml-kmeans": "^6.0.0",
    "ollama": "^0.5.10"
  }
}

================
File: repomix.config.json
================
{
    "output": {
        "filePath": "./repomix-semem.md",
        "headerText": "Semem repo",
        "removeComments": false
    },
    "include": [
        "**/*"
    ],
    "ignore": {
        "useDefaultPatterns": false,
        "customPatterns": [
            "data",
            "docs",
            ".nyc_output",
            ".env",
            "**/_*",
            "node_modules",
            "*.log",
            "**/*repomix*.txt",
            "**/*.html",
            "**/data/*",
            "**/*copy.js",
            "**/conversations.json"
        ]
    }
}
