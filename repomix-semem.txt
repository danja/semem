This file is a merged representation of the entire codebase, combining all repository files into a single document.
Generated by Repomix on: 2025-01-01T14:51:19.192Z

================================================================
File Summary
================================================================

Purpose:
--------
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

File Format:
------------
The content is organized as follows:
1. This summary section
2. Repository information
3. Repository structure
4. Multiple file entries, each consisting of:
  a. A separator line (================)
  b. The file path (File: path/to/file)
  c. Another separator line
  d. The full contents of the file
  e. A blank line

Usage Guidelines:
-----------------
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
- Pay special attention to the Repository Description. These contain important context and guidelines specific to this project.

Notes:
------
- Some files may have been excluded based on .gitignore rules and Repomix's
  configuration.
- Binary files are not included in this packed representation. Please refer to
  the Repository Structure section for a complete list of file paths, including
  binary files.
- Code comments have been removed.

Additional Info:
----------------
User Provided Header:
-----------------------
Semem repo

For more information about Repomix, visit: https://github.com/yamadashy/repomix

================================================================
Repository Structure
================================================================
_old-src/
  example.js
  memory-manager.js
  remote-storage.js
misc/
  scripts/
    ollama-embedding-test.sh
    sparql-auth-test.sh
    sparql-upload-test.sh
spec/
  helpers/
    jasmine_examples/
      SpecHelper.js
    reporter.js
  integration/
    Ollama.spec.js
    sparql-advanced-backup-spec.js
    sparql-basic-backup-spec.js
    sparql-federation-spec.js
    sparql-store-integration-spec.js
  mocks/
    Ollama.js
  support/
    jasmine.json
  unit/
    cached-sparql-store-spec.js
    ContextWindowManager.spec.js
    MemoryManager.spec.js
    sparql-endpoint-spec.js
    sparql-store-spec.js
src/
  connectors/
    OllamaConnector.js
  stores/
    BaseStore.js
    CachedSPARQLStore.js
    InMemoryStore.js
    JSONStore.js
    MemoryStore.js
    SPARQLStore.js
  utils/
    SPARQLHelpers.js
  Config.js
  ContextManager.js
  ContextWindowManager.js
  MemoryManager.js
  OllamaExample.js
  PromptTemplates.js
  SPARQLExample.js
  Utils.js
.git
.gitignore
about.md
jasmine.json
jsdoc.json
LICENSE
memory.json
package.json
repomix.config.json

================================================================
Repository Files
================================================================

================
File: _old-src/example.js
================
import MemoryManager from './memoryManager.js';
import JSONStorage from './jsonStorage.js';
import RemoteStorage from './remoteStorage.js';
import Config from './config.js';

async function main() {

    const config = new Config({
        storage: {
            type: 'remote',
            options: {
                endpoint: 'https://api.example.com/memory',
                apiKey: process.env.STORAGE_API_KEY
            }
        },
        models: {
            chat: {
                provider: 'openai',
                model: 'gpt-4-turbo-preview'
            },
            embedding: {
                provider: 'openai',
                model: 'text-embedding-3-small'
            }
        }
    });


    let storage;
    switch (config.get('storage.type')) {
        case 'json':
            storage = new JSONStorage(config.get('storage.options.path'));
            break;
        case 'remote':
            storage = new RemoteStorage(config.get('storage.options'));
            break;
        default:
            storage = new InMemoryStorage();
    }


    const memoryManager = new MemoryManager({
        apiKey: process.env.OPENAI_API_KEY,
        chatModel: config.get('models.chat.provider'),
        chatModelName: config.get('models.chat.model'),
        embeddingModel: config.get('models.embedding.provider'),
        embeddingModelName: config.get('models.embedding.model'),
        storage
    });


    const prompt = "What's the current state of AI technology?";


    const relevantInteractions = await memoryManager.retrieveRelevantInteractions(prompt);


    const response = await memoryManager.generateResponse(prompt, [], relevantInteractions);
    console.log('Response:', response);


    const embedding = await memoryManager.getEmbedding(`${prompt} ${response}`);
    const concepts = await memoryManager.extractConcepts(`${prompt} ${response}`);
    await memoryManager.addInteraction(prompt, response, embedding, concepts);
}

main().catch(console.error);

================
File: _old-src/memory-manager.js
================
import { ChatOpenAI } from '@langchain/openai';
import { ChatOllama } from '@langchain/community/chat_models/ollama';
import { OpenAIEmbeddings } from '@langchain/openai';
import ollama from 'ollama';
import { v4 as uuidv4 } from 'uuid';
import MemoryStore from './memoryStore.js';
import InMemoryStorage from './inMemoryStorage.js';
import { logger } from './utils.js';

export default class MemoryManager {
    constructor({
        apiKey,
        chatModel = 'ollama',
        chatModelName = 'llama2',
        embeddingModel = 'ollama',
        embeddingModelName = 'nomic-embed-text',
        storage = null
    }) {
        this.apiKey = apiKey;
        this.chatModelName = chatModelName;
        this.embeddingModelName = embeddingModelName;
        this.dimension = 1536;

        this.initializeChatModel(chatModel, chatModelName);
        this.initializeEmbeddingModel(embeddingModel, embeddingModelName);

        this.memoryStore = new MemoryStore(this.dimension);
        this.storage = storage || new InMemoryStorage();

        this.initialize();
    }

    initializeChatModel(chatModel, modelName) {
        if (chatModel.toLowerCase() === 'openai') {
            this.llm = new ChatOpenAI({
                modelName: modelName,
                apiKey: this.apiKey
            });
        } else if (chatModel.toLowerCase() === 'ollama') {
            this.llm = new ChatOllama({
                model: modelName,
                temperature: 0
            });
        } else {
            throw new Error(`Unsupported chat model: ${chatModel}`);
        }
    }

    async initializeEmbeddingModel(embeddingModel, modelName) {
        if (embeddingModel.toLowerCase() === 'openai') {
            this.embeddings = new OpenAIEmbeddings({
                modelName,
                apiKey: this.apiKey
            });
            this.dimension = modelName === 'text-embedding-3-small' ? 1536 : 1024;
        } else if (embeddingModel.toLowerCase() === 'ollama') {
            this.embeddings = async (text) => {
                const response = await ollama.embeddings({
                    model: modelName,
                    prompt: text
                });
                return response.embedding;
            };
            this.dimension = 1024;
        } else {
            throw new Error(`Unsupported embedding model: ${embeddingModel}`);
        }
    }

    async initialize() {
        const [shortTerm, longTerm] = await this.storage.loadHistory();

        for (const interaction of shortTerm) {
            const embedding = this.standardizeEmbedding(interaction.embedding);
            interaction.embedding = embedding;
            this.memoryStore.addInteraction(interaction);
        }

        this.memoryStore.longTermMemory.push(...longTerm);
        this.memoryStore.clusterInteractions();

        logger.info(`Memory initialized with ${shortTerm.length} short-term and ${longTerm.length} long-term memories`);
    }

    standardizeEmbedding(embedding) {
        const current = embedding.length;
        if (current === this.dimension) return embedding;

        if (current < this.dimension) {
            return [...embedding, ...new Array(this.dimension - current).fill(0)];
        }
        return embedding.slice(0, this.dimension);
    }

    async getEmbedding(text) {
        logger.info('Generating embedding...');
        let embedding;

        try {
            if (typeof this.embeddings === 'function') {
                embedding = await this.embeddings(text);
            } else {
                embedding = await this.embeddings.embedQuery(text);
            }

            return this.standardizeEmbedding(embedding);
        } catch (error) {
            logger.error('Error generating embedding:', error);
            throw error;
        }
    }

    async extractConcepts(text) {
        logger.info('Extracting concepts...');

        const messages = [{
            role: 'system',
            content: 'Extract key concepts from the text. Return only an array of strings.'
        }, {
            role: 'user',
            content: text
        }];

        try {
            const response = await this.llm.call(messages);
            const concepts = JSON.parse(response.content);
            logger.info('Extracted concepts:', concepts);
            return concepts;
        } catch (error) {
            logger.error('Error extracting concepts:', error);
            return [];
        }
    }

    async addInteraction(prompt, output, embedding, concepts) {
        const interaction = {
            id: uuidv4(),
            prompt,
            output,
            embedding,
            timestamp: Date.now(),
            accessCount: 1,
            concepts,
            decayFactor: 1.0
        };

        this.memoryStore.addInteraction(interaction);
        await this.storage.saveMemoryToHistory(this.memoryStore);
    }

    async retrieveRelevantInteractions(query, similarityThreshold = 40, excludeLastN = 0) {
        const queryEmbedding = await this.getEmbedding(query);
        const queryConcepts = await this.extractConcepts(query);
        return this.memoryStore.retrieve(queryEmbedding, queryConcepts, similarityThreshold, excludeLastN);
    }

    async generateResponse(prompt, lastInteractions = [], retrievals = [], contextWindow = 3) {
        const context = this.buildContext(lastInteractions, retrievals, contextWindow);

        const messages = [{
            role: 'system',
            content: "You're a helpful assistant with memory of past interactions."
        }, {
            role: 'user',
            content: `${context}\nCurrent prompt: ${prompt}`
        }];

        try {
            const response = await this.llm.call(messages);
            return response.content.trim();
        } catch (error) {
            logger.error('Error generating response:', error);
            throw error;
        }
    }

    buildContext(lastInteractions, retrievals, contextWindow) {

================
File: _old-src/remote-storage.js
================
import BaseStorage from './storage.js';
import { logger } from './utils.js';

export default class RemoteStorage extends BaseStorage {
    constructor(options = {}) {
        super();
        this.endpoint = options.endpoint || 'http://localhost:8080';
        this.apiKey = options.apiKey;
        this.timeout = options.timeout || 5000;
    }

    async loadHistory() {
        try {
            const response = await fetch(`${this.endpoint}/memory`, {
                method: 'GET',
                headers: {
                    'Authorization': `Bearer ${this.apiKey}`,
                    'Content-Type': 'application/json'
                },
                timeout: this.timeout
            });

            if (!response.ok) {
                throw new Error(`HTTP error! status: ${response.status}`);
            }

            const data = await response.json();
            return [
                data.shortTermMemory || [],
                data.longTermMemory || []
            ];
        } catch (error) {
            logger.error('Error loading remote history:', error);
            throw error;
        }
    }

    async saveMemoryToHistory(memoryStore) {
        try {
            const history = {
                shortTermMemory: memoryStore.shortTermMemory.map((item, idx) => ({
                    id: item.id,
                    prompt: item.prompt,
                    output: item.output,
                    embedding: Array.from(memoryStore.embeddings[idx].flat()),
                    timestamp: memoryStore.timestamps[idx],
                    accessCount: memoryStore.accessCounts[idx],
                    concepts: Array.from(memoryStore.conceptsList[idx]),
                    decayFactor: item.decayFactor || 1.0
                })),
                longTermMemory: memoryStore.longTermMemory
            };

            const response = await fetch(`${this.endpoint}/memory`, {
                method: 'POST',
                headers: {
                    'Authorization': `Bearer ${this.apiKey}`,
                    'Content-Type': 'application/json'
                },
                body: JSON.stringify(history),
                timeout: this.timeout
            });

            if (!response.ok) {
                throw new Error(`HTTP error! status: ${response.status}`);
            }

            logger.info(`Saved memory to remote storage. Short-term: ${history.shortTermMemory.length}, Long-term: ${history.longTermMemory.length}`);
        } catch (error) {
            logger.error('Error saving to remote storage:', error);
            throw error;
        }
    }
}

================
File: misc/scripts/ollama-embedding-test.sh
================
curl http://localhost:11434/api/embeddings -d '{
  "model": "nomic-embed-text",
  "prompt": "The sky is blue because of Rayleigh scattering"
}'

================
File: misc/scripts/sparql-auth-test.sh
================
curl -X POST \
  -H "Authorization: Basic $(echo -n 'invalid:credentials' | base64)" \
  -H "Content-Type: application/sparql-query" \
  -H "Accept: application/json" \
  --data 'SELECT * WHERE { ?s ?p ?o } LIMIT 1' \
  'http://localhost:4030/test/query'

================
File: misc/scripts/sparql-upload-test.sh
================
curl -X POST \
  -H "Authorization: Basic $(echo -n 'admin:admin123' | base64)" \
  -H "Content-Type: text/turtle" \
  --data-binary '@-' \
  'http://localhost:4030/test/data?graph=http://example.org/test-graph' << 'EOF'
@prefix ex: <http://example.org/> .
ex:subject ex:predicate "test value" .
EOF

================
File: spec/helpers/jasmine_examples/SpecHelper.js
================
beforeEach(function () {
  jasmine.addMatchers({
    toBePlaying: function () {
      return {
        compare: function (actual, expected) {
          const player = actual;

          return {
            pass: player.currentlyPlayingSong === expected && player.isPlaying
          };
        }
      };
    }
  });
});

================
File: spec/helpers/reporter.js
================
import { SpecReporter } from 'jasmine-spec-reporter';

class CustomReporter {
    constructor() {
        this.specReporter = new SpecReporter({
            spec: {
                displayPending: true
            }
        });
    }

    jasmineStarted() {
        this.specReporter.jasmineStarted.apply(this.specReporter, arguments);
    }

    suiteStarted() {
        this.specReporter.suiteStarted.apply(this.specReporter, arguments);
    }

    specStarted() {
        this.specReporter.specStarted.apply(this.specReporter, arguments);
    }

    specDone() {
        this.specReporter.specDone.apply(this.specReporter, arguments);
    }

    suiteDone() {
        this.specReporter.suiteDone.apply(this.specReporter, arguments);
    }

    jasmineDone() {
        this.specReporter.jasmineDone.apply(this.specReporter, arguments);
    }
}

export default CustomReporter;

================
File: spec/integration/Ollama.spec.js
================
import OllamaConnector from '../../src/connectors/OllamaConnector.js';

describe('OllamaConnector Integration', () => {
    let api;

    beforeEach(() => {
        api = new OllamaConnector('http://localhost:11434');
    });

    it('should generate chat response', async () => {
        const messages = [{
            role: 'user',
            content: 'Hello, how are you?'
        }];

        const response = await api.generateChat('llama2', messages);
        expect(typeof response).toBe('string');
        expect(response.length).toBeGreaterThan(0);
    });

    it('should generate embeddings', async () => {
        const embedding = await api.generateEmbedding(
            'nomic-embed-text',
            'Test text for embedding'
        );

        expect(Array.isArray(embedding)).toBe(true);
        expect(embedding.length).toBe(1536);
    });

    it('should handle API errors gracefully', async () => {
        try {
            await api.generateChat('nonexistent-model', []);
            fail('Should have thrown an error');
        } catch (error) {
            expect(error.message).toContain('Ollama API error');
        }
    });
});

================
File: spec/integration/sparql-advanced-backup-spec.js
================
import Config from '../../src/Config.js';
import SPARQLStore from '../../src/stores/SPARQLStore.js';
import { logger } from '../../src/Utils.js';

describe('SPARQLStore Advanced Backup Integration', () => {
    let store;
    let config;
    const testGraph = 'http://example.org/mcp/test-backup-advanced';
    let originalData;

    beforeAll(async () => {
        config = new Config();
        const sparqlConfig = config.get('sparqlEndpoints')[0];

        store = new SPARQLStore({
            query: `${sparqlConfig.urlBase}${sparqlConfig.query}`,
            update: `${sparqlConfig.urlBase}${sparqlConfig.update}`
        }, {
            user: sparqlConfig.user,
            password: sparqlConfig.password,
            graphName: testGraph
        });


        originalData = {
            shortTermMemory: [{
                id: 'advanced-backup-1',
                prompt: 'advanced backup test',
                output: 'original output',
                embedding: new Array(1536).fill(0).map(() => Math.random()),
                timestamp: Date.now(),
                accessCount: 1,
                concepts: ['advanced', 'backup'],
                decayFactor: 1.0
            }],
            longTermMemory: []
        };


        try {
            await store.beginTransaction();
            const setupQuery = `
                DROP SILENT GRAPH <${testGraph}>;
                CREATE GRAPH <${testGraph}>
            `;
            await store._executeSparqlUpdate(setupQuery, store.endpoint.update);
            await store.commitTransaction();


            await store.saveMemoryToHistory(originalData);
        } catch (error) {
            logger.error('Error in advanced backup test setup:', error);
            throw error;
        }
    });

    afterAll(async () => {
        try {
            await store.beginTransaction();
            const cleanupQuery = `
                DROP SILENT GRAPH <${testGraph}>;
                DROP SILENT GRAPH <${testGraph}.backup>
            `;
            await store._executeSparqlUpdate(cleanupQuery, store.endpoint.update);
            await store.commitTransaction();
        } finally {
            await store.close();
        }
    });

    it('should handle backup corruption', async () => {
        await store.beginTransaction();


        const corruptQuery = `
            INSERT DATA {
                GRAPH <${testGraph}.backup> {
                    _:corrupt a mcp:Invalid ;
                        mcp:invalidProp "test" .
                }
            }
        `;
        await store._executeSparqlUpdate(corruptQuery, store.endpoint.update);


        const modifiedData = {
            shortTermMemory: [{
                ...originalData.shortTermMemory[0],
                output: 'corrupt test output'
            }],
            longTermMemory: []
        };


        try {
            await store.saveMemoryToHistory(modifiedData);
            fail('Should have detected corruption');
        } catch (error) {

            const [shortTerm] = await store.loadHistory();
            expect(shortTerm[0].output).toBe('original output');
        }

        await store.rollbackTransaction();
    });

    it('should perform incremental backups', async () => {
        await store.beginTransaction();


        const updates = [
            { id: 'incremental-1', output: 'first update' },
            { id: 'incremental-2', output: 'second update' }
        ];

        for (const update of updates) {
            const incrementalData = {
                shortTermMemory: [
                    ...originalData.shortTermMemory,
                    {
                        ...originalData.shortTermMemory[0],
                        ...update
                    }
                ],
                longTermMemory: []
            };

            await store.saveMemoryToHistory(incrementalData);


            const verifyQuery = `
                PREFIX mcp: <http://purl.org/stuff/mcp/>
                ASK {
                    GRAPH <${testGraph}.backup> {
                        ?s mcp:id "${update.id}" ;
                           mcp:output "${update.output}" .
                    }
                }
            `;
            const result = await store._executeSparqlQuery(verifyQuery, store.endpoint.query);
            expect(result.boolean).toBe(true);
        }


        await store.rollbackTransaction();

        const [shortTerm] = await store.loadHistory();
        expect(shortTerm.length).toBe(1);
        expect(shortTerm[0].id).toBe('advanced-backup-1');
    });

    it('should handle concurrent backup operations', async () => {
        const store2 = new SPARQLStore({
            query: store.endpoint.query,
            update: store.endpoint.update
        }, {
            user: store.credentials.user,
            password: store.credentials.password,
            graphName: testGraph
        });

        await store.beginTransaction();


        await expectAsync(store2.beginTransaction())
            .toBeRejectedWithError(/Transaction already in progress/);

        await store.rollbackTransaction();
        await store2.close();
    });

    it('should verify backup integrity', async () => {
        await store.beginTransaction();


        const verifyQuery = `
            PREFIX mcp: <http://purl.org/stuff/mcp/>
            SELECT ?prop ?value
            WHERE {
                GRAPH <${testGraph}> {
                    ?s1 mcp:id "advanced-backup-1" ;
                        ?prop ?value .
                }
                GRAPH <${testGraph}.backup> {
                    ?s2 mcp:id "advanced-backup-1" ;
                        ?prop ?value2 .
                    FILTER(?value = ?value2)
                }
            }
        `;

        const results = await store._executeSparqlQuery(verifyQuery, store.endpoint.query);
        expect(results.results.bindings.length).toBeGreaterThan(0);

        await store.rollbackTransaction();
    });

    it('should handle large backup operations', async () => {
        await store.beginTransaction();


        const largeData = {
            shortTermMemory: Array(100).fill(null).map((_, i) => ({
                id: `large-backup-${i}`,
                prompt: `large backup test ${i}`,
                output: `test output ${i}`,
                embedding: new Array(1536).fill(0).map(() => Math.random()),
                timestamp: Date.now(),
                accessCount: 1,
                concepts: ['large', 'backup', `test-${i}`],
                decayFactor: 1.0
            })),
            longTermMemory: []
        };

        await store.saveMemoryToHistory(largeData);


        const countQuery = `
            SELECT (COUNT(?s) as ?count)
            WHERE {
                GRAPH <${testGraph}.backup> {
                    ?s a mcp:Interaction
                }
            }
        `;

        const results = await store._executeSparqlQuery(countQuery, store.endpoint.query);
        expect(parseInt(results.results.bindings[0].count.value)).toBe(100);

        await store.rollbackTransaction();
    });
});

================
File: spec/integration/sparql-basic-backup-spec.js
================
import Config from '../../src/Config.js';
import SPARQLStore from '../../src/stores/SPARQLStore.js';
import { logger } from '../../src/Utils.js';

describe('SPARQLStore Basic Backup Integration', () => {
    let store;
    let config;
    const testGraph = 'http://example.org/mcp/test-backup-basic';
    let originalData;

    beforeAll(async () => {
        config = new Config();
        const sparqlConfig = config.get('sparqlEndpoints')[0];

        store = new SPARQLStore({
            query: `${sparqlConfig.urlBase}${sparqlConfig.query}`,
            update: `${sparqlConfig.urlBase}${sparqlConfig.update}`
        }, {
            user: sparqlConfig.user,
            password: sparqlConfig.password,
            graphName: testGraph
        });


        originalData = {
            shortTermMemory: [{
                id: 'backup-test-1',
                prompt: 'backup test prompt',
                output: 'backup test output',
                embedding: new Array(1536).fill(0).map(() => Math.random()),
                timestamp: Date.now(),
                accessCount: 1,
                concepts: ['backup', 'test'],
                decayFactor: 1.0
            }],
            longTermMemory: []
        };


        try {
            await store.beginTransaction();
            const setupQuery = `
                DROP SILENT GRAPH <${testGraph}>;
                CREATE GRAPH <${testGraph}>
            `;
            await store._executeSparqlUpdate(setupQuery, store.endpoint.update);
            await store.commitTransaction();


            await store.saveMemoryToHistory(originalData);
        } catch (error) {
            logger.error('Error in backup test setup:', error);
            throw error;
        }
    });

    afterAll(async () => {
        try {
            await store.beginTransaction();
            const cleanupQuery = `
                DROP SILENT GRAPH <${testGraph}>;
                DROP SILENT GRAPH <${testGraph}.backup>
            `;
            await store._executeSparqlUpdate(cleanupQuery, store.endpoint.update);
            await store.commitTransaction();
        } finally {
            await store.close();
        }
    });

    it('should create backup during transaction', async () => {
        await store.beginTransaction();


        const verifyQuery = `
            ASK { GRAPH <${testGraph}.backup> { ?s ?p ?o } }
        `;
        const result = await store._executeSparqlQuery(verifyQuery, store.endpoint.query);
        expect(result.boolean).toBe(true);

        await store.commitTransaction();
    });

    it('should restore from backup on rollback', async () => {
        await store.beginTransaction();


        const modifiedData = {
            shortTermMemory: [{
                ...originalData.shortTermMemory[0],
                output: 'modified output'
            }],
            longTermMemory: []
        };

        await store.saveMemoryToHistory(modifiedData);


        let [shortTerm] = await store.loadHistory();
        expect(shortTerm[0].output).toBe('modified output');


        await store.rollbackTransaction();


        [shortTerm] = await store.loadHistory();
        expect(shortTerm[0].output).toBe('backup test output');
    });

    it('should cleanup backup graphs after commit', async () => {
        await store.beginTransaction();
        await store.commitTransaction();


        const verifyQuery = `
            ASK { GRAPH <${testGraph}.backup> { ?s ?p ?o } }
        `;
        const result = await store._executeSparqlQuery(verifyQuery, store.endpoint.query);
        expect(result.boolean).toBe(false);
    });

    it('should handle nested transaction attempts', async () => {
        await store.beginTransaction();

        await expectAsync(store.beginTransaction())
            .toBeRejectedWithError('Transaction already in progress');

        await store.rollbackTransaction();
    });

    it('should preserve backup during multiple operations', async () => {
        await store.beginTransaction();


        const modifications = [
            { output: 'first modification' },
            { output: 'second modification' },
            { output: 'third modification' }
        ];

        for (const mod of modifications) {
            const modData = {
                shortTermMemory: [{
                    ...originalData.shortTermMemory[0],
                    ...mod
                }],
                longTermMemory: []
            };
            await store.saveMemoryToHistory(modData);
        }


        await store.rollbackTransaction();

        const [shortTerm] = await store.loadHistory();
        expect(shortTerm[0].output).toBe('backup test output');
    });
});

================
File: spec/integration/sparql-federation-spec.js
================
import Config from '../../src/Config.js';
import SPARQLStore from '../../src/stores/SPARQLStore.js';
import { logger } from '../../src/Utils.js';

describe('SPARQLStore Federation Integration', () => {
    let store;
    let config;
    const testGraphs = {
        main: 'http://example.org/mcp/test-memory',
        metadata: 'http://example.org/mcp/test-metadata',
        archive: 'http://example.org/mcp/test-archive'
    };

    beforeAll(async () => {
        config = new Config();
        const sparqlConfig = config.get('sparqlEndpoints')[0];

        store = new SPARQLStore({
            query: `${sparqlConfig.urlBase}${sparqlConfig.query}`,
            update: `${sparqlConfig.urlBase}${sparqlConfig.update}`
        }, {
            user: sparqlConfig.user,
            password: sparqlConfig.password,
            graphName: testGraphs.main
        });


        try {
            await store.beginTransaction();
            const setupQuery = `
                DROP SILENT GRAPH <${testGraphs.main}>;
                DROP SILENT GRAPH <${testGraphs.metadata}>;
                DROP SILENT GRAPH <${testGraphs.archive}>;
                CREATE GRAPH <${testGraphs.main}>;
                CREATE GRAPH <${testGraphs.metadata}>;
                CREATE GRAPH <${testGraphs.archive}>
            `;
            await store._executeSparqlUpdate(setupQuery, store.endpoint.update);


            const metadataQuery = `
                INSERT DATA {
                    GRAPH <${testGraphs.metadata}> {
                        <${testGraphs.main}> a mcp:MemoryStore ;
                            mcp:hasVersion "1.0" ;
                            mcp:lastUpdated "${new Date().toISOString()}"^^xsd:dateTime .
                    }
                }
            `;
            await store._executeSparqlUpdate(metadataQuery, store.endpoint.update);
            await store.commitTransaction();
        } catch (error) {
            logger.error('Error in federation test setup:', error);
            throw error;
        }
    });

    afterAll(async () => {
        try {
            await store.beginTransaction();
            const cleanupQuery = `
                DROP SILENT GRAPH <${testGraphs.main}>;
                DROP SILENT GRAPH <${testGraphs.metadata}>;
                DROP SILENT GRAPH <${testGraphs.archive}>
            `;
            await store._executeSparqlUpdate(cleanupQuery, store.endpoint.update);
            await store.commitTransaction();
        } finally {
            await store.close();
        }
    });

    it('should query across multiple graphs', async () => {

        const testMemory = {
            shortTermMemory: [{
                id: 'federation-test-1',
                prompt: 'federation test prompt',
                output: 'federation test output',
                embedding: new Array(1536).fill(0).map(() => Math.random()),
                timestamp: Date.now(),
                concepts: ['federation', 'test'],
                accessCount: 1,
                decayFactor: 1.0
            }],
            longTermMemory: []
        };

        await store.saveMemoryToHistory(testMemory);


        const federatedQuery = `
            PREFIX mcp: <http://purl.org/stuff/mcp/>
            SELECT ?interaction ?version ?updated
            WHERE {
                GRAPH <${testGraphs.main}> {
                    ?interaction a mcp:Interaction ;
                        mcp:id "federation-test-1" .
                }
                GRAPH <${testGraphs.metadata}> {
                    <${testGraphs.main}> mcp:hasVersion ?version ;
                        mcp:lastUpdated ?updated .
                }
            }
        `;

        const results = await store._executeSparqlQuery(federatedQuery, store.endpoint.query);
        expect(results.results.bindings.length).toBe(1);
        expect(results.results.bindings[0].version.value).toBe('1.0');
    });

    it('should handle cross-graph data relationships', async () => {

        const setupQuery = `
            PREFIX mcp: <http://purl.org/stuff/mcp/>
            PREFIX qb: <http://purl.org/linked-data/cube#>

            INSERT DATA {
                GRAPH <${testGraphs.main}> {
                    _:interaction1 a mcp:Interaction ;
                        mcp:id "related-test-1" ;
                        mcp:relatedCube <cube1> .
                }

                GRAPH <${testGraphs.metadata}> {
                    <cube1> a qb:DataSet ;
                        qb:structure <dsd1> ;
                        rdfs:label "Test Cube" .
                }
            }
        `;

        await store._executeSparqlUpdate(setupQuery, store.endpoint.update);


        const relationQuery = `
            PREFIX mcp: <http://purl.org/stuff/mcp/>
            PREFIX qb: <http://purl.org/linked-data/cube#>

            SELECT ?id ?cubeLabel
            WHERE {
                GRAPH <${testGraphs.main}> {
                    ?interaction mcp:id ?id ;
                        mcp:relatedCube ?cube .
                }
                GRAPH <${testGraphs.metadata}> {
                    ?cube rdfs:label ?cubeLabel .
                }
            }
        `;

        const results = await store._executeSparqlQuery(relationQuery, store.endpoint.query);
        expect(results.results.bindings.length).toBe(1);
        expect(results.results.bindings[0].cubeLabel.value).toBe('Test Cube');
    });

    it('should support federated updates across graphs', async () => {
        await store.beginTransaction();
        try {
            const federatedUpdate = `
                PREFIX mcp: <http://purl.org/stuff/mcp/>

                WITH <${testGraphs.main}>
                DELETE { ?i mcp:accessCount ?oldCount }
                INSERT { ?i mcp:accessCount ?newCount }
                WHERE {
                    ?i mcp:id "federation-test-1" ;
                       mcp:accessCount ?oldCount .
                    BIND(?oldCount + 1 AS ?newCount)
                };

                WITH <${testGraphs.metadata}>
                DELETE { <${testGraphs.main}> mcp:lastUpdated ?old }
                INSERT { <${testGraphs.main}> mcp:lastUpdated "${new Date().toISOString()}"^^xsd:dateTime }
                WHERE {
                    <${testGraphs.main}> mcp:lastUpdated ?old
                }
            `;

            await store._executeSparqlUpdate(federatedUpdate, store.endpoint.update);
            await store.commitTransaction();


            const [shortTerm] = await store.loadHistory();
            expect(shortTerm[0].accessCount).toBe(2);
        } catch (error) {
            await store.rollbackTransaction();
            throw error;
        }
    });

    it('should handle service-based federation', async () => {

        const serviceQuery = `
            PREFIX mcp: <http://purl.org/stuff/mcp/>

            SELECT ?interaction ?metadata
            WHERE {
                SERVICE <${store.endpoint.query}> {
                    GRAPH <${testGraphs.main}> {
                        ?interaction mcp:id "federation-test-1"
                    }
                }
                SERVICE <${store.endpoint.query}> {
                    GRAPH <${testGraphs.metadata}> {
                        <${testGraphs.main}> ?p ?metadata
                    }
                }
            }
        `;

        const results = await store._executeSparqlQuery(serviceQuery, store.endpoint.query);
        expect(results.results.bindings.length).toBeGreaterThan(0);
    });
});

================
File: spec/integration/sparql-store-integration-spec.js
================
import Config from '../../src/Config.js';
import SPARQLStore from '../../src/stores/SPARQLStore.js';
import { logger } from '../../src/Utils.js';

describe('SPARQLStore Integration', () => {
    let store;
    let config;
    let testMemory;

    beforeAll(async () => {

        config = new Config();
        const sparqlConfig = config.get('sparqlEndpoints')[0];

        store = new SPARQLStore({
            query: `${sparqlConfig.urlBase}${sparqlConfig.query}`,
            update: `${sparqlConfig.urlBase}${sparqlConfig.update}`
        }, {
            user: sparqlConfig.user,
            password: sparqlConfig.password,
            graphName: 'http://example.org/mcp/test-memory'
        });


        testMemory = {
            shortTermMemory: [{
                id: 'test-integration-1',
                prompt: 'integration test prompt',
                output: 'integration test output',
                embedding: new Array(1536).fill(0).map(() => Math.random()),
                timestamp: Date.now(),
                accessCount: 1,
                concepts: ['test', 'integration'],
                decayFactor: 1.0
            }],
            longTermMemory: []
        };


        try {
            await store.beginTransaction();
            const clearQuery = `
                DROP SILENT GRAPH <http://example.org/mcp/test-memory>;
                CREATE GRAPH <http://example.org/mcp/test-memory>
            `;
            await store._executeSparqlUpdate(clearQuery, `${sparqlConfig.urlBase}${sparqlConfig.update}`);
            await store.commitTransaction();
        } catch (error) {
            logger.error('Error in test setup:', error);
            throw error;
        }
    });

    afterAll(async () => {

        try {
            await store.beginTransaction();
            const dropQuery = `DROP SILENT GRAPH <http://example.org/mcp/test-memory>`;
            await store._executeSparqlUpdate(dropQuery, `${config.get('sparqlEndpoints')[0].urlBase}${config.get('sparqlEndpoints')[0].update}`);
            await store.commitTransaction();
        } finally {
            await store.close();
        }
    });

    it('should verify empty graph exists', async () => {
        const exists = await store.verify();
        expect(exists).toBe(true);
    });

    it('should save and load memory data', async () => {

        await store.saveMemoryToHistory(testMemory);


        const [shortTerm, longTerm] = await store.loadHistory();

        expect(shortTerm.length).toBe(1);
        expect(longTerm.length).toBe(0);

        const loaded = shortTerm[0];
        expect(loaded.id).toBe(testMemory.shortTermMemory[0].id);
        expect(loaded.prompt).toBe(testMemory.shortTermMemory[0].prompt);
        expect(loaded.concepts).toEqual(testMemory.shortTermMemory[0].concepts);
        expect(loaded.embedding.length).toBe(1536);
    });

    it('should handle transaction rollback', async () => {
        await store.beginTransaction();

        const badMemory = {
            shortTermMemory: [{
                id: 'test-rollback',
                prompt: 'should not persist',
                output: 'rollback test',
                embedding: new Array(1536).fill(0),
                timestamp: Date.now(),
                accessCount: 1,
                concepts: ['rollback'],
                decayFactor: 1.0
            }],
            longTermMemory: []
        };

        try {

            await store.saveMemoryToHistory(badMemory);

            throw new Error('Test rollback');
        } catch (error) {
            await store.rollbackTransaction();
        }


        const [shortTerm] = await store.loadHistory();
        expect(shortTerm.length).toBe(1);
        expect(shortTerm[0].id).toBe('test-integration-1');
    });

    it('should handle concurrent transactions', async () => {
        const store2 = new SPARQLStore(store.endpoint, {
            user: store.credentials.user,
            password: store.credentials.password,
            graphName: store.graphName
        });

        await store.beginTransaction();


        await expectAsync(store2.beginTransaction())
            .toBeRejectedWithError(/Transaction already in progress/);

        await store.commitTransaction();
        await store2.close();
    });

    it('should support query pagination', async () => {

        const bulkMemory = {
            shortTermMemory: Array(5).fill(null).map((_, i) => ({
                id: `bulk-test-${i}`,
                prompt: `bulk test prompt ${i}`,
                output: `bulk test output ${i}`,
                embedding: new Array(1536).fill(0).map(() => Math.random()),
                timestamp: Date.now(),
                accessCount: 1,
                concepts: ['bulk', `test-${i}`],
                decayFactor: 1.0
            })),
            longTermMemory: []
        };

        await store.saveMemoryToHistory(bulkMemory);


        const pageSize = 2;
        const query = `
            PREFIX mcp: <http://purl.org/stuff/mcp/>
            SELECT ?id ?prompt
            FROM <${store.graphName}>
            WHERE {
                ?s mcp:id ?id ;
                   mcp:prompt ?prompt .
            }
            LIMIT ${pageSize}
        `;

        const results = await store._executeSparqlQuery(query, store.endpoint.query);
        expect(results.results.bindings.length).toBe(pageSize);
    });
});

================
File: spec/mocks/Ollama.js
================
export class MockOllamaConnector {
    async generateEmbedding(model, input) {
        return new Array(1536).fill(0).map(() => Math.random());
    }

    async generateChat(model, messages) {
        return 'Mock response';
    }

    async generateCompletion(model, prompt) {
        return 'Mock completion';
    }
}

================
File: spec/support/jasmine.json
================
{
  "spec_dir": "spec",
  "spec_files": [
    "**/*[sS]pec.?(m)js"
  ],
  "helpers": [
    "helpers/**/*.?(m)js"
  ],
  "env": {
    "stopSpecOnExpectationFailure": false,
    "random": true
  }
}

================
File: spec/unit/cached-sparql-store-spec.js
================
import CachedSPARQLStore from '../../src/stores/CachedSPARQLStore.js';

describe('CachedSPARQLStore', () => {
    let store;
    let mockFetch;
    let originalSetInterval;
    let mockSetInterval;

    const endpoint = {
        query: 'http://example.org/sparql/query',
        update: 'http://example.org/sparql/update'
    };

    beforeEach(() => {

        originalSetInterval = global.setInterval;
        mockSetInterval = jasmine.createSpy('setInterval').and.returnValue(123);
        global.setInterval = mockSetInterval;


        mockFetch = jasmine.createSpy('fetch').and.returnValue(
            Promise.resolve({
                ok: true,
                json: () => Promise.resolve({
                    results: { bindings: [] }
                })
            })
        );
        global.fetch = mockFetch;
        global.Buffer = {
            from: (str) => ({ toString: () => 'mock-base64' })
        };

        store = new CachedSPARQLStore(endpoint, {
            user: 'testuser',
            password: 'testpass',
            graphName: 'http://test.org/memory',
            cacheTTL: 1000,
            maxCacheSize: 2
        });

        jasmine.clock().install();
    });

    afterEach(() => {
        delete global.fetch;
        delete global.Buffer;
        global.setInterval = originalSetInterval;
        jasmine.clock().uninstall();
    });

    describe('cache operations', () => {
        it('should cache query results', async () => {
            const query = 'SELECT * WHERE { ?s ?p ?o }';
            const mockResult = { results: { bindings: [{ s: { value: 'test' } }] } };

            mockFetch.and.returnValue(
                Promise.resolve({
                    ok: true,
                    json: () => Promise.resolve(mockResult)
                })
            );


            await store._executeSparqlQuery(query, endpoint.query);
            expect(mockFetch).toHaveBeenCalledTimes(1);


            mockFetch.calls.reset();
            const cachedResult = await store._executeSparqlQuery(query, endpoint.query);
            expect(mockFetch).not.toHaveBeenCalled();
            expect(cachedResult).toEqual(mockResult);
        });

        it('should expire cache entries after TTL', async () => {
            const query = 'SELECT * WHERE { ?s ?p ?o }';


            await store._executeSparqlQuery(query, endpoint.query);
            expect(mockFetch).toHaveBeenCalledTimes(1);


            jasmine.clock().tick(1001);


            mockFetch.calls.reset();
            await store._executeSparqlQuery(query, endpoint.query);
            expect(mockFetch).toHaveBeenCalledTimes(1);
        });

        it('should respect max cache size', async () => {

            await store._executeSparqlQuery('query1', endpoint.query);
            await store._executeSparqlQuery('query2', endpoint.query);
            await store._executeSparqlQuery('query3', endpoint.query);

            expect(store.queryCache.size).toBeLessThanOrEqual(2);
        });

        it('should invalidate cache on data updates', async () => {

            await store._executeSparqlQuery('SELECT * WHERE { ?s ?p ?o }', endpoint.query);
            expect(store.queryCache.size).toBe(1);


            await store.saveMemoryToHistory({ shortTermMemory: [], longTermMemory: [] });
            expect(store.queryCache.size).toBe(0);
        });
    });

    describe('cache cleanup', () => {
        it('should remove expired entries during cleanup', () => {

            store.queryCache.set('test1', { data: 1 });
            store.cacheTimestamps.set('test1', Date.now() - 2000);
            store.queryCache.set('test2', { data: 2 });
            store.cacheTimestamps.set('test2', Date.now());

            store.cleanupCache();

            expect(store.queryCache.has('test1')).toBeFalse();
            expect(store.queryCache.has('test2')).toBeTrue();
        });

        it('should remove oldest entries when over size limit', () => {

            store.queryCache.set('test1', { data: 1 });
            store.cacheTimestamps.set('test1', 1000);
            store.queryCache.set('test2', { data: 2 });
            store.cacheTimestamps.set('test2', 2000);
            store.queryCache.set('test3', { data: 3 });
            store.cacheTimestamps.set('test3', 3000);

            store.cleanupCache();

            expect(store.queryCache.size).toBe(2);
            expect(store.queryCache.has('test1')).toBeFalse();
            expect(store.queryCache.has('test3')).toBeTrue();
        });
    });

    describe('cleanup on close', () => {
        it('should clear interval and cache on close', async () => {
            const mockClearInterval = jasmine.createSpy('clearInterval');
            global.clearInterval = mockClearInterval;

            await store.close();

            expect(mockClearInterval).toHaveBeenCalledWith(123);
            expect(store.queryCache.size).toBe(0);
            expect(store.cacheTimestamps.size).toBe(0);
        });
    });
});

================
File: spec/unit/ContextWindowManager.spec.js
================
import ContextWindowManager from '../../src/ContextWindowManager.js';

describe('ContextWindowManager', () => {
    let windowManager;

    beforeEach(() => {
        windowManager = new ContextWindowManager({
            maxWindowSize: 1000,
            minWindowSize: 250,
            overlapRatio: 0.1
        });
    });

    it('should calculate correct window size', () => {
        const size = windowManager.calculateWindowSize('x'.repeat(1000));
        expect(size).toBeLessThanOrEqual(1000);
        expect(size).toBeGreaterThanOrEqual(250);
    });

    it('should create overlapping windows', () => {
        const text = 'x'.repeat(2000);
        const windows = windowManager.createWindows(text, 1000);
        expect(windows.length).toBeGreaterThan(1);
        expect(windows[0].text.length).toBeLessThanOrEqual(1000);
    });

    it('should merge overlapping content', () => {
        const windows = [
            { text: 'Hello world' },
            { text: 'world and universe' }
        ];
        const merged = windowManager.mergeOverlappingContent(windows);
        expect(merged).toBe('Hello world and universe');
    });
});

================
File: spec/unit/MemoryManager.spec.js
================
import MemoryManager from '../../src/MemoryManager.js';
import { MockOllamaConnector } from '../mocks/Ollama.js';
import InMemoryStore from '../../src/stores/InMemoryStore.js';

describe('MemoryManager', () => {
    let manager;
    let mockOllama;

    beforeEach(() => {
        mockOllama = new MockOllamaConnector();
        manager = new MemoryManager({
            llmProvider: mockOllama,
            chatModel: 'qwen2:1.5b',
            embeddingModel: 'nomic-embed-text',
            storage: new InMemoryStorage()
        });
    });

    it('should generate embeddings', async () => {
        const embedding = await manager.getEmbedding('test text');
        expect(embedding.length).toBe(1536);
        expect(Array.isArray(embedding)).toBe(true);
    });

    it('should extract concepts', async () => {
        const concepts = await manager.extractConcepts('AI and machine learning');
        expect(Array.isArray(concepts)).toBe(true);
        expect(concepts.length).toBeGreaterThan(0);
    });

    it('should add and retrieve interactions', async () => {
        const prompt = 'test prompt';
        const response = 'test response';
        const embedding = new Array(1536).fill(0);
        const concepts = ['test'];

        await manager.addInteraction(prompt, response, embedding, concepts);
        const retrievals = await manager.retrieveRelevantInteractions(prompt);

        expect(retrievals.length).toBeGreaterThan(0);
        expect(retrievals[0].interaction.prompt).toBe(prompt);
    });
});

================
File: spec/unit/sparql-endpoint-spec.js
================
import Config from '../../src/Config.js';
import { SPARQLHelpers } from '../../src/utils/SPARQLHelpers.js';

describe('SPARQL Endpoint Integration', () => {
    let config;
    let endpoint;
    let auth;
    let baseUrl;
    const testGraph = 'http://example.org/test-graph';

    beforeAll(() => {
        config = new Config();
        const sparqlConfig = config.get('sparqlEndpoints')[0];

        baseUrl = `${sparqlConfig.urlBase}/test`;
        endpoint = {
            query: `${baseUrl}/query`,
            update: `${baseUrl}/update`
        };
        auth = SPARQLHelpers.createAuthHeader(sparqlConfig.user, sparqlConfig.password);
    });

    beforeEach(async () => {

        const clearQuery = `
            DROP SILENT GRAPH <${testGraph}>;
            CREATE GRAPH <${testGraph}>
        `;
        await SPARQLHelpers.executeSPARQLUpdate(endpoint.update, clearQuery, auth);
    });

    afterAll(async () => {

        const dropQuery = `DROP SILENT GRAPH <${testGraph}>`;
        await SPARQLHelpers.executeSPARQLUpdate(endpoint.update, dropQuery, auth);
    });

    describe('SPARQL UPDATE operations', () => {
        it('should insert data into graph', async () => {
            const insertQuery = `
                PREFIX ex: <http://example.org/>
                INSERT DATA {
                    GRAPH <${testGraph}> {
                        ex:subject ex:predicate "test object" .
                    }
                }
            `;

            await expectAsync(
                SPARQLHelpers.executeSPARQLUpdate(endpoint.update, insertQuery, auth)
            ).toBeResolved();
        });

        it('should delete data from graph', async () => {
            const deleteQuery = `
                PREFIX ex: <http://example.org/>
                DELETE DATA {
                    GRAPH <${testGraph}> {
                        ex:subject ex:predicate "test object" .
                    }
                }
            `;

            await expectAsync(
                SPARQLHelpers.executeSPARQLUpdate(endpoint.update, deleteQuery, auth)
            ).toBeResolved();
        });
    });

    describe('SPARQL SELECT operations', () => {
        beforeEach(async () => {

            const setupQuery = `
                PREFIX ex: <http://example.org/>
                INSERT DATA {
                    GRAPH <${testGraph}> {
                        ex:subject1 ex:predicate "value1" .
                        ex:subject2 ex:predicate "value2" .
                    }
                }
            `;
            await SPARQLHelpers.executeSPARQLUpdate(endpoint.update, setupQuery, auth);
        });

        it('should retrieve data with SELECT query', async () => {
            const selectQuery = `
                PREFIX ex: <http://example.org/>
                SELECT ?s ?o
                FROM <${testGraph}>
                WHERE {
                    ?s ex:predicate ?o .
                }
            `;

            const response = await SPARQLHelpers.executeSPARQLQuery(endpoint.query, selectQuery, auth);
            const data = await response.json();
            expect(data.results.bindings.length).toBe(2);
        });
    });

    describe('Turtle operations', () => {
        const testTurtle = `
            @prefix ex: <http://example.org/> .
            ex:subject ex:predicate "test value" .
        `;

        it('should upload Turtle data and return counts', async () => {
            const result = await SPARQLHelpers.uploadTurtle(baseUrl, testTurtle, auth, testGraph);

            expect(result.success).toBe(true);
            expect(result.counts.triples).toBe(1);
            expect(result.counts.total).toBe(1);


            const verifyQuery = `
                ASK FROM <${testGraph}>
                WHERE {
                    ?s ?p "test value"
                }
            `;
            const askResponse = await SPARQLHelpers.executeSPARQLQuery(endpoint.query, verifyQuery, auth);
            const askResult = await askResponse.json();
            expect(askResult.boolean).toBe(true);
        });

        it('should retrieve data as Turtle using CONSTRUCT', async () => {

            const insertQuery = `
                PREFIX ex: <http://example.org/>
                INSERT DATA {
                    GRAPH <${testGraph}> {
                        ex:subject ex:predicate "test value" .
                    }
                }
            `;
            await SPARQLHelpers.executeSPARQLUpdate(endpoint.update, insertQuery, auth);

            const constructQuery = `
                CONSTRUCT {
                    ?s ?p ?o
                }
                FROM <${testGraph}>
                WHERE {
                    ?s ?p ?o
                }
            `;

            const constructResponse = await SPARQLHelpers.executeSPARQLQuery(
                endpoint.query,
                constructQuery,
                auth,
                'text/turtle'
            );

            const turtle = await constructResponse.text();
            expect(turtle).toContain('http://example.org/subject');
        });
    });

    describe('Server interaction', () => {
        it('should handle authentication (note: auth currently not enforced)', async () => {
            const invalidAuth = SPARQLHelpers.createAuthHeader('invalid', 'credentials');
            const query = 'SELECT * WHERE { ?s ?p ?o } LIMIT 1';


            const queryResponse = await SPARQLHelpers.executeSPARQLQuery(endpoint.query, query, invalidAuth);
            const data = await queryResponse.json();
            expect(data.results.bindings.length).toBeGreaterThanOrEqual(0);
        });
    });
});

================
File: spec/unit/sparql-store-spec.js
================
import SPARQLStore from '../../src/stores/SPARQLStore.js';

describe('SPARQLStore', () => {
    let store;
    let mockFetch;

    const endpoint = {
        query: 'http://example.org/sparql/query',
        update: 'http://example.org/sparql/update'
    };

    beforeEach(() => {

        mockFetch = jasmine.createSpy('fetch').and.returnValue(
            Promise.resolve({
                ok: true,
                json: () => Promise.resolve({
                    results: {
                        bindings: [{
                            id: { value: 'test-id' },
                            prompt: { value: 'test prompt' },
                            output: { value: 'test output' },
                            embedding: { value: '[0,1,2]' },
                            timestamp: { value: '1234567890' },
                            accessCount: { value: '1' },
                            concepts: { value: '["test"]' },
                            decayFactor: { value: '1.0' },
                            memoryType: { value: 'short-term' }
                        }]
                    }
                })
            })
        );
        global.fetch = mockFetch;
        global.Buffer = {
            from: (str) => ({ toString: () => 'mock-base64' })
        };

        store = new SPARQLStore(endpoint, {
            user: 'testuser',
            password: 'testpass',
            graphName: 'http://test.org/memory'
        });
    });

    afterEach(() => {
        delete global.fetch;
        delete global.Buffer;
    });

    describe('loadHistory', () => {
        it('should load and parse memory data correctly', async () => {
            const [shortTerm, longTerm] = await store.loadHistory();

            expect(shortTerm.length).toBe(1);
            expect(longTerm.length).toBe(0);

            const memory = shortTerm[0];
            expect(memory.id).toBe('test-id');
            expect(memory.prompt).toBe('test prompt');
            expect(memory.embedding).toEqual([0,1,2]);
            expect(memory.timestamp).toBe(1234567890);
            expect(memory.concepts).toEqual(['test']);
        });

        it('should handle query errors', async () => {
            mockFetch.and.returnValue(Promise.resolve({ ok: false, status: 500 }));

            await expectAsync(store.loadHistory())
                .toBeRejectedWithError('SPARQL query failed: 500');
        });
    });

    describe('saveMemoryToHistory', () => {
        const mockMemoryStore = {
            shortTermMemory: [{
                id: 'test-id',
                prompt: 'test prompt',
                output: 'test output',
                embedding: [0,1,2],
                timestamp: 1234567890,
                accessCount: 1,
                concepts: ['test'],
                decayFactor: 1.0
            }],
            longTermMemory: []
        };

        it('should save memory data correctly', async () => {
            await store.saveMemoryToHistory(mockMemoryStore);

            expect(mockFetch).toHaveBeenCalledWith(
                endpoint.update,
                jasmine.objectContaining({
                    method: 'POST',
                    headers: jasmine.objectContaining({
                        'Content-Type': 'application/sparql-update'
                    })
                })
            );
        });

        it('should handle update errors', async () => {
            mockFetch.and.returnValue(Promise.resolve({ ok: false, status: 500 }));

            await expectAsync(store.saveMemoryToHistory(mockMemoryStore))
                .toBeRejectedWithError('SPARQL update failed: 500');
        });
    });

    describe('transaction handling', () => {
        it('should manage transactions correctly', async () => {
            await store.beginTransaction();
            expect(store.inTransaction).toBeTrue();

            await store.commitTransaction();
            expect(store.inTransaction).toBeFalse();
        });

        it('should handle transaction rollback', async () => {
            await store.beginTransaction();
            await store.rollbackTransaction();
            expect(store.inTransaction).toBeFalse();
        });

        it('should prevent nested transactions', async () => {
            await store.beginTransaction();
            await expectAsync(store.beginTransaction())
                .toBeRejectedWithError('Transaction already in progress');
        });
    });

    describe('verify', () => {
        it('should verify graph existence', async () => {
            mockFetch.and.returnValue(
                Promise.resolve({
                    ok: true,
                    json: () => Promise.resolve({ boolean: true })
                })
            );

            const isValid = await store.verify();
            expect(isValid).toBeTrue();
        });

        it('should handle verification failures', async () => {
            mockFetch.and.returnValue(Promise.resolve({ ok: false }));

            const isValid = await store.verify();
            expect(isValid).toBeFalse();
        });
    });

    describe('cleanup', () => {
        it('should clean up transaction state on close', async () => {
            await store.beginTransaction();
            await store.close();
            expect(store.inTransaction).toBeFalse();
        });
    });
});

================
File: src/connectors/OllamaConnector.js
================
import fetch from 'node-fetch';

export default class OllamaConnector {
    constructor(baseUrl = 'http://localhost:11434') {
        this.baseUrl = baseUrl;
    }

    async generateEmbedding(model, input) {
        const response = await fetch(`${this.baseUrl}/api/embeddings`, {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({
                model,
                prompt: input,
                options: {
                    num_ctx: 8192
                }
            })
        });

        if (!response.ok) {
            throw new Error(`Ollama API error: ${response.status}`);
        }

        const data = await response.json();
        return data.embedding;
    }

    async generateChat(model, messages, options = {}) {
        const response = await fetch(`${this.baseUrl}/api/chat`, {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({
                model,
                messages,
                stream: false,
                options
            })
        });

        if (!response.ok) {
            throw new Error(`Ollama API error: ${response.status}`);
        }

        const data = await response.json();
        return data.message.content;
    }

    async generateCompletion(model, prompt, options = {}) {
        const response = await fetch(`${this.baseUrl}/api/generate`, {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({
                model,
                prompt,
                stream: false,
                options
            })
        });

        if (!response.ok) {
            throw new Error(`Ollama API error: ${response.status}`);
        }

        const data = await response.json();
        return data.response;
    }
}

================
File: src/stores/BaseStore.js
================
export default class BaseStore {
    async loadHistory() {
        throw new Error('Method loadHistory() must be implemented');
    }

    async saveMemoryToHistory(memoryStore) {
        throw new Error('Method saveMemoryToHistory() must be implemented');
    }

    async beginTransaction() {
        throw new Error('Method beginTransaction() must be implemented');
    }

    async commitTransaction() {
        throw new Error('Method commitTransaction() must be implemented');
    }

    async rollbackTransaction() {
        throw new Error('Method rollbackTransaction() must be implemented');
    }

    async verify() {
        throw new Error('Method verify() must be implemented');
    }

    async close() {
        throw new Error('Method close() must be implemented');
    }
}

================
File: src/stores/CachedSPARQLStore.js
================
import SPARQLStore from './SPARQLStore.js';
import { logger } from '../Utils.js';

export default class CachedSPARQLStore extends SPARQLStore {
    constructor(endpoint, options = {}) {
        super(endpoint, options);


        this.cacheEnabled = options.cacheEnabled ?? true;
        this.cacheTTL = options.cacheTTL || 300000;
        this.maxCacheSize = options.maxCacheSize || 100;


        this.queryCache = new Map();
        this.cacheTimestamps = new Map();


        this.cleanupInterval = setInterval(() => {
            this.cleanupCache();
        }, this.cacheTTL / 2);
    }

    async _executeSparqlQuery(query, endpoint) {
        if (!this.cacheEnabled) {
            return super._executeSparqlQuery(query, endpoint);
        }

        const cacheKey = this._generateCacheKey(query);


        const cachedResult = this.queryCache.get(cacheKey);
        if (cachedResult) {
            const timestamp = this.cacheTimestamps.get(cacheKey);
            if (Date.now() - timestamp < this.cacheTTL) {
                logger.debug('Cache hit:', cacheKey);
                return JSON.parse(JSON.stringify(cachedResult));
            }
        }


        const result = await super._executeSparqlQuery(query, endpoint);


        this.queryCache.set(cacheKey, result);
        this.cacheTimestamps.set(cacheKey, Date.now());


        if (this.queryCache.size > this.maxCacheSize) {
            this.cleanupCache();
        }

        return result;
    }

    _generateCacheKey(query) {

        return query.replace(/\s+/g, ' ').trim();
    }

    cleanupCache() {
        const now = Date.now();


        for (const [key, timestamp] of this.cacheTimestamps.entries()) {
            if (now - timestamp > this.cacheTTL) {
                this.queryCache.delete(key);
                this.cacheTimestamps.delete(key);
            }
        }


        while (this.queryCache.size > this.maxCacheSize) {
            let oldestKey = null;
            let oldestTime = Infinity;

            for (const [key, timestamp] of this.cacheTimestamps.entries()) {
                if (timestamp < oldestTime) {
                    oldestTime = timestamp;
                    oldestKey = key;
                }
            }

            if (oldestKey) {
                this.queryCache.delete(oldestKey);
                this.cacheTimestamps.delete(oldestKey);
            }
        }
    }

    invalidateCache() {
        this.queryCache.clear();
        this.cacheTimestamps.clear();
    }

    async saveMemoryToHistory(memoryStore) {

        this.invalidateCache();
        return super.saveMemoryToHistory(memoryStore);
    }

    async close() {
        if (this.cleanupInterval) {
            clearInterval(this.cleanupInterval);
        }

        this.invalidateCache();
        return super.close();
    }
}

================
File: src/stores/InMemoryStore.js
================
import BaseStore from './BaseStore.js';
import { logger } from '../Utils.js';

export default class InMemoryStore extends BaseStore {
    constructor() {
        super();
        this.history = {
            shortTermMemory: [],
            longTermMemory: []
        };
    }

    async loadHistory() {
        logger.info('Loading history from in-memory storage');
        return [
            this.history.shortTermMemory || [],
            this.history.longTermMemory || []
        ];
    }

    async saveMemoryToHistory(memoryStore) {
        logger.info('Saving history to in-memory storage');

        this.history = {
            shortTermMemory: memoryStore.shortTermMemory.map((item, idx) => ({
                id: item.id,
                prompt: item.prompt,
                output: item.output,
                embedding: Array.from(memoryStore.embeddings[idx].flat()),
                timestamp: memoryStore.timestamps[idx],
                accessCount: memoryStore.accessCounts[idx],
                concepts: Array.from(memoryStore.conceptsList[idx]),
                decayFactor: item.decayFactor || 1.0
            })),
            longTermMemory: [...memoryStore.longTermMemory]
        };

        logger.info(`Saved ${this.history.shortTermMemory.length} short-term and ${this.history.longTermMemory.length} long-term memories`);
    }
}

================
File: src/stores/JSONStore.js
================
import { promises as fs } from 'fs';
import { dirname, join } from 'path';
import BaseStore from './BaseStore.js';
import { logger } from '../Utils.js';

export default class JSONStore extends BaseStore {
    constructor(filePath = 'interaction_history.json') {
        super();
        this.filePath = filePath;
        this.tempPath = null;
        this.backupPath = `${filePath}.bak`;
        this.inTransaction = false;
    }

    async ensureDirectory() {
        const dir = dirname(this.filePath);
        await fs.mkdir(dir, { recursive: true });
    }

    async loadHistory() {
        try {
            await this.ensureDirectory();
            const exists = await fs.access(this.filePath).then(() => true).catch(() => false);

            if (!exists) {
                logger.info('No existing interaction history found in JSON. Starting fresh.');
                return [[], []];
            }


            try {
                logger.info('Loading existing interaction history from JSON...');
                const data = await fs.readFile(this.filePath, 'utf8');
                const history = JSON.parse(data);
                return [
                    history.shortTermMemory || [],
                    history.longTermMemory || []
                ];
            } catch (mainError) {

                logger.warn('Main file corrupted, attempting to load backup...');
                const backupExists = await fs.access(this.backupPath).then(() => true).catch(() => false);

                if (backupExists) {
                    const backupData = await fs.readFile(this.backupPath, 'utf8');
                    const history = JSON.parse(backupData);

                    await fs.copyFile(this.backupPath, this.filePath);
                    return [
                        history.shortTermMemory || [],
                        history.longTermMemory || []
                    ];
                }

                throw mainError;
            }
        } catch (error) {
            logger.error('Error loading history:', error);
            return [[], []];
        }
    }

    async beginTransaction() {
        if (this.inTransaction) {
            throw new Error('Transaction already in progress');
        }
        this.inTransaction = true;
        this.tempPath = `${this.filePath}.tmp`;
    }

    async commitTransaction() {
        if (!this.inTransaction) {
            throw new Error('No transaction in progress');
        }

        try {

            const exists = await fs.access(this.filePath).then(() => true).catch(() => false);
            if (exists) {
                await fs.copyFile(this.filePath, this.backupPath);
            }


            await fs.rename(this.tempPath, this.filePath);


            if (exists) {
                await fs.unlink(this.backupPath).catch(() => { });
            }
        } finally {
            this.inTransaction = false;
            this.tempPath = null;
        }
    }

    async rollbackTransaction() {
        if (!this.inTransaction) {
            throw new Error('No transaction in progress');
        }

        try {
            if (this.tempPath) {
                await fs.unlink(this.tempPath).catch(() => { });
            }
        } finally {
            this.inTransaction = false;
            this.tempPath = null;
        }
    }

    async verify() {
        try {
            const data = await fs.readFile(this.filePath, 'utf8');
            JSON.parse(data);
            return true;
        } catch {
            return false;
        }
    }

    async saveMemoryToHistory(memoryStore) {
        try {
            await this.ensureDirectory();
            await this.beginTransaction();

            const history = {
                shortTermMemory: memoryStore.shortTermMemory.map((item, idx) => ({
                    id: item.id,
                    prompt: item.prompt,
                    output: item.output,
                    embedding: Array.from(memoryStore.embeddings[idx]),
                    timestamp: memoryStore.timestamps[idx],
                    accessCount: memoryStore.accessCounts[idx],
                    concepts: Array.from(memoryStore.conceptsList[idx]),
                    decayFactor: item.decayFactor || 1.0
                })),
                longTermMemory: memoryStore.longTermMemory
            };


            await fs.writeFile(this.tempPath, JSON.stringify(history, null, 2));


            if (!await this.verify()) {
                throw new Error('Data verification failed');
            }


            await this.commitTransaction();

            logger.info(`Saved interaction history to JSON. Short-term: ${history.shortTermMemory.length}, Long-term: ${history.longTermMemory.length}`);
        } catch (error) {
            await this.rollbackTransaction();
            logger.error('Error saving history:', error);
            throw error;
        }
    }

    async close() {
        if (this.inTransaction) {
            await this.rollbackTransaction();
        }
        return Promise.resolve();
    }
}

================
File: src/stores/MemoryStore.js
================
import faiss from 'faiss-node';
import { createRequire } from 'module';
import { kmeans } from 'ml-kmeans';
import { logger, vectorOps } from '../Utils.js';

const require = createRequire(import.meta.url);
const { Graph } = require('graphology');

export default class MemoryStore {
    constructor(dimension = 1536) {
        this.dimension = dimension;
        this.initializeIndex();
        this.shortTermMemory = [];
        this.longTermMemory = [];
        this.embeddings = [];
        this.timestamps = [];
        this.accessCounts = [];
        this.conceptsList = [];
        this.graph = new Graph();
        this.semanticMemory = new Map();
        this.clusterLabels = [];
    }

    initializeIndex() {
        try {
            this.index = new faiss.IndexFlatL2(this.dimension);
            if (!this.index || !this.index.getDimension) {
                throw new Error('Failed to initialize FAISS index');
            }
            logger.info(`Initialized FAISS index with dimension ${this.dimension}`);
        } catch (error) {
            logger.error('FAISS index initialization failed:', error);
            throw new Error('Failed to initialize FAISS index: ' + error.message);
        }
    }

    validateEmbedding(embedding) {
        if (!Array.isArray(embedding)) {
            throw new TypeError('Embedding must be an array');
        }
        if (embedding.length !== this.dimension) {
            throw new Error(`Embedding dimension mismatch: expected ${this.dimension}, got ${embedding.length}`);
        }
        if (!embedding.every(x => typeof x === 'number' && !isNaN(x))) {
            throw new TypeError('Embedding must contain only valid numbers');
        }
    }

    addInteraction(interaction) {
        const { id, prompt, output, embedding, timestamp = Date.now(),
            accessCount = 1, concepts = [], decayFactor = 1.0 } = interaction;

        try {
            this.validateEmbedding(embedding);
            logger.info(`Adding interaction: '${prompt}'`);

            this.shortTermMemory.push({
                id, prompt, output, timestamp, accessCount, decayFactor
            });

            const embeddingArray = Float32Array.from(embedding);
            this.embeddings.push(embeddingArray);
            this.index.add(embedding);
            this.timestamps.push(timestamp);
            this.accessCounts.push(accessCount);
            this.conceptsList.push(new Set(concepts));

            this.updateGraph(new Set(concepts));
            this.clusterInteractions();
        } catch (error) {
            logger.error('Failed to add interaction:', error);
            throw error;
        }
    }

    updateGraph(concepts) {
        for (const concept of concepts) {
            if (!this.graph.hasNode(concept)) {
                this.graph.addNode(concept);
            }
        }

        for (const concept1 of concepts) {
            for (const concept2 of concepts) {
                if (concept1 !== concept2) {
                    const edgeKey = `${concept1}--${concept2}`;
                    if (this.graph.hasEdge(edgeKey)) {
                        const weight = this.graph.getEdgeAttribute(edgeKey, 'weight');
                        this.graph.setEdgeAttribute(edgeKey, 'weight', weight + 1);
                    } else {
                        this.graph.addEdge(concept1, concept2, { weight: 1 });
                    }
                }
            }
        }
    }

    classifyMemory() {
        this.shortTermMemory.forEach((interaction, idx) => {
            if (this.accessCounts[idx] > 10 &&
                !this.longTermMemory.some(ltm => ltm.id === interaction.id)) {
                this.longTermMemory.push(interaction);
                logger.info(`Moved interaction ${interaction.id} to long-term memory`);
            }
        });
    }

    async retrieve(queryEmbedding, queryConcepts, similarityThreshold = 40, excludeLastN = 0) {
        if (this.shortTermMemory.length === 0) {
            logger.info('No interactions available');
            return [];
        }

        logger.info('Retrieving relevant interactions...');
        const relevantInteractions = [];
        const currentTime = Date.now();
        const decayRate = 0.0001;
        const relevantIndices = new Set();

        const normalizedQuery = vectorOps.normalize(queryEmbedding.flat());
        const normalizedEmbeddings = this.embeddings.map(e => vectorOps.normalize(Array.from(e)));

        for (let idx = 0; idx < this.shortTermMemory.length - excludeLastN; idx++) {
            const similarity = vectorOps.cosineSimilarity(normalizedQuery, normalizedEmbeddings[idx]) * 100;
            const timeDiff = (currentTime - this.timestamps[idx]) / 1000;
            const decayFactor = this.shortTermMemory[idx].decayFactor * Math.exp(-decayRate * timeDiff);
            const reinforcementFactor = Math.log1p(this.accessCounts[idx]);
            const adjustedSimilarity = similarity * decayFactor * reinforcementFactor;

            if (adjustedSimilarity >= similarityThreshold) {
                relevantIndices.add(idx);
                this.accessCounts[idx]++;
                this.timestamps[idx] = currentTime;
                this.shortTermMemory[idx].decayFactor *= 1.1;

                relevantInteractions.push({
                    similarity: adjustedSimilarity,
                    interaction: this.shortTermMemory[idx],
                    concepts: this.conceptsList[idx]
                });
            }
        }


        this.shortTermMemory.forEach((item, idx) => {
            if (!relevantIndices.has(idx)) {
                item.decayFactor *= 0.9;
            }
        });

        const activatedConcepts = await this.spreadingActivation(queryConcepts);


        return this.combineResults(relevantInteractions, activatedConcepts, normalizedQuery);
    }

    async spreadingActivation(queryConcepts) {
        const activatedNodes = new Map();
        const initialActivation = 1.0;
        const decayFactor = 0.5;

        queryConcepts.forEach(concept => {
            activatedNodes.set(concept, initialActivation);
        });


        for (let step = 0; step < 2; step++) {
            const newActivations = new Map();

            for (const [node, activation] of activatedNodes) {
                if (this.graph.hasNode(node)) {
                    this.graph.forEachNeighbor(node, (neighbor, attributes) => {
                        if (!activatedNodes.has(neighbor)) {
                            const weight = attributes.weight;
                            const newActivation = activation * decayFactor * weight;
                            newActivations.set(neighbor,
                                (newActivations.get(neighbor) || 0) + newActivation);
                        }
                    });
                }
            }

            newActivations.forEach((value, key) => {
                activatedNodes.set(key, value);
            });
        }

        return Object.fromEntries(activatedNodes);
    }

    clusterInteractions() {
        if (this.embeddings.length < 2) return;

        const embeddingsMatrix = this.embeddings.map(e => Array.from(e));
        const numClusters = Math.min(10, this.embeddings.length);

        const { clusters } = kmeans(embeddingsMatrix, numClusters);
        this.clusterLabels = clusters;

        this.semanticMemory.clear();
        clusters.forEach((label, idx) => {
            if (!this.semanticMemory.has(label)) {
                this.semanticMemory.set(label, []);
            }
            this.semanticMemory.get(label).push({
                embedding: this.embeddings[idx],
                interaction: this.shortTermMemory[idx]
            });
        });
    }

    combineResults(relevantInteractions, activatedConcepts, normalizedQuery) {
        const combined = relevantInteractions.map(({ similarity, interaction, concepts }) => {
            const activationScore = Array.from(concepts)
                .reduce((sum, c) => sum + (activatedConcepts[c] || 0), 0);
            return {
                ...interaction,
                totalScore: similarity + activationScore
            };
        });

        combined.sort((a, b) => b.totalScore - a.totalScore);


        const semanticResults = this.retrieveFromSemanticMemory(normalizedQuery);
        return [...combined, ...semanticResults];
    }

    retrieveFromSemanticMemory(normalizedQuery) {
        if (this.semanticMemory.size === 0) return [];


        let bestCluster = -1;
        let bestSimilarity = -1;

        this.semanticMemory.forEach((items, label) => {
            const centroid = this.calculateCentroid(items.map(i => i.embedding));
            const similarity = vectorOps.cosineSimilarity(normalizedQuery, centroid);

            if (similarity > bestSimilarity) {
                bestSimilarity = similarity;
                bestCluster = label;
            }
        });

        if (bestCluster === -1) return [];


        return this.semanticMemory.get(bestCluster)
            .map(({ embedding, interaction }) => ({
                ...interaction,
                similarity: vectorOps.cosineSimilarity(normalizedQuery,
                    vectorOps.normalize(Array.from(embedding)))
            }))
            .sort((a, b) => b.similarity - a.similarity)
            .slice(0, 5);
    }

    calculateCentroid(embeddings) {
        const sum = embeddings.reduce((acc, curr) => {
            const arr = Array.from(curr);
            return acc.map((val, idx) => val + arr[idx]);
        }, new Array(this.dimension).fill(0));

        return sum.map(val => val / embeddings.length);
    }
}

================
File: src/stores/SPARQLStore.js
================
import BaseStore from './BaseStore.js';
import { logger } from '../Utils.js';

export default class SPARQLStore extends BaseStore {
    constructor(endpoint, options = {}) {
        super();
        this.endpoint = endpoint;
        this.credentials = {
            user: options.user || 'admin',
            password: options.password || 'admin'
        };
        this.graphName = options.graphName || 'http://example.org/mcp/memory';
        this.inTransaction = false;
    }

    async _executeSparqlQuery(query, endpoint) {
        const auth = Buffer.from(`${this.credentials.user}:${this.credentials.password}`).toString('base64');

        try {
            const response = await fetch(endpoint, {
                method: 'POST',
                headers: {
                    'Authorization': `Basic ${auth}`,
                    'Content-Type': 'application/sparql-query',
                    'Accept': 'application/json'
                },
                body: query,
                credentials: 'include'
            });

            if (!response.ok) {
                const errorText = await response.text();
                throw new Error(`SPARQL query failed: ${response.status} - ${errorText}`);
            }

            return await response.json();
        } catch (error) {
            logger.error('SPARQL query error:', error);
            throw error;
        }
    }

    async _executeSparqlUpdate(update, endpoint) {
        const auth = Buffer.from(`${this.credentials.user}:${this.credentials.password}`).toString('base64');

        try {
            const response = await fetch(endpoint, {
                method: 'POST',
                headers: {
                    'Authorization': `Basic ${auth}`,
                    'Content-Type': 'application/sparql-update',
                    'Accept': 'application/json'
                },
                body: update,
                credentials: 'include'
            });

            if (!response.ok) {
                const errorText = await response.text();
                throw new Error(`SPARQL update failed: ${response.status} - ${errorText}`);
            }

            return response;
        } catch (error) {
            logger.error('SPARQL update error:', error);
            throw error;
        }
    }

    async verify() {
        try {

            try {
                const createQuery = `
                    CREATE SILENT GRAPH <${this.graphName}>;
                    INSERT DATA { GRAPH <${this.graphName}> {
                        <${this.graphName}> a <http://example.org/mcp/MemoryStore>
                    }}
                `;
                await this._executeSparqlUpdate(createQuery, this.endpoint.update);
            } catch (error) {

                logger.debug('Graph creation skipped:', error.message);
            }


            const checkQuery = `ASK { GRAPH <${this.graphName}> { ?s ?p ?o } }`;
            const result = await this._executeSparqlQuery(checkQuery, this.endpoint.query);
            return result.boolean;
        } catch (error) {
            logger.error('Graph verification failed:', error);
            throw error;
        }
    }

    async loadHistory() {
        await this.verify();

        const query = `
            PREFIX mcp: <http://purl.org/stuff/mcp/>
            PREFIX xsd: <http://www.w3.org/2001/XMLSchema#>

            SELECT ?id ?prompt ?output ?embedding ?timestamp ?accessCount ?concepts ?decayFactor ?memoryType
            FROM <${this.graphName}>
            WHERE {
                ?interaction a mcp:Interaction ;
                    mcp:id ?id ;
                    mcp:prompt ?prompt ;
                    mcp:output ?output ;
                    mcp:embedding ?embedding ;
                    mcp:timestamp ?timestamp ;
                    mcp:accessCount ?accessCount ;
                    mcp:decayFactor ?decayFactor ;
                    mcp:memoryType ?memoryType .
                OPTIONAL { ?interaction mcp:concepts ?concepts }
            }`;

        try {
            const result = await this._executeSparqlQuery(query, this.endpoint.query);
            const shortTermMemory = [];
            const longTermMemory = [];

            result.results.bindings.forEach(binding => {
                try {
                    const interaction = {
                        id: binding.id.value,
                        prompt: binding.prompt.value,
                        output: binding.output.value,
                        embedding: binding.embedding ? JSON.parse(binding.embedding.value.trim()) : new Array(1536).fill(0),
                        timestamp: parseInt(binding.timestamp.value) || Date.now(),
                        accessCount: parseInt(binding.accessCount.value) || 1,
                        concepts: binding.concepts ? JSON.parse(binding.concepts.value.trim()) : [],
                        decayFactor: parseFloat(binding.decayFactor.value) || 1.0
                    };

                    if (binding.memoryType.value === 'short-term') {
                        shortTermMemory.push(interaction);
                    } else {
                        longTermMemory.push(interaction);
                    }
                } catch (parseError) {
                    logger.error('Failed to parse interaction:', parseError, binding);
                }
            });

            logger.info(`Loaded ${shortTermMemory.length} short-term and ${longTermMemory.length} long-term memories from store ${this.endpoint.query} graph <${this.graphName}>`);
            return [shortTermMemory, longTermMemory];
        } catch (error) {
            logger.error('Error loading history from SPARQL store:', error);
            throw error;
        }
    }

    async saveMemoryToHistory(memoryStore) {
        if (this.inTransaction) {
            throw new Error('Transaction already in progress');
        }

        try {
            await this.verify();
            await this.beginTransaction();


            const clearQuery = `
                PREFIX mcp: <http://purl.org/stuff/mcp/>
                CLEAR GRAPH <${this.graphName}>
            `;
            await this._executeSparqlUpdate(clearQuery, this.endpoint.update);


            const insertQuery = `
                PREFIX mcp: <http://purl.org/stuff/mcp/>
                PREFIX xsd: <http://www.w3.org/2001/XMLSchema#>

                INSERT DATA {
                    GRAPH <${this.graphName}> {
                        ${this._generateInsertStatements(memoryStore.shortTermMemory, 'short-term')}
                        ${this._generateInsertStatements(memoryStore.longTermMemory, 'long-term')}
                    }
                }
            `;

            await this._executeSparqlUpdate(insertQuery, this.endpoint.update);
            await this.commitTransaction();

            logger.info(`Saved memory to SPARQL store ${this.endpoint.update} graph <${this.graphName}>. Stats: ${memoryStore.shortTermMemory.length} short-term, ${memoryStore.longTermMemory.length} long-term memories`);
        } catch (error) {
            await this.rollbackTransaction();
            logger.error('Error saving to SPARQL store:', error);
            throw error;
        }
    }

    _generateInsertStatements(memories, type) {
        return memories.map((interaction, index) => `
            _:interaction${type}${index} a mcp:Interaction ;
                mcp:id "${interaction.id}" ;
                mcp:prompt "${this._escapeSparqlString(interaction.prompt)}" ;
                mcp:output "${this._escapeSparqlString(interaction.output)}" ;
                mcp:embedding """${JSON.stringify(interaction.embedding)}""" ;
                mcp:timestamp "${interaction.timestamp}"^^xsd:integer ;
                mcp:accessCount "${interaction.accessCount}"^^xsd:integer ;
                mcp:concepts """${JSON.stringify(interaction.concepts)}""" ;
                mcp:decayFactor "${interaction.decayFactor}"^^xsd:decimal ;
                mcp:memoryType "${type}" .
        `).join('\n');
    }

    _escapeSparqlString(str) {
        return str.replace(/["\\]/g, '\\$&').replace(/\n/g, '\\n');
    }

    async beginTransaction() {
        if (this.inTransaction) {
            throw new Error('Transaction already in progress');
        }

        this.inTransaction = true;


        const backupQuery = `
            PREFIX mcp: <http://purl.org/stuff/mcp/>
            COPY GRAPH <${this.graphName}> TO GRAPH <${this.graphName}.backup>
        `;
        await this._executeSparqlUpdate(backupQuery, this.endpoint.update);
    }

    async commitTransaction() {
        if (!this.inTransaction) {
            throw new Error('No transaction in progress');
        }

        try {

            const dropBackup = `
                PREFIX mcp: <http://purl.org/stuff/mcp/>
                DROP SILENT GRAPH <${this.graphName}.backup>
            `;
            await this._executeSparqlUpdate(dropBackup, this.endpoint.update);
        } finally {
            this.inTransaction = false;
        }
    }

    async rollbackTransaction() {
        if (!this.inTransaction) {
            throw new Error('No transaction in progress');
        }

        try {

            const restoreQuery = `
                PREFIX mcp: <http://purl.org/stuff/mcp/>
                DROP SILENT GRAPH <${this.graphName}> ;
                MOVE GRAPH <${this.graphName}.backup> TO GRAPH <${this.graphName}>
            `;
            await this._executeSparqlUpdate(restoreQuery, this.endpoint.update);
        } finally {
            this.inTransaction = false;
        }
    }

    async close() {
        if (this.inTransaction) {
            await this.rollbackTransaction();
        }
    }
}

================
File: src/utils/SPARQLHelpers.js
================
import { Buffer } from 'buffer';

export class SPARQLHelpers {
    static createAuthHeader(username, password) {
        return `Basic ${Buffer.from(`${username}:${password}`).toString('base64')}`;
    }

    static async executeSPARQLQuery(endpoint, query, auth, accept = 'application/json') {
        try {
            const response = await fetch(endpoint, {
                method: 'POST',
                headers: {
                    'Authorization': auth,
                    'Content-Type': 'application/sparql-query',
                    'Accept': accept
                },
                body: query
            });

            if (!response.ok) {
                const errorText = await response.text();
                const errorMessage = this.parseFusekiError(response.status, errorText);
                throw new Error(errorMessage);
            }

            return response;
        } catch (error) {
            if (error.name === 'TypeError') {
                throw new Error(`Connection failed to endpoint: ${endpoint}`);
            }
            throw error;
        }
    }

    static async executeSPARQLUpdate(endpoint, update, auth) {
        const response = await fetch(endpoint, {
            method: 'POST',
            headers: {
                'Authorization': auth,
                'Content-Type': 'application/sparql-update'
            },
            body: update
        });

        if (!response.ok) {
            throw new Error(`SPARQL update failed: ${response.status}`);
        }

        return response;
    }

    static async uploadTurtle(baseUrl, turtle, auth, graphUri) {

        const uploadUrl = baseUrl.endsWith('/') ? `${baseUrl}data` : `${baseUrl}/data`;
        const url = graphUri ? `${uploadUrl}?graph=${encodeURIComponent(graphUri)}` : uploadUrl;

        try {
            const response = await fetch(url, {
                method: 'POST',
                headers: {
                    'Authorization': auth,
                    'Content-Type': 'text/turtle',
                    'Accept': 'application/json'
                },
                body: turtle
            });

            if (!response.ok) {
                const errorText = await response.text();
                throw new Error(`Turtle upload failed: ${response.status} - ${errorText}`);
            }

            const result = await response.json();
            return {
                success: true,
                counts: {
                    triples: result.tripleCount || 0,
                    quads: result.quadCount || 0,
                    total: result.count || 0
                }
            };
        } catch (error) {
            throw new Error(`Upload failed: ${error.message}`);
        }
    }

    static parseFusekiError(status, errorText) {
        switch (status) {
            case 400:
                return `Invalid SPARQL syntax: ${errorText}`;
            case 401:
                return 'Authentication required';
            case 403:
                return 'Access forbidden - check credentials';
            case 404:
                return 'Dataset or endpoint not found';
            case 405:
                return 'Method not allowed - check endpoint URL';
            case 500:
                return `Fuseki server error: ${errorText}`;
            case 503:
                return 'Fuseki server unavailable';
            default:
                return `SPARQL operation failed (${status}): ${errorText}`;
        }
    }
}

================
File: src/Config.js
================
export default class Config {
    static defaults = {
        storage: {
            type: 'memory',
            options: {
                path: 'interaction_history.json',

                endpoint: 'http://localhost:8080',
                apiKey: '',
                timeout: 5000
            }
        },
        models: {
            chat: {
                provider: 'ollama',
                model: 'qwen2:1.5b',
                options: {}
            },
            embedding: {
                provider: 'ollama',
                model: 'nomic-embed-text',
                options: {}
            }
        },
        memory: {
            dimension: 1536,
            similarityThreshold: 40,
            contextWindow: 3,
            decayRate: 0.0001
        },
        sparqlEndpoints: [
            {
                label: "tbox-test",
                user: "admin",
                password: "admin123",
                urlBase: "http://localhost:4030",
                upload: "/test/upload",
                gspRead: "/test/get",
                query: "/test/query",
                update: "/test/update"
            }
        ]

    };

    constructor(userConfig = {}) {
        this.config = this.mergeConfigs(Config.defaults, userConfig);
    }

    mergeConfigs(defaults, user) {
        const merged = { ...defaults };
        for (const [key, value] of Object.entries(user)) {
            if (value && typeof value === 'object') {
                merged[key] = this.mergeConfigs(defaults[key] || {}, value);
            } else {
                merged[key] = value;
            }
        }
        return merged;
    }

    get(path) {
        return path.split('.').reduce((obj, key) => obj && obj[key], this.config);
    }

    set(path, value) {
        const keys = path.split('.');
        const last = keys.pop();
        const target = keys.reduce((obj, key) => obj[key] = obj[key] || {}, this.config);
        target[last] = value;
    }
}

================
File: src/ContextManager.js
================
import ContextWindowManager from './ContextWindowManager.js'
import { logger } from './Utils.js';

export default class ContextManager {
    constructor(options = {}) {
        this.maxTokens = options.maxTokens || 8192;
        this.maxTimeWindow = options.maxTimeWindow || 24 * 60 * 60 * 1000;
        this.relevanceThreshold = options.relevanceThreshold || 0.7;
        this.maxContextSize = options.maxContextSize || 5;
        this.contextBuffer = [];

        this.windowManager = new ContextWindowManager({
            maxWindowSize: this.maxTokens,
            minWindowSize: Math.floor(this.maxTokens / 4),
            overlapRatio: options.overlapRatio || 0.1
        });
    }

    addToContext(interaction, similarity = 1.0) {
        this.contextBuffer.push({
            ...interaction,
            similarity,
            addedAt: Date.now()
        });


        if (this.contextBuffer.length > this.maxContextSize * 2) {
            this.pruneContext();
        }
    }

    pruneContext() {
        const now = Date.now();
        this.contextBuffer = this.contextBuffer
            .filter(item => {
                const age = now - item.addedAt;
                return age < this.maxTimeWindow && item.similarity >= this.relevanceThreshold;
            })
            .sort((a, b) => b.similarity - a.similarity)
            .slice(0, this.maxContextSize);
    }

    summarizeContext(interactions) {

        const groupedInteractions = {};

        for (const interaction of interactions) {
            const mainConcept = interaction.concepts?.[0] || 'general';
            if (!groupedInteractions[mainConcept]) {
                groupedInteractions[mainConcept] = [];
            }
            groupedInteractions[mainConcept].push(interaction);
        }


        const summaries = [];
        for (const [concept, group] of Object.entries(groupedInteractions)) {
            if (group.length === 1) {
                summaries.push(this.formatSingleInteraction(group[0]));
            } else {
                summaries.push(this.formatGroupSummary(concept, group));
            }
        }

        return summaries.join('\n\n');
    }

    formatSingleInteraction(interaction) {
        return `Q: ${interaction.prompt}\nA: ${interaction.output}`;
    }

    formatGroupSummary(concept, interactions) {
        const summary = `Topic: ${concept}\n` +
            interactions
                .slice(0, 3)
                .map(i => `- ${i.prompt}  ${i.output.substring(0, 50)}...`)
                .join('\n');
        return summary;
    }

    buildContext(currentPrompt, retrievals = [], recentInteractions = [], options = {}) {
        this.pruneContext();


        retrievals.forEach(retrieval => {
            this.addToContext(retrieval.interaction, retrieval.similarity);
        });


        recentInteractions.forEach(interaction => {
            this.addToContext(interaction, 0.9);
        });

        const contextParts = [];


        if (options.systemContext) {
            contextParts.push(`System Context: ${options.systemContext}`);
        }


        const historicalContext = this.summarizeContext(
            this.contextBuffer.slice(0, this.maxContextSize)
        );

        if (historicalContext) {
            contextParts.push('Relevant Context:', historicalContext);
        }

        const fullContext = contextParts.join('\n\n');


        if (this.windowManager.estimateTokens(fullContext) > this.maxTokens) {
            const windows = this.windowManager.processContext(fullContext);
            return this.windowManager.mergeOverlappingContent(windows);
        }

        return fullContext;
    }
}

================
File: src/ContextWindowManager.js
================
import { logger } from './Utils.js';

export default class ContextWindowManager {
    constructor(options = {}) {
        this.minWindowSize = options.minWindowSize || 1024;
        this.maxWindowSize = options.maxWindowSize || 8192;
        this.overlapRatio = options.overlapRatio || 0.1;
        this.avgTokenLength = options.avgTokenLength || 4;
    }


    estimateTokens(text) {
        return Math.ceil(text.length / this.avgTokenLength);
    }


    calculateWindowSize(input) {
        const estimatedTokens = this.estimateTokens(input);


        let windowSize = Math.min(
            this.maxWindowSize,
            Math.max(
                this.minWindowSize,
                estimatedTokens * 1.2
            )
        );

        logger.debug(`Calculated window size: ${windowSize} for input length: ${input.length}`);
        return windowSize;
    }


    createWindows(text, windowSize) {
        const windows = [];
        const overlapSize = Math.floor(windowSize * this.overlapRatio);
        const stride = windowSize - overlapSize;

        let position = 0;
        while (position < text.length) {
            const window = {
                text: text.slice(position, position + windowSize),
                start: position,
                end: Math.min(position + windowSize, text.length)
            };

            windows.push(window);
            position += stride;

            if (position + windowSize >= text.length) {

                if (position < text.length) {
                    windows.push({
                        text: text.slice(position),
                        start: position,
                        end: text.length
                    });
                }
                break;
            }
        }

        return windows;
    }


    mergeOverlappingContent(windows) {
        if (windows.length === 0) return '';
        if (windows.length === 1) return windows[0].text;

        let merged = windows[0].text;
        for (let i = 1; i < windows.length; i++) {
            const overlap = this._findBestOverlap(
                merged.slice(-this.maxWindowSize),
                windows[i].text
            );
            merged += windows[i].text.slice(overlap);
        }

        return merged;
    }


    _findBestOverlap(end, start, minOverlap = 10) {

        for (let overlap = Math.min(end.length, start.length); overlap >= minOverlap; overlap--) {
            const endSlice = end.slice(-overlap);
            const startSlice = start.slice(0, overlap);

            if (endSlice === startSlice) {
                return overlap;
            }
        }

        return 0;
    }


    processContext(context, options = {}) {
        const windowSize = this.calculateWindowSize(context);
        const windows = this.createWindows(context, windowSize);

        logger.debug(`Created ${windows.length} windows with size ${windowSize}`);


        if (options.includeMetadata) {
            return windows.map(window => ({
                ...window,
                tokenEstimate: this.estimateTokens(window.text)
            }));
        }

        return windows;
    }
}

================
File: src/MemoryManager.js
================
import { v4 as uuidv4 } from 'uuid';
import MemoryStore from './stores/MemoryStore.js';
import InMemoryStore from './stores/InMemoryStore.js';
import ContextManager from './ContextManager.js';
import PromptTemplates from './PromptTemplates.js';
import { logger } from './Utils.js';

export default class MemoryManager {
    constructor({
        llmProvider,
        chatModel = 'llama2',
        embeddingModel = 'nomic-embed-text',
        storage = null,
        dimension = 1536,
        contextOptions = {
            maxTokens: embeddingModel === 'nomic-embed-text' ? 8192 : 4096
        },
        cacheOptions = {
            maxSize: 1000,
            ttl: 3600000
        }
    }) {
        if (!llmProvider) {
            throw new Error('LLM provider is required');
        }

        this.llmProvider = llmProvider;
        this.chatModel = chatModel;
        this.embeddingModel = embeddingModel;
        this.dimension = dimension;
        this.cacheOptions = cacheOptions;


        this.embeddingCache = new Map();
        this.cacheTimestamps = new Map();

        try {
            this.memoryStore = new MemoryStore(this.dimension);
            this.storage = storage || new InMemoryStore();
            this.contextManager = new ContextManager(contextOptions);
        } catch (error) {
            logger.error('Failed to initialize MemoryManager:', error);
            throw new Error('Memory manager initialization failed: ' + error.message);
        }

        this.initialize();


        this.cleanupInterval = setInterval(() => {
            this.cleanupCache();
        }, cacheOptions.ttl / 2);
    }

    async initialize() {
        try {
            const [shortTerm, longTerm] = await this.storage.loadHistory();

            for (const interaction of shortTerm) {
                const embedding = this.standardizeEmbedding(interaction.embedding);
                interaction.embedding = embedding;
                this.memoryStore.addInteraction(interaction);
            }

            this.memoryStore.longTermMemory.push(...longTerm);
            this.memoryStore.clusterInteractions();

            logger.info(`Memory initialized with ${shortTerm.length} short-term and ${longTerm.length} long-term memories`);
        } catch (error) {
            logger.error('Memory initialization failed:', error);
            throw error;
        }
    }

    cleanupCache() {
        const now = Date.now();
        for (const [key, timestamp] of this.cacheTimestamps.entries()) {
            if (now - timestamp > this.cacheOptions.ttl) {
                this.embeddingCache.delete(key);
                this.cacheTimestamps.delete(key);
            }
        }


        while (this.embeddingCache.size > this.cacheOptions.maxSize) {
            let oldestKey = null;
            let oldestTime = Infinity;

            for (const [key, timestamp] of this.cacheTimestamps.entries()) {
                if (timestamp < oldestTime) {
                    oldestTime = timestamp;
                    oldestKey = key;
                }
            }

            if (oldestKey) {
                this.embeddingCache.delete(oldestKey);
                this.cacheTimestamps.delete(oldestKey);
            }
        }
    }

    getCacheKey(text) {

        return `${this.embeddingModel}:${text.slice(0, 100)}`;
    }

    async generateEmbedding(text) {
        const cacheKey = this.getCacheKey(text);


        if (this.embeddingCache.has(cacheKey)) {
            const cached = this.embeddingCache.get(cacheKey);

            this.cacheTimestamps.set(cacheKey, Date.now());
            return cached;
        }

        try {
            const embedding = await this.llmProvider.generateEmbedding(
                this.embeddingModel,
                text
            );


            this.embeddingCache.set(cacheKey, embedding);
            this.cacheTimestamps.set(cacheKey, Date.now());


            if (this.embeddingCache.size > this.cacheOptions.maxSize) {
                this.cleanupCache();
            }

            return embedding;
        } catch (error) {
            logger.error('Error generating embedding:', error);
            throw error;
        }
    }

    validateEmbedding(embedding) {
        if (!Array.isArray(embedding)) {
            throw new TypeError('Embedding must be an array');
        }
        if (!embedding.every(x => typeof x === 'number' && !isNaN(x))) {
            throw new TypeError('Embedding must contain only valid numbers');
        }
    }

    standardizeEmbedding(embedding) {
        this.validateEmbedding(embedding);
        const current = embedding.length;
        if (current === this.dimension) return embedding;

        if (current < this.dimension) {
            return [...embedding, ...new Array(this.dimension - current).fill(0)];
        }
        return embedding.slice(0, this.dimension);
    }

    async addInteraction(prompt, output, embedding, concepts) {
        try {
            this.validateEmbedding(embedding);
            const standardizedEmbedding = this.standardizeEmbedding(embedding);

            const interaction = {
                id: uuidv4(),
                prompt,
                output,
                embedding: standardizedEmbedding,
                timestamp: Date.now(),
                accessCount: 1,
                concepts,
                decayFactor: 1.0
            };

            this.memoryStore.addInteraction(interaction);
            await this.storage.saveMemoryToHistory(this.memoryStore);
        } catch (error) {
            logger.error('Failed to add interaction:', error);
            throw error;
        }
    }

    async retrieveRelevantInteractions(query, similarityThreshold = 40, excludeLastN = 0) {
        try {
            const queryEmbedding = await this.generateEmbedding(query);
            const queryConcepts = await this.extractConcepts(query);
            return this.memoryStore.retrieve(queryEmbedding, queryConcepts, similarityThreshold, excludeLastN);
        } catch (error) {
            logger.error('Failed to retrieve relevant interactions:', error);
            throw error;
        }
    }

    async extractConcepts(text) {
        logger.info('Extracting concepts...');
        try {
            const prompt = PromptTemplates.formatConceptPrompt(this.chatModel, text);
            const response = await this.llmProvider.generateCompletion(
                this.chatModel,
                prompt,
                { temperature: 0.2 }
            );

            const match = response.match(/\[.*\]/);
            if (match) {
                const concepts = JSON.parse(match[0]);
                logger.info('Extracted concepts:', concepts);
                return concepts;
            }

            logger.info('No concepts extracted, returning empty array');
            return [];
        } catch (error) {
            logger.error('Error extracting concepts:', error);
            return [];
        }
    }

    async generateResponse(prompt, lastInteractions = [], retrievals = [], contextWindow = 3) {
        const context = this.contextManager.buildContext(
            prompt,
            retrievals,
            lastInteractions,
            { systemContext: "You're a helpful assistant with memory of past interactions." }
        );

        try {
            const messages = PromptTemplates.formatChatPrompt(
                this.chatModel,
                "You're a helpful assistant with memory of past interactions.",
                context,
                prompt
            );

            const response = await this.llmProvider.generateChat(
                this.chatModel,
                messages,
                { temperature: 0.7 }
            );

            return response.trim();
        } catch (error) {
            logger.error('Error generating response:', error);
            throw error;
        }
    }


    async dispose() {
        logger.info('Starting MemoryManager shutdown...');


        if (this.cleanupInterval) {
            clearInterval(this.cleanupInterval);
        }


        try {
            await this.storage.saveMemoryToHistory(this.memoryStore);
            logger.info('Final memory state saved');
        } catch (error) {
            logger.error('Error saving final memory state:', error);
        }


        this.embeddingCache.clear();
        this.cacheTimestamps.clear();


        if (this.storage && typeof this.storage.close === 'function') {
            await this.storage.close();
        }


        this.memoryStore = null;
        this.llmProvider = null;

        logger.info('MemoryManager shutdown complete');
    }
}

================
File: src/OllamaExample.js
================
import MemoryManager from './MemoryManager.js';
import JSONStore from './stores/JSONStore.js';
import Config from './Config.js';
import OllamaConnector from './connectors/OllamaConnector.js';


let memoryManager = null;

async function shutdown(signal) {
    console.log(`\nReceived ${signal}, starting graceful shutdown...`);
    if (memoryManager) {
        try {
            await memoryManager.dispose();
            console.log('Cleanup complete');
            process.exit(0);
        } catch (error) {
            console.error('Error during cleanup:', error);
            process.exit(1);
        }
    } else {
        process.exit(0);
    }
}


process.on('SIGTERM', () => shutdown('SIGTERM'));
process.on('SIGINT', () => shutdown('SIGINT'));
process.on('uncaughtException', async (error) => {
    console.error('Uncaught Exception:', error);
    await shutdown('uncaughtException');
});
process.on('unhandledRejection', async (reason, promise) => {
    console.error('Unhandled Rejection at:', promise, 'reason:', reason);
    await shutdown('unhandledRejection');
});

async function main() {
    const config = new Config({
        storage: {
            type: 'json',
            options: {
                path: 'memory.json'
            }
        },
        models: {
            chat: {
                provider: 'ollama',
                model: 'qwen2:1.5b'
            },
            embedding: {
                provider: 'ollama',
                model: 'nomic-embed-text'
            }
        }
    });

    const storage = new JSONStore(config.get('storage.options.path'));
    const ollama = new OllamaConnector();

    memoryManager = new MemoryManager({
        llmProvider: ollama,
        chatModel: config.get('models.chat.model'),
        embeddingModel: config.get('models.embedding.model'),
        storage
    });

    const prompt = "What's the current state of AI technology?";

    try {
        const relevantInteractions = await memoryManager.retrieveRelevantInteractions(prompt);
        const response = await memoryManager.generateResponse(prompt, [], relevantInteractions);
        console.log('Response:', response);

        const embedding = await memoryManager.generateEmbedding(`${prompt} ${response}`);
        const concepts = await memoryManager.extractConcepts(`${prompt} ${response}`);
        await memoryManager.addInteraction(prompt, response, embedding, concepts);
    } catch (error) {
        console.error('Error during execution:', error);
        await shutdown('error');
    }
}


main().catch(async (error) => {
    console.error('Fatal error:', error);
    await shutdown('fatal error');
});

================
File: src/PromptTemplates.js
================
export default class PromptTemplates {
    static templates = {
        'llama2': {
            chat: (system, context, query) => {
                const messages = [{
                    role: 'system',
                    content: system
                }];

                if (context) {
                    messages.push({
                        role: 'user',
                        content: context
                    });
                    messages.push({
                        role: 'assistant',
                        content: 'I understand the context provided. How can I help with your query?'
                    });
                }

                messages.push({
                    role: 'user',
                    content: query
                });

                return messages;
            },
            completion: (context, query) => {
                return `[INST] ${context ? `Context:\n${context}\n\n` : ''}Query: ${query} [/INST]`;
            },
            extractConcepts: (text) => {
                return `[INST] Extract key concepts from the following text and return them as a JSON array of strings only. Example: ["concept1", "concept2"]. Text: "${text}" [/INST]`;
            }
        },

        'mistral': {
            chat: (system, context, query) => {
                const messages = [{
                    role: 'system',
                    content: system
                }];

                if (context) {
                    messages.push({
                        role: 'user',
                        content: `Previous Context:\n${context}`
                    });
                    messages.push({
                        role: 'assistant',
                        content: 'Context received. What would you like to know?'
                    });
                }

                messages.push({
                    role: 'user',
                    content: query
                });

                return messages;
            },
            completion: (context, query) => {
                return `<s>[INST] ${context ? `${context}\n\n` : ''}${query} [/INST]`;
            },
            extractConcepts: (text) => {
                return `<s>[INST] Extract and return only a JSON array of key concepts from: "${text}" [/INST]`;
            }
        }
    };

    static getTemplateForModel(modelName) {
        // Handle model name variants
        const baseModel = modelName.split(':')[0].toLowerCase();
        const modelFamily = baseModel.replace(/[\d.]/g, ''); // Remove version numbers
        return this.templates[modelFamily] || this.templates['llama2'];
    }

    static formatChatPrompt(modelName, system, context, query) {
        const template = this.getTemplateForModel(modelName);
        return template.chat(system, context, query);
    }

    static formatCompletionPrompt(modelName, context, query) {
        const template = this.getTemplateForModel(modelName);
        return template.completion(context, query);
    }

    static formatConceptPrompt(modelName, text) {
        const template = this.getTemplateForModel(modelName);
        return template.extractConcepts(text);
    }

    static registerTemplate(modelName, template) {
        if (!template.chat || !template.completion || !template.extractConcepts) {
            throw new Error('Template must implement chat, completion, and extractConcepts methods');
        }
        this.templates[modelName.toLowerCase()] = template;
    }
}

================
File: src/SPARQLExample.js
================
import Config from './Config.js';
import SPARQLStore from './stores/SPARQLStore.js';
import MemoryManager from './MemoryManager.js';
import OllamaConnector from './connectors/OllamaConnector.js';

async function main() {

    const config = new Config({
        storage: {
            type: 'sparql',
            options: {
                graphName: 'http://example.org/mcp/memory'
            }
        }
    });


    const sparqlConfig = config.get('sparqlEndpoints')[0];


    const store = new SPARQLStore({
        query: `${sparqlConfig.urlBase}${sparqlConfig.query}`,
        update: `${sparqlConfig.urlBase}${sparqlConfig.update}`
    }, {
        user: sparqlConfig.user,
        password: sparqlConfig.password,
        graphName: config.get('storage.options.graphName')
    });


    const ollama = new OllamaConnector();
    const memoryManager = new MemoryManager({
        llmProvider: ollama,
        chatModel: config.get('models.chat.model'),
        embeddingModel: config.get('models.embedding.model'),
        storage: store
    });


    const prompt = "What's the current state of AI technology?";
    try {
        const relevantInteractions = await memoryManager.retrieveRelevantInteractions(prompt);
        const response = await memoryManager.generateResponse(prompt, [], relevantInteractions);
        console.log('Response:', response);

        const embedding = await memoryManager.generateEmbedding(`${prompt} ${response}`);
        const concepts = await memoryManager.extractConcepts(`${prompt} ${response}`);
        await memoryManager.addInteraction(prompt, response, embedding, concepts);
    } catch (error) {
        console.error('Error:', error);
    } finally {
        await store.close();
    }
}

main().catch(console.error);

================
File: src/Utils.js
================
export const logger = {
    info: (...args) => console.log('[INFO]', ...args),
    error: (...args) => console.error('[ERROR]', ...args),
    debug: (...args) => console.debug('[DEBUG]', ...args)
};


export const vectorOps = {
    normalize: (vector) => {
        const magnitude = Math.sqrt(vector.reduce((sum, val) => sum + val * val, 0));
        return vector.map(val => val / magnitude);
    },

    cosineSimilarity: (vec1, vec2) => {
        const dotProduct = vec1.reduce((sum, val, i) => sum + val * vec2[i], 0);
        const mag1 = Math.sqrt(vec1.reduce((sum, val) => sum + val * val, 0));
        const mag2 = Math.sqrt(vec2.reduce((sum, val) => sum + val * val, 0));
        return dotProduct / (mag1 * mag2);
    }
};

================
File: .git
================
gitdir: ../../.git/modules/packages/semem

================
File: .gitignore
================
# Logs
logs
*.log
npm-debug.log*
yarn-debug.log*
yarn-error.log*
lerna-debug.log*
.pnpm-debug.log*

# Diagnostic reports (https://nodejs.org/api/report.html)
report.[0-9]*.[0-9]*.[0-9]*.[0-9]*.json

# Runtime data
pids
*.pid
*.seed
*.pid.lock

# Directory for instrumented libs generated by jscoverage/JSCover
lib-cov

# Coverage directory used by tools like istanbul
coverage
*.lcov

# nyc test coverage
.nyc_output

# Grunt intermediate storage (https://gruntjs.com/creating-plugins#storing-task-files)
.grunt

# Bower dependency directory (https://bower.io/)
bower_components

# node-waf configuration
.lock-wscript

# Compiled binary addons (https://nodejs.org/api/addons.html)
build/Release

# Dependency directories
node_modules/
jspm_packages/

# Snowpack dependency directory (https://snowpack.dev/)
web_modules/

# TypeScript cache
*.tsbuildinfo

# Optional npm cache directory
.npm

# Optional eslint cache
.eslintcache

# Optional stylelint cache
.stylelintcache

# Microbundle cache
.rpt2_cache/
.rts2_cache_cjs/
.rts2_cache_es/
.rts2_cache_umd/

# Optional REPL history
.node_repl_history

# Output of 'npm pack'
*.tgz

# Yarn Integrity file
.yarn-integrity

# dotenv environment variable files
.env
.env.development.local
.env.test.local
.env.production.local
.env.local

# parcel-bundler cache (https://parceljs.org/)
.cache
.parcel-cache

# Next.js build output
.next
out

# Nuxt.js build / generate output
.nuxt
dist

# Gatsby files
.cache/
# Comment in the public line in if your project uses Gatsby and not Next.js
# https://nextjs.org/blog/next-9-1#public-directory-support
# public

# vuepress build output
.vuepress/dist

# vuepress v2.x temp and cache directory
.temp
.cache

# Docusaurus cache and generated files
.docusaurus

# Serverless directories
.serverless/

# FuseBox cache
.fusebox/

# DynamoDB Local files
.dynamodb/

# TernJS port file
.tern-port

# Stores VSCode versions used for testing VSCode extensions
.vscode-test

# yarn v2
.yarn/cache
.yarn/unplugged
.yarn/build-state.yml
.yarn/install-state.gz
.pnp.*

================
File: about.md
================
# About

```sh
node src/OllamaExample.js
...
 node src/SPARQLExample.js
```

```sh
# ollama pull nomic-embed-text

curl http://localhost:11434/api/embeddings -d '{
  "model": "nomic-embed-text",
  "prompt": "The sky is blue because of Rayleigh scattering"
}'
```

```sh
npm test -- --filter="SPARQL Endpoint Integration"
```

Needs #:tbox

```sh
 docker-compose up -d
```

================
File: jasmine.json
================
{
    "spec_dir": "spec",
    "spec_files": [
        "**/*[sS]pec.js"
    ],
    "helpers": [
        "helpers/reporter.js"
    ],
    "stopSpecOnExpectationFailure": true,
    "random": false
}

================
File: jsdoc.json
================
{
    "source": {
        "include": [
            "src"
        ],
        "exclude": [
            "node_modules"
        ],
        "includePattern": ".+\\.js(doc|x)?$",
        "excludePattern": "(^|\\/|\\\\)_"
    },
    "opts": {
        "verbose": true,
        "recurse": true,
        "destination": "./docs/jsdoc"
    },
    "plugins": [
        "plugins/markdown"
    ]
}

================
File: LICENSE
================
MIT License

Copyright (c) 2024 Danny Ayers

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.

================
File: memory.json
================
{
  "shortTermMemory": [
    {
      "id": "7aa15967-53c2-4bf9-bfe4-ca131244b25f",
      "prompt": "What's the current state of AI technology?",
      "output": "AI (artificial intelligence) has made significant progress in recent years, leading to impressive advancements in various fields such as natural language processing, computer vision, and machine learning. Currently, AI systems are becoming increasingly accurate at recognizing images and videos, recognizing speech, interpreting text, and even understanding complex human emotions.\n\nOne of the most significant areas of advancement is the development of sophisticated models that can mimic human thought processes, particularly in tasks like decision-making and reasoning. These advancements have led to a greater ability for machines to perform tasks that were once considered exclusive to humans.\n\nHowever, there are still challenges associated with AI technology, such as bias and ethical considerations. For example, AI systems may make decisions based on biased data or be programmed to reflect their developers' biases, leading to unfair outcomes in certain situations.\n\nOverall, the current state of AI technology is highly advanced and rapidly evolving, providing numerous opportunities for further development and innovation.",
      "embedding": [
        0.12491976469755173,
        1.8369801044464111,
        -2.836359977722168,
        -0.3198566436767578,
        1.7091443538665771,
        1.5368757247924805,
        0.7231138348579407,
        -0.31715020537376404,
        -0.2587197422981262,
        0.3269461691379547,
        1.0604941844940186,
        0.7397330403327942,
        2.290015935897827,
        0.801360547542572,
        0.17032265663146973,
        -0.38454383611679077,
        -0.3839293420314789,
        -0.4265367090702057,
        -0.2563811242580414,
        0.5484700202941895,
        0.5512731671333313,
        -0.5205145478248596,
        -0.60490882396698,
        -0.03516291081905365,
        1.5169135332107544,
        0.5205880999565125,
        -0.9432008266448975,
        -0.2396751195192337,
        0.6017621159553528,
        0.3353649377822876,
        0.6224137544631958,
        -0.7372823357582092,
        0.6936832666397095,
        -0.07453795522451401,
        -0.752737820148468,
        -0.3770278990268707,
        1.2988159656524658,
        -0.10293739289045334,
        0.9212092757225037,
        0.449664443731308,
        0.3961152136325836,
        0.9351158738136292,
        -0.16183677315711975,
        -0.8058592677116394,
        1.1469560861587524,
        0.660257875919342,
        0.30902472138404846,
        -0.5333623290061951,
        1.135331630706787,
        -1.482588768005371,
        0.3244958817958832,
        -0.38344013690948486,
        -1.141682505607605,
        0.2691633105278015,
        1.7396323680877686,
        -0.27805423736572266,
        -1.4318652153015137,
        0.20038539171218872,
        -0.150314599275589,
        -1.465523600578308,
        1.1625736951828003,
        2.073531150817871,
        -0.2901071012020111,
        0.783062756061554,
        1.2035300731658936,
        -0.7621263265609741,
        -0.6678009033203125,
        0.43446844816207886,
        0.3989027738571167,
        -0.11519447714090347,
        -0.4392530918121338,
        -0.6506828665733337,
        0.3704580068588257,
        1.294490933418274,
        -1.1668901443481445,
        -0.31891781091690063,
        0.10757721215486526,
        -0.6186971664428711,
        -0.34397056698799133,
        1.2805521488189697,
        0.9083972573280334,
        -1.6961243152618408,
        0.6530604958534241,
        -0.904271125793457,
        0.33928295969963074,
        -0.2913009524345398,
        -0.8646867275238037,
        -0.28774183988571167,
        -0.06879623979330063,
        2.6437838077545166,
        0.04489341005682945,
        0.8472090363502502,
        0.41787341237068176,
        -0.171571284532547,
        -1.414387822151184,
        0.052539486438035965,
        -0.7514325380325317,
        -0.16111132502555847,
        -0.7432562112808228,
        -0.19829311966896057,
        -0.5333774089813232,
        -0.23900139331817627,
        -0.04754523187875748,
        -0.7912653088569641,
        0.6138137578964233,
        0.7652236223220825,
        -0.32825416326522827,
        -0.34328845143318176,
        -0.4439810812473297,
        0.2986944913864136,
        -0.6434121131896973,
        0.6425718069076538,
        0.27182936668395996,
        0.04993228614330292,
        -0.8132908344268799,
        -0.614517092704773,
        -0.20235249400138855,
        -0.24016651511192322,
        0.12934601306915283,
        0.6191941499710083,
        -0.3683989346027374,
        -0.5036599636077881,
        -0.09661989659070969,
        -0.2473200112581253,
        0.1410902589559555,
        0.8190312385559082,
        -1.3268420696258545,
        0.28631874918937683,
        -0.7989341020584106,
        0.009322346188127995,
        0.4586319625377655,
        -0.00863624271005392,
        -0.40042605996131897,
        -0.4290793240070343,
        -0.5920175909996033,
        1.6775420904159546,
        -0.8716408014297485,
        -1.134478211402893,
        0.5091079473495483,
        0.32744100689888,
        1.3389161825180054,
        -0.13113607466220856,
        -0.01889372430741787,
        -0.3812280595302582,
        0.09504830092191696,
        -0.9104759693145752,
        0.10588764399290085,
        0.9216278195381165,
        -0.6222221255302429,
        -0.4472877085208893,
        0.12102110683917999,
        1.1952182054519653,
        0.38629043102264404,
        -0.2694146931171417,
        -0.04500475525856018,
        -0.19077782332897186,
        -0.8417075872421265,
        0.763364851474762,
        0.35849907994270325,
        -0.34026196599006653,
        1.6267677545547485,
        0.5263851284980774,
        -0.04410485923290253,
        0.35138124227523804,
        -0.1854589879512787,
        0.12851740419864655,
        0.5387017130851746,
        -0.3015521764755249,
        0.40523090958595276,
        0.8867528438568115,
        -1.449172019958496,
        0.4930073022842407,
        0.6477272510528564,
        0.012066707946360111,
        0.7018056511878967,
        -0.801101803779602,
        0.7843977808952332,
        -1.547490119934082,
        0.2737274169921875,
        -0.851638913154602,
        -0.3021281063556671,
        -1.493752121925354,
        0.6918375492095947,
        0.4490542709827423,
        -0.5076760053634644,
        -0.7853366732597351,
        0.03702256828546524,
        -0.8162757754325867,
        -0.40978163480758667,
        -0.43101009726524353,
        0.02284211665391922,
        0.7925400137901306,
        -1.3230433464050293,
        -0.6700342893600464,
        -0.7719236612319946,
        -0.7631769180297852,
        0.8212094306945801,
        0.18651390075683594,
        1.2387291193008423,
        -0.34159597754478455,
        -0.5352373719215393,
        0.0030540423467755318,
        -1.556527018547058,
        0.05646669119596481,
        -0.49080798029899597,
        0.5476893782615662,
        0.3175978362560272,
        0.27324920892715454,
        -0.4573691487312317,
        -1.133535385131836,
        1.1181085109710693,
        -0.03285442665219307,
        0.5667941570281982,
        0.22967088222503662,
        -0.3295646905899048,
        0.41139665246009827,
        0.30733397603034973,
        -0.8020079731941223,
        -0.13211730122566223,
        -0.31191286444664,
        0.9004729986190796,
        -0.22096988558769226,
        0.17851302027702332,
        0.4664468467235565,
        0.5166496634483337,
        -0.6298418045043945,
        -1.741819977760315,
        -0.0464639812707901,
        -0.8251755237579346,
        1.0274327993392944,
        -0.25635674595832825,
        -0.6607926487922668,
        1.1447278261184692,
        -0.06328494101762772,
        0.8838855624198914,
        1.2228628396987915,
        0.18944181501865387,
        0.7626209259033203,
        1.0020198822021484,
        0.33281514048576355,
        -0.08524961769580841,
        0.5206738710403442,
        -0.9754936099052429,
        0.5802676677703857,
        -0.7957125902175903,
        -0.7904571890830994,
        -0.3967117667198181,
        -1.0418528318405151,
        -0.48379552364349365,
        1.036049485206604,
        -0.39303749799728394,
        -0.6383791565895081,
        -0.09060866385698318,
        0.41354483366012573,
        0.5235046148300171,
        -0.08256173133850098,
        -0.010850892402231693,
        0.536450982093811,
        0.4913088381290436,
        0.8148770928382874,
        1.0756150484085083,
        -0.9778867363929749,
        0.7928803563117981,
        -0.19083340466022491,
        0.17845486104488373,
        0.0871540755033493,
        0.5762256979942322,
        0.18677055835723877,
        0.23899810016155243,
        -0.19605927169322968,
        0.70145183801651,
        1.2135578393936157,
        -0.14284057915210724,
        0.46146848797798157,
        0.5753531455993652,
        0.4437130093574524,
        -0.5208219289779663,
        -0.8124105334281921,
        0.3637951612472534,
        -0.11712818592786789,
        -0.6160479784011841,
        -0.871920645236969,
        -1.0844913721084595,
        -0.10876434296369553,
        0.09140688180923462,
        0.45230937004089355,
        -0.1349988877773285,
        0.2935565114021301,
        0.39470747113227844,
        0.296043336391449,
        -0.002227185759693384,
        -0.771233081817627,
        -1.0470333099365234,
        -0.7649186253547668,
        -1.0398919582366943,
        0.8502532839775085,
        0.42348334193229675,
        -0.4404062032699585,
        0.6499478816986084,
        -0.9586893320083618,
        0.3363354504108429,
        0.43532004952430725,
        1.6408923864364624,
        0.769572377204895,
        0.9631974101066589,
        -0.5469291806221008,
        -0.2005710005760193,
        0.042685359716415405,
        0.4644899368286133,
        -0.14594799280166626,
        -1.9416673183441162,
        0.37619587779045105,
        -0.2908209562301636,
        0.12069422751665115,
        -0.3507130742073059,
        -0.0831666812300682,
        0.31872883439064026,
        0.6199519038200378,
        0.8404874205589294,
        -0.09725815057754517,
        0.04585915803909302,
        -0.8093162775039673,
        -1.1803678274154663,
        -0.7012977004051208,
        0.2917172908782959,
        1.351790428161621,
        0.4673451781272888,
        0.13064076006412506,
        -1.1810475587844849,
        0.029403360560536385,
        0.8622151017189026,
        -0.07627612352371216,
        -0.10484194755554199,
        -0.818717360496521,
        -0.16108375787734985,
        0.1374860405921936,
        0.3474540114402771,
        0.4489806592464447,
        0.5150687098503113,
        0.0760321393609047,
        0.7842822074890137,
        -0.03244958817958832,
        0.8928248286247253,
        -0.4251404106616974,
        -0.4220188558101654,
        0.005760360509157181,
        -0.40477466583251953,
        0.09207206964492798,
        0.21506287157535553,
        0.5353277325630188,
        -0.04401965066790581,
        1.1268750429153442,
        -0.10538072139024734,
        -0.15716460347175598,
        0.4393766522407532,
        -0.016307931393384933,
        -0.6943178176879883,
        1.5189834833145142,
        0.33541229367256165,
        0.04034176096320152,
        0.18494732677936554,
        0.120241180062294,
        0.09297816455364227,
        -1.2079592943191528,
        0.09421088546514511,
        -0.2416362464427948,
        -0.10840460658073425,
        -0.3381482660770416,
        -0.12903085350990295,
        -0.689944863319397,
        0.4653768241405487,
        -0.6843000650405884,
        -0.6634242534637451,
        1.0446946620941162,
        -0.4697904586791992,
        0.3605439066886902,
        -1.6151982545852661,
        -0.3113892376422882,
        -0.5775696635246277,
        -0.10037367045879364,
        -0.028028052300214767,
        -0.1049714982509613,
        -0.8264880180358887,
        -0.15058763325214386,
        0.3387994170188904,
        0.13385970890522003,
        -0.6163891553878784,
        -0.9996985793113708,
        -0.7955232858657837,
        -0.2956680953502655,
        0.0753006860613823,
        -0.6171594858169556,
        -1.0724986791610718,
        -0.5275229215621948,
        0.007050176616758108,
        -1.0205134153366089,
        -0.5931673645973206,
        0.0703272670507431,
        -0.08636439591646194,
        0.6120859384536743,
        -0.8236427307128906,
        -0.42829522490501404,
        0.7928633689880371,
        -0.3130899965763092,
        -0.2641674876213074,
        -0.41620150208473206,
        -1.222638487815857,
        -0.9340586066246033,
        0.9531692862510681,
        -0.19083720445632935,
        0.6265625953674316,
        0.924618124961853,
        -0.5879073739051819,
        -1.4996159076690674,
        0.8476712107658386,
        0.05222977697849274,
        0.19351769983768463,
        0.8002361059188843,
        -0.4341951608657837,
        -0.04731566458940506,
        0.9865787625312805,
        0.4893644154071808,
        0.22834061086177826,
        -0.1311991959810257,
        0.3569967448711395,
        0.350721538066864,
        0.6167551279067993,
        0.5712622404098511,
        -0.07990540564060211,
        -0.7585358023643494,
        1.4336929321289062,
        0.04830209165811539,
        0.32281816005706787,
        -0.4236983060836792,
        -0.4258350729942322,
        1.3668770790100098,
        -0.2297571301460266,
        0.6358726620674133,
        0.11411086469888687,
        1.0004655122756958,
        1.439334750175476,
        -0.3743727505207062,
        -0.7899316549301147,
        -0.7560003399848938,
        0.41063806414604187,
        1.3468023538589478,
        1.3341996669769287,
        0.0364358089864254,
        -1.4369202852249146,
        1.1886193752288818,
        -0.49254167079925537,
        0.18601347506046295,
        0.7576262354850769,
        0.3808034062385559,
        0.8657183647155762,
        -0.3536398708820343,
        -0.14133292436599731,
        -0.039732933044433594,
        -0.40783634781837463,
        0.29993587732315063,
        -0.020395806059241295,
        -0.10164795070886612,
        -1.0161166191101074,
        0.747763454914093,
        -0.09805314987897873,
        0.26052337884902954,
        -0.2975066304206848,
        -0.8963685035705566,
        0.6704666018486023,
        0.1054091602563858,
        -0.16580839455127716,
        0.563453733921051,
        0.3609849214553833,
        0.006870919838547707,
        -1.367591142654419,
        -0.2836892306804657,
        -0.7733685970306396,
        -0.5858754515647888,
        0.3894437551498413,
        1.307384729385376,
        0.21954946219921112,
        -1.3772008419036865,
        -0.3646112382411957,
        -0.0472681038081646,
        0.4817284345626831,
        0.6253397464752197,
        0.12500864267349243,
        0.4367496967315674,
        -1.0798637866973877,
        -0.21812602877616882,
        1.186380386352539,
        0.5303252339363098,
        -0.14463795721530914,
        -0.9445869326591492,
        -0.8800593614578247,
        -0.22256270051002502,
        -1.3106275796890259,
        0.6365478038787842,
        0.35412904620170593,
        0.21321144700050354,
        -0.10074368864297867,
        0.3076353967189789,
        -0.009662910364568233,
        0.243843212723732,
        0.04420771449804306,
        0.17725145816802979,
        0.41420337557792664,
        -2.7429685592651367,
        -0.730103075504303,
        1.3149638175964355,
        0.19261880218982697,
        0.3478052020072937,
        0.9170361757278442,
        0.15444332361221313,
        0.45176342129707336,
        -0.6419556140899658,
        0.830455482006073,
        0.10339301824569702,
        -1.5855348110198975,
        -0.08640597015619278,
        0.31007227301597595,
        -0.5635018348693848,
        0.32263827323913574,
        -0.25482046604156494,
        -1.7611489295959473,
        0.11386673897504807,
        0.8007599115371704,
        -0.7803658246994019,
        1.0839449167251587,
        -0.7420787215232849,
        0.4350135326385498,
        0.5494168400764465,
        -1.2089242935180664,
        -0.4119323194026947,
        -0.007634792011231184,
        0.2579122483730316,
        -0.49815285205841064,
        -0.9424623847007751,
        1.1910675764083862,
        0.6728699803352356,
        1.034467101097107,
        0.821312665939331,
        -0.29322728514671326,
        -0.02554570510983467,
        0.0993541032075882,
        0.28725481033325195,
        -0.2724417448043823,
        1.3095228672027588,
        -0.4064194858074188,
        -1.7227613925933838,
        0.5788276791572571,
        -1.0830150842666626,
        0.07601701468229294,
        -0.061027996242046356,
        0.6679896712303162,
        -0.5852273106575012,
        -0.36454832553863525,
        -0.6329775452613831,
        0.5003455281257629,
        -0.3594553768634796,
        0.04473971575498581,
        0.5129671096801758,
        1.3657727241516113,
        -0.2155320793390274,
        -0.06972330808639526,
        0.015242187306284904,
        0.022966500371694565,
        -0.28250354528427124,
        0.3284933567047119,
        1.2920868396759033,
        0.988864004611969,
        -0.5642206072807312,
        0.2140612006187439,
        0.14496144652366638,
        0.5006557703018188,
        -1.0940454006195068,
        -0.03152639791369438,
        -0.46176666021347046,
        -1.5681239366531372,
        -0.5055309534072876,
        0.06582289189100266,
        -1.387479305267334,
        0.5952484607696533,
        0.4120424687862396,
        1.0116971731185913,
        0.4271255135536194,
        -1.3887708187103271,
        -0.0037337327376008034,
        0.9874992966651917,
        -1.190869688987732,
        -0.7581613063812256,
        -0.03333369642496109,
        0.17155377566814423,
        -0.8056365847587585,
        -0.5423871278762817,
        0.15347039699554443,
        -0.9923530220985413,
        -0.7565686702728271,
        -0.6814156174659729,
        -1.6068638563156128,
        0.16284862160682678,
        -0.05651761591434479,
        0.7458723187446594,
        -0.29425960779190063,
        0.2548219561576843,
        0.6581794619560242,
        0.13677380979061127,
        1.2579867839813232,
        0.4644255042076111,
        -1.245871901512146,
        0.41930365562438965,
        -0.6908015608787537,
        -0.678593099117279,
        -0.443755179643631,
        0.9433008432388306,
        -0.3156392276287079,
        1.8480339050292969,
        -1.443995714187622,
        -1.0577826499938965,
        0.04565560445189476,
        -0.7318659424781799,
        -0.8980718851089478,
        0.3040700852870941,
        -0.5145719647407532,
        1.090153694152832,
        0.6157602071762085,
        -0.3044062554836273,
        -0.28547537326812744,
        0.2654309570789337,
        1.932816743850708,
        -0.434665709733963,
        0.3547246754169464,
        0.1304294764995575,
        0.5060722231864929,
        -0.28693467378616333,
        -0.7067394256591797,
        0.0005606435588560998,
        0.9050934314727783,
        0.5641219615936279,
        0.6168197989463806,
        0.7220308184623718,
        -0.8858780264854431,
        -1.1087327003479004,
        1.2435047626495361,
        0.7107523679733276,
        -0.8030774593353271,
        0.5964246392250061,
        2.091747999191284,
        -0.29288044571876526,
        -0.4379083812236786,
        0.5221770405769348,
        1.38614022731781,
        0.7799273133277893,
        -0.6985093951225281,
        -0.19745251536369324,
        0.636011004447937,
        0.06418178975582123,
        -0.1742507964372635,
        -0.1322631984949112,
        -0.9857559204101562,
        0.5106373429298401,
        0.03714164346456528,
        -0.29911431670188904,
        0.14910857379436493,
        0.3796568214893341,
        -0.6740549206733704,
        -0.040461815893650055,
        0.01732320711016655,
        -0.377246618270874,
        -0.2288718968629837,
        1.1858152151107788,
        0.01040287222713232,
        0.02458789199590683,
        -1.1207348108291626,
        0.7965196371078491,
        0.6612324714660645,
        0.40144050121307373,
        0.13382263481616974,
        -0.1355479657649994,
        0.1381136178970337,
        0.2485298216342926,
        -0.3863011300563812,
        0.6508268713951111,
        -0.8059253096580505,
        -0.615628182888031,
        -0.31838259100914,
        0.2677658796310425,
        -0.16817547380924225,
        -0.9376029968261719,
        -1.388631820678711,
        -0.5126394033432007,
        -0.96100914478302,
        -0.673586368560791,
        0.05880352854728699,
        0.018396418541669846,
        0.12704439461231232,
        -0.07513265311717987,
        0.40454477071762085,
        0.7226549386978149,
        1.039684534072876,
        -0.3859487473964691,
        0.8128030300140381,
        0.9302374720573425,
        0.6721031069755554,
        -0.06485624611377716,
        -0.2727017104625702,
        0.11579937487840652,
        -0.059921395033597946,
        -0.04896221682429314,
        0.1661171019077301,
        -0.07284030318260193,
        0.6315520405769348,
        -0.5605798363685608,
        0.8463625311851501,
        -0.4269089698791504,
        -0.10213126987218857,
        0.045721352100372314,
        -0.9723871350288391,
        -0.8126567602157593,
        0.3983558118343353,
        0.9014229774475098,
        -0.6786601543426514,
        -1.4534780979156494,
        -0.4742042124271393,
        -0.6637701988220215,
        0.42657798528671265,
        1.529600739479065,
        -0.39255499839782715,
        0.06771010905504227,
        -0.4873483180999756,
        0.3753877878189087,
        -0.23610499501228333,
        -0.6509894132614136,
        0.7735357880592346,
        -0.5464348793029785,
        0.38458871841430664,
        -0.953687846660614,
        -0.5627199411392212,
        -1.3212617635726929,
        -0.2875279188156128,
        0.5161432027816772,
        0.6674443483352661,
        0.37745580077171326,
        -0.3249814212322235,
        0.11489737033843994,
        -0.2363080084323883,
        -0.5372691750526428,
        0.9680010080337524,
        0.313289612531662,
        -0.41329604387283325,
        0.4879644811153412,
        0.5513832569122314,
        -0.8678826689720154,
        -0.3900988698005676,
        -0.523661196231842,
        0.6726242303848267,
        0.15538863837718964,
        1.0664007663726807,
        2.555957555770874,
        0.31111061573028564,
        0.3926152288913727,
        -0.9738065600395203,
        1.0788644552230835,
        -0.7905405163764954,
        -1.352218508720398,
        -0.794523298740387,
        -0.9644606709480286,
        0.04721686616539955,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      "timestamp": 1735589346786,
      "accessCount": 2,
      "concepts": [
        "AI (artificial intelligence) has made significant progress in recent years",
        "current state of AI technology",
        "significant advancements in various fields",
        "natural language processing",
        "computer vision",
        "machine learning",
        "accuracy at recognizing images and videos",
        "recognition of speech",
        "interpretation of text",
        "understanding complex human emotions",
        "development of sophisticated models that can mimic human thought processes",
        "decision-making and reasoning",
        "bias and ethical considerations",
        "AI systems may make decisions based on biased data or be programmed to reflect their developers' biases",
        "unfair outcomes in certain situations"
      ],
      "decayFactor": 1.1
    },
    {
      "id": "d4193315-d28f-43f4-916b-3e27e9b9ce34",
      "prompt": "What's the current state of AI technology?",
      "output": "AI (Artificial Intelligence) technology has advanced significantly in recent years, and its capabilities have become increasingly more sophisticated across various fields such as speech recognition, natural language processing, computer vision, robotics, and machine learning. Here are some key areas where AI technologies are currently being utilized:\n\n1. Speech Recognition: AI-powered speech recognition is becoming increasingly accurate, allowing machines to understand and process human voice inputs in real-time.\n\n2. Natural Language Processing (NLP): NLP technology allows computers to interpret and respond to natural language input. It has been used for tasks such as chatbots, virtual assistants, and automated customer service.\n\n3. Computer Vision: AI-powered computer vision enables machines to analyze images or videos by recognizing patterns and objects within them. This technology is being used in applications such as object detection, facial recognition, and medical diagnosis.\n\n4. Robotics: Robot software has advanced significantly, enabling robots to perform tasks autonomously without human intervention. Examples include drones for surveillance and delivery services.\n\n5. Machine Learning (ML): ML is a subset of AI that involves training computers with vast amounts of data to improve their performance. This technology has been used in applications such as predictive analytics, fraud detection, and personalized marketing.\n\n6. Deep Learning: Deep learning represents the advanced form of machine learning where multiple layers of artificial neurons are combined to create complex patterns, which then help machines learn from large sets of data.\n\n7. Reinforcement Learning (RL): RL is a type of ML where an agent learns by making choices in response to rewards and penalties. It's used for applications like self-driving cars and video game AI.\n\n8. Autonomous vehicles: Autonomous vehicles utilize various forms of machine learning, including computer vision, machine learning, and deep learning to navigate roads, detect obstacles, and make decisions based on that information.\n\n9. Financial services: AI is being used in financial services to improve fraud detection, underwriting processes, investment management, and predictive analytics.\n\n10. Healthcare: AI has been applied in the healthcare sector for tasks such as diagnosis, medical imaging analysis, disease prediction, drug discovery, and patient care.\n\nAI technology continues to evolve at an unprecedented pace, with new developments emerging every day. These advancements are expected to further revolutionize various industries by enhancing efficiency, accuracy, and capabilities.",
      "embedding": [
        -0.10433521121740341,
        1.8697201013565063,
        -3.184619426727295,
        -0.2206520140171051,
        1.6739252805709839,
        0.614357590675354,
        0.5829628109931946,
        -0.2629427909851074,
        -0.12132082134485245,
        -0.14462168514728546,
        0.8505654335021973,
        0.6306716203689575,
        2.0592658519744873,
        0.48753687739372253,
        0.07995526492595673,
        -0.4965257942676544,
        -0.6542823910713196,
        -0.43938031792640686,
        -0.3869960904121399,
        0.21164266765117645,
        0.22473026812076569,
        -0.6871693730354309,
        -0.38590675592422485,
        -0.20888212323188782,
        1.3392958641052246,
        0.5396700501441956,
        -1.359850525856018,
        -0.0598413348197937,
        0.7177659869194031,
        0.16285911202430725,
        0.951171875,
        -1.0563395023345947,
        0.5318397879600525,
        -0.05355701595544815,
        -0.716783344745636,
        -0.783730685710907,
        1.442060112953186,
        -0.12770570814609528,
        0.721474289894104,
        0.5662090182304382,
        0.4891010820865631,
        1.0490577220916748,
        -0.01493546087294817,
        -0.5670116543769836,
        1.311440110206604,
        0.6456825733184814,
        0.34383079409599304,
        -0.8195984959602356,
        1.165393590927124,
        -1.3246511220932007,
        0.2726297080516815,
        -0.04322192445397377,
        -0.8259214162826538,
        0.21056564152240753,
        1.9229223728179932,
        -0.37493380904197693,
        -1.3607856035232544,
        0.17280802130699158,
        0.04996584355831146,
        -1.3931457996368408,
        1.678268313407898,
        2.001239538192749,
        -0.34232649207115173,
        1.0248805284500122,
        1.1832817792892456,
        -0.6564522981643677,
        -0.3367833197116852,
        0.481473833322525,
        0.6205921173095703,
        -0.2993152439594269,
        -0.45989885926246643,
        -0.6584509611129761,
        0.36783483624458313,
        1.1859029531478882,
        -1.081889271736145,
        -0.593357264995575,
        -0.23053960502147675,
        -0.734898567199707,
        -0.46959492564201355,
        1.6153481006622314,
        1.186361312866211,
        -1.5686877965927124,
        1.0294495820999146,
        -0.5016153454780579,
        0.7008347511291504,
        -0.4013672173023224,
        -1.0132887363433838,
        -0.3441283702850342,
        0.04293934255838394,
        2.4780526161193848,
        0.2919187843799591,
        1.0239859819412231,
        0.5270856618881226,
        -0.26147744059562683,
        -1.0588374137878418,
        -0.04022267460823059,
        -0.30905410647392273,
        -0.4475598633289337,
        -0.8491366505622864,
        -0.863986074924469,
        -0.5600830912590027,
        -0.21846666932106018,
        0.10902906209230423,
        -0.7227169275283813,
        1.0638175010681152,
        0.7955090999603271,
        -0.5002639889717102,
        -0.6795476078987122,
        -0.5422601103782654,
        0.4937867224216461,
        -0.5202124714851379,
        0.8737892508506775,
        0.16428987681865692,
        0.06551658362150192,
        -0.9977352619171143,
        -0.5322259068489075,
        -0.3602137863636017,
        -0.01139324065297842,
        0.6830971837043762,
        0.6099944114685059,
        -0.3387778103351593,
        -0.6653800010681152,
        -0.039969976991415024,
        -0.25402289628982544,
        0.3118310272693634,
        1.0713982582092285,
        -1.4270365238189697,
        0.12924087047576904,
        -0.7463906407356262,
        0.21162940561771393,
        0.46933773159980774,
        0.09443691372871399,
        -0.4531583786010742,
        -0.2649460434913635,
        -0.30798640847206116,
        1.9993956089019775,
        -1.1609736680984497,
        -1.0086162090301514,
        0.6942870020866394,
        0.35487812757492065,
        1.2570295333862305,
        -0.1754561960697174,
        -0.19488190114498138,
        -0.23127543926239014,
        -0.013485553674399853,
        -0.8094710111618042,
        -0.008385006338357925,
        1.003747820854187,
        -1.250714898109436,
        -0.10683752596378326,
        0.2631816267967224,
        1.21544349193573,
        0.19546698033809662,
        -0.40006914734840393,
        0.35528600215911865,
        0.17624160647392273,
        -0.7655799984931946,
        0.2765638530254364,
        0.4816440939903259,
        0.232059046626091,
        1.3963336944580078,
        0.2331322729587555,
        -0.19175229966640472,
        0.6193367838859558,
        -0.11497992277145386,
        -0.037537459284067154,
        0.5157771110534668,
        -0.1756729781627655,
        0.4764678478240967,
        1.2450026273727417,
        -1.0952640771865845,
        0.45894113183021545,
        0.30721357464790344,
        0.36280909180641174,
        0.6524468660354614,
        -0.42498210072517395,
        0.6190058588981628,
        -1.7388299703598022,
        0.412248432636261,
        -0.8751434683799744,
        0.31744447350502014,
        -1.5105915069580078,
        0.5945526361465454,
        0.7481050491333008,
        -0.670433759689331,
        -0.47020280361175537,
        -0.030114799737930298,
        -0.6808082461357117,
        -0.44042539596557617,
        -0.4268733859062195,
        -0.04579836130142212,
        1.0183963775634766,
        -1.368414282798767,
        -0.9551790952682495,
        -0.6469736695289612,
        -0.26343247294425964,
        0.5946378707885742,
        0.10054568201303482,
        0.7613319158554077,
        -0.6003469824790955,
        -0.5526561737060547,
        0.0026358922477811575,
        -1.4386076927185059,
        -0.25498050451278687,
        -0.5516588091850281,
        0.8354066610336304,
        0.4686480760574341,
        0.5286406874656677,
        -0.482278436422348,
        -0.47603175044059753,
        1.20375657081604,
        0.10748901218175888,
        0.7928076386451721,
        -0.13685227930545807,
        -0.43177130818367004,
        0.33314207196235657,
        0.21091513335704803,
        -1.3419476747512817,
        0.05701163038611412,
        -0.13118895888328552,
        1.1131126880645752,
        -0.20840094983577728,
        0.324397474527359,
        0.6147359013557434,
        0.2715483009815216,
        -0.35285305976867676,
        -1.6441704034805298,
        0.05560322478413582,
        -0.7445988655090332,
        0.921908974647522,
        -0.381445974111557,
        -0.6519695520401001,
        1.0412756204605103,
        -0.2738056778907776,
        0.9770664572715759,
        0.728954553604126,
        0.023705633357167244,
        0.8348273038864136,
        0.6425100564956665,
        1.0542057752609253,
        0.12122709304094315,
        0.6582216620445251,
        -1.0310921669006348,
        0.27663853764533997,
        -0.9946478009223938,
        -0.8337415456771851,
        -0.8001947999000549,
        -1.201650619506836,
        -0.17157800495624542,
        1.1109087467193604,
        -0.12069711834192276,
        -0.39034342765808105,
        -0.043511878699064255,
        0.7818061113357544,
        0.41469860076904297,
        0.030674880370497704,
        0.2749217450618744,
        0.634619951248169,
        0.053507447242736816,
        0.6457354426383972,
        1.0334380865097046,
        -1.018062710762024,
        0.9474088549613953,
        -0.5986846685409546,
        0.05884794890880585,
        0.021380262449383736,
        0.17621441185474396,
        0.24399985373020172,
        -0.029314011335372925,
        -0.11513346433639526,
        0.6849346160888672,
        1.0101466178894043,
        -0.09860412031412125,
        0.2742013931274414,
        0.31439754366874695,
        0.6921884417533875,
        -0.05679567530751228,
        -0.6281152367591858,
        0.06653756648302078,
        -0.056667011231184006,
        -0.5182458162307739,
        -1.2661235332489014,
        -1.1665716171264648,
        -0.13467463850975037,
        -0.19846776127815247,
        0.4522762596607208,
        0.42234838008880615,
        0.2880312502384186,
        0.345945805311203,
        0.21714933216571808,
        0.14827772974967957,
        -1.0015939474105835,
        -0.5587285161018372,
        -0.9208228588104248,
        -1.2482043504714966,
        1.0305877923965454,
        0.5067489147186279,
        -0.31622931361198425,
        0.7894078493118286,
        -0.7877297401428223,
        0.7433751225471497,
        0.3410733938217163,
        1.9590294361114502,
        0.4562174379825592,
        0.8614208698272705,
        -0.20170968770980835,
        -0.2834736406803131,
        -0.0902552530169487,
        0.25910288095474243,
        -0.1122942641377449,
        -1.9255406856536865,
        0.16606147587299347,
        -0.14367510378360748,
        0.11127150803804398,
        -0.4573374092578888,
        0.09562954306602478,
        0.33589333295822144,
        0.5008395910263062,
        0.7920140027999878,
        0.16286230087280273,
        -0.028971465304493904,
        -1.3645859956741333,
        -1.1667495965957642,
        -0.8286677598953247,
        0.33175531029701233,
        1.2712678909301758,
        0.4424116611480713,
        -0.0061119114980101585,
        -1.2359998226165771,
        -0.30720123648643494,
        0.7362446784973145,
        0.17271758615970612,
        -0.2363297939300537,
        -1.082771897315979,
        -0.15360723435878754,
        0.37423175573349,
        0.20182833075523376,
        0.4832465350627899,
        0.5534840822219849,
        -0.2937971353530884,
        1.0509148836135864,
        -0.07789558917284012,
        0.7655156850814819,
        0.07962666451931,
        -0.29578396677970886,
        0.21191677451133728,
        -0.19970163702964783,
        0.1934390515089035,
        0.14931686222553253,
        0.31755462288856506,
        -0.1729116588830948,
        1.0408295392990112,
        -0.0933811292052269,
        -0.3661085367202759,
        0.3441629409790039,
        -0.056133415549993515,
        -0.3952384293079376,
        1.3012984991073608,
        0.6664328575134277,
        -0.06578680872917175,
        0.6295623183250427,
        0.07160265743732452,
        0.20822614431381226,
        -0.8474737405776978,
        -0.010025151073932648,
        -0.19516025483608246,
        0.09657637774944305,
        -0.32363447546958923,
        -0.11279032379388809,
        -0.39592310786247253,
        0.5672619938850403,
        -0.5257101655006409,
        -0.6383329629898071,
        0.8266454935073853,
        -0.6284335255622864,
        0.23151163756847382,
        -2.030125141143799,
        -0.6578400135040283,
        -0.4523724913597107,
        -0.4882620573043823,
        -0.49074608087539673,
        -0.35181277990341187,
        -0.9720458388328552,
        -0.09048385173082352,
        0.21765872836112976,
        0.0812351405620575,
        -0.7823981642723083,
        -0.8528996706008911,
        -0.672522246837616,
        -0.3049739897251129,
        0.0741376057267189,
        -0.4172172248363495,
        -1.0243757963180542,
        -0.7985929250717163,
        -0.08991395682096481,
        -1.134962558746338,
        -0.4173886477947235,
        -0.13899841904640198,
        -0.19378705322742462,
        0.8066068887710571,
        -0.785818338394165,
        -0.6421162486076355,
        0.5260369777679443,
        -0.5494968891143799,
        -0.3686043620109558,
        -0.41132858395576477,
        -0.9247201085090637,
        -0.6865880489349365,
        1.1074018478393555,
        0.04771993309259415,
        0.4074588716030121,
        0.5671375393867493,
        -0.5084776282310486,
        -1.4905580282211304,
        1.0105913877487183,
        0.04881337657570839,
        0.30495765805244446,
        0.503121554851532,
        -0.7091776728630066,
        0.30400434136390686,
        1.0403331518173218,
        0.3364880681037903,
        0.3616762161254883,
        -0.1532125622034073,
        0.1512303203344345,
        0.4062534272670746,
        0.09008614718914032,
        0.9959255456924438,
        -0.15029264986515045,
        -0.7323565483093262,
        1.586368203163147,
        -0.29465022683143616,
        0.1569834053516388,
        -0.6999294757843018,
        -0.5284394025802612,
        1.5057451725006104,
        -0.057665999978780746,
        0.9601718187332153,
        0.6354497075080872,
        0.8543076515197754,
        1.0645768642425537,
        -0.46204012632369995,
        -0.6000677943229675,
        -0.8233442306518555,
        0.33534812927246094,
        1.7656619548797607,
        1.186784029006958,
        0.34925392270088196,
        -1.0587908029556274,
        1.1931812763214111,
        -0.8008753061294556,
        0.31781190633773804,
        0.8181281089782715,
        0.14065727591514587,
        0.920791506767273,
        -0.4699588119983673,
        0.011583592742681503,
        -0.040479253977537155,
        0.34322062134742737,
        0.5663056373596191,
        -0.0745641216635704,
        0.45919734239578247,
        -1.152259111404419,
        0.3574152886867523,
        -0.26004964113235474,
        0.1705566793680191,
        -0.30494827032089233,
        -1.0927631855010986,
        0.553850531578064,
        0.309013307094574,
        -0.23135589063167572,
        -0.04146690294146538,
        0.4118243455886841,
        -0.5362999439239502,
        -1.3135451078414917,
        -0.6044697165489197,
        -0.3472212851047516,
        -0.5323159098625183,
        -0.027451826259493828,
        1.0058016777038574,
        0.7171875834465027,
        -1.629889965057373,
        -0.4859532117843628,
        -0.14379216730594635,
        0.4148000478744507,
        0.809313952922821,
        0.06985366344451904,
        0.3968183994293213,
        -0.9482083916664124,
        -0.13673178851604462,
        0.7891221642494202,
        0.4627153277397156,
        -0.11148174852132797,
        -0.9695566296577454,
        -1.033050775527954,
        -0.3943972587585449,
        -1.2227373123168945,
        0.5846888422966003,
        0.4027356505393982,
        0.26953816413879395,
        -0.22139762341976166,
        0.17953628301620483,
        0.13948099315166473,
        0.07172950357198715,
        0.059146586805582047,
        0.33083170652389526,
        0.6266754269599915,
        -2.2423949241638184,
        -0.8577259182929993,
        1.3643407821655273,
        0.28827208280563354,
        0.4870804250240326,
        0.529589056968689,
        0.26091688871383667,
        0.6427937746047974,
        -0.6571256518363953,
        0.8595463037490845,
        0.17364437878131866,
        -1.530450463294983,
        0.008848508819937706,
        0.2308075875043869,
        -0.5449746251106262,
        0.33524641394615173,
        0.10009465366601944,
        -1.4242695569992065,
        0.31939688324928284,
        0.6663052439689636,
        -0.6072368025779724,
        1.3995150327682495,
        -0.5802900791168213,
        0.3982914984226227,
        0.3404252827167511,
        -1.4217067956924438,
        -0.45225614309310913,
        0.34955182671546936,
        0.6085098385810852,
        -0.33668115735054016,
        -0.9434632658958435,
        1.26180899143219,
        0.5541850328445435,
        0.5895596146583557,
        0.6253746151924133,
        -0.23796150088310242,
        -0.09287828952074051,
        0.17634661495685577,
        -0.12222568690776825,
        0.0070228478871285915,
        1.2085330486297607,
        -0.36279475688934326,
        -1.9439527988433838,
        0.5787628293037415,
        -1.6572747230529785,
        0.13625775277614594,
        0.12649773061275482,
        0.7308952212333679,
        -0.8286677598953247,
        -0.36411091685295105,
        -0.7533265352249146,
        -0.11854198575019836,
        -0.6775456666946411,
        -0.20588894188404083,
        0.44743186235427856,
        1.430631399154663,
        -0.17496323585510254,
        -0.08243739604949951,
        -0.028025249019265175,
        0.06878223270177841,
        -0.31949320435523987,
        0.42605143785476685,
        0.983340859413147,
        0.6601770520210266,
        -0.7459907531738281,
        0.2719126045703888,
        0.08778773993253708,
        0.6505849957466125,
        -0.8083724975585938,
        0.49429887533187866,
        -0.26845234632492065,
        -1.529458999633789,
        -0.3676965534687042,
        0.44142279028892517,
        -1.2462033033370972,
        0.9462212324142456,
        0.5030062794685364,
        1.3288531303405762,
        0.4730844497680664,
        -1.4515447616577148,
        -0.058426883071660995,
        0.8057146668434143,
        -1.1374486684799194,
        -0.5131610631942749,
        0.14932531118392944,
        0.13129279017448425,
        -1.0617473125457764,
        -0.9596604704856873,
        0.10844684392213821,
        -0.7738557457923889,
        -0.5974507331848145,
        -0.6057577729225159,
        -1.6913484334945679,
        -0.11103890091180801,
        -0.14231042563915253,
        0.9689733982086182,
        -0.39598920941352844,
        0.13958515226840973,
        0.5949275493621826,
        0.03629579022526741,
        0.9436140060424805,
        0.13610053062438965,
        -1.0857754945755005,
        0.25753873586654663,
        -0.7165136337280273,
        -0.3853425681591034,
        -0.29732221364974976,
        0.8579427599906921,
        -0.5418738722801208,
        1.7795296907424927,
        -1.618507742881775,
        -0.4648197591304779,
        0.014602100476622581,
        -0.7729672789573669,
        -0.9885097146034241,
        0.3641601502895355,
        -0.559778094291687,
        0.9100103974342346,
        0.4209540784358978,
        -0.4840755760669708,
        -0.18544788658618927,
        0.12990276515483856,
        1.5390971899032593,
        -0.36837896704673767,
        0.5683218836784363,
        0.43165141344070435,
        0.2702963650226593,
        -0.32022517919540405,
        -0.4306519031524658,
        -0.0462467223405838,
        0.43297600746154785,
        0.6786072850227356,
        0.9336377382278442,
        0.7317653894424438,
        -1.110927939414978,
        -0.9217392206192017,
        1.2582802772521973,
        0.9088456034660339,
        -0.8898516297340393,
        0.748028039932251,
        2.437042474746704,
        -0.2437034249305725,
        -0.39200180768966675,
        0.9204779863357544,
        1.4366724491119385,
        0.5128756761550903,
        -0.5986008644104004,
        -0.4154890477657318,
        0.27676379680633545,
        0.007390833459794521,
        -0.16876673698425293,
        -0.04886099323630333,
        -0.972829282283783,
        0.4036029875278473,
        0.36473190784454346,
        -0.14763064682483673,
        -0.1373266726732254,
        0.49644413590431213,
        -0.5589876174926758,
        -0.09459290653467178,
        -0.26510751247406006,
        -0.5763946175575256,
        -0.6343258023262024,
        1.0721536874771118,
        0.3282551169395447,
        -0.09674239903688431,
        -1.3405460119247437,
        0.4781624972820282,
        0.8754708766937256,
        0.65118008852005,
        0.15955156087875366,
        -0.07708778977394104,
        0.09506911039352417,
        -0.07570785284042358,
        -0.09799903631210327,
        0.2618679702281952,
        -0.8051590323448181,
        -0.23304490745067596,
        -0.3286440968513489,
        0.3986692726612091,
        -0.03307554870843887,
        -0.42751291394233704,
        -1.4969979524612427,
        -0.31788861751556396,
        -0.9072713255882263,
        -0.6183444261550903,
        0.2492101639509201,
        0.30828291177749634,
        0.484958678483963,
        -0.0934031680226326,
        0.04830041527748108,
        0.38354453444480896,
        1.2520239353179932,
        -0.2768252491950989,
        1.2195020914077759,
        0.9199044704437256,
        0.6297537088394165,
        -0.26001760363578796,
        -0.06797393411397934,
        0.15240754187107086,
        -0.1648259162902832,
        0.13153144717216492,
        -0.00444209948182106,
        -0.22405892610549927,
        0.44466158747673035,
        -0.2002941220998764,
        0.8547253608703613,
        -0.538314938545227,
        0.09053679555654526,
        0.3487159013748169,
        -0.8163697123527527,
        -0.78739333152771,
        0.8997126221656799,
        0.7122155427932739,
        -1.0946863889694214,
        -0.8500771522521973,
        -0.10547694563865662,
        -1.0186347961425781,
        0.46041786670684814,
        1.4483509063720703,
        -0.08522850275039673,
        0.07094091922044754,
        -0.6250513792037964,
        0.15095287561416626,
        -0.20651771128177643,
        -0.9498836994171143,
        0.755817711353302,
        -0.8259238600730896,
        0.04729749262332916,
        -0.9738371968269348,
        -0.4798695147037506,
        -1.0733362436294556,
        -0.04936966300010681,
        0.11281718313694,
        0.6369627714157104,
        0.5500438809394836,
        -0.5253809690475464,
        -0.03933371603488922,
        -0.726639449596405,
        -0.4729374647140503,
        0.6250970959663391,
        0.35265836119651794,
        -0.8351016640663147,
        0.5153428912162781,
        0.484529048204422,
        -0.6393654346466064,
        -0.45981210470199585,
        -0.6020746827125549,
        0.6020305156707764,
        0.1014949232339859,
        1.3058781623840332,
        2.919060707092285,
        0.385562002658844,
        0.7458072304725647,
        -0.7732770442962646,
        0.8178797364234924,
        -0.9829421043395996,
        -1.3561407327651978,
        -0.7724470496177673,
        -1.0516159534454346,
        -0.008720380254089832,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0
      ],
      "timestamp": 1735589460059,
      "accessCount": 1,
      "concepts": [
        "speech recognition",
        "natural language processing (nlp)",
        "computer vision",
        "robotics",
        "machine learning (ml)",
        "deep learning",
        "reinforcement learning (rl)",
        "autonomous vehicles",
        "financial services",
        "healthcare"
      ],
      "decayFactor": 1
    }
  ],
  "longTermMemory": []
}

================
File: package.json
================
{
  "name": "semem",
  "version": "1.0.0",
  "description": "Semantic Memory",
  "type": "module",
  "main": "index.js",
  "scripts": {
    "test": "jasmine --config=jasmine.json --reporter=spec/helpers/reporter.js",
    "cov": "nyc -a --include=src --reporter=lcov npm run test",
    "docs": "jsdoc -c jsdoc.json",
    "rp": "repomix -c repomix.config.json . "
  },
  "repository": {
    "type": "git",
    "url": "git+https://github.com/danja/semem.git"
  },
  "keywords": [
    "semantic",
    "memory",
    "llm",
    "rdf",
    "sparql"
  ],
  "author": "Danny Ayers",
  "license": "MIT",
  "bugs": {
    "url": "https://github.com/danja/semem/issues"
  },
  "homepage": "https://github.com/danja/semem#readme",
  "devDependencies": {
    "jasmine": "^5.5.0",
    "jasmine-spec-reporter": "^7.0.0",
    "jsdoc": "^4.0.4"
  },
  "dependencies": {
    "@langchain/core": "^0.3.19",
    "@langchain/openai": "^0.3.14",
    "faiss-node": "^0.5.1",
    "graphology": "^0.25.4",
    "ml-kmeans": "^6.0.0",
    "ollama": "^0.5.10"
  }
}

================
File: repomix.config.json
================
{
    "output": {
        "filePath": "./repomix-semem.txt",
        "headerText": "Semem repo",
        "removeComments": true
    },
    "include": [
        "**/*"
    ],
    "ignore": {
        "useDefaultPatterns": false,
        "customPatterns": [
            "docs",
            "docs/jsdoc",
            ".nyc_output",
            ".env",
            "**/_*",
            "node_modules",
            "*.log",
            "**/*repomix*.txt",
            "**/*.html",
            "**/data/*",
            "**/*copy.js",
            "**/conversations.json"
        ]
    }
}
