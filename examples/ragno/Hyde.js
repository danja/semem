/**
 * Hyde.js - HyDE (Hypothetical Document Embeddings) Algorithm Demo
 * 
 * This example demonstrates the HyDE algorithm implementation for Ragno knowledge graphs.
 * HyDE enhances retrieval by generating hypothetical answers using LLMs, then using these
 * synthetic documents to improve semantic search and knowledge graph augmentation.
 * 
 * Key Features Demonstrated:
 * 1. **Hypothesis Generation**: Using LLM to create hypothetical answers for queries
 * 2. **RDF Integration**: Adding hypotheses to knowledge graph with ragno:maybe property
 * 3. **Entity Extraction**: Extracting entities from generated hypothetical content
 * 4. **Graph Augmentation**: Creating relationships between queries, hypotheses, and entities
 * 5. **Uncertainty Modeling**: Using ragno:maybe to mark hypothetical vs. factual content
 * 
 * Use Cases:
 * - Improving search with vague or poorly phrased queries
 * - Augmenting sparse knowledge graphs with hypothetical content
 * - Creating training data for retrieval systems
 * - Exploring potential knowledge graph connections
 * 
 * Prerequisites:
 * - Ollama running with qwen2:1.5b model for text generation
 * - nomic-embed-text model for embeddings (optional for full pipeline)
 * - Ragno infrastructure (entities, semantic units, RDF-Ext)
 */

import logger from 'loglevel'
import rdf from 'rdf-ext'
import Config from '../../src/Config.js'
import MemoryManager from '../../src/MemoryManager.js'
import InMemoryStore from '../../src/stores/InMemoryStore.js'
import EmbeddingConnectorFactory from '../../src/connectors/EmbeddingConnectorFactory.js'
import { ClientFactory } from 'hyperdata-clients'
import Hyde from '../../src/ragno/algorithms/Hyde.js'
import NamespaceManager from '../../src/ragno/core/NamespaceManager.js'
// Note: RDF export functionality would use existing utilities

// Configure logging
logger.setLevel('info')

/**
 * Demo configuration
 */
const CONFIG = {
    ollama: {
        baseURL: 'http://localhost:11434',
        model: 'qwen2:1.5b',
        embeddingModel: 'nomic-embed-text'
    },
    hyde: {
        hypothesesPerQuery: 3,
        temperature: 0.7,
        maxTokens: 400,
        extractEntities: true,
        maxEntitiesPerHypothesis: 8,
        confidenceThreshold: 0.4
    },
    demo: {
        queries: [
            "What are the benefits of renewable energy?",
            //     "How does machine learning work?",
            "What is the impact of climate change on biodiversity?"
            //   "How can artificial intelligence improve healthcare?",
            // "What are the challenges of quantum computing?"
        ],
        showRDFOutput: true,
        exportToTurtle: true
    }
}

/**
 * Main demo function
 */
async function runHydeDemo() {
    logger.info('ðŸ”¬ Starting HyDE Algorithm Demo')
    logger.info('â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”')

    let memoryManager = null

    try {
        // Step 1: Initialize components
        logger.info('ðŸ“‹ Step 1: Initializing components...')

        // Initialize config system
        const config = new Config('config/config.json')
        await config.init()

        // Get LLM providers from config
        const llmProviders = config.get('llmProviders')
        if (!llmProviders || llmProviders.length === 0) {
            throw new Error('No LLM providers configured. Please check your config.')
        }

        // Find the first chat provider
        const chatProviderConfig = llmProviders.find(p => p.capabilities?.includes('chat'))
        if (!chatProviderConfig) {
            throw new Error('No chat provider found in config')
        }

        logger.info(`Using chat provider: ${chatProviderConfig.type} with model: ${chatProviderConfig.chatModel}`)

        // Create chat provider as configured
        const chatProvider = await ClientFactory.createClient(chatProviderConfig.type, {
            model: chatProviderConfig.chatModel,
            baseUrl: chatProviderConfig.baseUrl,
            apiKey: chatProviderConfig.apiKey
        })

        // Create embedding provider using EmbeddingConnectorFactory (compatible with MemoryManager)
        const embeddingProvider = config.get('embeddingProvider') || 'ollama'
        const embeddingModel = config.get('embeddingModel') || 'nomic-embed-text'

        let embeddingProviderConfig = {}
        if (embeddingProvider === 'nomic') {
            embeddingProviderConfig = {
                provider: 'nomic',
                apiKey: process.env.NOMIC_API_KEY,
                model: embeddingModel
            }
        } else if (embeddingProvider === 'ollama') {
            embeddingProviderConfig = {
                provider: 'ollama',
                baseUrl: 'http://localhost:11434',
                model: embeddingModel
            }
        }

        const embeddingConnector = EmbeddingConnectorFactory.createConnector(embeddingProviderConfig)

        logger.info(`Using embedding provider: ${embeddingProvider} with model: ${embeddingModel}`)

        // Create memory manager with providers from config
        const storage = new InMemoryStore()
        memoryManager = new MemoryManager({
            llmProvider: chatProvider,
            embeddingProvider: embeddingConnector,
            chatModel: chatProviderConfig.chatModel,
            embeddingModel: embeddingModel,
            storage
        })

        // Get LLM handler from memory manager
        const llmHandler = memoryManager.llmHandler

        const hydeOptions = {
            ...CONFIG.hyde,
            model: chatProviderConfig.chatModel // Get model from config
        }
        const hyde = new Hyde(hydeOptions)
        const namespaces = new NamespaceManager()
        const dataset = rdf.dataset()

        logger.info('âœ… Components initialized successfully')

        // Step 2: Generate hypotheses for each query
        logger.info('\\nðŸ§  Step 2: Generating hypotheses...')

        const allResults = []

        for (let i = 0; i < CONFIG.demo.queries.length; i++) {
            const query = CONFIG.demo.queries[i]
            logger.info(`\\nðŸ“ Processing Query ${i + 1}: "${query}"`)

            try {
                const results = await hyde.generateHypotheses(
                    query,
                    llmHandler,
                    dataset,
                    hydeOptions
                )

                allResults.push({ query, results })

                // Display results for this query
                displayQueryResults(query, results, i + 1)

            } catch (error) {
                logger.error(`âŒ Failed to process query "${query}": ${error.message}`)
            }
        }

        // Step 3: Analyze the complete dataset
        logger.info('\\nðŸ“Š Step 3: Analyzing complete dataset...')
        analyzeDataset(dataset, namespaces)

        // Step 4: Query hypothetical content
        logger.info('\\nðŸ” Step 4: Querying hypothetical content...')
        demonstrateHypotheticalQueries(hyde, dataset)

        // Step 5: Export results if requested
        if (CONFIG.demo.exportToTurtle) {
            logger.info('\\nðŸ’¾ Step 5: Exporting to RDF formats...')
            await exportResults(dataset, namespaces)
        }

        // Step 6: Display statistics
        logger.info('\\nðŸ“ˆ Step 6: Algorithm statistics...')
        displayStatistics(hyde, allResults)

        logger.info('\\nðŸŽ‰ HyDE Demo completed successfully!')

    } catch (error) {
        logger.error('ðŸ’¥ Demo failed:', error)
        throw error
    } finally {
        if (memoryManager) {
            logger.info('ðŸ§¹ Cleaning up memory manager...')
            await memoryManager.dispose()
        }
    }
}

/**
 * Display results for a single query
 */
function displayQueryResults(query, results, queryNumber) {
    logger.info(`   ðŸ“Š Query ${queryNumber} Results:`)
    logger.info(`   â€¢ Generated ${results.hypotheses.length} hypotheses`)
    logger.info(`   â€¢ Extracted ${results.entities.length} entities`)
    logger.info(`   â€¢ Created ${results.relationships.length} relationships`)
    logger.info(`   â€¢ Added ${results.rdfTriples} RDF triples`)
    logger.info(`   â€¢ Processing time: ${results.processingTime}ms`)

    if (results.hypotheses.length > 0) {
        logger.info(`   \\n   ðŸ’­ Sample Hypothesis:`)
        const sample = results.hypotheses[0]
        const content = sample.getText() || sample.getContent() || ''
        const preview = content.substring(0, 150) + (content.length > 150 ? '...' : '')
        logger.info(`      "${preview}"`)
        const confidence = sample.metadata?.confidence || 'N/A'
        logger.info(`      Confidence: ${typeof confidence === 'number' ? confidence.toFixed(3) : confidence}`)
    }

    if (results.entities.length > 0) {
        logger.info(`   \\n   ðŸ·ï¸  Extracted Entities:`)
        results.entities.slice(0, 5).forEach(entity => {
            const confidence = entity.metadata?.confidence
            const confidenceStr = typeof confidence === 'number' ? confidence.toFixed(3) : 'N/A'
            logger.info(`      â€¢ ${entity.getPrefLabel()} (confidence: ${confidenceStr})`)
        })
        if (results.entities.length > 5) {
            logger.info(`      ... and ${results.entities.length - 5} more`)
        }
    }
}

/**
 * Analyze the complete RDF dataset
 */
function analyzeDataset(dataset, namespaces) {
    const stats = {
        totalTriples: dataset.size,
        hypotheticalTriples: 0,
        entities: new Set(),
        hypotheticalEntities: new Set(),
        semanticUnits: new Set(),
        relationships: new Set()
    }

    // Count different types of content
    for (const quad of dataset) {
        const subject = quad.subject.value
        const predicate = quad.predicate.value
        const object = quad.object.value

        // Check for hypothetical markers
        if (predicate === namespaces.ragno('maybe').value && object === 'true') {
            stats.hypotheticalTriples++
        }

        // Categorize subjects
        if (predicate === namespaces.rdf('type').value) {
            if (object === namespaces.ragno('Entity').value) {
                stats.entities.add(subject)
            } else if (object === namespaces.ragno('SemanticUnit').value) {
                stats.semanticUnits.add(subject)
            } else if (object === namespaces.ragno('Relationship').value) {
                stats.relationships.add(subject)
            }
        }

        // Check if entity is hypothetical
        if (stats.entities.has(subject) && predicate === namespaces.ragno('maybe').value && object === 'true') {
            stats.hypotheticalEntities.add(subject)
        }
    }

    logger.info(`   ðŸ“Š Dataset Analysis:`)
    logger.info(`   â€¢ Total RDF triples: ${stats.totalTriples}`)
    logger.info(`   â€¢ Hypothetical triples: ${stats.hypotheticalTriples}`)
    logger.info(`   â€¢ Total entities: ${stats.entities.size}`)
    logger.info(`   â€¢ Hypothetical entities: ${stats.hypotheticalEntities.size}`)
    logger.info(`   â€¢ Semantic units: ${stats.semanticUnits.size}`)
    logger.info(`   â€¢ Relationships: ${stats.relationships.size}`)

    const hypotheticalRatio = stats.totalTriples > 0 ? (stats.hypotheticalTriples / stats.totalTriples * 100).toFixed(1) : 0
    logger.info(`   â€¢ Hypothetical content ratio: ${hypotheticalRatio}%`)
}

/**
 * Demonstrate querying hypothetical content
 */
function demonstrateHypotheticalQueries(hyde, dataset) {
    logger.info(`   ðŸ” Querying hypothetical content...`)

    // Query all hypothetical content
    const allHypothetical = hyde.queryHypotheticalContent(dataset)
    logger.info(`   â€¢ Found ${allHypothetical.length} hypothetical items`)

    // Query by confidence (if available)
    const confidentHypothetical = hyde.queryHypotheticalContent(dataset, {
        'http://purl.org/stuff/ragno/confidence': '0.6' // Find high-confidence hypotheses
    })
    logger.info(`   â€¢ High-confidence hypotheses: ${confidentHypothetical.length}`)

    // Display sample hypothetical item
    if (allHypothetical.length > 0) {
        const sample = allHypothetical[0]
        logger.info(`   \\n   ðŸ’­ Sample Hypothetical Item:`)
        logger.info(`      URI: ${sample.uri}`)
        logger.info(`      Properties: ${Object.keys(sample.properties).length}`)

        // Show some properties
        const interestingProps = ['http://purl.org/stuff/ragno/confidence', 'http://www.w3.org/2000/01/rdf-schema#label']
        interestingProps.forEach(prop => {
            if (sample.properties[prop]) {
                const value = sample.properties[prop][0]
                const shortProp = prop.split('/').pop()
                logger.info(`      ${shortProp}: ${value}`)
            }
        })
    }
}

/**
 * Export results to various RDF formats
 */
async function exportResults(dataset, namespaces) {
    try {
        // Export basic dataset statistics
        logger.info(`   ðŸ’¾ Exporting ${dataset.size} triples...`)

        // Create a simple export using the existing SPARQL export function
        const exportData = {
            dataset: dataset,
            timestamp: new Date(),
            metadata: {
                generator: 'Hyde Algorithm Demo',
                tripleCount: dataset.size,
                namespaces: Object.fromEntries(namespaces.prefixes)
            }
        }

        logger.info(`   âœ… Export data prepared`)
        logger.info(`   ðŸ“„ Dataset contains ${dataset.size} triples`)
        logger.info(`   ðŸ·ï¸  Using ${namespaces.prefixes.size} namespace prefixes`)

        // Note: Full RDF serialization would require additional dependencies
        // For demo purposes, we're showing the export structure

    } catch (error) {
        logger.warn(`   âš ï¸  Export warning: ${error.message}`)
    }
}

/**
 * Display comprehensive statistics
 */
function displayStatistics(hyde, allResults) {
    const stats = hyde.getStatistics()

    logger.info(`   ðŸ“ˆ HyDE Algorithm Statistics:`)
    logger.info(`   â€¢ Total queries processed: ${stats.totalQueries}`)
    logger.info(`   â€¢ Total hypotheses generated: ${stats.totalHypotheses}`)
    logger.info(`   â€¢ Total entities extracted: ${stats.totalEntitiesExtracted}`)
    logger.info(`   â€¢ Total execution time: ${stats.totalExecutionTime}ms`)
    logger.info(`   â€¢ Average time per query: ${stats.averageExecutionTime.toFixed(2)}ms`)
    logger.info(`   â€¢ Average hypotheses per query: ${stats.averageHypothesesPerQuery.toFixed(2)}`)
    logger.info(`   â€¢ Average entities per query: ${stats.averageEntitiesPerQuery.toFixed(2)}`)

    // Calculate additional metrics from results
    const totalConfidence = allResults.reduce((sum, result) => {
        return sum + result.results.hypotheses.reduce((hSum, h) => {
            const confidence = h.metadata?.confidence || 0
            return hSum + (typeof confidence === 'number' ? confidence : 0)
        }, 0)
    }, 0)

    const totalHypotheses = allResults.reduce((sum, result) => sum + result.results.hypotheses.length, 0)
    const avgConfidence = totalHypotheses > 0 ? (totalConfidence / totalHypotheses).toFixed(3) : 0

    logger.info(`   â€¢ Average hypothesis confidence: ${avgConfidence}`)
    logger.info(`   â€¢ Last run: ${stats.lastRun ? stats.lastRun.toISOString() : 'Never'}`)
}

/**
 * Error handling wrapper
 */
async function main() {
    try {
        await runHydeDemo()
    } catch (error) {
        logger.error('ðŸ’¥ HyDE Demo failed with error:', error)
        process.exit(1)
    }
}

// Run the demo
if (import.meta.url === `file://${process.argv[1]}`) {
    main()
}

export { runHydeDemo, CONFIG }