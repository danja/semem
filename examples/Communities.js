/**
 * Community Detection Demo
 * 
 * This demo showcases the Leiden algorithm for community detection in semantic
 * knowledge graphs. It demonstrates:
 * 
 * 1. Creating a larger social network knowledge graph with multiple domains
 * 2. Running Leiden community detection with different parameters
 * 3. Analyzing community structure and quality metrics
 * 4. Comparing different resolution parameters
 * 5. Exporting communities to RDF format
 * 6. Visualizing community statistics and modularity
 * 
 * The scenario simulates a multi-domain knowledge graph including academic
 * collaborations, technology companies, research projects, and funding bodies.
 */

import CommunityDetection from '../src/ragno/algorithms/CommunityDetection.js'
import rdf from 'rdf-ext'
import { logger } from '../src/Utils.js'

console.log('='.repeat(60))
console.log('üåê Community Detection Demo - Multi-Domain Knowledge Graph')
console.log('='.repeat(60))

/**
 * Create a larger, more complex knowledge graph for community detection
 * This simulates a multi-domain research and industry ecosystem
 */
function createMultiDomainKnowledgeGraph() {
    console.log('\nüìä Step 1: Creating multi-domain knowledge graph...')
    
    const graph = {
        nodes: new Map(),
        edges: new Map(),
        adjacency: new Map()
    }
    
    // Multi-domain entities covering academia, industry, research areas, and funding
    const entities = [
        // Academic Cluster 1: Deep Learning Researchers
        { uri: 'http://example.org/person/geoffrey-hinton', type: 'ragno:Entity', label: 'Geoffrey Hinton', domain: 'academia', cluster: 'deep-learning' },
        { uri: 'http://example.org/person/yann-lecun', type: 'ragno:Entity', label: 'Yann LeCun', domain: 'academia', cluster: 'deep-learning' },
        { uri: 'http://example.org/person/yoshua-bengio', type: 'ragno:Entity', label: 'Yoshua Bengio', domain: 'academia', cluster: 'deep-learning' },
        { uri: 'http://example.org/person/ian-goodfellow', type: 'ragno:Entity', label: 'Ian Goodfellow', domain: 'academia', cluster: 'deep-learning' },
        
        // Academic Cluster 2: NLP Researchers
        { uri: 'http://example.org/person/chris-manning', type: 'ragno:Entity', label: 'Christopher Manning', domain: 'academia', cluster: 'nlp' },
        { uri: 'http://example.org/person/dan-jurafsky', type: 'ragno:Entity', label: 'Dan Jurafsky', domain: 'academia', cluster: 'nlp' },
        { uri: 'http://example.org/person/emily-bender', type: 'ragno:Entity', label: 'Emily Bender', domain: 'academia', cluster: 'nlp' },
        { uri: 'http://example.org/person/noah-smith', type: 'ragno:Entity', label: 'Noah Smith', domain: 'academia', cluster: 'nlp' },
        
        // Academic Cluster 3: Robotics Researchers
        { uri: 'http://example.org/person/rodney-brooks', type: 'ragno:Entity', label: 'Rodney Brooks', domain: 'academia', cluster: 'robotics' },
        { uri: 'http://example.org/person/sebastian-thrun', type: 'ragno:Entity', label: 'Sebastian Thrun', domain: 'academia', cluster: 'robotics' },
        { uri: 'http://example.org/person/pieter-abbeel', type: 'ragno:Entity', label: 'Pieter Abbeel', domain: 'academia', cluster: 'robotics' },
        
        // Industry Cluster 1: Tech Giants
        { uri: 'http://example.org/org/google', type: 'ragno:Entity', label: 'Google', domain: 'industry', cluster: 'tech-giants' },
        { uri: 'http://example.org/org/microsoft', type: 'ragno:Entity', label: 'Microsoft', domain: 'industry', cluster: 'tech-giants' },
        { uri: 'http://example.org/org/meta', type: 'ragno:Entity', label: 'Meta', domain: 'industry', cluster: 'tech-giants' },
        { uri: 'http://example.org/org/amazon', type: 'ragno:Entity', label: 'Amazon', domain: 'industry', cluster: 'tech-giants' },
        
        // Industry Cluster 2: AI Startups
        { uri: 'http://example.org/org/openai', type: 'ragno:Entity', label: 'OpenAI', domain: 'industry', cluster: 'ai-startups' },
        { uri: 'http://example.org/org/anthropic', type: 'ragno:Entity', label: 'Anthropic', domain: 'industry', cluster: 'ai-startups' },
        { uri: 'http://example.org/org/cohere', type: 'ragno:Entity', label: 'Cohere', domain: 'industry', cluster: 'ai-startups' },
        { uri: 'http://example.org/org/huggingface', type: 'ragno:Entity', label: 'Hugging Face', domain: 'industry', cluster: 'ai-startups' },
        
        // Universities forming their own cluster
        { uri: 'http://example.org/org/stanford', type: 'ragno:Entity', label: 'Stanford University', domain: 'academia', cluster: 'universities' },
        { uri: 'http://example.org/org/mit', type: 'ragno:Entity', label: 'MIT', domain: 'academia', cluster: 'universities' },
        { uri: 'http://example.org/org/toronto', type: 'ragno:Entity', label: 'University of Toronto', domain: 'academia', cluster: 'universities' },
        { uri: 'http://example.org/org/montreal', type: 'ragno:Entity', label: 'University of Montreal', domain: 'academia', cluster: 'universities' },
        { uri: 'http://example.org/org/washington', type: 'ragno:Entity', label: 'University of Washington', domain: 'academia', cluster: 'universities' },
        
        // Funding Bodies cluster
        { uri: 'http://example.org/org/nsf', type: 'ragno:Entity', label: 'National Science Foundation', domain: 'funding', cluster: 'funding' },
        { uri: 'http://example.org/org/nih', type: 'ragno:Entity', label: 'National Institutes of Health', domain: 'funding', cluster: 'funding' },
        { uri: 'http://example.org/org/darpa', type: 'ragno:Entity', label: 'DARPA', domain: 'funding', cluster: 'funding' },
        
        // Research Projects that bridge communities
        { uri: 'http://example.org/project/transformer', type: 'ragno:Unit', label: 'Transformer Architecture', domain: 'research', cluster: 'bridge' },
        { uri: 'http://example.org/project/gpt', type: 'ragno:Unit', label: 'GPT Models', domain: 'research', cluster: 'bridge' },
        { uri: 'http://example.org/project/bert', type: 'ragno:Unit', label: 'BERT Models', domain: 'research', cluster: 'bridge' },
        { uri: 'http://example.org/project/alphago', type: 'ragno:Unit', label: 'AlphaGo Project', domain: 'research', cluster: 'bridge' }
    ]
    
    console.log(`   Adding ${entities.length} entities across multiple domains...`)
    
    // Add nodes to graph
    for (const entity of entities) {
        graph.nodes.set(entity.uri, {
            type: entity.type,
            label: entity.label,
            domain: entity.domain,
            cluster: entity.cluster
        })
        graph.adjacency.set(entity.uri, new Set())
    }
    
    // Define relationships that will form clear communities
    const relationships = [
        // Deep Learning Research Community (strong internal connections)
        { from: 'http://example.org/person/geoffrey-hinton', to: 'http://example.org/person/yann-lecun', weight: 0.9, type: 'collaborates' },
        { from: 'http://example.org/person/geoffrey-hinton', to: 'http://example.org/person/yoshua-bengio', weight: 0.9, type: 'collaborates' },
        { from: 'http://example.org/person/yoshua-bengio', to: 'http://example.org/person/ian-goodfellow', weight: 0.8, type: 'mentors' },
        { from: 'http://example.org/person/yann-lecun', to: 'http://example.org/person/ian-goodfellow', weight: 0.7, type: 'collaborates' },
        
        // NLP Research Community (strong internal connections)
        { from: 'http://example.org/person/chris-manning', to: 'http://example.org/person/dan-jurafsky', weight: 0.9, type: 'collaborates' },
        { from: 'http://example.org/person/chris-manning', to: 'http://example.org/person/noah-smith', weight: 0.8, type: 'collaborates' },
        { from: 'http://example.org/person/emily-bender', to: 'http://example.org/person/noah-smith', weight: 0.8, type: 'collaborates' },
        { from: 'http://example.org/person/dan-jurafsky', to: 'http://example.org/person/emily-bender', weight: 0.7, type: 'collaborates' },
        
        // Robotics Community (strong internal connections)
        { from: 'http://example.org/person/rodney-brooks', to: 'http://example.org/person/sebastian-thrun', weight: 0.8, type: 'collaborates' },
        { from: 'http://example.org/person/sebastian-thrun', to: 'http://example.org/person/pieter-abbeel', weight: 0.9, type: 'mentors' },
        { from: 'http://example.org/person/rodney-brooks', to: 'http://example.org/person/pieter-abbeel', weight: 0.7, type: 'collaborates' },
        
        // Tech Giants Community (business relationships)
        { from: 'http://example.org/org/google', to: 'http://example.org/org/microsoft', weight: 0.6, type: 'competes' },
        { from: 'http://example.org/org/google', to: 'http://example.org/org/meta', weight: 0.7, type: 'competes' },
        { from: 'http://example.org/org/microsoft', to: 'http://example.org/org/amazon', weight: 0.6, type: 'competes' },
        { from: 'http://example.org/org/meta', to: 'http://example.org/org/amazon', weight: 0.5, type: 'competes' },
        
        // AI Startups Community
        { from: 'http://example.org/org/openai', to: 'http://example.org/org/anthropic', weight: 0.8, type: 'competes' },
        { from: 'http://example.org/org/anthropic', to: 'http://example.org/org/cohere', weight: 0.7, type: 'collaborates' },
        { from: 'http://example.org/org/cohere', to: 'http://example.org/org/huggingface', weight: 0.9, type: 'collaborates' },
        { from: 'http://example.org/org/openai', to: 'http://example.org/org/huggingface', weight: 0.6, type: 'collaborates' },
        
        // University cluster (institutional relationships)
        { from: 'http://example.org/org/stanford', to: 'http://example.org/org/mit', weight: 0.8, type: 'collaborates' },
        { from: 'http://example.org/org/toronto', to: 'http://example.org/org/montreal', weight: 0.9, type: 'collaborates' },
        { from: 'http://example.org/org/stanford', to: 'http://example.org/org/washington', weight: 0.7, type: 'collaborates' },
        { from: 'http://example.org/org/mit', to: 'http://example.org/org/toronto', weight: 0.6, type: 'collaborates' },
        
        // Funding cluster
        { from: 'http://example.org/org/nsf', to: 'http://example.org/org/nih', weight: 0.7, type: 'coordinates' },
        { from: 'http://example.org/org/nsf', to: 'http://example.org/org/darpa', weight: 0.8, type: 'coordinates' },
        { from: 'http://example.org/org/nih', to: 'http://example.org/org/darpa', weight: 0.6, type: 'coordinates' },
        
        // Cross-community bridges (weaker connections between clusters)
        // Academics to Universities (affiliations)
        { from: 'http://example.org/person/geoffrey-hinton', to: 'http://example.org/org/toronto', weight: 0.9, type: 'affiliated' },
        { from: 'http://example.org/person/yann-lecun', to: 'http://example.org/org/meta', weight: 0.8, type: 'employed' },
        { from: 'http://example.org/person/chris-manning', to: 'http://example.org/org/stanford', weight: 0.9, type: 'affiliated' },
        { from: 'http://example.org/person/noah-smith', to: 'http://example.org/org/washington', weight: 0.9, type: 'affiliated' },
        { from: 'http://example.org/person/sebastian-thrun', to: 'http://example.org/org/stanford', weight: 0.8, type: 'affiliated' },
        
        // Industry partnerships (weaker cross-cluster)
        { from: 'http://example.org/org/openai', to: 'http://example.org/org/microsoft', weight: 0.7, type: 'partnership' },
        { from: 'http://example.org/org/google', to: 'http://example.org/org/stanford', weight: 0.6, type: 'funds' },
        { from: 'http://example.org/org/meta', to: 'http://example.org/org/mit', weight: 0.5, type: 'funds' },
        
        // Funding relationships (cross-cluster bridges)
        { from: 'http://example.org/org/nsf', to: 'http://example.org/org/stanford', weight: 0.7, type: 'funds' },
        { from: 'http://example.org/org/darpa', to: 'http://example.org/org/mit', weight: 0.8, type: 'funds' },
        { from: 'http://example.org/org/nsf', to: 'http://example.org/person/chris-manning', weight: 0.6, type: 'funds' },
        
        // Research projects bridge multiple communities
        { from: 'http://example.org/project/transformer', to: 'http://example.org/person/chris-manning', weight: 0.8, type: 'involves' },
        { from: 'http://example.org/project/transformer', to: 'http://example.org/org/google', weight: 0.9, type: 'developed_at' },
        { from: 'http://example.org/project/gpt', to: 'http://example.org/org/openai', weight: 0.9, type: 'developed_at' },
        { from: 'http://example.org/project/bert', to: 'http://example.org/org/google', weight: 0.9, type: 'developed_at' },
        { from: 'http://example.org/project/alphago', to: 'http://example.org/org/google', weight: 0.8, type: 'developed_at' },
        
        // Some weak inter-research-area connections
        { from: 'http://example.org/person/geoffrey-hinton', to: 'http://example.org/person/chris-manning', weight: 0.4, type: 'knows' },
        { from: 'http://example.org/person/sebastian-thrun', to: 'http://example.org/person/yann-lecun', weight: 0.3, type: 'knows' },
        { from: 'http://example.org/person/pieter-abbeel', to: 'http://example.org/person/yoshua-bengio', weight: 0.4, type: 'knows' }
    ]
    
    console.log(`   Adding ${relationships.length} relationships with varying strengths...`)
    
    // Add edges and adjacency
    for (const rel of relationships) {
        const edgeKey = `${rel.from}->${rel.to}`
        graph.edges.set(edgeKey, {
            weight: rel.weight,
            type: rel.type,
            source: rel.from,
            target: rel.to
        })
        
        // Update adjacency lists (undirected graph)
        if (!graph.adjacency.has(rel.from)) {
            graph.adjacency.set(rel.from, new Set())
        }
        if (!graph.adjacency.has(rel.to)) {
            graph.adjacency.set(rel.to, new Set())
        }
        
        graph.adjacency.get(rel.from).add(rel.to)
        graph.adjacency.get(rel.to).add(rel.from)
    }
    
    console.log(`   ‚úÖ Multi-domain graph created: ${graph.nodes.size} nodes, ${graph.edges.size} edges`)
    
    // Log domain and expected cluster statistics
    const domains = new Map()
    const expectedClusters = new Map()
    
    for (const [uri, node] of graph.nodes) {
        domains.set(node.domain, (domains.get(node.domain) || 0) + 1)
        expectedClusters.set(node.cluster, (expectedClusters.get(node.cluster) || 0) + 1)
    }
    
    console.log('   üìä Domain distribution:')
    for (const [domain, count] of domains) {
        console.log(`      ${domain}: ${count} entities`)
    }
    
    console.log('   üéØ Expected communities:')
    for (const [cluster, count] of expectedClusters) {
        console.log(`      ${cluster}: ${count} entities`)
    }
    
    return graph
}

/**
 * Demonstrate basic Leiden community detection
 */
async function demonstrateBasicCommunityDetection(graph) {
    console.log('\nüîç Step 2: Running basic Leiden community detection...')
    
    const detector = new CommunityDetection({
        resolution: 1.0,           // Standard modularity resolution
        minCommunitySize: 2,       // Minimum 2 nodes per community
        maxIterations: 50,         // Maximum iterations
        convergenceThreshold: 1e-6,
        randomSeed: 42,           // For reproducible results
        logProgress: true         // Enable progress logging
    })
    
    console.log('   ‚öôÔ∏è  Algorithm parameters:')
    console.log('      ‚Ä¢ Resolution: 1.0 (standard modularity)')
    console.log('      ‚Ä¢ Min community size: 2')
    console.log('      ‚Ä¢ Max iterations: 50')
    console.log('      ‚Ä¢ Random seed: 42 (reproducible)')
    
    const startTime = Date.now()
    const results = detector.detectCommunities(graph)
    const duration = Date.now() - startTime
    
    console.log(`   ‚è±Ô∏è  Completed in ${duration}ms`)
    console.log(`   üìä Detected ${results.communities.length} communities`)
    console.log(`   üìà Final modularity: ${results.modularity.toFixed(4)}`)
    console.log(`   üîÑ Iterations used: ${results.iterations}`)
    
    // Display community details
    console.log('\n   üèòÔ∏è  Detected communities:')
    
    results.communities.forEach((community, index) => {
        const nodes = Array.from(community)
        const size = nodes.length
        
        console.log(`      Community ${index + 1} (${size} nodes):`)
        
        // Group by domain and show sample members
        const domains = new Map()
        for (const nodeUri of nodes) {
            const node = graph.nodes.get(nodeUri)
            if (node) {
                const domain = node.domain
                if (!domains.has(domain)) {
                    domains.set(domain, [])
                }
                domains.get(domain).push(node.label)
            }
        }
        
        for (const [domain, labels] of domains) {
            const sampleMembers = labels.slice(0, 3).join(', ')
            const remaining = labels.length > 3 ? ` (+${labels.length - 3} more)` : ''
            console.log(`        ${domain}: ${sampleMembers}${remaining}`)
        }
    })
    
    // Display community statistics
    console.log('\n   üìä Community statistics:')
    const stats = results.statistics
    console.log(`      ‚Ä¢ Average size: ${stats.avgSize.toFixed(1)} nodes`)
    console.log(`      ‚Ä¢ Largest community: ${stats.maxSize} nodes`)
    console.log(`      ‚Ä¢ Smallest community: ${stats.minSize} nodes`)
    console.log(`      ‚Ä¢ Internal edges: ${stats.totalInternalEdges}`)
    console.log(`      ‚Ä¢ External edges: ${stats.totalExternalEdges}`)
    console.log(`      ‚Ä¢ Internal ratio: ${(stats.internalRatio * 100).toFixed(1)}%`)
    
    return results
}

/**
 * Demonstrate different resolution parameters
 */
async function demonstrateResolutionComparison(graph) {
    console.log('\nüî¨ Step 3: Comparing different resolution parameters...')
    
    const resolutions = [0.5, 1.0, 1.5, 2.0]
    const results = []
    
    console.log('   üéöÔ∏è  Testing resolution parameters: 0.5, 1.0, 1.5, 2.0')
    console.log('      ‚Ä¢ Lower resolution ‚Üí Larger communities')
    console.log('      ‚Ä¢ Higher resolution ‚Üí Smaller communities')
    
    for (const resolution of resolutions) {
        console.log(`\n   üîç Resolution ${resolution}:`)
        
        const detector = new CommunityDetection({
            resolution: resolution,
            minCommunitySize: 2,
            maxIterations: 30,
            randomSeed: 42,
            logProgress: false
        })
        
        const startTime = Date.now()
        const result = detector.detectCommunities(graph)
        const duration = Date.now() - startTime
        
        console.log(`      ‚è±Ô∏è  ${duration}ms, ${result.iterations} iterations`)
        console.log(`      üèòÔ∏è  ${result.communities.length} communities detected`)
        console.log(`      üìà Modularity: ${result.modularity.toFixed(4)}`)
        console.log(`      üìä Avg size: ${result.statistics.avgSize.toFixed(1)} nodes`)
        console.log(`      üîó Internal ratio: ${(result.statistics.internalRatio * 100).toFixed(1)}%`)
        
        results.push({
            resolution,
            result,
            duration
        })
    }
    
    // Compare results
    console.log('\n   üìä Resolution comparison summary:')
    console.log('      Resolution  Communities  Modularity  Avg Size  Quality')
    console.log('      ' + '-'.repeat(55))
    
    for (const { resolution, result } of results) {
        const quality = result.statistics.internalRatio > 0.8 ? 'High' : 
                       result.statistics.internalRatio > 0.6 ? 'Medium' : 'Low'
        console.log(`      ${resolution.toFixed(1).padEnd(11)} ${String(result.communities.length).padEnd(12)} ${result.modularity.toFixed(4).padEnd(11)} ${result.statistics.avgSize.toFixed(1).padEnd(9)} ${quality}`)
    }
    
    // Find optimal resolution
    const optimal = results.reduce((best, current) => 
        current.result.modularity > best.result.modularity ? current : best
    )
    
    console.log(`\n   üéØ Optimal resolution: ${optimal.resolution} (modularity: ${optimal.result.modularity.toFixed(4)})`)
    
    return optimal.result
}

/**
 * Demonstrate community quality analysis
 */
async function demonstrateCommunityQuality(graph, communityResults) {
    console.log('\nüìè Step 4: Analyzing community quality and structure...')
    
    console.log('   üîç Detailed community analysis:')
    
    // Analyze each community in detail
    const qualityMetrics = []
    
    communityResults.communities.forEach((community, index) => {
        const nodes = Array.from(community)
        console.log(`\n   üèòÔ∏è  Community ${index + 1} (${nodes.length} nodes):`)
        
        // Calculate internal connectivity
        let internalEdges = 0
        let externalEdges = 0
        const communityNodeSet = new Set(nodes)
        
        for (const node of nodes) {
            const neighbors = graph.adjacency.get(node) || new Set()
            for (const neighbor of neighbors) {
                if (communityNodeSet.has(neighbor)) {
                    internalEdges++
                } else {
                    externalEdges++
                }
            }
        }
        
        internalEdges /= 2 // Each edge counted twice
        const connectivity = internalEdges / (internalEdges + externalEdges)
        
        // Analyze domain composition
        const domainComposition = new Map()
        const clusterComposition = new Map()
        
        for (const nodeUri of nodes) {
            const node = graph.nodes.get(nodeUri)
            if (node) {
                domainComposition.set(node.domain, (domainComposition.get(node.domain) || 0) + 1)
                clusterComposition.set(node.cluster, (clusterComposition.get(node.cluster) || 0) + 1)
            }
        }
        
        console.log(`      üìä Connectivity: ${(connectivity * 100).toFixed(1)}% internal`)
        console.log(`      üîó Edges: ${internalEdges} internal, ${externalEdges} external`)
        
        console.log('      üåê Domain composition:')
        for (const [domain, count] of domainComposition) {
            const percentage = (count / nodes.length * 100).toFixed(1)
            console.log(`         ${domain}: ${count} (${percentage}%)`)
        }
        
        console.log('      üéØ Expected cluster alignment:')
        const dominantCluster = Array.from(clusterComposition.entries())
            .reduce((max, current) => current[1] > max[1] ? current : max)
        
        const alignment = dominantCluster[1] / nodes.length
        console.log(`         Primary: ${dominantCluster[0]} (${(alignment * 100).toFixed(1)}% alignment)`)
        
        if (clusterComposition.size > 1) {
            console.log('         Mixed cluster composition:')
            for (const [cluster, count] of clusterComposition) {
                if (cluster !== dominantCluster[0]) {
                    console.log(`           ${cluster}: ${count} nodes`)
                }
            }
        }
        
        qualityMetrics.push({
            id: index + 1,
            size: nodes.length,
            connectivity,
            alignment,
            dominantCluster: dominantCluster[0],
            domains: domainComposition.size
        })
    })
    
    // Overall quality summary
    console.log('\n   üìà Overall quality summary:')
    const avgConnectivity = qualityMetrics.reduce((sum, m) => sum + m.connectivity, 0) / qualityMetrics.length
    const avgAlignment = qualityMetrics.reduce((sum, m) => sum + m.alignment, 0) / qualityMetrics.length
    const wellFormedCommunities = qualityMetrics.filter(m => m.connectivity > 0.7 && m.alignment > 0.6).length
    
    console.log(`      ‚Ä¢ Average internal connectivity: ${(avgConnectivity * 100).toFixed(1)}%`)
    console.log(`      ‚Ä¢ Average cluster alignment: ${(avgAlignment * 100).toFixed(1)}%`)
    console.log(`      ‚Ä¢ Well-formed communities: ${wellFormedCommunities}/${qualityMetrics.length}`)
    console.log(`      ‚Ä¢ Cross-domain communities: ${qualityMetrics.filter(m => m.domains > 1).length}`)
    
    return qualityMetrics
}

/**
 * Demonstrate iterative refinement
 */
async function demonstrateIterativeRefinement(graph) {
    console.log('\nüîÑ Step 5: Demonstrating iterative refinement process...')
    
    console.log('   üéØ Running multiple iterations with different random seeds...')
    
    const seeds = [42, 123, 456, 789, 999]
    const runs = []
    
    for (const seed of seeds) {
        console.log(`   üé≤ Seed ${seed}:`)
        
        const detector = new CommunityDetection({
            resolution: 1.0,
            minCommunitySize: 2,
            maxIterations: 30,
            randomSeed: seed,
            logProgress: false
        })
        
        const result = detector.detectCommunities(graph)
        runs.push({ seed, result })
        
        console.log(`      üèòÔ∏è  ${result.communities.length} communities, modularity: ${result.modularity.toFixed(4)}`)
    }
    
    // Find most stable solution
    console.log('\n   üìä Stability analysis:')
    const modularities = runs.map(r => r.result.modularity)
    const communityCounts = runs.map(r => r.result.communities.length)
    
    const avgModularity = modularities.reduce((a, b) => a + b, 0) / modularities.length
    const stdModularity = Math.sqrt(modularities.reduce((sum, x) => sum + Math.pow(x - avgModularity, 2), 0) / modularities.length)
    
    const avgCommunities = communityCounts.reduce((a, b) => a + b, 0) / communityCounts.length
    const stdCommunities = Math.sqrt(communityCounts.reduce((sum, x) => sum + Math.pow(x - avgCommunities, 2), 0) / communityCounts.length)
    
    console.log(`      ‚Ä¢ Modularity: ${avgModularity.toFixed(4)} ¬± ${stdModularity.toFixed(4)}`)
    console.log(`      ‚Ä¢ Community count: ${avgCommunities.toFixed(1)} ¬± ${stdCommunities.toFixed(1)}`)
    
    // Select best result
    const bestRun = runs.reduce((best, current) => 
        current.result.modularity > best.result.modularity ? current : best
    )
    
    console.log(`      ‚Ä¢ Best result: seed ${bestRun.seed} (modularity: ${bestRun.result.modularity.toFixed(4)})`)
    console.log(`      ‚Ä¢ Algorithm stability: ${stdModularity < 0.01 ? 'High' : stdModularity < 0.05 ? 'Medium' : 'Low'}`)
    
    return bestRun.result
}

/**
 * Demonstrate RDF export functionality
 */
async function demonstrateRDFExport(communityResults) {
    console.log('\nüì§ Step 6: Exporting community structure to RDF...')
    
    // Create RDF dataset for export
    const dataset = rdf.dataset()
    
    // Create detector instance for export
    const detector = new CommunityDetection()
    
    // Export communities to RDF
    detector.exportCommunitiesToRDF(communityResults, dataset)
    
    console.log(`   üìã Created RDF dataset with ${dataset.size} triples`)
    
    // Display sample RDF triples
    console.log('\n   üìÑ Sample RDF triples:')
    let tripleCount = 0
    for (const quad of dataset) {
        if (tripleCount >= 10) break
        
        const subject = quad.subject.value.split('/').pop() || quad.subject.value
        const predicate = quad.predicate.value.split('/').pop() || quad.predicate.value
        const object = quad.object.value
        
        console.log(`      ${tripleCount + 1}. <${subject}> ${predicate} "${object}"`)
        tripleCount++
    }
    
    // Count triples by type
    const predicateCount = new Map()
    const subjectTypes = new Map()
    
    for (const quad of dataset) {
        const fullPredicate = quad.predicate.value
        const predicate = fullPredicate.split('/').pop() || fullPredicate.split('#').pop()
        predicateCount.set(predicate, (predicateCount.get(predicate) || 0) + 1)
        
        if (predicate === 'type' || fullPredicate.includes('#type')) {
            const objectType = quad.object.value.split('/').pop() || quad.object.value.split('#').pop()
            subjectTypes.set(objectType, (subjectTypes.get(objectType) || 0) + 1)
        }
    }
    
    console.log('\n   üìä RDF Export Statistics:')
    console.log(`      ‚Ä¢ Total triples: ${dataset.size}`)
    console.log(`      ‚Ä¢ Community entities: ${subjectTypes.get('Community') || 0}`)
    console.log(`      ‚Ä¢ Analysis entities: ${subjectTypes.get('CommunityAnalysis') || 0}`)
    console.log('      ‚Ä¢ Predicate distribution:')
    
    for (const [predicate, count] of predicateCount) {
        console.log(`        - ${predicate}: ${count} triples`)
    }
    
    return dataset
}

/**
 * Display final statistics and insights
 */
function displayFinalSummary(detectorInstance, allResults) {
    console.log('\nüìà Step 7: Final Statistics and Community Insights')
    
    const stats = detectorInstance.getStatistics()
    
    console.log('\n   üìä Algorithm Statistics (from best run):')
    console.log(`      ‚Ä¢ Last clustering: ${stats.lastClustering}`)
    console.log(`      ‚Ä¢ Communities detected: ${stats.communityCount}`)
    console.log(`      ‚Ä¢ Final modularity: ${stats.modularity.toFixed(4)}`)
    console.log(`      ‚Ä¢ Iterations used: ${stats.iterations}`)
    
    // Aggregate statistics across all demo runs
    console.log('\n   üìä Demo Session Aggregate Statistics:')
    let totalRuns = 0
    let totalCommunities = 0
    let avgModularity = 0
    
    if (allResults.basic) {
        totalRuns++
        totalCommunities += allResults.basic.communities.length
        avgModularity += allResults.basic.modularity
    }
    
    if (allResults.resolutionTests) {
        totalRuns += 4 // Four different resolutions tested
        totalCommunities += allResults.resolutionTests.communities.length * 4
        avgModularity += allResults.resolutionTests.modularity * 4
    }
    
    if (allResults.iterativeRuns) {
        totalRuns += 5 // Five different seeds tested
        totalCommunities += allResults.iterativeRuns.communities.length * 5
        avgModularity += allResults.iterativeRuns.modularity * 5
    }
    
    console.log(`      ‚Ä¢ Total algorithm runs: ${totalRuns}`)
    console.log(`      ‚Ä¢ Total communities detected: ${totalCommunities}`)
    console.log(`      ‚Ä¢ Average communities per run: ${(totalCommunities / totalRuns).toFixed(1)}`)
    console.log(`      ‚Ä¢ Average modularity: ${(avgModularity / totalRuns).toFixed(4)}`)
    
    console.log('\n   üéØ Key Community Detection Insights:')
    console.log('      ‚Ä¢ Leiden algorithm successfully identified domain-based communities')
    console.log('      ‚Ä¢ Academic collaborations form tight, well-connected clusters')
    console.log('      ‚Ä¢ Industry relationships create competitive communities')
    console.log('      ‚Ä¢ Cross-domain bridges (funding, projects) connect different areas')
    console.log('      ‚Ä¢ Resolution parameter significantly affects community granularity')
    console.log('      ‚Ä¢ Algorithm shows good stability across different random seeds')
    
    console.log('\n   üí° Real-World Applications Demonstrated:')
    console.log('      ‚Ä¢ Research collaboration network analysis')
    console.log('      ‚Ä¢ Industry ecosystem mapping')
    console.log('      ‚Ä¢ Academic-industry partnership discovery')
    console.log('      ‚Ä¢ Funding flow analysis and optimization')
    console.log('      ‚Ä¢ Knowledge domain boundary identification')
    console.log('      ‚Ä¢ Multi-stakeholder community detection')
}

/**
 * Main demo execution
 */
async function runDemo() {
    try {
        console.log('üöÄ Starting Community Detection comprehensive demo...\n')
        
        // Step 1: Create multi-domain knowledge graph
        const graph = createMultiDomainKnowledgeGraph()
        
        // Step 2: Basic community detection
        const basicResults = await demonstrateBasicCommunityDetection(graph)
        
        // Step 3: Resolution parameter comparison
        const optimalResults = await demonstrateResolutionComparison(graph)
        
        // Step 4: Community quality analysis
        const qualityMetrics = await demonstrateCommunityQuality(graph, optimalResults)
        
        // Step 5: Iterative refinement demonstration
        const refinedResults = await demonstrateIterativeRefinement(graph)
        
        // Step 6: RDF export demonstration
        const rdfDataset = await demonstrateRDFExport(refinedResults)
        
        // Step 7: Final summary with statistics
        const allResults = {
            basic: basicResults,
            resolutionTests: optimalResults,
            iterativeRuns: refinedResults,
            quality: qualityMetrics
        }
        
        // Use the detector instance from the last successful run
        const detector = new CommunityDetection()
        detector.stats = {
            lastClustering: refinedResults.timestamp,
            communityCount: refinedResults.communities.length,
            modularity: refinedResults.modularity,
            iterations: refinedResults.iterations
        }
        
        displayFinalSummary(detector, allResults)
        
        console.log('\n' + '='.repeat(60))
        console.log('‚úÖ Community Detection Demo completed successfully!')
        console.log('üéâ The Leiden algorithm successfully identified meaningful communities')
        console.log(`üìä Generated ${rdfDataset.size} RDF triples for semantic integration`)
        console.log('üåê Discovered cross-domain relationships and community structures')
        console.log('='.repeat(60))
        
    } catch (error) {
        console.error('\n‚ùå Demo failed:', error)
        console.error('Stack trace:', error.stack)
        process.exit(1)
    }
}

// Run the demo
if (import.meta.url === `file://${process.argv[1]}`) {
    runDemo()
}

export { runDemo }